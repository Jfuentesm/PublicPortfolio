--- Goal Description ---

**2. Feature: Admin View/Manage All Jobs**

*   **Explanation:** Allow superusers to view the job history of *all* users, not just their own. Potentially add actions like cancelling a pending/processing job.
*   **Value:** Essential for platform monitoring, troubleshooting user issues (e.g., why a job failed or is stuck), and understanding overall system load. Cancellation helps manage stuck or unwanted jobs.
*   **Implementation Sketch:**
    *   **Backend (`api/jobs.py` - List Jobs Endpoint):**
        *   Modify the `/` (list jobs) endpoint.
        *   Inside the endpoint, check if `current_user.is_superuser`.
        *   If superuser, *remove* the `filter(Job.created_by == current_user.username)` condition to query all jobs.
        *   If not superuser, keep the filter.
    *   **Backend (Optional - New Endpoint for Cancellation):**
        *   `POST /api/v1/admin/jobs/{job_id}/cancel`: Requires superuser auth.
        *   **Logic:** Find the job. Check if status is PENDING or PROCESSING. If so, update status to FAILED (or a new CANCELLED status), set an error message ("Cancelled by admin"), potentially try to kill the Celery task (more complex, requires task ID and signalling).
    *   **Frontend (`JobHistory.vue`):**
        *   The existing component should automatically display all jobs if the backend API returns them for a superuser.
        *   Add a "User" column to the history table, visible only to admins.
        *   Add a "Cancel" button for pending/processing jobs, visible only to admins.

--- Instructions for LLM ---

Based on the goal described above and the provided project context (file tree and source code below), identify the key files that likely need to be created, modified, or consulted to achieve the goal.

Please provide the list of relevant file paths as a single line, comma-separated string. Include only relative paths from the project root.

Example Output:
src/core/feature.py, src/utils/helpers.py, tests/test_feature.py, README.md

--- End Instructions ---

<Project File Tree (excluding .log files)>
- Dockerfile.web
- Dockerfile.worker
- aggregator_gui11.py
- aggregator_gui13.py
- app/api/__init__.py
- app/api/admin.py
- app/api/auth.py
- app/api/health_utils.py
- app/api/jobs.py
- app/api/main.py
- app/api/password_reset.py
- app/api/users.py
- app/core/config.py
- app/core/database.py
- app/core/initialize_db.py
- app/core/log_context.py
- app/core/log_formatters.py
- app/core/log_handlers.py
- app/core/logging_config.py
- app/middleware/__init__.py
- app/middleware/db_logging_middleware.py
- app/middleware/logging_middleware.py
- app/models/classification.py
- app/models/job.py
- app/models/taxonomy.py
- app/models/user.py
- app/schemas/admin.py
- app/schemas/job.py
- app/schemas/password_reset.py
- app/schemas/review.py
- app/schemas/user.py
- app/services/email_service.py
- app/services/file_service.py
- app/services/llm_service.py
- app/services/search_service.py
- app/services/user_service.py
- app/tasks/celery_app.py
- app/tasks/classification_logic.py
- app/tasks/classification_prompts.py
- app/tasks/classification_tasks.py
- app/tasks/reclassification_logic.py
- app/tasks/reclassification_prompts.py
- app/utils/log_utils.py
- app/utils/taxonomy_loader.py
- app/utils/text_processing.py
- core/config.py
- docker-compose.yml
- docs/1_response_solution design.md
- docs/moving_to_AWS_diagram.md
- frontend/vue_frontend/README.md
- frontend/vue_frontend/env.d.ts
- frontend/vue_frontend/index.html
- frontend/vue_frontend/postcss.config.js
- frontend/vue_frontend/src/App.vue
- frontend/vue_frontend/src/assets/base.css
- frontend/vue_frontend/src/assets/main.css
- frontend/vue_frontend/src/assets/styles.css
- frontend/vue_frontend/src/components/AdminDashboard.vue
- frontend/vue_frontend/src/components/AppContent.vue
- frontend/vue_frontend/src/components/Footer.vue
- frontend/vue_frontend/src/components/ForgotPassword.vue
- frontend/vue_frontend/src/components/HintInputModal.vue
- frontend/vue_frontend/src/components/JobHistory.vue
- frontend/vue_frontend/src/components/JobResultsTable.vue
- frontend/vue_frontend/src/components/JobStats.vue
- frontend/vue_frontend/src/components/JobStatus.vue
- frontend/vue_frontend/src/components/LandingPage.vue
- frontend/vue_frontend/src/components/Login.vue
- frontend/vue_frontend/src/components/Navbar.vue
- frontend/vue_frontend/src/components/Register.vue
- frontend/vue_frontend/src/components/ResetPassword.vue
- frontend/vue_frontend/src/components/ReviewResultsTable.vue
- frontend/vue_frontend/src/components/StatCard.vue
- frontend/vue_frontend/src/components/UploadForm.vue
- frontend/vue_frontend/src/components/UserFormModal.vue
- frontend/vue_frontend/src/components/UserManagement.vue
- frontend/vue_frontend/src/components/icons/IconCommunity.vue
- frontend/vue_frontend/src/components/icons/IconDocumentation.vue
- frontend/vue_frontend/src/components/icons/IconEcosystem.vue
- frontend/vue_frontend/src/components/icons/IconSupport.vue
- frontend/vue_frontend/src/components/icons/IconTooling.vue
- frontend/vue_frontend/src/main.ts
- frontend/vue_frontend/src/services/api.ts
- frontend/vue_frontend/src/stores/admin.ts
- frontend/vue_frontend/src/stores/auth.ts
- frontend/vue_frontend/src/stores/counter.ts
- frontend/vue_frontend/src/stores/job.ts
- frontend/vue_frontend/src/stores/view.ts
- frontend/vue_frontend/tailwind.config.js
- frontend/vue_frontend/vite.config.ts
- frontend/vue_frontend/yarn.lock
- requirements.txt
- run_local_V2.sh
</Project File Tree>


<Project Source Code (excluding .log files)>

<file path='Dockerfile.web'>
# --- Stage 1: Build Frontend ---
# Using standard Debian-based image
FROM node:18 AS builder

WORKDIR /frontend

# Log contents of the context's frontend directories before attempting COPY
RUN echo ">>> [Builder Stage 1] Listing context contents:"
RUN echo ">>> [Builder Stage 1] Context Root:" && ls -la ../ || echo "Cannot list context root"
RUN echo ">>> [Builder Stage 1] Context 'frontend/':" && ls -la ../frontend/ || echo ">>> [Builder Stage 1] INFO: ../frontend/ not found or empty"
RUN echo ">>> [Builder Stage 1] Context 'frontend/vue_frontend/':" && ls -la ../frontend/vue_frontend/ || echo ">>> [Builder Stage 1] INFO: ../frontend/vue_frontend/ not found or empty"

# Copy package manifests first
COPY frontend/vue_frontend/package.json frontend/vue_frontend/package-lock.json* ./

# Clean cache and update npm
RUN echo ">>> [Builder Stage 1] Cleaning npm cache..." && \
    npm cache clean --force || echo ">>> [Builder Stage 1] WARNING: npm cache clean failed, continuing..."
# RUN echo ">>> [Builder Stage 1] Updating npm..." && \
#     npm install -g npm@latest || echo ">>> [Builder Stage 1] WARNING: Failed to update npm, continuing with default version..."
# RUN echo ">>> [Builder Stage 1] Current npm version:" && npm --version

# Install dependencies using the manifests copied earlier
# Keep --no-optional here, but we'll add the specific one later
RUN echo ">>> [Builder Stage 1] Running npm install --no-optional..." && \
    npm install --no-optional || { echo ">>> [Builder Stage 1] ERROR: npm install failed!"; exit 1; }
RUN echo ">>> [Builder Stage 1] npm install completed."

# Copy the rest of the frontend source code
COPY frontend/vue_frontend/ ./

# --- MODIFIED: Explicitly install the required optional Rollup binary ---
# Determine the target architecture (this assumes linux/arm64 based on the error)
# If building on a different host, Docker buildx might need platform flags
RUN echo ">>> [Builder Stage 1] Explicitly installing @rollup/rollup-linux-arm64-gnu..." && \
    npm install --no-save @rollup/rollup-linux-arm64-gnu || \
    { echo ">>> [Builder Stage 1] WARNING: Failed to explicitly install optional dependency, build might still fail."; }
# --- END MODIFIED ---


# --- ADDED LOGGING ---
# Verify the structure inside the container *before* running the build
RUN echo ">>> [Builder Stage 1] Listing WORKDIR (/frontend) contents BEFORE build:" && ls -la node_modules/@rollup || echo "Cannot list node_modules/@rollup"
RUN echo ">>> [Builder Stage 1] Checking for src/main.ts:" && ls -l src/main.ts || echo ">>> [Builder Stage 1] WARNING: src/main.ts not found!"
RUN echo ">>> [Builder Stage 1] Checking for vite.config.ts:" && ls -l vite.config.ts || echo ">>> [Builder Stage 1] WARNING: vite.config.ts not found!"
# --- END ADDED LOGGING ---

# Build the Vue application
# Ensure 'build' script is defined in your frontend/vue_frontend/package.json
RUN echo ">>> [Builder Stage 1] Running npm run build..." && \
    npm run build || { echo ">>> [Builder Stage 1] ERROR: npm run build failed!"; exit 1; }
RUN echo ">>> [Builder Stage 1] npm run build completed."

# --- ADDED LOGGING ---
# Verify the output of the build - THIS IS CRITICAL
RUN echo ">>> [Builder Stage 1] Listing contents of /frontend/dist AFTER build:" && \
    ls -lA dist/ || { echo ">>> [Builder Stage 1] ERROR: /frontend/dist directory NOT FOUND or empty after build!"; exit 1; }
RUN echo ">>> [Builder Stage 1] Checking for index.html in dist:" && \
    ls -l dist/index.html || { echo ">>> [Builder Stage 1] ERROR: dist/index.html NOT FOUND after build!"; exit 1; }
# --- END ADDED LOGGING ---


# --- Stage 2: Final Python Application ---
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies (same as before)
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    net-tools \
    curl \
    procps \
    && rm -rf /var/lib/apt/lists/*

# Create directories for data
RUN mkdir -p /data/input /data/output /data/taxonomy /data/logs

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir numpy==1.24.4
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code (backend only)
COPY ./app /app

# --- ADDED DIAGNOSTIC STEP ---
# Print the contents of the config file right after copying it
RUN echo ">>> [Final Stage 2] Contents of /app/core/config.py:" && \
    cat /app/core/config.py || \
    echo ">>> [Final Stage 2] ERROR: Could not cat /app/core/config.py"
# --- END ADDED DIAGNOSTIC STEP ---


# --- ADDED DIAGNOSTIC ---
# Verify that __init__.py and users.py are present in /app/api/
RUN echo ">>> [Final Stage 2] Verifying contents of /app/api/:" && \
    ls -lA /app/api/ || echo ">>> [Final Stage 2] WARNING: Cannot list /app/api/"
# --- END ADDED DIAGNOSTIC ---

# Copy Built Frontend from Builder Stage
RUN echo ">>> [Final Stage 2] Copying built frontend from builder stage (/frontend/dist) to /app/frontend/dist..."
COPY --from=builder /frontend/dist /app/frontend/dist
# --- ADDED LOGGING ---
# Verify the copy - THIS IS CRITICAL
RUN echo ">>> [Final Stage 2] Listing contents of /app/frontend/dist AFTER COPY:" && \
    ls -lA /app/frontend/dist || { echo ">>> [Final Stage 2] ERROR: /app/frontend/dist directory NOT FOUND or empty after copy!"; exit 1; }
RUN echo ">>> [Final Stage 2] Checking for index.html in /app/frontend/dist:" && \
    ls -l /app/frontend/dist/index.html || { echo ">>> [Final Stage 2] ERROR: /app/frontend/dist/index.html NOT FOUND after copy!"; exit 1; }
# --- END ADDED LOGGING ---

# Set environment variables
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# Expose port
EXPOSE 8000

# Diagnostic output (remains useful)
RUN echo ">>> [Final Stage 2] Python version:" && python --version
RUN echo ">>> [Final Stage 2] Checking Python app directory contents (/app):" && ls -la /app || echo "App directory not found"

# Add a healthcheck
HEALTHCHECK --interval=30s --timeout=5s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run the application
CMD ["sh", "-c", "echo '>>> [CMD Start] Starting web server...' && \
                    echo '>>> [CMD Start] Final check of /app/frontend/dist:' && \
                    ls -lA /app/frontend/dist && \
                    echo '>>> [CMD Start] Running Uvicorn...' && \
                    uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload --log-level debug"]
    
</file>

<file path='Dockerfile.worker'>

# --- file path='Dockerfile.worker' ---

# Dockerfile.worker

FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    net-tools \
    procps \
    && rm -rf /var/lib/apt/lists/*

# Create directories for data
RUN mkdir -p /data/input /data/output /data/taxonomy

# Install Python dependencies in a specific order to avoid binary conflicts
COPY requirements.txt .

# Install NumPy first to ensure pandas works with it correctly
RUN pip install --no-cache-dir numpy==1.24.4
RUN pip install --no-cache-dir -r requirements.txt

# --- ADDED LOGGING ---
# Verify the installed version of pydantic-settings after installation
RUN echo "Checking pydantic-settings installation details:" && pip show pydantic-settings || echo "pydantic-settings not found after install attempt"
RUN echo "Checking Celery installation details:" && pip show celery || echo "Celery not found after install attempt"
# --- END ADDED LOGGING ---

# Copy application code
COPY ./app /app

# Set environment variables
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# Diagnostic output for troubleshooting
RUN echo "Python version:" && python --version
RUN echo "NumPy version:" && python -c "import numpy; print(f'NumPy: {numpy.__version__}')"
RUN echo "Pandas version:" && python -c "import pandas; print(f'Pandas: {pandas.__version__}')" || echo "Pandas not installed"
RUN echo "Checking pandas installation details:" && pip show pandas | grep Version || echo "Pandas package details not available"
RUN echo "Directory structure:" && find /app -type f -name "*.py" | sort

# --- UPDATED CMD ---
# Run Celery worker with corrected app path relative to WORKDIR/PYTHONPATH
# Use -A app.tasks.celery_app:celery_app if app module structure requires it
# Based on current imports, tasks.celery_app seems correct as PYTHONPATH=/app
CMD ["sh", "-c", "echo 'Worker starting...' && \
                  echo 'Current directory:' $(pwd) && \
                  echo 'PYTHONPATH:' $PYTHONPATH && \
                  echo 'Contents of /app/tasks:' && ls -la /app/tasks && \
                  echo 'Running command: celery -A tasks.celery_app worker --loglevel=debug' && \
                  celery -A tasks.celery_app worker --loglevel=debug"]

# --- END UPDATED CMD ---

</file>

<file path='aggregator_gui11.py'>
# --- COMPLETE UPDATED SCRIPT ---

import sys
import os
from pathlib import Path
from datetime import datetime
import re # For parsing comma-separated list robustly AND file blocks
import shutil # For file copying
import tempfile # For temporary directory
import traceback # For detailed error printing

# --- Try importing PySide6 ---
try:
    from PySide6 import QtCore, QtGui, QtWidgets
    from PySide6.QtCore import Qt, Slot
    from PySide6.QtWidgets import (
        QApplication, QWidget, QVBoxLayout, QHBoxLayout,
        QPushButton, QTreeView, QLabel, QRadioButton, QGroupBox,
        QMessageBox, QFrame, QTextEdit, QLineEdit, QCheckBox,
        QScrollArea # <-- Import QScrollArea
    )
    from PySide6.QtGui import QStandardItemModel, QStandardItem, QIcon, QFont
except ImportError:
    print("Error: PySide6 is not installed.")
    print("Please install it using: pip install PySide6")
    sys.exit(1)

# --- Constants for Output Directories ---
OUTPUT_BASE_DIR_NAME = "dev_prompts"
PLANNING_SUBDIR_NAME = "1a_planning_prompts"
ACTION_SUBDIR_NAME = "1b_dev_prompts"

# --- Constants for File Parsing ---
# Regex to find <file path='...'>...</file> blocks.
# Handles potential code fences (```) within the content block because:
# - `.*?` is non-greedy, matching up to the *first* `</file>`.
# - `re.DOTALL` makes `.` match newline characters.
# - `re.IGNORECASE` allows `<file>` or `<FILE>`.
FILE_BLOCK_REGEX = re.compile(
    r"<file\s+path=['\"](.*?)['\"]\s*>(.*?)</file>",
    re.DOTALL | re.IGNORECASE
)


# --- Reusable Core Logic ---

def read_file_content(file_path):
    """Read and return the content of a file, handling potential encoding issues."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        try:
            with open(file_path, 'r', encoding='latin-1') as f:
                print(f"Warning: Read {file_path} with latin-1 encoding.")
                return f.read()
        except Exception as e:
            print(f"Error reading {file_path} (tried utf-8, latin-1): {str(e)}")
            return f"--- ERROR READING FILE (tried utf-8, latin-1) ---\nPath: {file_path}\nError: {str(e)}\n--- END ERROR ---"
    except FileNotFoundError:
        # This is now expected when reading a backup of a newly created file during undo test
        # print(f"Info: File not found during read (might be expected): {file_path}")
        return None # Return None to indicate it didn't exist or couldn't be read
    except Exception as e:
        print(f"Error reading {file_path}: {str(e)}")
        return f"--- ERROR READING FILE ---\nPath: {file_path}\nError: {str(e)}\n--- END ERROR ---"

def get_potential_files_recursively(current_directory, original_root_dir, script_name, include_logs=False):
    """
    Recursively get potential files relative to the original_root_dir,
    excluding specified types and patterns. Returns relative paths.
    """
    potential_files = []
    current_directory_path = Path(current_directory).resolve()
    original_root_dir_resolved = original_root_dir.resolve()

    # --- Root-level checks ---
    if current_directory_path == original_root_dir_resolved:
        compose_file = original_root_dir_resolved / 'compose.yaml'
        dockerfile = original_root_dir_resolved / 'Dockerfile'
        if compose_file.exists() and compose_file.is_file():
            potential_files.append(compose_file.relative_to(original_root_dir_resolved))
        if dockerfile.exists() and dockerfile.is_file():
            potential_files.append(dockerfile.relative_to(original_root_dir_resolved))

        docs_dir = original_root_dir_resolved / 'docs'
        if docs_dir.exists() and docs_dir.is_dir():
            for item in docs_dir.glob('*.md'):
                if item.is_file() and item.parent == docs_dir:
                    potential_files.append(item.resolve().relative_to(original_root_dir_resolved))

    # --- Recursive scan ---
    try:
        for item_entry in os.scandir(current_directory_path):
            item = Path(item_entry.path)
            # Handle potential symlinks carefully - resolve first
            try:
                item_abs_path = item.resolve()
            except OSError as e:
                print(f"Warning: Could not resolve path {item}, possibly broken symlink: {e}. Skipping.")
                continue

            try:
                # Ensure the item is actually within the project root before proceeding
                if not item_abs_path.is_relative_to(original_root_dir_resolved):
                     continue
                relative_path = item_abs_path.relative_to(original_root_dir_resolved)
                relative_path_str = relative_path.as_posix()
            except ValueError:
                print(f"Warning: Could not get relative path for {item_abs_path} against {original_root_dir_resolved}. Skipping.")
                continue
            except Exception as e:
                print(f"Warning: Error during relative path calculation for {item}: {e}. Skipping.")
                continue

            # --- Exclusions ---
            if item.name == script_name: continue
            if item.name.startswith('.') and item.name != '.scripts': continue
            if item.name in ['.venv', 'venv', 'env', '__pycache__', 'node_modules', 'dist', 'build', OUTPUT_BASE_DIR_NAME, '.git'] or \
               item.name.startswith('concatignore') or \
               item.name.startswith('archive') or \
               item.name.startswith('planning_and_focus_window') or \
               item.name.startswith('planning_request_') or \
               item.name.startswith('concat_'):
                continue
            if item.is_dir() and item.name == 'docs' and 'scripts' not in relative_path_str.split('/'): continue

            # --- File processing ---
            if item.is_file():
                excluded_suffixes = [
                    '.xlsx', '.xls', '.csv', '.data', '.db', '.sqlite', '.sqlite3',
                    '.pkl', '.joblib', '.h5', '.hdf5',
                    '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.svg', '.ico',
                    '.pdf', '.doc', '.docx', '.ppt', '.pptx',
                    '.zip', '.gz', '.tar', '.rar',
                    '.exe', '.dll', '.so', '.o', '.a', '.lib',
                    '.pyc', '.pyd', '.pyo',
                    '.swp', '.swo', '.json'
                ]
                # Use Path.suffix for reliable extension checking
                file_suffix = item.suffix.lower()
                if file_suffix == '.log' and not include_logs:
                    continue
                if file_suffix in excluded_suffixes:
                    continue
                if relative_path not in potential_files:
                    potential_files.append(relative_path)

            # --- Directory processing ---
            elif item.is_dir():
                potential_files.extend(get_potential_files_recursively(item_abs_path, original_root_dir_resolved, script_name, include_logs))

    except FileNotFoundError: print(f"Warning: Directory not found during scan: {current_directory_path}. Skipping.")
    except PermissionError: print(f"Warning: Permission denied for directory: {current_directory_path}. Skipping.")
    except Exception as e: print(f"Error scanning directory {current_directory_path}: {e}")

    return sorted(list(dict.fromkeys(potential_files)), key=lambda p: p.as_posix())


# --- Mode Definitions (Unchanged) ---
MODES = {
    "debug": {
        "name": "Debug Mode",
        "issue_placeholder": "<Describe the bug or unexpected behavior observed>\n\n\n",
        "output_instruction": (
            "1) Reflect on 5-7 different possible sources of the problem based on the code provided and the goal/issue description.\n"
            "2) Distill those down to the most likely root cause.\n"
            "3) Provide the COMPLETE UPDATED VERSION of *only* the files that need changes to fix the likely root cause.\n"
            "   Use the format: <file path='relative/path/to/file.ext'>\n```[language]\n[COMPLETE FILE CONTENT]\n```\n</file>\n" # Added ``` hint
            "   Ensure the file path is relative to the project root and the content is enclosed in markdown code fences."
        )
    },
    "add_feature": {
        "name": "Add New Feature",
        "issue_placeholder": "<Describe the new feature or enhancement required>\n\n\n",
        "output_instruction": (
            "1) Explain if this is already complete, or what is missing\n"
            "2) Provide the COMPLETE code for any NEW files needed.\n"
            "3) Provide the COMPLETE UPDATED VERSION of any EXISTING files that need changes.\n"
            "   Use the format: <file path='relative/path/to/file.ext'>\n```[language]\n[COMPLETE FILE CONTENT]\n```\n</file>\n for both new and updated files." # Added ``` hint
            "   Ensure the file path is relative to the project root and the content is enclosed in markdown code fences."
        )
    },
    "explain": {
        "name": "Explain / Brainstorm",
        "issue_placeholder": "<Ask a question about the code, request an explanation, or describe a concept to brainstorm>\n\n\n",
        "output_instruction": (
            "Provide a clear explanation, answer the question, or offer brainstorming ideas/approaches.\n"
            "If suggesting code changes or approaches, illustrate with concise examples where appropriate (no need for full file rewrites unless specifically asked).\n"
        )
    }
}

# --- Custom Role for Storing Path Data in Model ---
PathRole = Qt.UserRole + 1

# --- PySide6 GUI Application Class ---

class ScriptAggregatorApp(QWidget):
    def __init__(self, script_dir, script_name):
        super().__init__()
        self.script_dir = Path(script_dir).resolve()
        self.script_name = script_name
        self.folder_icon = self.style().standardIcon(QtWidgets.QStyle.StandardPixmap.SP_DirIcon)
        self.file_icon = self.style().standardIcon(QtWidgets.QStyle.StandardPixmap.SP_FileIcon)
        self.log_icon = self.style().standardIcon(QtWidgets.QStyle.StandardPixmap.SP_FileIcon) # Using file icon for logs too
        self.model = QStandardItemModel()
        self.tree_view = QTreeView()
        self.status_label = QLabel("Ready. Scanning for files...")
        self.mode_buttons = {}
        self.goal_input = QTextEdit()
        self.suggestion_input = QLineEdit()
        self.include_logs_checkbox = QCheckBox("Include selected .log files in Step 1b output")
        self.llm_response_input = QTextEdit()
        self.item_path_map = {}

        # --- Undo State ---
        self.last_applied_changes = [] # List to store info about the last applied changes
        self.temp_backup_dir = None # Path to the temporary backup directory for the last apply

        # --- Define output directories relative to script_dir ---
        self.output_base_dir = self.script_dir / OUTPUT_BASE_DIR_NAME
        self.planning_output_dir = self.output_base_dir / PLANNING_SUBDIR_NAME
        self.action_output_dir = self.output_base_dir / ACTION_SUBDIR_NAME

        self.initUI()
        self.populate_file_tree()
        file_count = self.count_files_in_model()
        self.status_label.setText(f"Ready. Found {file_count} potential files (including .log).")


    def initUI(self):
        self.setWindowTitle("Script Aggregator & Applier (with Undo)")
        self.setGeometry(150, 150, 1050, 800) # Adjusted initial height slightly

        # --- Main Horizontal Layout (will go inside scroll area) ---
        main_h_layout = QHBoxLayout()
        left_v_layout = QVBoxLayout()
        right_v_layout = QVBoxLayout()
        right_v_layout.setAlignment(Qt.AlignmentFlag.AlignTop) # Keep controls aligned top

        # --- Left Side: File Tree ---
        tree_header_label = QLabel("Files in Project (Checkboxes for Step 1b):")
        font = tree_header_label.font(); font.setBold(True); tree_header_label.setFont(font)
        self.tree_view.setModel(self.model)
        self.tree_view.setHeaderHidden(True)
        self.tree_view.setSelectionMode(QtWidgets.QAbstractItemView.SelectionMode.NoSelection)
        # Set minimum height for tree view to prevent it collapsing too much
        self.tree_view.setMinimumHeight(400)
        left_v_layout.addWidget(tree_header_label)
        left_v_layout.addWidget(self.tree_view)
        left_v_layout.addStretch(1) # Add stretch to push tree up if space allows

        # --- Right Side: Controls ---
        # Step 0
        step0_groupbox = QGroupBox("Step 0: Generate Planning Request (excludes .log files)")
        step0_layout = QVBoxLayout()
        step0_layout.addWidget(QLabel("Describe your overall goal or task:"))
        self.goal_input.setPlaceholderText("e.g., Refactor the database connection logic...")
        self.goal_input.setMinimumHeight(60)
        self.goal_input.setMaximumHeight(150) # Limit max height
        step0_layout.addWidget(self.goal_input)
        generate_planning_button = QPushButton("Generate Planning Request File")
        generate_planning_button.clicked.connect(self.generate_planning_request)
        step0_layout.addWidget(generate_planning_button)
        step0_groupbox.setLayout(step0_layout)
        right_v_layout.addWidget(step0_groupbox)

        # Step 1a
        step1a_groupbox = QGroupBox("Step 1a: Apply LLM File Suggestions")
        step1a_layout = QVBoxLayout()
        step1a_layout.addWidget(QLabel("Paste comma-separated file list from LLM:"))
        self.suggestion_input.setPlaceholderText("e.g., src/db.py, src/auth/jwt.py,...")
        step1a_layout.addWidget(self.suggestion_input)
        apply_suggestion_button = QPushButton("Apply Suggested Files to Selection Below")
        apply_suggestion_button.clicked.connect(self.apply_suggested_files)
        step1a_layout.addWidget(apply_suggestion_button)
        step1a_groupbox.setLayout(step1a_layout)
        right_v_layout.addWidget(step1a_groupbox)

        # Manual Selection
        select_groupbox = QGroupBox("Manual File Selection (for Step 1b)")
        select_layout = QVBoxLayout()
        select_buttons_layout = QHBoxLayout()
        select_all_button = QPushButton("Select All Visible Files")
        select_none_button = QPushButton("Deselect All Visible Files")
        select_all_button.clicked.connect(self.select_all)
        select_none_button.clicked.connect(self.select_none)
        select_buttons_layout.addWidget(select_all_button)
        select_buttons_layout.addWidget(select_none_button)
        select_layout.addLayout(select_buttons_layout)
        select_groupbox.setLayout(select_layout)
        right_v_layout.addWidget(select_groupbox)

        # Step 1b Mode
        mode_groupbox = QGroupBox("Step 1b: Select Action Mode & Generate Action Prompt")
        mode_layout = QVBoxLayout()
        first_mode_key = list(MODES.keys())[0]
        for key, mode_info in MODES.items():
            rb = QRadioButton(mode_info["name"])
            self.mode_buttons[key] = rb
            if key == first_mode_key: rb.setChecked(True)
            mode_layout.addWidget(rb)
        mode_layout.addWidget(self.include_logs_checkbox)
        self.include_logs_checkbox.setChecked(False)
        self.generate_button = QPushButton("Execute Step 1b: Generate Concatenated File for LLM Action")
        self.generate_button.clicked.connect(self.generate_final_output_file)
        mode_layout.addWidget(self.generate_button)
        mode_groupbox.setLayout(mode_layout)
        right_v_layout.addWidget(mode_groupbox)

        # Step 2 Apply Changes
        step2_groupbox = QGroupBox("Step 2: Apply LLM Changes")
        step2_layout = QVBoxLayout()
        step2_layout.addWidget(QLabel("Paste the LLM response containing <file> blocks below:"))
        self.llm_response_input.setPlaceholderText("<file path='relative/path/to/file.ext'>\n```[language]\n[COMPLETE FILE CONTENT]\n```\n</file>\n...") # Added ``` hint
        self.llm_response_input.setMinimumHeight(150)
        self.llm_response_input.setMaximumHeight(300) # Limit max height
        self.llm_response_input.setAcceptRichText(False)
        step2_layout.addWidget(self.llm_response_input)
        apply_undo_layout = QHBoxLayout()
        self.apply_changes_button = QPushButton("Parse and Apply Changes to Project Files")
        self.apply_changes_button.clicked.connect(self.apply_llm_changes)
        self.undo_button = QPushButton("Undo Last Apply")
        self.undo_button.clicked.connect(self.undo_last_apply)
        self.undo_button.setEnabled(False)
        apply_undo_layout.addWidget(self.apply_changes_button, 2)
        apply_undo_layout.addWidget(self.undo_button, 1)
        step2_layout.addLayout(apply_undo_layout)
        step2_groupbox.setLayout(step2_layout)
        right_v_layout.addWidget(step2_groupbox)

        # Add stretch to the bottom of the right layout if needed,
        # but AlignTop should handle most cases.
        # right_v_layout.addStretch(1)

        # Assemble Main Horizontal Layout
        left_widget = QWidget(); left_widget.setLayout(left_v_layout)
        right_widget = QWidget(); right_widget.setLayout(right_v_layout)
        main_h_layout.addWidget(left_widget, 3) # Ratio 3 for left
        main_h_layout.addWidget(right_widget, 4) # Ratio 4 for right

        # --- Create a container widget for the main horizontal layout ---
        main_content_widget = QWidget()
        main_content_widget.setLayout(main_h_layout)

        # --- Create Scroll Area and add the main content widget to it ---
        scroll_area = QScrollArea()
        scroll_area.setWidgetResizable(True) # Crucial for layout to expand
        scroll_area.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded) # Also allow horizontal if needed
        scroll_area.setWidget(main_content_widget)

        # --- Bottom Area (Status Bar) ---
        bottom_v_layout = QVBoxLayout()
        self.status_label.setFrameStyle(QFrame.Shape.Panel | QFrame.Shadow.Sunken)
        self.status_label.setLineWidth(1)
        # Ensure status label doesn't stretch vertically
        bottom_v_layout.addWidget(self.status_label)
        bottom_v_layout.addStretch(0) # Prevent stretch

        # --- Overall Layout ---
        overall_layout = QVBoxLayout(self) # Set layout ON the main window (self)
        # Add the scroll area (containing the main content)
        overall_layout.addWidget(scroll_area, 1) # Give scroll area stretch factor 1
        # Add the status bar layout (fixed height)
        overall_layout.addLayout(bottom_v_layout, 0) # Give status bar stretch factor 0

    def populate_file_tree(self):
        """Populates the tree view, including .log files."""
        self.model.clear()
        self.item_path_map.clear()
        invisible_root = self.model.invisibleRootItem()
        folder_items = {'': invisible_root}

        potential_files = get_potential_files_recursively(
            self.script_dir,
            self.script_dir,
            self.script_name,
            include_logs=True
        )

        for rel_path in potential_files:
            if not isinstance(rel_path, Path): continue

            parent_item = invisible_root
            current_path_part_cumulative = Path()

            for part in rel_path.parts[:-1]:
                current_path_part_cumulative = current_path_part_cumulative / part
                current_path_part_str = current_path_part_cumulative.as_posix()
                if current_path_part_str not in folder_items:
                    folder_item = QStandardItem(part)
                    folder_item.setIcon(self.folder_icon)
                    folder_item.setEditable(False)
                    folder_item.setCheckable(False) # Folders not checkable
                    parent_item.appendRow(folder_item)
                    folder_items[current_path_part_str] = folder_item
                    parent_item = folder_item
                else:
                    parent_item = folder_items[current_path_part_str]

            file_name = rel_path.name
            file_item = QStandardItem(file_name)
            # Use Path.suffix for reliable extension checking
            if rel_path.suffix.lower() == '.log':
                file_item.setIcon(self.log_icon)
            else:
                file_item.setIcon(self.file_icon)

            file_item.setCheckable(True)
            file_item.setCheckState(Qt.CheckState.Checked) # Default to checked
            file_item.setEditable(False)
            file_item.setData(rel_path, PathRole)
            parent_item.appendRow(file_item)
            self.item_path_map[rel_path.as_posix()] = file_item

        self.tree_view.expandToDepth(0)

    def iterate_model_items(self, parent_item=None):
        """Generator to recursively yield all items in the model."""
        if parent_item is None: parent_item = self.model.invisibleRootItem()
        for row in range(parent_item.rowCount()):
            item = parent_item.child(row, 0)
            if item:
                yield item
                if item.hasChildren(): yield from self.iterate_model_items(item)

    def count_files_in_model(self):
        """Counts file items using the item_path_map."""
        return len(self.item_path_map)

    @Slot()
    def select_all(self):
        """Checks all file items (leaves) in the tree view."""
        for item in self.item_path_map.values():
            if item.isCheckable():
                item.setCheckState(Qt.CheckState.Checked)
        self.status_label.setText("All visible files selected (for Step 1b).")

    @Slot()
    def select_none(self):
        """Unchecks all file items (leaves) in the tree view."""
        for item in self.item_path_map.values():
             if item.isCheckable():
                item.setCheckState(Qt.CheckState.Unchecked)
        self.status_label.setText("All visible files deselected (for Step 1b).")

    @Slot()
    def generate_planning_request(self):
        """Generates the Step 0 request file (excluding .log files)."""
        goal = self.goal_input.toPlainText().strip()
        if not goal:
            QMessageBox.warning(self, "Input Missing", "Please describe your overall goal for Step 0.")
            return

        self.status_label.setText("Gathering project files (excluding .log) for planning request...")
        QApplication.processEvents()

        all_potential_files_no_logs = get_potential_files_recursively(
            self.script_dir, self.script_dir, self.script_name, include_logs=False
        )

        if not all_potential_files_no_logs:
             QMessageBox.warning(self, "No Files Found", "No source files (excluding .log) found for planning request.")
             self.status_label.setText("Ready.")
             return

        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = self.planning_output_dir
        output_filename = f"planning_request_{timestamp_str}.txt"
        output_file = output_dir / output_filename

        self.status_label.setText(f"Generating {output_filename} in {output_dir.relative_to(self.script_dir)}...")
        QApplication.processEvents()

        try:
            output_dir.mkdir(parents=True, exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                # --- Content for Planning Request ---
                f.write("--- Goal Description ---\n\n")
                f.write(goal + "\n\n")
                f.write("--- Instructions for LLM ---\n\n")
                f.write("Based on the goal described above and the provided project context (file tree and source code below), identify the key files that likely need to be created, modified, or consulted to achieve the goal.\n\n")
                f.write("Please provide the list of relevant file paths as a single line, comma-separated string. Include only relative paths from the project root.\n\n")
                f.write("Example Output:\n")
                f.write("src/core/feature.py, src/utils/helpers.py, tests/test_feature.py, README.md\n\n")
                f.write("--- End Instructions ---\n\n")

                f.write("<Project File Tree (excluding .log files)>\n")
                sorted_all_files = sorted(all_potential_files_no_logs, key=lambda p: p.as_posix())
                for rel_path in sorted_all_files:
                    f.write(f"- {rel_path.as_posix()}\n")
                f.write("</Project File Tree>\n\n\n")

                f.write("<Project Source Code (excluding .log files)>\n\n")
                for rel_path in sorted_all_files:
                    abs_path = self.script_dir / rel_path
                    rel_path_str = rel_path.as_posix()
                    f.write(f"<file path='{rel_path_str}'>\n")
                    content = read_file_content(abs_path)
                    if content is not None:
                        f.write(content) # Check if read was successful
                    else:
                        f.write(f"--- Error reading file: {rel_path_str} ---")
                    f.write("\n</file>\n\n")
                f.write("</Project Source Code>\n\n")

                f.write("--- Identified Files (Provide comma-separated list below) ---\n\n\n")

            relative_output_path = output_file.relative_to(self.script_dir)
            self.status_label.setText(f"Planning request file generated: {relative_output_path}")
            QMessageBox.information(self, "Step 0 Success", f"Planning request file created:\n{relative_output_path}\n\nPaste this entire file content into the LLM to get the list of files for Step 1a.")

        except Exception as e:
            self.status_label.setText(f"Error generating planning request file: {e}")
            QMessageBox.critical(self, "Step 0 Error", f"Could not generate planning request file.\nError: {e}")
            print(f"Error details during planning generation:")
            traceback.print_exc()


    @Slot()
    def apply_suggested_files(self):
        """Parses the suggestion input and updates the tree view selection."""
        suggestions_text = self.suggestion_input.text().strip()
        if not suggestions_text:
            QMessageBox.warning(self, "Input Missing", "Please paste the comma-separated file list from the LLM.")
            return

        # Robust parsing of comma-separated list, handling quotes and whitespace
        try:
            # Find non-comma/whitespace sequences or quoted sequences
            suggested_paths_raw = re.findall(r'[^,\s"]+|"[^"]*"', suggestions_text)
            # Strip whitespace and quotes from each found part
            suggested_paths_raw = [p.strip().strip('"').strip() for p in suggested_paths_raw if p.strip()]
        except Exception as e:
            QMessageBox.warning(self, "Parsing Error", f"Could not parse file list.\nError: {e}")
            return

        # Normalize paths (use forward slashes, remove leading/trailing slashes)
        suggested_paths_normalized = set()
        for p_raw in suggested_paths_raw:
            p_norm = p_raw.replace("\\", "/").strip('/')
            if p_norm: # Ensure it's not empty after normalization
                suggested_paths_normalized.add(p_norm)

        if not suggested_paths_normalized:
             QMessageBox.warning(self, "Parsing Error", "Could not parse valid file paths from the input.")
             return

        self.select_none() # Start by deselecting all
        found_count = 0
        not_found = []

        # Apply suggestions to the tree view
        for norm_path in suggested_paths_normalized:
            item = self.item_path_map.get(norm_path)
            if item and item.isCheckable():
                item.setCheckState(Qt.CheckState.Checked)
                found_count += 1
                # Expand parent nodes to make the selected item visible
                parent = item.parent()
                while parent and parent != self.model.invisibleRootItem():
                    self.tree_view.expand(self.model.indexFromItem(parent))
                    parent = parent.parent()
            else:
                not_found.append(norm_path)

        # Report results
        status_msg = f"Applied suggestions: {found_count} files selected."
        if not_found:
            status_msg += f" ({len(not_found)} not found/selectable: {', '.join(not_found[:3])}{'...' if len(not_found) > 3 else ''})"
            print(f"Warning: Suggested files not found/selectable: {', '.join(not_found)}")
            QMessageBox.warning(self, "Partial Match", f"Applied suggestions, but some files were not found or are not selectable (e.g., directories):\n\n- {chr(10).join(not_found)}\n\nCheck the selection in the tree view.")
        elif found_count > 0:
             QMessageBox.information(self, "Suggestions Applied", f"Successfully selected {found_count} file(s) based on the provided list.")
        else:
             QMessageBox.warning(self, "No Matches", "None of the suggested files were found or selectable in the project tree.")

        self.status_label.setText(status_msg)


    @Slot()
    def generate_final_output_file(self):
        """Generates the final output file for LLM action."""
        goal_text = self.goal_input.toPlainText().strip()
        if not goal_text:
            QMessageBox.warning(self, "Input Missing", "Please ensure the overall goal is described in Step 0.")
            return

        include_logs_in_output = self.include_logs_checkbox.isChecked()
        selected_relative_paths = []
        # Iterate through the map which only contains file items
        for item in self.item_path_map.values():
            if item.isCheckable() and item.checkState() == Qt.CheckState.Checked:
                rel_path = item.data(PathRole)
                if rel_path and isinstance(rel_path, Path): # Ensure it's a Path object
                    # Skip .log files if checkbox is unchecked
                    if not include_logs_in_output and rel_path.suffix.lower() == '.log':
                        continue
                    selected_relative_paths.append(rel_path)
                elif rel_path:
                    print(f"Warning: Item data is not a Path object for item '{item.text()}'") # Debugging
                # else: # No PathRole data - should not happen for items in map
                #    print(f"Warning: Item '{item.text()}' has no PathRole data.")

        if not selected_relative_paths:
            msg = "Please select at least one file in the tree view before executing Step 1b."
            if not include_logs_in_output:
                msg += "\nNote: .log files are currently excluded based on the checkbox setting. Ensure other files are selected."
            QMessageBox.warning(self, "No Files Selected", msg)
            return

        selected_mode_key = None
        for key, button in self.mode_buttons.items():
            if button.isChecked():
                selected_mode_key = key
                break
        if not selected_mode_key:
             # Should not happen if one is checked by default, but good practice
             QMessageBox.critical(self, "Error", "No action mode (Step 1b) selected.")
             return
        selected_mode = MODES[selected_mode_key]

        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = self.action_output_dir
        project_folder_name = self.script_dir.name # Get project folder name
        log_status_tag = "_inclLogs" if include_logs_in_output else "_exclLogs"
        # Construct filename: action_PROJECTNAME_MODE_LOGSTATUS_TIMESTAMP.txt
        output_filename = f"action_{project_folder_name}_{selected_mode_key}{log_status_tag}_{timestamp_str}.txt"
        output_file = output_dir / output_filename

        status_prefix = "Including" if include_logs_in_output else "Excluding"
        self.status_label.setText(f"{status_prefix} .log files. Generating action file: {output_filename}...")
        QApplication.processEvents() # Update UI

        try:
            output_dir.mkdir(parents=True, exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                # --- Content for Action Prompt ---
                f.write('<goal or issue to address>\n')
                f.write(goal_text + '\n')
                f.write('</goal or issue to address>\n\n\n')

                f.write('<output instruction>\n')
                f.write(selected_mode["output_instruction"] + '\n')
                f.write('</output instruction>\n\n\n')

                f.write("<Tree of Included Files>\n")
                sorted_rel_paths = sorted(selected_relative_paths, key=lambda p: p.as_posix())
                for rel_path in sorted_rel_paths:
                    f.write(f"- {rel_path.as_posix()}\n")

                # Check if any log files EXIST in the project (using the map values)
                # and if they were excluded by the checkbox setting.
                log_files_exist_in_project = any(
                    item.data(PathRole).suffix.lower() == '.log'
                    for item in self.item_path_map.values()
                    if item.data(PathRole) and isinstance(item.data(PathRole), Path) # Check data exists and is Path
                )

                if not include_logs_in_output and log_files_exist_in_project:
                     # Add note only if logs exist in the project but were excluded by the checkbox
                     f.write("\n(Note: .log files were present but excluded from this context based on selection.)\n")

                f.write("</Tree of Included Files>\n\n\n")

                f.write("<Concatenated Source Code>\n\n")
                for rel_path in sorted_rel_paths:
                    abs_path = self.script_dir / rel_path
                    rel_path_str = rel_path.as_posix()
                    f.write(f"<file path='{rel_path_str}'>\n")
                    content = read_file_content(abs_path)
                    if content is not None:
                        f.write(content)
                    else:
                         f.write(f"--- Error reading file: {rel_path_str} ---")
                    f.write("\n</file>\n\n") # Add a newline before closing tag for clarity
                f.write("</Concatenated Source Code>")

            relative_output_path = output_file.relative_to(self.script_dir)
            self.status_label.setText(f"Successfully generated action file: {relative_output_path}")
            QMessageBox.information(self, "Step 1b Success", f"Action file created:\n{relative_output_path}\n\nPaste this entire file content into the LLM, then paste the LLM's response into the Step 2 input box below.")

        except Exception as e:
            self.status_label.setText(f"Error generating action file: {e}")
            QMessageBox.critical(self, "Step 1b Error", f"Could not generate action file.\nError: {e}")
            # Print detailed error including traceback for debugging
            print(f"Error details during final generation:")
            traceback.print_exc()


    @Slot()
    def apply_llm_changes(self):
        """Parses LLM response, creates backups, applies changes, and enables Undo."""
        llm_response = self.llm_response_input.toPlainText().strip()
        if not llm_response:
            QMessageBox.warning(self, "Input Missing", "Please paste the LLM response into the 'Step 2' input box.")
            return

        # --- Clear previous undo state ---
        self._cleanup_backup_dir() # Remove any old temp dir first
        self.last_applied_changes = []
        self.undo_button.setEnabled(False)

        self.status_label.setText("Parsing LLM response...")
        QApplication.processEvents()

        try:
            # Use the pre-compiled regex to find all file blocks
            file_blocks = FILE_BLOCK_REGEX.findall(llm_response)
        except Exception as e:
            # Regex errors are unlikely but possible with complex patterns
            self.status_label.setText("Error parsing LLM response.")
            QMessageBox.critical(self, "Parsing Error", f"Could not parse response using regex.\nError: {e}")
            return

        if not file_blocks:
            self.status_label.setText("No file blocks found.")
            QMessageBox.information(self, "No Changes Found", "No `<file path='...'>...</file>` blocks found in the Step 2 input. Ensure the response uses this exact format.")
            return

        self.status_label.setText(f"Found {len(file_blocks)} file blocks. Validating paths...")
        QApplication.processEvents()

        valid_changes_to_confirm = []
        skipped_files = []
        project_root_resolved = self.script_dir.resolve()

        for path_str, raw_content in file_blocks: # Renamed 'content' to 'raw_content'
            # Normalize path extracted from regex group 1
            relative_path_str = path_str.strip().replace("\\", "/").strip('/')
            if not relative_path_str:
                 skipped_files.append("(Empty path provided in <file> tag)")
                 continue

            try:
                # Resolve the absolute path safely
                abs_path = (project_root_resolved / relative_path_str).resolve()

                # --- Security/Validation Checks ---
                # 1. Ensure path stays within the project directory
                if not abs_path.is_relative_to(project_root_resolved):
                    skipped_files.append(f"{relative_path_str} (Path is outside project directory)")
                    print(f"Security Warning: Skipping path outside project root: {abs_path}")
                    continue

                # 2. Check if parent directory exists and is actually a directory
                parent_dir = abs_path.parent
                # Allow creation of parent dirs later, but check if *existing* parent is a file
                if parent_dir.exists() and not parent_dir.is_dir():
                     skipped_files.append(f"{relative_path_str} (Parent path exists but is a file)")
                     print(f"Error: Cannot write file {relative_path_str}, parent path {parent_dir} is a file.")
                     continue

                # 3. Check if the target path itself is an existing directory
                if abs_path.is_dir():
                    skipped_files.append(f"{relative_path_str} (Path points to an existing directory)")
                    print(f"Error: Cannot overwrite directory with file: {relative_path_str}")
                    continue

                # If all checks pass, add to list for confirmation
                valid_changes_to_confirm.append({
                    "abs_path": abs_path,
                    "raw_content": raw_content, # Store the raw content captured by regex
                    "rel_path_str": relative_path_str
                })

            except Exception as e:
                # Catch potential errors during path resolution or checks
                skipped_files.append(f"{relative_path_str} (Validation Error: {e})")
                print(f"Error validating path {relative_path_str}: {e}")
                continue

        if not valid_changes_to_confirm:
            self.status_label.setText("No valid file paths found after validation.")
            msg = "No valid file changes found in the response after validation."
            if skipped_files:
                msg += "\n\nSkipped paths:\n- " + "\n- ".join(skipped_files)
            QMessageBox.warning(self, "No Valid Changes", msg)
            return

        # --- Confirmation Dialog ---
        confirmation_message = f"Found {len(valid_changes_to_confirm)} valid file change(s) to apply:\n\n"
        for change in valid_changes_to_confirm:
            rel_path_display = change['rel_path_str']
            status = " (Will be created)" if not change['abs_path'].exists() else " (Will be overwritten)"
            confirmation_message += f"- {rel_path_display}{status}\n"

        confirmation_message += "\nBackups will be created in a temporary directory for overwritten files.\nCode fences (```) will be automatically stripped from content if found.\n\nProceed with applying these changes?"

        if skipped_files:
             # Show skipped files in a scrollable text box within the message box if there are many
             if len(skipped_files) > 5:
                  detailed_skipped = "\n\nSkipped paths:\n" + "\n".join(f"- {s}" for s in skipped_files)
                  msg_box = QMessageBox(self)
                  msg_box.setIcon(QMessageBox.Icon.Question)
                  msg_box.setWindowTitle("Confirm Changes")
                  msg_box.setText(confirmation_message + f"\n\nNote: {len(skipped_files)} path(s) were skipped (see details).")
                  msg_box.setDetailedText(detailed_skipped)
                  msg_box.setStandardButtons(QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
                  msg_box.setDefaultButton(QMessageBox.StandardButton.No)
                  reply = msg_box.exec()
             else:
                  confirmation_message += f"\n\nNote: {len(skipped_files)} path(s) skipped:\n- " + "\n- ".join(skipped_files)
                  reply = QMessageBox.question(self, "Confirm Changes", confirmation_message,
                                     QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                                     QMessageBox.StandardButton.No)
        else:
             reply = QMessageBox.question(self, "Confirm Changes", confirmation_message,
                                     QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                                     QMessageBox.StandardButton.No)


        if reply != QMessageBox.StandardButton.Yes: # Check for explicit Yes
            self.status_label.setText("Changes cancelled by user.")
            return

        # --- Create Backup Directory ---
        try:
            # Create a unique temporary directory for this operation's backups
            self.temp_backup_dir = Path(tempfile.mkdtemp(prefix="script_aggregator_undo_"))
            print(f"Created temporary backup directory: {self.temp_backup_dir}")
        except Exception as e:
            self.status_label.setText("Error creating backup directory.")
            QMessageBox.critical(self, "Backup Error", f"Could not create temporary backup directory.\nError: {e}")
            self.temp_backup_dir = None # Ensure it's None if creation failed
            return

        # --- Apply Changes & Create Backups ---
        self.status_label.setText(f"Applying changes to {len(valid_changes_to_confirm)} file(s)...")
        QApplication.processEvents()

        success_count = 0
        failed_files = []
        self.last_applied_changes = [] # Reset just before applying

        for change in valid_changes_to_confirm:
            abs_path = change["abs_path"]
            raw_content = change["raw_content"] # Use the raw captured content
            rel_path_str = change["rel_path_str"]
            backup_path = None
            was_created = False

            try:
                # --- Backup Logic ---
                if abs_path.exists():
                    # File exists, create backup before overwriting
                    safe_filename_part = rel_path_str.replace('/', '_').replace('\\', '_')
                    backup_filename = f"{safe_filename_part}_{datetime.now().strftime('%Y%m%d%H%M%S%f')}.bak"
                    backup_path = self.temp_backup_dir / backup_filename
                    shutil.copy2(abs_path, backup_path) # copy2 preserves metadata
                    print(f"Backed up '{rel_path_str}' to '{backup_path.name}' in temp dir")
                    was_created = False
                else:
                    # File doesn't exist, will be created
                    was_created = True
                    backup_path = None # No backup needed for created files

                # --- Strip Code Fences ---
                content_to_write = raw_content # Start with the raw content
                # Use strip() first to handle leading/trailing whitespace around the whole block
                stripped_raw_content = raw_content.strip()
                fences_stripped = False

                # Check for fences using startswith/endswith on the stripped content
                # Allows for ```language or just ```
                if stripped_raw_content.startswith("```") and stripped_raw_content.endswith("```"):
                    # Find the first newline after the opening fence
                    first_newline_index = stripped_raw_content.find('\n')
                    # Find the last newline before the closing fence (or start if no newline)
                    # Search up to the start of the closing ```
                    last_newline_index = stripped_raw_content.rfind('\n', 0, len(stripped_raw_content) - 3)

                    if first_newline_index != -1: # Found a newline after opening fence
                        # Content starts after the first newline
                        content_start_index = first_newline_index + 1
                        # Content ends before the last newline (if one exists before ```) or right before ```
                        content_end_index = last_newline_index if last_newline_index != -1 and last_newline_index >= content_start_index else len(stripped_raw_content) - 3

                        # Extract the content between the fences
                        # Check if end index is valid before slicing
                        if content_end_index >= content_start_index:
                             extracted_content = stripped_raw_content[content_start_index:content_end_index]
                             # Strip only leading/trailing whitespace/newlines from the *extracted* part
                             content_to_write = extracted_content.strip()
                             fences_stripped = True
                        else: # Edge case: ```\n```
                             content_to_write = ""
                             fences_stripped = True

                    else:
                        # Handle case like ```content``` (no newlines) or ``` ```
                        # Content is between the first ``` and the last ```
                        content_start_index = stripped_raw_content.find('`')+3 # Start after ```
                        content_end_index = len(stripped_raw_content) - 3 # End before ```
                        if content_start_index <= content_end_index:
                            extracted_content = stripped_raw_content[content_start_index:content_end_index]
                            content_to_write = extracted_content.strip() # Strip whitespace from content
                            fences_stripped = True
                        else: # Likely just ``` ```
                            content_to_write = ""
                            fences_stripped = True

                    if fences_stripped:
                        print(f"Stripped code fences for: {rel_path_str}")

                # --- Write File ---
                # Ensure parent directory exists before writing
                abs_path.parent.mkdir(parents=True, exist_ok=True)
                with open(abs_path, 'w', encoding='utf-8') as f:
                    # Write the potentially cleaned content
                    f.write(content_to_write)

                # --- Record Change for Undo ---
                self.last_applied_changes.append({
                    "original_path": abs_path,
                    "backup_path": backup_path, # Will be None if created
                    "was_created": was_created
                })
                success_count += 1
                action = "Created" if was_created else "Overwritten"
                print(f"Successfully {action}: {rel_path_str}")

            except (IOError, OSError, shutil.Error) as e:
                failed_files.append(f"{rel_path_str} (Write/Backup Error: {e})")
                print(f"Error processing file {rel_path_str}: {e}")
                # Attempt to rollback this specific file if backup exists? (Could get complex, skip for now)
            except Exception as e:
                # Catch any other unexpected errors during file processing
                failed_files.append(f"{rel_path_str} (Unexpected Error: {e})")
                print(f"Unexpected error processing file {rel_path_str}: {e}")
                traceback.print_exc() # Print traceback for unexpected errors

        # --- Final Report ---
        final_message = f"Apply complete. {success_count} file(s) updated/created."
        if failed_files:
            final_message += f"\nFailed to apply changes to {len(failed_files)} file(s):\n- " + "\n- ".join(failed_files)
            QMessageBox.warning(self, "Apply Partially Failed", final_message)
        elif success_count > 0: # Only show success message if something actually happened
             QMessageBox.information(self, "Apply Successful", final_message + "\nUndo is now available.")
        elif not failed_files and success_count == 0: # Should not happen if confirmation passed, but handle defensively
             final_message = "No changes were applied (though some were expected)."
             QMessageBox.information(self, "No Changes Applied", final_message)


        if skipped_files and success_count == 0 and not failed_files:
             # If only skipped files occurred, mention that specifically
             final_message = f"No changes applied. {len(skipped_files)} path(s) were skipped during validation."
        elif skipped_files:
             # Append skipped info if other actions occurred
             final_message += f"\n({len(skipped_files)} initial path(s) skipped during validation)"

        self.status_label.setText(final_message)

        # --- Enable Undo Button if successful changes were made and recorded ---
        if self.last_applied_changes: # Check if any changes were successfully recorded for undo
            self.undo_button.setEnabled(True)
        else:
            # If all failed or were skipped, cleanup the (likely empty) backup dir
             self._cleanup_backup_dir()
             self.undo_button.setEnabled(False)


    # --- NEW SLOT ---
    @Slot()
    def undo_last_apply(self):
        """Reverts the last set of applied changes using backups."""
        if not self.last_applied_changes:
            QMessageBox.information(self, "Undo", "No changes have been applied since the last undo or startup.")
            self.undo_button.setEnabled(False) # Ensure button is disabled
            return
        if not self.temp_backup_dir or not self.temp_backup_dir.exists():
             # Check if dir exists as well, might have been cleaned up prematurely
             QMessageBox.warning(self, "Undo Error", "Cannot undo: Backup directory information is missing or directory was removed.")
             self.last_applied_changes = [] # Clear state if backup is gone
             self.undo_button.setEnabled(False) # Disable button if state is inconsistent
             return

        reply = QMessageBox.question(self, "Confirm Undo",
                                     f"This will revert the last {len(self.last_applied_changes)} file change(s) applied in Step 2.\n\nProceed with Undo?",
                                     QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                                     QMessageBox.StandardButton.No)

        if reply == QMessageBox.StandardButton.No:
            return

        self.status_label.setText("Undoing changes...")
        QApplication.processEvents()

        undo_success_count = 0
        undo_failed_files = []

        # Iterate through the recorded changes (order might matter if dirs were involved, but likely ok here)
        for change_info in self.last_applied_changes:
            original_path = change_info["original_path"]
            backup_path = change_info["backup_path"]
            was_created = change_info["was_created"]
            rel_path_str = "UnknownPath" # Default
            try:
                 # Get relative path for messages, handle potential error if outside script_dir (shouldn't happen with validation)
                 rel_path_str = original_path.relative_to(self.script_dir).as_posix()
            except ValueError:
                 rel_path_str = str(original_path) # Fallback to absolute path string

            try:
                if was_created:
                    # If the file was newly created by 'apply', delete it
                    if original_path.exists() and original_path.is_file(): # Check it's a file before unlinking
                        original_path.unlink() # Delete the file
                        print(f"Undo: Deleted newly created file '{rel_path_str}'")
                        undo_success_count += 1
                    elif not original_path.exists():
                        # File already deleted? Count as success for undo.
                        print(f"Undo: Newly created file '{rel_path_str}' was already deleted.")
                        undo_success_count += 1
                    else:
                         # Path exists but is not a file (e.g., a directory was created somehow?) - report error
                         undo_failed_files.append(f"{rel_path_str} (Cannot delete, path is not a file)")
                         print(f"Error: Cannot undo creation of '{rel_path_str}', path exists but is not a file.")

                else:
                    # If the file was overwritten, restore from backup
                    if backup_path and backup_path.exists() and backup_path.is_file():
                        # Ensure parent dir exists before restoring (it should, but safety check)
                        original_path.parent.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(backup_path, original_path) # Restore content and metadata
                        print(f"Undo: Restored '{rel_path_str}' from backup '{backup_path.name}'.")
                        undo_success_count += 1
                    elif backup_path and not backup_path.exists():
                        # Backup missing! Cannot restore.
                        undo_failed_files.append(f"{rel_path_str} (Backup file missing: {backup_path.name})")
                        print(f"Error: Cannot undo '{rel_path_str}', backup file missing: {backup_path}")
                    elif backup_path and not backup_path.is_file():
                         # Backup path exists but isn't a file
                         undo_failed_files.append(f"{rel_path_str} (Backup path is not a file: {backup_path.name})")
                         print(f"Error: Cannot undo '{rel_path_str}', backup path is not a file: {backup_path}")
                    elif not backup_path:
                        # Should not happen if was_created is False, but handle defensively
                         undo_failed_files.append(f"{rel_path_str} (Invalid state: Overwritten but no backup path recorded)")
                         print(f"Error: Cannot undo '{rel_path_str}', invalid state (no backup path).")

            except (IOError, OSError, shutil.Error) as e:
                 undo_failed_files.append(f"{rel_path_str} (Undo Error: {e})")
                 print(f"Error undoing change for {rel_path_str}: {e}")
            except Exception as e:
                 # Catch any other unexpected errors during undo
                 undo_failed_files.append(f"{rel_path_str} (Unexpected Undo Error: {e})")
                 print(f"Unexpected error undoing change for {rel_path_str}: {e}")

        # --- Report Undo Status ---
        final_message = f"Undo complete: {undo_success_count} change(s) reverted."
        if undo_failed_files:
            final_message += f"\nFailed to undo {len(undo_failed_files)} change(s):\n- " + "\n- ".join(undo_failed_files)
            QMessageBox.warning(self, "Undo Partially Failed", final_message + "\nManual check recommended.")
        elif undo_success_count > 0: # Only show success if something was reverted
            QMessageBox.information(self, "Undo Successful", final_message)
        else: # No successes and no failures (e.g., files were already deleted)
             QMessageBox.information(self, "Undo Complete", "Undo process finished. No files needed reverting (e.g., they were already in the target state).")


        self.status_label.setText(final_message)

        # --- Cleanup and Reset State ---
        self._cleanup_backup_dir() # Remove the temp backup dir
        self.last_applied_changes = [] # Clear the list of changes
        self.undo_button.setEnabled(False) # Disable undo button

        # Optional: Refresh tree view after undo? Might be useful if files were created/deleted.
        # print("Refreshing file tree after undo...")
        # self.populate_file_tree()
        # file_count = self.count_files_in_model()
        # self.status_label.setText(f"{final_message} | Found {file_count} files.")


    # --- Helper for cleaning up backup dir ---
    def _cleanup_backup_dir(self):
        """Safely removes the temporary backup directory if it exists."""
        if self.temp_backup_dir and self.temp_backup_dir.exists():
            try:
                shutil.rmtree(self.temp_backup_dir)
                print(f"Removed temporary backup directory: {self.temp_backup_dir}")
            except (IOError, OSError) as e:
                print(f"Warning: Could not remove temporary backup directory: {self.temp_backup_dir}\nError: {e}")
                # Optionally inform user if cleanup fails non-critically
                # QMessageBox.warning(self, "Cleanup Warning", f"Could not automatically remove the temporary backup directory:\n{self.temp_backup_dir}\nYou may need to remove it manually.\nError: {e}")
            finally:
                 self.temp_backup_dir = None # Reset path regardless of success

    # --- Ensure cleanup on exit ---
    def closeEvent(self, event):
        """Ensure temporary directory is cleaned up when the application closes."""
        print("Close event triggered, cleaning up backup directory...")
        self._cleanup_backup_dir()
        event.accept() # Proceed with closing the window


# --- Main Execution ---
if __name__ == "__main__":
    # Determine the directory where the script is running
    if getattr(sys, 'frozen', False):
        # If running as a bundled executable (e.g., PyInstaller)
        application_path = Path(sys.executable).parent
        script_name = Path(sys.executable).name
    else:
        # If running as a normal Python script
        application_path = Path(__file__).parent
        script_name = Path(__file__).name

    script_dir_abs = application_path.resolve()
    print(f"Running script '{script_name}' from directory: {script_dir_abs}")

    # Set up the Qt Application
    app = QApplication(sys.argv)
    # Apply a style if desired (optional)
    # app.setStyle('Fusion')

    # Create and show the main window
    window = ScriptAggregatorApp(script_dir=script_dir_abs, script_name=script_name)
    window.show()

    # Start the Qt event loop
    sys.exit(app.exec())
</file>

<file path='aggregator_gui13.py'>
# --- COMPLETE UPDATED SCRIPT ---

import sys
import os
from pathlib import Path
from datetime import datetime
import re # For parsing comma-separated list robustly AND file blocks
import shutil # For file copying
import tempfile # For temporary directory
import traceback # For detailed error printing

# --- Try importing PySide6 ---
try:
    from PySide6 import QtCore, QtGui, QtWidgets
    from PySide6.QtCore import Qt, Slot
    from PySide6.QtWidgets import (
        QApplication, QWidget, QVBoxLayout, QHBoxLayout,
        QPushButton, QTreeView, QLabel, QRadioButton, QGroupBox,
        QMessageBox, QFrame, QTextEdit, QLineEdit, QCheckBox,
        QScrollArea # <-- Import QScrollArea
    )
    from PySide6.QtGui import QStandardItemModel, QStandardItem, QIcon, QFont
except ImportError:
    print("Error: PySide6 is not installed.")
    print("Please install it using: pip install PySide6")
    sys.exit(1)

# --- Constants for Output Directories ---
OUTPUT_BASE_DIR_NAME = "dev_prompts"
PLANNING_SUBDIR_NAME = "1a_planning_prompts"
ACTION_SUBDIR_NAME = "1b_dev_prompts"
PLANNING_ALT_SUBDIR_NAME = "1b_alt1_planning_prompts" # New constant for alternative path
ACTION_ALT_SUBDIR_NAME = "1b_alt2_dev_prompts" # New constant for alternative path

# --- Constants for File Parsing ---
# Regex to find <file path='...'>...</file> blocks.
# Handles potential code fences (```) within the content block because:
# - `.*?` is non-greedy, matching up to the *first* `</file>`.
# - `re.DOTALL` makes `.` match newline characters.
# - `re.IGNORECASE` allows `<file>` or `<FILE>`.
FILE_BLOCK_REGEX = re.compile(
    r"<file\s+path=['\"](.*?)['\"]\s*>(.*?)</file>",
    re.DOTALL | re.IGNORECASE
)

# New regex for file plan blocks in alternative path
FILE_PLAN_BLOCK_REGEX = re.compile(
    r"<file_plan\s+path=['\"](.*?)['\"]\s*>(.*?)</file_plan>",
    re.DOTALL | re.IGNORECASE
)


# --- Reusable Core Logic ---

def read_file_content(file_path):
    """Read and return the content of a file, handling potential encoding issues."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        try:
            with open(file_path, 'r', encoding='latin-1') as f:
                print(f"Warning: Read {file_path} with latin-1 encoding.")
                return f.read()
        except Exception as e:
            print(f"Error reading {file_path} (tried utf-8, latin-1): {str(e)}")
            return f"--- ERROR READING FILE (tried utf-8, latin-1) ---\nPath: {file_path}\nError: {str(e)}\n--- END ERROR ---"
    except FileNotFoundError:
        # This is now expected when reading a backup of a newly created file during undo test
        # print(f"Info: File not found during read (might be expected): {file_path}")
        return None # Return None to indicate it didn't exist or couldn't be read
    except Exception as e:
        print(f"Error reading {file_path}: {str(e)}")
        return f"--- ERROR READING FILE ---\nPath: {file_path}\nError: {str(e)}\n--- END ERROR ---"

def get_potential_files_recursively(current_directory, original_root_dir, script_name, include_logs=False):
    """
    Recursively get potential files relative to the original_root_dir,
    excluding specified types and patterns. Returns relative paths.
    """
    potential_files = []
    current_directory_path = Path(current_directory).resolve()
    original_root_dir_resolved = original_root_dir.resolve()

    # --- Root-level checks ---
    if current_directory_path == original_root_dir_resolved:
        compose_file = original_root_dir_resolved / 'compose.yaml'
        dockerfile = original_root_dir_resolved / 'Dockerfile'
        if compose_file.exists() and compose_file.is_file():
            potential_files.append(compose_file.relative_to(original_root_dir_resolved))
        if dockerfile.exists() and dockerfile.is_file():
            potential_files.append(dockerfile.relative_to(original_root_dir_resolved))

        docs_dir = original_root_dir_resolved / 'docs'
        if docs_dir.exists() and docs_dir.is_dir():
            for item in docs_dir.glob('*.md'):
                if item.is_file() and item.parent == docs_dir:
                    potential_files.append(item.resolve().relative_to(original_root_dir_resolved))

    # --- Recursive scan ---
    try:
        for item_entry in os.scandir(current_directory_path):
            item = Path(item_entry.path)
            # Handle potential symlinks carefully - resolve first
            try:
                item_abs_path = item.resolve()
            except OSError as e:
                print(f"Warning: Could not resolve path {item}, possibly broken symlink: {e}. Skipping.")
                continue

            try:
                # Ensure the item is actually within the project root before proceeding
                if not item_abs_path.is_relative_to(original_root_dir_resolved):
                     continue
                relative_path = item_abs_path.relative_to(original_root_dir_resolved)
                relative_path_str = relative_path.as_posix()
            except ValueError:
                print(f"Warning: Could not get relative path for {item_abs_path} against {original_root_dir_resolved}. Skipping.")
                continue
            except Exception as e:
                print(f"Warning: Error during relative path calculation for {item}: {e}. Skipping.")
                continue

            # --- Exclusions ---
            if item.name == script_name: continue
            if item.name.startswith('.') and item.name != '.scripts': continue
            if item.name in ['.venv', 'venv', 'env', '__pycache__', 'node_modules', 'dist', 'build', OUTPUT_BASE_DIR_NAME, '.git'] or \
               item.name.startswith('concatignore') or \
               item.name.startswith('archive') or \
               item.name.startswith('planning_and_focus_window') or \
               item.name.startswith('planning_request_') or \
               item.name.startswith('concat_'):
                continue
            if item.is_dir() and item.name == 'docs' and 'scripts' not in relative_path_str.split('/'): continue

            # --- File processing ---
            if item.is_file():
                excluded_suffixes = [
                    '.xlsx', '.xls', '.csv', '.data', '.db', '.sqlite', '.sqlite3',
                    '.pkl', '.joblib', '.h5', '.hdf5',
                    '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.svg', '.ico',
                    '.pdf', '.doc', '.docx', '.ppt', '.pptx',
                    '.zip', '.gz', '.tar', '.rar',
                    '.exe', '.dll', '.so', '.o', '.a', '.lib',
                    '.pyc', '.pyd', '.pyo',
                    '.swp', '.swo', '.json'
                ]
                # Use Path.suffix for reliable extension checking
                file_suffix = item.suffix.lower()
                if file_suffix == '.log' and not include_logs:
                    continue
                if file_suffix in excluded_suffixes:
                    continue
                if relative_path not in potential_files:
                    potential_files.append(relative_path)

            # --- Directory processing ---
            elif item.is_dir():
                potential_files.extend(get_potential_files_recursively(item_abs_path, original_root_dir_resolved, script_name, include_logs))

    except FileNotFoundError: print(f"Warning: Directory not found during scan: {current_directory_path}. Skipping.")
    except PermissionError: print(f"Warning: Permission denied for directory: {current_directory_path}. Skipping.")
    except Exception as e: print(f"Error scanning directory {current_directory_path}: {e}")

    return sorted(list(dict.fromkeys(potential_files)), key=lambda p: p.as_posix())


# --- Mode Definitions (Unchanged) ---
MODES = {
    "debug": {
        "name": "Debug Mode",
        "issue_placeholder": "<Describe the bug or unexpected behavior observed>\n\n\n",
        "output_instruction": (
            "1) Reflect on 5-7 different possible sources of the problem based on the code provided and the goal/issue description.\n"
            "2) Distill those down to the most likely root cause.\n"
            "3) Provide the COMPLETE UPDATED VERSION of *only* the files that need changes to fix the likely root cause.\n"
            "   Use the format: <file path='relative/path/to/file.ext'>\n```[language]\n[COMPLETE FILE CONTENT]\n```\n</file>\n" # Added ``` hint
            "   Ensure the file path is relative to the project root and the content is enclosed in markdown code fences."
        )
    },
    "add_feature": {
        "name": "Add New Feature",
        "issue_placeholder": "<Describe the new feature or enhancement required>\n\n\n",
        "output_instruction": (
            "1) Explain if this is already complete, or what is missing\n"
            "2) Provide the COMPLETE code for any NEW files needed.\n"
            "3) Provide the COMPLETE UPDATED VERSION of any EXISTING files that need changes.\n"
            "   Use the format: <file path='relative/path/to/file.ext'>\n```[language]\n[COMPLETE FILE CONTENT]\n```\n</file>\n for both new and updated files." # Added ``` hint
            "   Ensure the file path is relative to the project root and the content is enclosed in markdown code fences."
        )
    },
    "explain": {
        "name": "Explain / Brainstorm",
        "issue_placeholder": "<Ask a question about the code, request an explanation, or describe a concept to brainstorm>\n\n\n",
        "output_instruction": (
            "Provide a clear explanation, answer the question, or offer brainstorming ideas/approaches.\n"
            "If suggesting code changes or approaches, illustrate with concise examples where appropriate (no need for full file rewrites unless specifically asked).\n"
        )
    },
    # New alternative planning mode
    "planning_alt": {
        "name": "Planning (Alt Path)",
        "issue_placeholder": "<Describe the new feature or enhancement required>\n\n\n",
        "output_instruction": (
            "Provide the COMPLETE list of any NEW files needed or any EXISTING files that need changes. "
            "For each file, DESCRIBE conceptually what is needed or what changes are required (do not write the new code yet).\n\n"
            "Use the following format for each file:\n"
            "<file_plan path='relative/path/to/file.ext'>\n"
            "[Conceptual description of what this file needs to contain or how it should be modified]\n"
            "</file_plan>\n\n"
            "Example:\n"
            "<file_plan path='src/new_module.py'>\n"
            "Create a new module that implements a REST API client with functions for authentication, data retrieval, and posting updates.\n"
            "Should include proper error handling and logging.\n"
            "</file_plan>\n\n"
            "<file_plan path='src/existing_module.py'>\n"
            "Update to include imports for the new module and modify the main function to call the new API client functions.\n"
            "</file_plan>"
        )
    }
}

# --- Custom Role for Storing Path Data in Model ---
PathRole = Qt.UserRole + 1

# --- PySide6 GUI Application Class ---

class ScriptAggregatorApp(QWidget):
    def __init__(self, script_dir, script_name):
        super().__init__()
        self.script_dir = Path(script_dir).resolve()
        self.script_name = script_name
        self.folder_icon = self.style().standardIcon(QtWidgets.QStyle.StandardPixmap.SP_DirIcon)
        self.file_icon = self.style().standardIcon(QtWidgets.QStyle.StandardPixmap.SP_FileIcon)
        self.log_icon = self.style().standardIcon(QtWidgets.QStyle.StandardPixmap.SP_FileIcon) # Using file icon for logs too
        self.model = QStandardItemModel()
        self.tree_view = QTreeView()
        self.status_label = QLabel("Ready. Scanning for files...")
        self.mode_buttons = {}
        self.goal_input = QTextEdit()
        self.suggestion_input = QLineEdit()
        self.include_logs_checkbox = QCheckBox("Include selected .log files in Step 1b output")
        self.llm_response_input = QTextEdit()
        self.item_path_map = {}
        
        # New attributes for alternative path
        self.planning_alt_response_input = QTextEdit()
        self.alt_path_enabled = False  # Track if the alternative path is being used
        self.file_plans = {}  # To store file plans from 1b_alt.1
        
        # --- Undo State ---
        self.last_applied_changes = [] # List to store info about the last applied changes
        self.temp_backup_dir = None # Path to the temporary backup directory for the last apply

        # --- Define output directories relative to script_dir ---
        self.output_base_dir = self.script_dir / OUTPUT_BASE_DIR_NAME
        self.planning_output_dir = self.output_base_dir / PLANNING_SUBDIR_NAME
        self.action_output_dir = self.output_base_dir / ACTION_SUBDIR_NAME
        # New output directories for alternative path
        self.planning_alt_output_dir = self.output_base_dir / PLANNING_ALT_SUBDIR_NAME
        self.action_alt_output_dir = self.output_base_dir / ACTION_ALT_SUBDIR_NAME

        self.initUI()
        self.populate_file_tree()
        file_count = self.count_files_in_model()
        self.status_label.setText(f"Ready. Found {file_count} potential files (including .log).")

    def initUI(self):
        self.setWindowTitle("Script Aggregator & Applier (with Undo)")
        self.setGeometry(150, 150, 1050, 800) # Adjusted initial height slightly

        # --- Main Horizontal Layout (will go inside scroll area) ---
        main_h_layout = QHBoxLayout()
        left_v_layout = QVBoxLayout()
        right_v_layout = QVBoxLayout()
        right_v_layout.setAlignment(Qt.AlignmentFlag.AlignTop) # Keep controls aligned top

        # --- Left Side: File Tree ---
        tree_header_label = QLabel("Files in Project (Checkboxes for Step 1b):")
        font = tree_header_label.font(); font.setBold(True); tree_header_label.setFont(font)
        self.tree_view.setModel(self.model)
        self.tree_view.setHeaderHidden(True)
        self.tree_view.setSelectionMode(QtWidgets.QAbstractItemView.SelectionMode.NoSelection)
        # Set minimum height for tree view to prevent it collapsing too much
        self.tree_view.setMinimumHeight(400)
        left_v_layout.addWidget(tree_header_label)
        left_v_layout.addWidget(self.tree_view)
        left_v_layout.addStretch(1) # Add stretch to push tree up if space allows

        # --- Right Side: Controls ---
        # Step 0
        step0_groupbox = QGroupBox("Step 0: Generate Planning Request (excludes .log files)")
        step0_layout = QVBoxLayout()
        step0_layout.addWidget(QLabel("Describe your overall goal or task:"))
        self.goal_input.setPlaceholderText("e.g., Refactor the database connection logic...")
        self.goal_input.setMinimumHeight(60)
        self.goal_input.setMaximumHeight(150) # Limit max height
        step0_layout.addWidget(self.goal_input)
        generate_planning_button = QPushButton("Generate Planning Request File")
        generate_planning_button.clicked.connect(self.generate_planning_request)
        step0_layout.addWidget(generate_planning_button)
        step0_groupbox.setLayout(step0_layout)
        right_v_layout.addWidget(step0_groupbox)

        # Step 1a
        step1a_groupbox = QGroupBox("Step 1a: Apply LLM File Suggestions")
        step1a_layout = QVBoxLayout()
        step1a_layout.addWidget(QLabel("Paste comma-separated file list from LLM:"))
        self.suggestion_input.setPlaceholderText("e.g., src/db.py, src/auth/jwt.py,...")
        step1a_layout.addWidget(self.suggestion_input)
        apply_suggestion_button = QPushButton("Apply Suggested Files to Selection Below")
        apply_suggestion_button.clicked.connect(self.apply_suggested_files)
        step1a_layout.addWidget(apply_suggestion_button)
        step1a_groupbox.setLayout(step1a_layout)
        right_v_layout.addWidget(step1a_groupbox)

        # Manual Selection
        select_groupbox = QGroupBox("Manual File Selection (for Step 1b)")
        select_layout = QVBoxLayout()
        select_buttons_layout = QHBoxLayout()
        select_all_button = QPushButton("Select All Visible Files")
        select_none_button = QPushButton("Deselect All Visible Files")
        select_all_button.clicked.connect(self.select_all)
        select_none_button.clicked.connect(self.select_none)
        select_buttons_layout.addWidget(select_all_button)
        select_buttons_layout.addWidget(select_none_button)
        select_layout.addLayout(select_buttons_layout)
        select_groupbox.setLayout(select_layout)
        right_v_layout.addWidget(select_groupbox)

        # Step 1b Mode
        mode_groupbox = QGroupBox("Step 1b: Select Action Mode & Generate Action Prompt")
        mode_layout = QVBoxLayout()
        first_mode_key = list(MODES.keys())[0]
        for key, mode_info in MODES.items():
            rb = QRadioButton(mode_info["name"])
            self.mode_buttons[key] = rb
            if key == first_mode_key: rb.setChecked(True)
            mode_layout.addWidget(rb)
        mode_layout.addWidget(self.include_logs_checkbox)
        self.include_logs_checkbox.setChecked(False)
        self.generate_button = QPushButton("Execute Step 1b: Generate Concatenated File for LLM Action")
        self.generate_button.clicked.connect(self.generate_final_output_file)
        mode_layout.addWidget(self.generate_button)
        
        # New section: Alternative 1b path
        alt_path_heading = QLabel("Alternative Step 1b Path:")
        font = alt_path_heading.font(); font.setBold(True); alt_path_heading.setFont(font)
        mode_layout.addWidget(alt_path_heading)
        
        alt_path_button = QPushButton("Execute Step 1b_alt.1: Generate Planning Request for Files")
        alt_path_button.clicked.connect(self.generate_alt_planning_request)
        mode_layout.addWidget(alt_path_button)
        
        # Add section for alt path planning response
        mode_layout.addWidget(QLabel("Step 1b_alt.1 Response (paste LLM file plan response here):"))
        self.planning_alt_response_input.setPlaceholderText("Paste the LLM response from Step 1b_alt.1 containing <file_plan> blocks here...")
        self.planning_alt_response_input.setMinimumHeight(100)
        self.planning_alt_response_input.setMaximumHeight(200)
        self.planning_alt_response_input.setAcceptRichText(False)
        mode_layout.addWidget(self.planning_alt_response_input)
        
        # Add button for alt path final action
        alt_action_button = QPushButton("Execute Step 1b_alt.2: Generate Action Prompt with Planning")
        alt_action_button.clicked.connect(self.generate_alt_final_output_file)
        mode_layout.addWidget(alt_action_button)
        
        mode_groupbox.setLayout(mode_layout)
        right_v_layout.addWidget(mode_groupbox)

        # Step 2 Apply Changes
        step2_groupbox = QGroupBox("Step 2: Apply LLM Changes")
        step2_layout = QVBoxLayout()
        step2_layout.addWidget(QLabel("Paste the LLM response containing <file> blocks below:"))
        self.llm_response_input.setPlaceholderText("<file path='relative/path/to/file.ext'>\n```[language]\n[COMPLETE FILE CONTENT]\n```\n</file>\n...") # Added ``` hint
        self.llm_response_input.setMinimumHeight(150)
        self.llm_response_input.setMaximumHeight(300) # Limit max height
        self.llm_response_input.setAcceptRichText(False)
        step2_layout.addWidget(self.llm_response_input)
        apply_undo_layout = QHBoxLayout()
        self.apply_changes_button = QPushButton("Parse and Apply Changes to Project Files")
        self.apply_changes_button.clicked.connect(self.apply_llm_changes)
        self.undo_button = QPushButton("Undo Last Apply")
        self.undo_button.clicked.connect(self.undo_last_apply)
        self.undo_button.setEnabled(False)
        apply_undo_layout.addWidget(self.apply_changes_button, 2)
        apply_undo_layout.addWidget(self.undo_button, 1)
        step2_layout.addLayout(apply_undo_layout)
        step2_groupbox.setLayout(step2_layout)
        right_v_layout.addWidget(step2_groupbox)

        # Add stretch to the bottom of the right layout if needed,
        # but AlignTop should handle most cases.
        # right_v_layout.addStretch(1)

        # Assemble Main Horizontal Layout
        left_widget = QWidget(); left_widget.setLayout(left_v_layout)
        right_widget = QWidget(); right_widget.setLayout(right_v_layout)
        main_h_layout.addWidget(left_widget, 3) # Ratio 3 for left
        main_h_layout.addWidget(right_widget, 4) # Ratio 4 for right

        # --- Create a container widget for the main horizontal layout ---
        main_content_widget = QWidget()
        main_content_widget.setLayout(main_h_layout)

        # --- Create Scroll Area and add the main content widget to it ---
        scroll_area = QScrollArea()
        scroll_area.setWidgetResizable(True) # Crucial for layout to expand
        scroll_area.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded) # Also allow horizontal if needed
        scroll_area.setWidget(main_content_widget)

        # --- Bottom Area (Status Bar) ---
        bottom_v_layout = QVBoxLayout()
        self.status_label.setFrameStyle(QFrame.Shape.Panel | QFrame.Shadow.Sunken)
        self.status_label.setLineWidth(1)
        # Ensure status label doesn't stretch vertically
        bottom_v_layout.addWidget(self.status_label)
        bottom_v_layout.addStretch(0) # Prevent stretch

        # --- Overall Layout ---
        overall_layout = QVBoxLayout(self) # Set layout ON the main window (self)
        # Add the scroll area (containing the main content)
        overall_layout.addWidget(scroll_area, 1) # Give scroll area stretch factor 1
        # Add the status bar layout (fixed height)
        overall_layout.addLayout(bottom_v_layout, 0) # Give status bar stretch factor 0

    def populate_file_tree(self):
        """Populates the tree view, including .log files."""
        self.model.clear()
        self.item_path_map.clear()
        invisible_root = self.model.invisibleRootItem()
        folder_items = {'': invisible_root}

        potential_files = get_potential_files_recursively(
            self.script_dir,
            self.script_dir,
            self.script_name,
            include_logs=True
        )

        for rel_path in potential_files:
            if not isinstance(rel_path, Path): continue

            parent_item = invisible_root
            current_path_part_cumulative = Path()

            for part in rel_path.parts[:-1]:
                current_path_part_cumulative = current_path_part_cumulative / part
                current_path_part_str = current_path_part_cumulative.as_posix()
                if current_path_part_str not in folder_items:
                    folder_item = QStandardItem(part)
                    folder_item.setIcon(self.folder_icon)
                    folder_item.setEditable(False)
                    folder_item.setCheckable(False) # Folders not checkable
                    parent_item.appendRow(folder_item)
                    folder_items[current_path_part_str] = folder_item
                    parent_item = folder_item
                else:
                    parent_item = folder_items[current_path_part_str]

            file_name = rel_path.name
            file_item = QStandardItem(file_name)
            # Use Path.suffix for reliable extension checking
            if rel_path.suffix.lower() == '.log':
                file_item.setIcon(self.log_icon)
            else:
                file_item.setIcon(self.file_icon)

            file_item.setCheckable(True)
            file_item.setCheckState(Qt.CheckState.Checked) # Default to checked
            file_item.setEditable(False)
            file_item.setData(rel_path, PathRole)
            parent_item.appendRow(file_item)
            self.item_path_map[rel_path.as_posix()] = file_item

        self.tree_view.expandToDepth(0)

    def iterate_model_items(self, parent_item=None):
        """Generator to recursively yield all items in the model."""
        if parent_item is None: parent_item = self.model.invisibleRootItem()
        for row in range(parent_item.rowCount()):
            item = parent_item.child(row, 0)
            if item:
                yield item
                if item.hasChildren(): yield from self.iterate_model_items(item)

    def count_files_in_model(self):
        """Counts file items using the item_path_map."""
        return len(self.item_path_map)

    @Slot()
    def select_all(self):
        """Checks all file items (leaves) in the tree view."""
        for item in self.item_path_map.values():
            if item.isCheckable():
                item.setCheckState(Qt.CheckState.Checked)
        self.status_label.setText("All visible files selected (for Step 1b).")

    @Slot()
    def select_none(self):
        """Unchecks all file items (leaves) in the tree view."""
        for item in self.item_path_map.values():
             if item.isCheckable():
                item.setCheckState(Qt.CheckState.Unchecked)
        self.status_label.setText("All visible files deselected (for Step 1b).")

    @Slot()
    def generate_planning_request(self):
        """Generates the Step 0 request file (excluding .log files)."""
        goal = self.goal_input.toPlainText().strip()
        if not goal:
            QMessageBox.warning(self, "Input Missing", "Please describe your overall goal for Step 0.")
            return

        self.status_label.setText("Gathering project files (excluding .log) for planning request...")
        QApplication.processEvents()

        all_potential_files_no_logs = get_potential_files_recursively(
            self.script_dir, self.script_dir, self.script_name, include_logs=False
        )

        if not all_potential_files_no_logs:
             QMessageBox.warning(self, "No Files Found", "No source files (excluding .log) found for planning request.")
             self.status_label.setText("Ready.")
             return

        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = self.planning_output_dir
        output_filename = f"planning_request_{timestamp_str}.txt"
        output_file = output_dir / output_filename

        self.status_label.setText(f"Generating {output_filename} in {output_dir.relative_to(self.script_dir)}...")
        QApplication.processEvents()

        try:
            output_dir.mkdir(parents=True, exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                # --- Content for Planning Request ---
                f.write("--- Goal Description ---\n\n")
                f.write(goal + "\n\n")
                f.write("--- Instructions for LLM ---\n\n")
                f.write("Based on the goal described above and the provided project context (file tree and source code below), identify the key files that likely need to be created, modified, or consulted to achieve the goal.\n\n")
                f.write("Please provide the list of relevant file paths as a single line, comma-separated string. Include only relative paths from the project root.\n\n")
                f.write("Example Output:\n")
                f.write("src/core/feature.py, src/utils/helpers.py, tests/test_feature.py, README.md\n\n")
                f.write("--- End Instructions ---\n\n")

                f.write("<Project File Tree (excluding .log files)>\n")
                sorted_all_files = sorted(all_potential_files_no_logs, key=lambda p: p.as_posix())
                for rel_path in sorted_all_files:
                    f.write(f"- {rel_path.as_posix()}\n")
                f.write("</Project File Tree>\n\n\n")

                f.write("<Project Source Code (excluding .log files)>\n\n")
                for rel_path in sorted_all_files:
                    abs_path = self.script_dir / rel_path
                    rel_path_str = rel_path.as_posix()
                    f.write(f"<file path='{rel_path_str}'>\n")
                    content = read_file_content(abs_path)
                    if content is not None:
                        f.write(content) # Check if read was successful
                    else:
                        f.write(f"--- Error reading file: {rel_path_str} ---")
                    f.write("\n</file>\n\n")
                f.write("</Project Source Code>\n\n")

                f.write("--- Identified Files (Provide comma-separated list below) ---\n\n\n")

            relative_output_path = output_file.relative_to(self.script_dir)
            self.status_label.setText(f"Planning request file generated: {relative_output_path}")
            QMessageBox.information(self, "Step 0 Success", f"Planning request file created:\n{relative_output_path}\n\nPaste this entire file content into the LLM to get the list of files for Step 1a.")

        except Exception as e:
            self.status_label.setText(f"Error generating planning request file: {e}")
            QMessageBox.critical(self, "Step 0 Error", f"Could not generate planning request file.\nError: {e}")
            print(f"Error details during planning generation:")
            traceback.print_exc()


    @Slot()
    def apply_suggested_files(self):
        """Parses the suggestion input and updates the tree view selection."""
        suggestions_text = self.suggestion_input.text().strip()
        if not suggestions_text:
            QMessageBox.warning(self, "Input Missing", "Please paste the comma-separated file list from the LLM.")
            return

        # Robust parsing of comma-separated list, handling quotes and whitespace
        try:
            # Find non-comma/whitespace sequences or quoted sequences
            suggested_paths_raw = re.findall(r'[^,\s"]+|"[^"]*"', suggestions_text)
            # Strip whitespace and quotes from each found part
            suggested_paths_raw = [p.strip().strip('"').strip() for p in suggested_paths_raw if p.strip()]
        except Exception as e:
            QMessageBox.warning(self, "Parsing Error", f"Could not parse file list.\nError: {e}")
            return

        # Normalize paths (use forward slashes, remove leading/trailing slashes)
        suggested_paths_normalized = set()
        for p_raw in suggested_paths_raw:
            p_norm = p_raw.replace("\\", "/").strip('/')
            if p_norm: # Ensure it's not empty after normalization
                suggested_paths_normalized.add(p_norm)

        if not suggested_paths_normalized:
             QMessageBox.warning(self, "Parsing Error", "Could not parse valid file paths from the input.")
             return

        self.select_none() # Start by deselecting all
        found_count = 0
        not_found = []

        # Apply suggestions to the tree view
        for norm_path in suggested_paths_normalized:
            item = self.item_path_map.get(norm_path)
            if item and item.isCheckable():
                item.setCheckState(Qt.CheckState.Checked)
                found_count += 1
                # Expand parent nodes to make the selected item visible
                parent = item.parent()
                while parent and parent != self.model.invisibleRootItem():
                    self.tree_view.expand(self.model.indexFromItem(parent))
                    parent = parent.parent()
            else:
                not_found.append(norm_path)

        # Report results
        status_msg = f"Applied suggestions: {found_count} files selected."
        if not_found:
            status_msg += f" ({len(not_found)} not found/selectable: {', '.join(not_found[:3])}{'...' if len(not_found) > 3 else ''})"
            print(f"Warning: Suggested files not found/selectable: {', '.join(not_found)}")
            QMessageBox.warning(self, "Partial Match", f"Applied suggestions, but some files were not found or are not selectable (e.g., directories):\n\n- {chr(10).join(not_found)}\n\nCheck the selection in the tree view.")
        elif found_count > 0:
             QMessageBox.information(self, "Suggestions Applied", f"Successfully selected {found_count} file(s) based on the provided list.")
        else:
             QMessageBox.warning(self, "No Matches", "None of the suggested files were found or selectable in the project tree.")

        self.status_label.setText(status_msg)


    @Slot()
    def generate_final_output_file(self):
        """Generates the final output file for LLM action."""
        goal_text = self.goal_input.toPlainText().strip()
        if not goal_text:
            QMessageBox.warning(self, "Input Missing", "Please ensure the overall goal is described in Step 0.")
            return

        include_logs_in_output = self.include_logs_checkbox.isChecked()
        selected_relative_paths = []
        # Iterate through the map which only contains file items
        for item in self.item_path_map.values():
            if item.isCheckable() and item.checkState() == Qt.CheckState.Checked:
                rel_path = item.data(PathRole)
                if rel_path and isinstance(rel_path, Path): # Ensure it's a Path object
                    # Skip .log files if checkbox is unchecked
                    if not include_logs_in_output and rel_path.suffix.lower() == '.log':
                        continue
                    selected_relative_paths.append(rel_path)
                elif rel_path:
                    print(f"Warning: Item data is not a Path object for item '{item.text()}'") # Debugging
                # else: # No PathRole data - should not happen for items in map
                #    print(f"Warning: Item '{item.text()}' has no PathRole data.")

        if not selected_relative_paths:
            msg = "Please select at least one file in the tree view before executing Step 1b."
            if not include_logs_in_output:
                msg += "\nNote: .log files are currently excluded based on the checkbox setting. Ensure other files are selected."
            QMessageBox.warning(self, "No Files Selected", msg)
            return

        selected_mode_key = None
        for key, button in self.mode_buttons.items():
            if button.isChecked():
                selected_mode_key = key
                break
        if not selected_mode_key:
             # Should not happen if one is checked by default, but good practice
             QMessageBox.critical(self, "Error", "No action mode (Step 1b) selected.")
             return
        selected_mode = MODES[selected_mode_key]

        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = self.action_output_dir
        project_folder_name = self.script_dir.name # Get project folder name
        log_status_tag = "_inclLogs" if include_logs_in_output else "_exclLogs"
        # Construct filename: action_PROJECTNAME_MODE_LOGSTATUS_TIMESTAMP.txt
        output_filename = f"action_{project_folder_name}_{selected_mode_key}{log_status_tag}_{timestamp_str}.txt"
        output_file = output_dir / output_filename

        status_prefix = "Including" if include_logs_in_output else "Excluding"
        self.status_label.setText(f"{status_prefix} .log files. Generating action file: {output_filename}...")
        QApplication.processEvents() # Update UI

        try:
            output_dir.mkdir(parents=True, exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                # --- Content for Action Prompt ---
                f.write('<goal or issue to address>\n')
                f.write(goal_text + '\n')
                f.write('</goal or issue to address>\n\n\n')

                f.write('<output instruction>\n')
                f.write(selected_mode["output_instruction"] + '\n')
                f.write('</output instruction>\n\n\n')

                f.write("<Tree of Included Files>\n")
                sorted_rel_paths = sorted(selected_relative_paths, key=lambda p: p.as_posix())
                for rel_path in sorted_rel_paths:
                    f.write(f"- {rel_path.as_posix()}\n")

                # Check if any log files EXIST in the project (using the map values)
                # and if they were excluded by the checkbox setting.
                log_files_exist_in_project = any(
                    item.data(PathRole).suffix.lower() == '.log'
                    for item in self.item_path_map.values()
                    if item.data(PathRole) and isinstance(item.data(PathRole), Path) # Check data exists and is Path
                )

                if not include_logs_in_output and log_files_exist_in_project:
                     # Add note only if logs exist in the project but were excluded by the checkbox
                     f.write("\n(Note: .log files were present but excluded from this context based on selection.)\n")

                f.write("</Tree of Included Files>\n\n\n")

                f.write("<Concatenated Source Code>\n\n")
                for rel_path in sorted_rel_paths:
                    abs_path = self.script_dir / rel_path
                    rel_path_str = rel_path.as_posix()
                    f.write(f"<file path='{rel_path_str}'>\n")
                    content = read_file_content(abs_path)
                    if content is not None:
                        f.write(content)
                    else:
                         f.write(f"--- Error reading file: {rel_path_str} ---")
                    f.write("\n</file>\n\n") # Add a newline before closing tag for clarity
                f.write("</Concatenated Source Code>")

            relative_output_path = output_file.relative_to(self.script_dir)
            self.status_label.setText(f"Successfully generated action file: {relative_output_path}")
            QMessageBox.information(self, "Step 1b Success", f"Action file created:\n{relative_output_path}\n\nPaste this entire file content into the LLM, then paste the LLM's response into the Step 2 input box below.")

        except Exception as e:
            self.status_label.setText(f"Error generating action file: {e}")
            QMessageBox.critical(self, "Step 1b Error", f"Could not generate action file.\nError: {e}")
            # Print detailed error including traceback for debugging
            print(f"Error details during final generation:")
            traceback.print_exc()


    @Slot()
    def apply_llm_changes(self):
        """Parses LLM response, creates backups, applies changes, and enables Undo."""
        llm_response = self.llm_response_input.toPlainText().strip()
        if not llm_response:
            QMessageBox.warning(self, "Input Missing", "Please paste the LLM response into the 'Step 2' input box.")
            return

        # --- Clear previous undo state ---
        self._cleanup_backup_dir() # Remove any old temp dir first
        self.last_applied_changes = []
        self.undo_button.setEnabled(False)

        self.status_label.setText("Parsing LLM response...")
        QApplication.processEvents()

        try:
            # Use the pre-compiled regex to find all file blocks
            file_blocks = FILE_BLOCK_REGEX.findall(llm_response)
        except Exception as e:
            # Regex errors are unlikely but possible with complex patterns
            self.status_label.setText("Error parsing LLM response.")
            QMessageBox.critical(self, "Parsing Error", f"Could not parse response using regex.\nError: {e}")
            return

        if not file_blocks:
            self.status_label.setText("No file blocks found.")
            QMessageBox.information(self, "No Changes Found", "No `<file path='...'>...</file>` blocks found in the Step 2 input. Ensure the response uses this exact format.")
            return

        self.status_label.setText(f"Found {len(file_blocks)} file blocks. Validating paths...")
        QApplication.processEvents()

        valid_changes_to_confirm = []
        skipped_files = []
        project_root_resolved = self.script_dir.resolve()

        for path_str, raw_content in file_blocks: # Renamed 'content' to 'raw_content'
            # Normalize path extracted from regex group 1
            relative_path_str = path_str.strip().replace("\\", "/").strip('/')
            if not relative_path_str:
                 skipped_files.append("(Empty path provided in <file> tag)")
                 continue

            try:
                # Resolve the absolute path safely
                abs_path = (project_root_resolved / relative_path_str).resolve()

                # --- Security/Validation Checks ---
                # 1. Ensure path stays within the project directory
                if not abs_path.is_relative_to(project_root_resolved):
                    skipped_files.append(f"{relative_path_str} (Path is outside project directory)")
                    print(f"Security Warning: Skipping path outside project root: {abs_path}")
                    continue

                # 2. Check if parent directory exists and is actually a directory
                parent_dir = abs_path.parent
                # Allow creation of parent dirs later, but check if *existing* parent is a file
                if parent_dir.exists() and not parent_dir.is_dir():
                     skipped_files.append(f"{relative_path_str} (Parent path exists but is a file)")
                     print(f"Error: Cannot write file {relative_path_str}, parent path {parent_dir} is a file.")
                     continue

                # 3. Check if the target path itself is an existing directory
                if abs_path.is_dir():
                    skipped_files.append(f"{relative_path_str} (Path points to an existing directory)")
                    print(f"Error: Cannot overwrite directory with file: {relative_path_str}")
                    continue

                # If all checks pass, add to list for confirmation
                valid_changes_to_confirm.append({
                    "abs_path": abs_path,
                    "raw_content": raw_content, # Store the raw content captured by regex
                    "rel_path_str": relative_path_str
                })

            except Exception as e:
                # Catch potential errors during path resolution or checks
                skipped_files.append(f"{relative_path_str} (Validation Error: {e})")
                print(f"Error validating path {relative_path_str}: {e}")
                continue

        if not valid_changes_to_confirm:
            self.status_label.setText("No valid file paths found after validation.")
            msg = "No valid file changes found in the response after validation."
            if skipped_files:
                msg += "\n\nSkipped paths:\n- " + "\n- ".join(skipped_files)
            QMessageBox.warning(self, "No Valid Changes", msg)
            return

        # --- Confirmation Dialog ---
        confirmation_message = f"Found {len(valid_changes_to_confirm)} valid file change(s) to apply:\n\n"
        for change in valid_changes_to_confirm:
            rel_path_display = change['rel_path_str']
            status = " (Will be created)" if not change['abs_path'].exists() else " (Will be overwritten)"
            confirmation_message += f"- {rel_path_display}{status}\n"

        confirmation_message += "\nBackups will be created in a temporary directory for overwritten files.\nCode fences (```) will be automatically stripped from content if found.\n\nProceed with applying these changes?"

        if skipped_files:
             # Show skipped files in a scrollable text box within the message box if there are many
             if len(skipped_files) > 5:
                  detailed_skipped = "\n\nSkipped paths:\n" + "\n".join(f"- {s}" for s in skipped_files)
                  msg_box = QMessageBox(self)
                  msg_box.setIcon(QMessageBox.Icon.Question)
                  msg_box.setWindowTitle("Confirm Changes")
                  msg_box.setText(confirmation_message + f"\n\nNote: {len(skipped_files)} path(s) were skipped (see details).")
                  msg_box.setDetailedText(detailed_skipped)
                  msg_box.setStandardButtons(QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
                  msg_box.setDefaultButton(QMessageBox.StandardButton.No)
                  reply = msg_box.exec()
             else:
                  confirmation_message += f"\n\nNote: {len(skipped_files)} path(s) skipped:\n- " + "\n- ".join(skipped_files)
                  reply = QMessageBox.question(self, "Confirm Changes", confirmation_message,
                                     QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                                     QMessageBox.StandardButton.No)
        else:
             reply = QMessageBox.question(self, "Confirm Changes", confirmation_message,
                                     QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                                     QMessageBox.StandardButton.No)


        if reply != QMessageBox.StandardButton.Yes: # Check for explicit Yes
            self.status_label.setText("Changes cancelled by user.")
            return

        # --- Create Backup Directory ---
        try:
            # Create a unique temporary directory for this operation's backups
            self.temp_backup_dir = Path(tempfile.mkdtemp(prefix="script_aggregator_undo_"))
            print(f"Created temporary backup directory: {self.temp_backup_dir}")
        except Exception as e:
            self.status_label.setText("Error creating backup directory.")
            QMessageBox.critical(self, "Backup Error", f"Could not create temporary backup directory.\nError: {e}")
            self.temp_backup_dir = None # Ensure it's None if creation failed
            return

        # --- Apply Changes & Create Backups ---
        self.status_label.setText(f"Applying changes to {len(valid_changes_to_confirm)} file(s)...")
        QApplication.processEvents()

        success_count = 0
        failed_files = []
        self.last_applied_changes = [] # Reset just before applying

        for change in valid_changes_to_confirm:
            abs_path = change["abs_path"]
            raw_content = change["raw_content"] # Use the raw captured content
            rel_path_str = change["rel_path_str"]
            backup_path = None
            was_created = False

            try:
                # --- Backup Logic ---
                if abs_path.exists():
                    # File exists, create backup before overwriting
                    safe_filename_part = rel_path_str.replace('/', '_').replace('\\', '_')
                    backup_filename = f"{safe_filename_part}_{datetime.now().strftime('%Y%m%d%H%M%S%f')}.bak"
                    backup_path = self.temp_backup_dir / backup_filename
                    shutil.copy2(abs_path, backup_path) # copy2 preserves metadata
                    print(f"Backed up '{rel_path_str}' to '{backup_path.name}' in temp dir")
                    was_created = False
                else:
                    # File doesn't exist, will be created
                    was_created = True
                    backup_path = None # No backup needed for created files

                # --- Strip Code Fences ---
                content_to_write = raw_content # Start with the raw content
                # Use strip() first to handle leading/trailing whitespace around the whole block
                stripped_raw_content = raw_content.strip()
                fences_stripped = False

                # Check for fences using startswith/endswith on the stripped content
                # Allows for ```language or just ```
                if stripped_raw_content.startswith("```") and stripped_raw_content.endswith("```"):
                    # Find the first newline after the opening fence
                    first_newline_index = stripped_raw_content.find('\n')
                    # Find the last newline before the closing fence (or start if no newline)
                    # Search up to the start of the closing ```
                    last_newline_index = stripped_raw_content.rfind('\n', 0, len(stripped_raw_content) - 3)

                    if first_newline_index != -1: # Found a newline after opening fence
                        # Content starts after the first newline
                        content_start_index = first_newline_index + 1
                        # Content ends before the last newline (if one exists before ```) or right before ```
                        content_end_index = last_newline_index if last_newline_index != -1 and last_newline_index >= content_start_index else len(stripped_raw_content) - 3

                        # Extract the content between the fences
                        # Check if end index is valid before slicing
                        if content_end_index >= content_start_index:
                             extracted_content = stripped_raw_content[content_start_index:content_end_index]
                             # Strip only leading/trailing whitespace/newlines from the *extracted* part
                             content_to_write = extracted_content.strip()
                             fences_stripped = True
                        else: # Edge case: ```\n```
                             content_to_write = ""
                             fences_stripped = True

                    else:
                        # Handle case like ```content``` (no newlines) or ``` ```
                        # Content is between the first ``` and the last ```
                        content_start_index = stripped_raw_content.find('`')+3 # Start after ```
                        content_end_index = len(stripped_raw_content) - 3 # End before ```
                        if content_start_index <= content_end_index:
                            extracted_content = stripped_raw_content[content_start_index:content_end_index]
                            content_to_write = extracted_content.strip() # Strip whitespace from content
                            fences_stripped = True
                        else: # Likely just ``` ```
                            content_to_write = ""
                            fences_stripped = True

                    if fences_stripped:
                        print(f"Stripped code fences for: {rel_path_str}")

                # --- Write File ---
                # Ensure parent directory exists before writing
                abs_path.parent.mkdir(parents=True, exist_ok=True)
                with open(abs_path, 'w', encoding='utf-8') as f:
                    # Write the potentially cleaned content
                    f.write(content_to_write)

                # --- Record Change for Undo ---
                self.last_applied_changes.append({
                    "original_path": abs_path,
                    "backup_path": backup_path, # Will be None if created
                    "was_created": was_created
                })
                success_count += 1
                action = "Created" if was_created else "Overwritten"
                print(f"Successfully {action}: {rel_path_str}")

            except (IOError, OSError, shutil.Error) as e:
                failed_files.append(f"{rel_path_str} (Write/Backup Error: {e})")
                print(f"Error processing file {rel_path_str}: {e}")
                # Attempt to rollback this specific file if backup exists? (Could get complex, skip for now)
            except Exception as e:
                # Catch any other unexpected errors during file processing
                failed_files.append(f"{rel_path_str} (Unexpected Error: {e})")
                print(f"Unexpected error processing file {rel_path_str}: {e}")
                traceback.print_exc() # Print traceback for unexpected errors

        # --- Final Report ---
        final_message = f"Apply complete. {success_count} file(s) updated/created."
        if failed_files:
            final_message += f"\nFailed to apply changes to {len(failed_files)} file(s):\n- " + "\n- ".join(failed_files)
            QMessageBox.warning(self, "Apply Partially Failed", final_message)
        elif success_count > 0: # Only show success message if something actually happened
             QMessageBox.information(self, "Apply Successful", final_message + "\nUndo is now available.")
        elif not failed_files and success_count == 0: # Should not happen if confirmation passed, but handle defensively
             final_message = "No changes were applied (though some were expected)."
             QMessageBox.information(self, "No Changes Applied", final_message)


        if skipped_files and success_count == 0 and not failed_files:
             # If only skipped files occurred, mention that specifically
             final_message = f"No changes applied. {len(skipped_files)} path(s) were skipped during validation."
        elif skipped_files:
             # Append skipped info if other actions occurred
             final_message += f"\n({len(skipped_files)} initial path(s) skipped during validation)"

        self.status_label.setText(final_message)

        # --- Enable Undo Button if successful changes were made and recorded ---
        if self.last_applied_changes: # Check if any changes were successfully recorded for undo
            self.undo_button.setEnabled(True)
        else:
            # If all failed or were skipped, cleanup the (likely empty) backup dir
             self._cleanup_backup_dir()
             self.undo_button.setEnabled(False)


    # --- NEW SLOT ---
    @Slot()
    def undo_last_apply(self):
        """Reverts the last set of applied changes using backups."""
        if not self.last_applied_changes:
            QMessageBox.information(self, "Undo", "No changes have been applied since the last undo or startup.")
            self.undo_button.setEnabled(False) # Ensure button is disabled
            return
        if not self.temp_backup_dir or not self.temp_backup_dir.exists():
             # Check if dir exists as well, might have been cleaned up prematurely
             QMessageBox.warning(self, "Undo Error", "Cannot undo: Backup directory information is missing or directory was removed.")
             self.last_applied_changes = [] # Clear state if backup is gone
             self.undo_button.setEnabled(False) # Disable button if state is inconsistent
             return

        reply = QMessageBox.question(self, "Confirm Undo",
                                     f"This will revert the last {len(self.last_applied_changes)} file change(s) applied in Step 2.\n\nProceed with Undo?",
                                     QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                                     QMessageBox.StandardButton.No)

        if reply == QMessageBox.StandardButton.No:
            return

        self.status_label.setText("Undoing changes...")
        QApplication.processEvents()

        undo_success_count = 0
        undo_failed_files = []

        # Iterate through the recorded changes (order might matter if dirs were involved, but likely ok here)
        for change_info in self.last_applied_changes:
            original_path = change_info["original_path"]
            backup_path = change_info["backup_path"]
            was_created = change_info["was_created"]
            rel_path_str = "UnknownPath" # Default
            try:
                 # Get relative path for messages, handle potential error if outside script_dir (shouldn't happen with validation)
                 rel_path_str = original_path.relative_to(self.script_dir).as_posix()
            except ValueError:
                 rel_path_str = str(original_path) # Fallback to absolute path string

            try:
                if was_created:
                    # If the file was newly created by 'apply', delete it
                    if original_path.exists() and original_path.is_file(): # Check it's a file before unlinking
                        original_path.unlink() # Delete the file
                        print(f"Undo: Deleted newly created file '{rel_path_str}'")
                        undo_success_count += 1
                    elif not original_path.exists():
                        # File already deleted? Count as success for undo.
                        print(f"Undo: Newly created file '{rel_path_str}' was already deleted.")
                        undo_success_count += 1
                    else:
                         # Path exists but is not a file (e.g., a directory was created somehow?) - report error
                         undo_failed_files.append(f"{rel_path_str} (Cannot delete, path is not a file)")
                         print(f"Error: Cannot undo creation of '{rel_path_str}', path exists but is not a file.")

                else:
                    # If the file was overwritten, restore from backup
                    if backup_path and backup_path.exists() and backup_path.is_file():
                        # Ensure parent dir exists before restoring (it should, but safety check)
                        original_path.parent.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(backup_path, original_path) # Restore content and metadata
                        print(f"Undo: Restored '{rel_path_str}' from backup '{backup_path.name}'.")
                        undo_success_count += 1
                    elif backup_path and not backup_path.exists():
                        # Backup missing! Cannot restore.
                        undo_failed_files.append(f"{rel_path_str} (Backup file missing: {backup_path.name})")
                        print(f"Error: Cannot undo '{rel_path_str}', backup file missing: {backup_path}")
                    elif backup_path and not backup_path.is_file():
                         # Backup path exists but isn't a file
                         undo_failed_files.append(f"{rel_path_str} (Backup path is not a file: {backup_path.name})")
                         print(f"Error: Cannot undo '{rel_path_str}', backup path is not a file: {backup_path}")
                    elif not backup_path:
                        # Should not happen if was_created is False, but handle defensively
                         undo_failed_files.append(f"{rel_path_str} (Invalid state: Overwritten but no backup path recorded)")
                         print(f"Error: Cannot undo '{rel_path_str}', invalid state (no backup path).")

            except (IOError, OSError, shutil.Error) as e:
                 undo_failed_files.append(f"{rel_path_str} (Undo Error: {e})")
                 print(f"Error undoing change for {rel_path_str}: {e}")
            except Exception as e:
                 # Catch any other unexpected errors during undo
                 undo_failed_files.append(f"{rel_path_str} (Unexpected Undo Error: {e})")
                 print(f"Unexpected error undoing change for {rel_path_str}: {e}")

        # --- Report Undo Status ---
        final_message = f"Undo complete: {undo_success_count} change(s) reverted."
        if undo_failed_files:
            final_message += f"\nFailed to undo {len(undo_failed_files)} change(s):\n- " + "\n- ".join(undo_failed_files)
            QMessageBox.warning(self, "Undo Partially Failed", final_message + "\nManual check recommended.")
        elif undo_success_count > 0: # Only show success if something was reverted
            QMessageBox.information(self, "Undo Successful", final_message)
        else: # No successes and no failures (e.g., files were already deleted)
             QMessageBox.information(self, "Undo Complete", "Undo process finished. No files needed reverting (e.g., they were already in the target state).")


        self.status_label.setText(final_message)

        # --- Cleanup and Reset State ---
        self._cleanup_backup_dir() # Remove the temp backup dir
        self.last_applied_changes = [] # Clear the list of changes
        self.undo_button.setEnabled(False) # Disable undo button

        # Optional: Refresh tree view after undo? Might be useful if files were created/deleted.
        # print("Refreshing file tree after undo...")
        # self.populate_file_tree()
        # file_count = self.count_files_in_model()
        # self.status_label.setText(f"{final_message} | Found {file_count} files.")


    # --- Helper for cleaning up backup dir ---
    def _cleanup_backup_dir(self):
        """Safely removes the temporary backup directory if it exists."""
        if self.temp_backup_dir and self.temp_backup_dir.exists():
            try:
                shutil.rmtree(self.temp_backup_dir)
                print(f"Removed temporary backup directory: {self.temp_backup_dir}")
            except (IOError, OSError) as e:
                print(f"Warning: Could not remove temporary backup directory: {self.temp_backup_dir}\nError: {e}")
                # Optionally inform user if cleanup fails non-critically
                # QMessageBox.warning(self, "Cleanup Warning", f"Could not automatically remove the temporary backup directory:\n{self.temp_backup_dir}\nYou may need to remove it manually.\nError: {e}")
            finally:
                 self.temp_backup_dir = None # Reset path regardless of success

    # --- Ensure cleanup on exit ---
    def closeEvent(self, event):
        """Ensure temporary directory is cleaned up when the application closes."""
        print("Close event triggered, cleaning up backup directory...")
        self._cleanup_backup_dir()
        event.accept() # Proceed with closing the window

    @Slot()
    def generate_alt_planning_request(self):
        """Generates the Step 1b_alt.1 request file for conceptual planning."""
        goal = self.goal_input.toPlainText().strip()
        if not goal:
            QMessageBox.warning(self, "Input Missing", "Please describe your overall goal for Step 1b_alt.1.")
            return
            
        self.status_label.setText("Generating alternative planning request...")
        QApplication.processEvents()
        
        # Get selected files (same as in generate_final_output_file)
        include_logs_in_output = self.include_logs_checkbox.isChecked()
        selected_relative_paths = []
        for item in self.item_path_map.values():
            if item.isCheckable() and item.checkState() == Qt.CheckState.Checked:
                rel_path = item.data(PathRole)
                if rel_path and isinstance(rel_path, Path):
                    if not include_logs_in_output and rel_path.suffix.lower() == '.log':
                        continue
                    selected_relative_paths.append(rel_path)
                    
        if not selected_relative_paths:
            msg = "Please select at least one file in the tree view before executing Step 1b_alt.1."
            if not include_logs_in_output:
                msg += "\nNote: .log files are currently excluded based on the checkbox setting. Ensure other files are selected."
            QMessageBox.warning(self, "No Files Selected", msg)
            return
            
        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = self.planning_alt_output_dir
        project_folder_name = self.script_dir.name 
        log_status_tag = "_inclLogs" if include_logs_in_output else "_exclLogs"
        output_filename = f"planning_alt_{project_folder_name}{log_status_tag}_{timestamp_str}.txt"
        output_file = output_dir / output_filename
        
        self.status_label.setText(f"Generating alternative planning file: {output_filename}...")
        QApplication.processEvents()
        
        try:
            output_dir.mkdir(parents=True, exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                # --- Content for Alternative Planning ---
                f.write('<goal or issue to address>\n')
                f.write(goal + '\n')
                f.write('</goal or issue to address>\n\n\n')
                
                # Use the planning_alt mode instructions
                planning_alt_mode = MODES["planning_alt"]
                f.write('<output instruction>\n')
                f.write(planning_alt_mode["output_instruction"] + '\n')
                f.write('</output instruction>\n\n\n')
                
                f.write("<Tree of Included Files>\n")
                sorted_rel_paths = sorted(selected_relative_paths, key=lambda p: p.as_posix())
                for rel_path in sorted_rel_paths:
                    f.write(f"- {rel_path.as_posix()}\n")
                    
                if not include_logs_in_output and any(
                    item.data(PathRole).suffix.lower() == '.log'
                    for item in self.item_path_map.values()
                    if item.data(PathRole) and isinstance(item.data(PathRole), Path)
                ):
                    f.write("\n(Note: .log files were present but excluded from this context based on selection.)\n")
                    
                f.write("</Tree of Included Files>\n\n\n")
                
                f.write("<Concatenated Source Code>\n\n")
                for rel_path in sorted_rel_paths:
                    abs_path = self.script_dir / rel_path
                    rel_path_str = rel_path.as_posix()
                    f.write(f"<file path='{rel_path_str}'>\n")
                    content = read_file_content(abs_path)
                    if content is not None:
                        f.write(content)
                    else:
                        f.write(f"--- Error reading file: {rel_path_str} ---")
                    f.write("\n</file>\n\n")
                f.write("</Concatenated Source Code>")
                
            relative_output_path = output_file.relative_to(self.script_dir)
            self.status_label.setText(f"Successfully generated planning file: {relative_output_path}")
            QMessageBox.information(self, "Step 1b_alt.1 Success", 
                                   f"Alternative planning file created:\n{relative_output_path}\n\nPaste this file content into the LLM, then paste the LLM's response into the Step 1b_alt.1 Response box.")
            self.alt_path_enabled = True
            
        except Exception as e:
            self.status_label.setText(f"Error generating alternative planning file: {e}")
            QMessageBox.critical(self, "Step 1b_alt.1 Error", f"Could not generate alternative planning file.\nError: {e}")
            print(f"Error details during alt planning generation:")
            traceback.print_exc()
    
    @Slot()
    def generate_alt_final_output_file(self):
        """Generates the Step 1b_alt.2 file for LLM action with planning context."""
        goal = self.goal_input.toPlainText().strip()
        if not goal:
            QMessageBox.warning(self, "Input Missing", "Please describe your overall goal for Step 1b_alt.2.")
            return
            
        planning_response = self.planning_alt_response_input.toPlainText().strip()
        if not planning_response:
            QMessageBox.warning(self, "Input Missing", "Please paste the LLM response from Step 1b_alt.1 in the response box.")
            return
            
        # Parse the file_plan blocks from the planning response
        try:
            file_plans = FILE_PLAN_BLOCK_REGEX.findall(planning_response)
            if not file_plans:
                QMessageBox.warning(self, "No File Plans Found", "No <file_plan path='...'>...</file_plan> blocks found in the response. Please check the format.")
                return
                
            self.file_plans = file_plans
            self.status_label.setText(f"Found {len(file_plans)} file plan blocks. Generating action file...")
            QApplication.processEvents()
            
        except Exception as e:
            self.status_label.setText("Error parsing planning response.")
            QMessageBox.critical(self, "Parsing Error", f"Could not parse file plans using regex.\nError: {e}")
            return
            
        # Now generate the final output file similar to generate_final_output_file
        include_logs_in_output = self.include_logs_checkbox.isChecked()
        selected_relative_paths = []
        for item in self.item_path_map.values():
            if item.isCheckable() and item.checkState() == Qt.CheckState.Checked:
                rel_path = item.data(PathRole)
                if rel_path and isinstance(rel_path, Path):
                    if not include_logs_in_output and rel_path.suffix.lower() == '.log':
                        continue
                    selected_relative_paths.append(rel_path)
                    
        if not selected_relative_paths:
            msg = "Please select at least one file in the tree view before executing Step 1b_alt.2."
            if not include_logs_in_output:
                msg += "\nNote: .log files are currently excluded based on the checkbox setting. Ensure other files are selected."
            QMessageBox.warning(self, "No Files Selected", msg)
            return
            
        selected_mode_key = None
        for key, button in self.mode_buttons.items():
            if button.isChecked():
                selected_mode_key = key
                break
        if not selected_mode_key:
            QMessageBox.critical(self, "Error", "No action mode selected.")
            return
        selected_mode = MODES[selected_mode_key]
        
        timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = self.action_alt_output_dir
        project_folder_name = self.script_dir.name
        log_status_tag = "_inclLogs" if include_logs_in_output else "_exclLogs"
        output_filename = f"action_alt_{project_folder_name}_{selected_mode_key}{log_status_tag}_{timestamp_str}.txt"
        output_file = output_dir / output_filename
        
        status_prefix = "Including" if include_logs_in_output else "Excluding"
        self.status_label.setText(f"{status_prefix} .log files. Generating alternative action file: {output_filename}...")
        QApplication.processEvents()
        
        try:
            output_dir.mkdir(parents=True, exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                # --- Content for Alternative Action Prompt ---
                f.write('<goal or issue to address>\n')
                f.write(goal + '\n')
                f.write('</goal or issue to address>\n\n\n')
                
                f.write('<output instruction>\n')
                f.write(selected_mode["output_instruction"] + '\n')
                f.write('</output instruction>\n\n\n')
                
                # Include the file plans section
                f.write("<File Plans from Step 1b_alt.1>\n")
                for path_str, plan_content in self.file_plans:
                    normalized_path = path_str.strip().replace("\\", "/").strip('/')
                    f.write(f"<file_plan path='{normalized_path}'>\n")
                    f.write(plan_content.strip() + "\n")
                    f.write("</file_plan>\n\n")
                f.write("</File Plans from Step 1b_alt.1>\n\n\n")
                
                # Include the file tree
                f.write("<Tree of Included Files>\n")
                sorted_rel_paths = sorted(selected_relative_paths, key=lambda p: p.as_posix())
                for rel_path in sorted_rel_paths:
                    f.write(f"- {rel_path.as_posix()}\n")
                    
                if not include_logs_in_output and any(
                    item.data(PathRole).suffix.lower() == '.log'
                    for item in self.item_path_map.values()
                    if item.data(PathRole) and isinstance(item.data(PathRole), Path)
                ):
                    f.write("\n(Note: .log files were present but excluded from this context based on selection.)\n")
                    
                f.write("</Tree of Included Files>\n\n\n")
                
                # Include the source code
                f.write("<Concatenated Source Code>\n\n")
                for rel_path in sorted_rel_paths:
                    abs_path = self.script_dir / rel_path
                    rel_path_str = rel_path.as_posix()
                    f.write(f"<file path='{rel_path_str}'>\n")
                    content = read_file_content(abs_path)
                    if content is not None:
                        f.write(content)
                    else:
                        f.write(f"--- Error reading file: {rel_path_str} ---")
                    f.write("\n</file>\n\n")
                f.write("</Concatenated Source Code>")
                
            relative_output_path = output_file.relative_to(self.script_dir)
            self.status_label.setText(f"Successfully generated alternative action file: {relative_output_path}")
            QMessageBox.information(self, "Step 1b_alt.2 Success", 
                                   f"Alternative action file created:\n{relative_output_path}\n\nPaste this file content into the LLM, then paste the LLM's response into the Step 2 input box below.")
            
        except Exception as e:
            self.status_label.setText(f"Error generating alternative action file: {e}")
            QMessageBox.critical(self, "Step 1b_alt.2 Error", f"Could not generate alternative action file.\nError: {e}")
            print(f"Error details during alternative action generation:")
            traceback.print_exc()


# --- Main Execution ---
if __name__ == "__main__":
    # Determine the directory where the script is running
    if getattr(sys, 'frozen', False):
        # If running as a bundled executable (e.g., PyInstaller)
        application_path = Path(sys.executable).parent
        script_name = Path(sys.executable).name
    else:
        # If running as a normal Python script
        application_path = Path(__file__).parent
        script_name = Path(__file__).name

    script_dir_abs = application_path.resolve()
    print(f"Running script '{script_name}' from directory: {script_dir_abs}")

    # Set up the Qt Application
    app = QApplication(sys.argv)
    # Apply a style if desired (optional)
    # app.setStyle('Fusion')

    # Create and show the main window
    window = ScriptAggregatorApp(script_dir=script_dir_abs, script_name=script_name)
    window.show()

    # Start the Qt event loop
    sys.exit(app.exec())
</file>

<file path='app/api/__init__.py'>

</file>

<file path='app/api/admin.py'>
# app/api/admin.py
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from sqlalchemy import func, select, case
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Any

from core.database import get_db
from models.user import User
from models.job import Job, JobStatus
from schemas.admin import SystemStatsResponse, RecentJobsResponse, RecentJobItem
from api.auth import get_current_active_superuser
from core.logging_config import get_logger
# --- UPDATED IMPORT ---
from api.health_utils import health_check # Import health check function from new location
# --- END UPDATED IMPORT ---

logger = get_logger("vendor_classification.admin_api")

router = APIRouter()

@router.get("/stats", response_model=SystemStatsResponse)
async def get_admin_stats(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_superuser) # Ensures only superusers can access
):
    """
    Provides aggregated system statistics for the admin dashboard.
    Requires superuser privileges.
    """
    logger.info(f"Admin stats request by superuser: {current_user.username}")
    try:
        # User Counts
        total_users = db.query(func.count(User.id)).scalar()

        # Job Counts
        total_jobs = db.query(func.count(Job.id)).scalar()
        pending_jobs = db.query(func.count(Job.id)).filter(Job.status == JobStatus.PENDING.value).scalar()
        processing_jobs = db.query(func.count(Job.id)).filter(Job.status == JobStatus.PROCESSING.value).scalar()
        completed_jobs = db.query(func.count(Job.id)).filter(Job.status == JobStatus.COMPLETED.value).scalar()

        # Failed Jobs in the last 24 hours
        time_24h_ago = datetime.now(timezone.utc) - timedelta(hours=24)
        failed_jobs_last_24h = db.query(func.count(Job.id)).filter(
            Job.status == JobStatus.FAILED.value,
            Job.updated_at >= time_24h_ago # Use updated_at as completion/failure time indicator
        ).scalar()

        # Health Check Status (reuse existing logic from health_utils)
        health_status_data = await health_check()

        # TODO: Implement Estimated API Costs (requires cost tracking per job/API call)
        estimated_recent_cost = None # Placeholder

        stats = SystemStatsResponse(
            total_users=total_users or 0,
            total_jobs=total_jobs or 0,
            pending_jobs=pending_jobs or 0,
            processing_jobs=processing_jobs or 0,
            completed_jobs=completed_jobs or 0,
            failed_jobs_last_24h=failed_jobs_last_24h or 0,
            estimated_recent_cost=estimated_recent_cost,
            health_status=health_status_data # Include the full health check response
        )
        logger.debug("Admin stats calculated successfully.", extra={"stats": stats.model_dump(exclude={'health_status'})}) # Exclude verbose health status from log
        return stats

    except Exception as e:
        logger.error("Error fetching admin statistics", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Could not fetch system statistics."
        )

@router.get("/recent-jobs", response_model=RecentJobsResponse)
async def get_recent_jobs(
    limit: int = 15,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_superuser) # Ensures only superusers can access
):
    """
    Provides a list of the most recent jobs across all users.
    Requires superuser privileges.
    """
    logger.info(f"Recent jobs request by superuser: {current_user.username} (limit={limit})")
    try:
        recent_jobs_query = (
            select(
                Job.id,
                Job.created_by,
                Job.status,
                Job.created_at,
                Job.job_type,
                Job.company_name # Added company name for context
            )
            .order_by(Job.created_at.desc())
            .limit(limit)
        )
        results = db.execute(recent_jobs_query).all()

        # Map results to Pydantic model
        recent_jobs_list = [
            RecentJobItem(
                id=row.id,
                created_by=row.created_by,
                status=row.status,
                created_at=row.created_at,
                job_type=row.job_type,
                company_name=row.company_name
            ) for row in results
        ]

        logger.debug(f"Fetched {len(recent_jobs_list)} recent jobs.")
        return RecentJobsResponse(jobs=recent_jobs_list)

    except Exception as e:
        logger.error("Error fetching recent jobs", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Could not fetch recent jobs."
        )

</file>

<file path='app/api/auth.py'>
# <file path='app/api/auth.py'>

# app/api/auth.py
from fastapi import Depends, HTTPException, status, Request
from fastapi.security import OAuth2PasswordBearer
from jose import JWTError, jwt
from passlib.context import CryptContext
from datetime import datetime, timedelta, timezone # Added timezone
from typing import Optional, Dict, Any # Added Dict, Any
import uuid

from core.config import settings
# Import logger and context functions from refactored modules
from core.logging_config import get_logger
from core.log_context import set_user, get_user, get_correlation_id
# Import log helpers from utils
from utils.log_utils import LogTimer, log_function_call

from models.user import User
from core.database import get_db

# Configure logging using our custom logger
logger = get_logger("vendor_classification.auth")

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")

# --- Constants ---
PASSWORD_RESET_TOKEN_TYPE = "password_reset"
ACCESS_TOKEN_TYPE = "access"

@log_function_call(logger, include_args=False) # Don't log passwords
def verify_password(plain_password, hashed_password):
    """Verify password against hashed version."""
    try:
        with LogTimer(logger, "Password verification", include_in_stats=True):
            hash_prefix = hashed_password[:5] if hashed_password else None
            logger.debug(f"Verifying password", extra={"hash_prefix": hash_prefix})
            result = pwd_context.verify(plain_password, hashed_password)
            logger.debug(f"Password verification result", extra={"result": result})
            return result
    except Exception as e:
        logger.error(f"Password verification error: {type(e).__name__}", exc_info=False)
        return False

@log_function_call(logger, include_args=False) # Don't log password
def get_password_hash(password):
    """Generate password hash."""
    try:
        with LogTimer(logger, "Password hashing", include_in_stats=True):
            hashed = pwd_context.hash(password)
            logger.debug(f"Generated password hash", extra={"hash_prefix": hashed[:5] if hashed else None})
            return hashed
    except Exception as e:
        logger.error(f"Password hashing error", exc_info=True)
        raise

@log_function_call(logger, include_args=False) # Don't log password
def authenticate_user(db, username: str, password: str):
    """Authenticate user."""
    try:
        logger.info(f"Authentication attempt", extra={"username": username})
        with LogTimer(logger, f"User authentication", include_in_stats=True):
            user = db.query(User).filter(User.username == username).first()
            if not user:
                logger.warning(f"Authentication failed: user not found", extra={"username": username})
                return None
            logger.debug(f"User found in database", extra={"username": user.username, "user_id": user.id})
            if not verify_password(password, user.hashed_password):
                logger.warning(f"Authentication failed: invalid password", extra={"username": username})
                return None
            logger.info(f"Authentication successful", extra={"username": username, "user_id": user.id})
            return user
    except Exception as e:
        logger.error(f"Authentication error", exc_info=True, extra={"username": username})
        return None

# --- UPDATED: Generic Token Creation ---
@log_function_call(logger)
def _create_jwt_token(
    subject: str,
    expires_delta: timedelta,
    token_type: str,
    additional_claims: Optional[Dict[str, Any]] = None
) -> str:
    """Internal function to create a JWT token with specific type and claims."""
    try:
        with LogTimer(logger, f"{token_type} token creation", include_in_stats=True):
            logger.debug(f"Creating {token_type} token", extra={"subject": subject, "expires_in_seconds": expires_delta.total_seconds()})
            expire = datetime.now(timezone.utc) + expires_delta
            to_encode: Dict[str, Any] = {
                "sub": str(subject), # Ensure subject is string (e.g., user ID)
                "exp": expire,
                "iat": datetime.now(timezone.utc),
                "type": token_type, # Add token type claim
                "jti": str(uuid.uuid4()) # Add unique token identifier
            }
            if additional_claims:
                to_encode.update(additional_claims)

            encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
            logger.debug(f"{token_type} token created successfully", extra={"subject": subject, "expires_at": expire.isoformat(), "jti": to_encode["jti"]})
            return encoded_jwt
    except Exception as e:
        logger.error(f"{token_type} token creation error", exc_info=True, extra={"subject": subject})
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Could not create {token_type} token")

# --- Access Token Creation (uses generic function) ---
@log_function_call(logger)
def create_access_token(subject: str) -> str:
    """Creates a standard JWT access token."""
    expires_delta = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    return _create_jwt_token(
        subject=subject,
        expires_delta=expires_delta,
        token_type=ACCESS_TOKEN_TYPE
        # Add roles or other claims if needed: additional_claims={"roles": ["user"]}
    )

# --- ADDED: Password Reset Token Creation ---
@log_function_call(logger)
def create_password_reset_token(subject: str) -> str:
    """Creates a JWT token specifically for password reset."""
    expires_delta = timedelta(minutes=settings.PASSWORD_RESET_TOKEN_EXPIRE_MINUTES)
    return _create_jwt_token(
        subject=subject,
        expires_delta=expires_delta,
        token_type=PASSWORD_RESET_TOKEN_TYPE
    )

# --- ADDED: Generic Token Verification ---
def _verify_jwt_token(token: str, expected_token_type: str) -> Optional[str]:
    """
    Internal function to verify a JWT token, check its type, and return the subject.
    Raises HTTPException on validation errors.
    """
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    token_preview = token[:10] + "..." if token else "None"

    try:
        logger.debug(f"Attempting JWT decode for {expected_token_type} token", extra={"token_preview": token_preview})
        payload = jwt.decode(
            token,
            settings.SECRET_KEY,
            algorithms=[settings.ALGORITHM]
        )
        subject: Optional[str] = payload.get("sub")
        token_type: Optional[str] = payload.get("type")
        jti: Optional[str] = payload.get("jti") # Get unique identifier

        log_extra = {"subject": subject, "token_type": token_type, "jti": jti, "payload_keys": list(payload.keys()) if payload else []}

        if subject is None:
            logger.warning("JWT token missing 'sub' (subject) claim", extra=log_extra)
            credentials_exception.detail = "Invalid token: Missing subject."
            raise credentials_exception
        if token_type != expected_token_type:
            logger.warning(f"JWT token type mismatch. Expected '{expected_token_type}', got '{token_type}'", extra=log_extra)
            credentials_exception.detail = f"Invalid token type. Expected {expected_token_type}."
            raise credentials_exception

        # Optional: Check against a token blacklist (e.g., in Redis) using jti if implementing revocation
        # if is_token_revoked(jti):
        #    logger.warning(f"{expected_token_type} token has been revoked", extra=log_extra)
        #    credentials_exception.detail = "Token has been revoked."
        #    raise credentials_exception

        logger.debug(f"{expected_token_type} token decoded successfully", extra=log_extra)
        return subject

    except jwt.ExpiredSignatureError:
        logger.warning(f"{expected_token_type} token has expired", extra={"token_preview": token_preview})
        credentials_exception.detail = f"{expected_token_type.replace('_', ' ').title()} token has expired."
        raise credentials_exception
    except jwt.JWTClaimsError as claims_err:
        logger.error(f"JWT claims error during {expected_token_type} token decode: {str(claims_err)}", exc_info=False, extra={"error_details": str(claims_err), "token_preview": token_preview})
        credentials_exception.detail = f"Invalid token claims: {str(claims_err)}"
        raise credentials_exception
    except JWTError as jwt_err:
        logger.error(f"JWT decode error (JWTError) for {expected_token_type} token: {str(jwt_err)}", exc_info=False, extra={"error_details": str(jwt_err), "token_preview": token_preview})
        credentials_exception.detail = "Could not validate token credentials."
        if "invalid signature" in str(jwt_err).lower():
            credentials_exception.detail = "Invalid token signature."
        raise credentials_exception
    except Exception as decode_err:
        logger.error(f"Unexpected error during {expected_token_type} token JWT decode", exc_info=True, extra={"error_details": str(decode_err)})
        credentials_exception.detail = "An unexpected error occurred during token validation."
        raise credentials_exception


# --- ADDED: Password Reset Token Verification ---
def verify_password_reset_token(token: str) -> Optional[str]:
    """
    Verifies a password reset token and returns the user ID (subject).
    Raises HTTPException on errors.
    """
    logger.info("Verifying password reset token.")
    # Use the generic verification function, expecting the specific type
    # Note: We are returning the subject (user_id) directly here.
    # The calling function (/reset-password endpoint) will handle user lookup.
    return _verify_jwt_token(token, expected_token_type=PASSWORD_RESET_TOKEN_TYPE)


async def get_current_user(request: Request, db = Depends(get_db)):
    """Get current user from the JWT token by manually reading header."""
    correlation_id = get_correlation_id() or str(uuid.uuid4())
    logger.debug(f"===> Entered get_current_user function (manual header read)", extra={'correlation_id': correlation_id})

    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer", "X-Correlation-ID": correlation_id},
    )

    token: Optional[str] = None
    try:
        logger.debug("Attempting to manually get Authorization header...")
        auth_header: Optional[str] = request.headers.get("Authorization")
        if not auth_header:
            logger.warning("Authorization header missing")
            raise credentials_exception

        parts = auth_header.split()
        if len(parts) == 1 or parts[0].lower() != "bearer":
                logger.warning(f"Invalid Authorization header format. Header starts with: '{auth_header[:20]}...'")
                if len(parts) == 1 and len(parts[0]) > 20:
                    token = parts[0]
                    logger.warning("Assuming token was provided without 'Bearer ' prefix.")
                else:
                    raise credentials_exception
        elif len(parts) > 2:
                logger.warning(f"Authorization header has too many parts. Header starts with: '{auth_header[:40]}...'")
                raise credentials_exception
        else:
            token = parts[1]

        token_preview = token[:10] + "..." if token else "None"
        logger.debug(f"Manually extracted token: {token_preview}")

    except HTTPException:
        raise
    except Exception as header_err:
        logger.error(f"Error manually extracting token from header", exc_info=True, extra={"error_details": str(header_err)})
        raise credentials_exception

    # --- Use generic verification for access token ---
    username = _verify_jwt_token(token, expected_token_type=ACCESS_TOKEN_TYPE)
    # _verify_jwt_token raises HTTPException on failure, so no need to check username is None here
    # --- End generic verification ---

    user = None
    try:
        logger.debug(f"Looking up user in database", extra={"username": username})
        # --- MODIFIED: Fetch user by username from token ---
        user = db.query(User).filter(User.username == username).first()
        # --- END MODIFIED ---
        if user is None:
            logger.warning(f"User '{username}' not found in database after token decode")
            # Reuse the credentials exception from _verify_jwt_token if possible, or create new
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="User associated with token not found.",
                headers={"WWW-Authenticate": "Bearer"},
            )


        # --- Set user context HERE after successful validation ---
        set_user(user) # Store the full user object in context
        # --- End set user context ---
        logger.debug(f"User found, returning user object.", extra={"username": user.username, "user_id": user.id})
        return user
    except HTTPException:
            raise
    except Exception as db_err:
        logger.error(f"Database error during user lookup in get_current_user", exc_info=True, extra={"error_details": str(db_err)})
        credentials_exception.detail = "Database error during authentication"
        raise credentials_exception

async def get_current_active_user(current_user: User = Depends(get_current_user)):
    """Dependency to get the current user and ensure they are active."""
    if not current_user.is_active:
        logger.warning(f"Authentication failed: User '{current_user.username}' is inactive.")
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Inactive user")
    logger.debug(f"User '{current_user.username}' is active.")
    return current_user

async def get_current_active_superuser(current_user: User = Depends(get_current_active_user)):
    """Dependency to get the current active user and ensure they are a superuser."""
    if not current_user.is_superuser:
        logger.warning(f"Authorization failed: User '{current_user.username}' is not a superuser.")
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="The user doesn't have enough privileges"
        )
    logger.debug(f"User '{current_user.username}' is an active superuser.")
    return current_user
#</file>
</file>

<file path='app/api/health_utils.py'>
# app/api/health_utils.py
import socket
import sqlalchemy
import httpx
import os
from datetime import datetime, timezone
from fastapi import HTTPException, status # Import if needed for direct use, though health_check returns dict

# --- Core Imports ---
from core import config # Import config module directly
from core.config import settings
from core.database import SessionLocal
from core.logging_config import get_logger
from tasks.celery_app import celery_app

logger = get_logger("vendor_classification.health_check")

# --- Moved Health Check Logic ---
async def health_check():
    """Health check logic, moved from main.py to avoid circular imports."""
    hostname = socket.gethostname()
    local_ip = ""
    try:
        local_ip = socket.gethostbyname(hostname)
    except socket.gaierror:
        try:
            # Fallback for environments where hostname might not resolve directly
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.settimeout(1.0) # Add timeout
            s.connect(("8.8.8.8", 80))
            local_ip = s.getsockname()[0]
            s.close()
        except Exception as ip_err:
                logger.warning(f"Could not resolve local IP via fallback: {ip_err}")
                local_ip = "Could not resolve IP"

    logger.debug(f"Health check called", extra={"hostname": hostname, "ip": local_ip})
    db_status = "unknown"
    db = None
    try:
        db = SessionLocal()
        # Use a simple query that doesn't lock tables
        db.execute(sqlalchemy.text("SELECT 1"))
        db_status = "connected"
    except Exception as e:
        logger.error(f"Health Check: Database connection error", exc_info=True, extra={"error_details": str(e)})
        db_status = f"error: {str(e)[:100]}"
    finally:
        if db:
            db.close()

    # Check Vue frontend index file existence (relative path assumed from Docker context)
    # This path is checked within the container after build
    vue_build_dir = "/app/frontend/dist"
    vue_index_file = os.path.join(vue_build_dir, "index.html")
    vue_frontend_status = "found" if os.path.exists(vue_index_file) else "missing"

    celery_broker_status = "unknown"
    celery_connection = None
    try:
        # Use a short timeout for health check connection attempt
        celery_connection = celery_app.connection(heartbeat=2.0, transport_options={'max_retries': 1})
        celery_connection.ensure_connection(max_retries=1, timeout=2)
        celery_broker_status = "connected"
    except Exception as celery_e:
        logger.error(f"Celery broker connection error during health check: {str(celery_e)}", exc_info=False)
        celery_broker_status = f"error: {str(celery_e)[:100]}"
    finally:
            if celery_connection:
                try: celery_connection.close()
                except Exception as close_err: logger.warning(f"Error closing celery connection in health check: {close_err}")

    # API Checks (using manually loaded config)
    openrouter_status = "unknown"
    tavily_status = "unknown"
    tavily_api_functional = False

    if config.MANUAL_OPENROUTER_PROVISIONING_KEYS and settings.OPENROUTER_API_BASE:
        openrouter_status = "CONFIGURED"
        if any("REPLACE_WITH_YOUR_VALID" in k for k in config.MANUAL_OPENROUTER_PROVISIONING_KEYS):
             openrouter_status = "CONFIGURED (PLACEHOLDER KEYS)"
             logger.warning("OpenRouter health check: Provisioning keys appear to be placeholders.")
    else:
        openrouter_status = "NOT CONFIGURED"
        logger.warning("OpenRouter provisioning keys or API base missing/empty for health check.")

    if config.MANUAL_TAVILY_API_KEYS:
        tavily_status = "CONFIGURED"
        if any("REPLACE_WITH_YOUR_VALID" in k for k in config.MANUAL_TAVILY_API_KEYS):
             tavily_status = "CONFIGURED (PLACEHOLDER KEYS)"
             logger.warning("Tavily health check: API keys appear to be placeholders.")
        else:
            try:
                async with httpx.AsyncClient(timeout=5.0) as client:
                    test_payload = {"api_key": config.MANUAL_TAVILY_API_KEYS[0], "query": "test", "max_results": 1}
                    # Use the correct Tavily API endpoint URL
                    tavily_api_url = settings.TAVILY_API_URL or "https://api.tavily.com/search"
                    response = await client.post(tavily_api_url, json=test_payload)
                    if response.status_code == 200:
                        tavily_api_functional = True
                        tavily_status = "API FUNCTIONAL"
                    else:
                        logger.warning(f"Tavily health check API call failed with status {response.status_code}")
                        tavily_status = f"API ERROR ({response.status_code})"
            except Exception as e:
                logger.error(f"Tavily health check API call failed: {e}", exc_info=False)
                tavily_status = f"API ERROR ({type(e).__name__})"
    else:
        tavily_status = "NOT CONFIGURED"
        logger.warning("Tavily API keys missing/empty for health check.")

    email_status = "configured" if settings.SMTP_HOST and settings.SMTP_USER and settings.EMAIL_FROM else "not_configured"

    return {
        "status": "healthy", # Overall status, might need adjustment based on component checks
        "hostname": hostname,
        "ip": local_ip,
        "database": db_status,
        "celery_broker": celery_broker_status,
        "vue_frontend_index": vue_frontend_status,
        "email_service": email_status,
        "openrouter_status": openrouter_status,
        "tavily_status": tavily_status,
        "tavily_api_functional": tavily_api_functional,
        "timestamp": datetime.now(timezone.utc).isoformat()
    }

</file>

<file path='app/api/jobs.py'>
# <file path='app/api/jobs.py'>
# app/api/jobs.py
from fastapi import APIRouter, Depends, HTTPException, Query, status, Path # Added Path
from sqlalchemy.orm import Session
from typing import List, Optional, Dict, Union, Any # <<< ADDED Union, Any
from datetime import datetime, timezone # <<< ADDED timezone
import logging # Import logging
import uuid # <<< ADDED for generating review job IDs
import os # <<< ADDED for path joining

from core.database import get_db
from api.auth import get_current_user
from models.user import User
# --- CORRECTED IMPORT: Add ProcessingStage ---
from models.job import Job, JobStatus, JobType, ProcessingStage
# --- END CORRECTED IMPORT ---
# --- UPDATED: Import specific schemas ---
from schemas.job import JobResponse, JobResultItem, JobResultsResponse
from schemas.review import ReclassifyPayload, ReclassifyResponse, ReviewResultItem # <<< ADDED Review Schemas
# --- END UPDATED ---
from core.logging_config import get_logger
from core.log_context import set_log_context
from core.config import settings # Need settings for file path construction
# --- CORRECTED IMPORT PATH ---
from tasks.classification_tasks import reclassify_flagged_vendors_task
# --- END CORRECTED IMPORT PATH ---
# --- ADDED: Import file service for merge ---
from services.file_service import generate_output_file
# --- END ADDED ---


logger = get_logger("vendor_classification.api.jobs")
logger.debug("Successfully imported Dict from typing for jobs API.")

router = APIRouter()

@router.get("/", response_model=List[JobResponse])
async def list_jobs(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
    status_filter: Optional[JobStatus] = Query(None, alias="status", description="Filter jobs by status"),
    start_date: Optional[datetime] = Query(None, description="Filter jobs created on or after this date (ISO format)"),
    end_date: Optional[datetime] = Query(None, description="Filter jobs created on or before this date (ISO format)"),
    job_type_filter: Optional[JobType] = Query(None, alias="type", description="Filter jobs by type (CLASSIFICATION or REVIEW)"), # <<< ADDED Filter
    skip: int = Query(0, ge=0, description="Number of jobs to skip for pagination"),
    limit: int = Query(100, ge=1, le=500, description="Maximum number of jobs to return"),
):
    """
    List jobs for the current user. Admins can see all jobs (optional enhancement).
    Supports filtering by status, date range, type, and pagination.
    """
    set_log_context({"username": current_user.username})
    logger.info("Fetching job history", extra={
        "status_filter": status_filter,
        "job_type_filter": job_type_filter, # <<< ADDED Log
        "start_date": start_date.isoformat() if start_date else None,
        "end_date": end_date.isoformat() if end_date else None,
        "skip": skip,
        "limit": limit,
    })

    query = db.query(Job)

    # Filter by user (Admins could potentially see all - add logic here if needed)
    # For now, all users only see their own jobs
    # if not current_user.is_superuser: # Example admin check
    query = query.filter(Job.created_by == current_user.username)

    # Apply filters
    if status_filter:
        query = query.filter(Job.status == status_filter.value)
    if job_type_filter: # <<< ADDED Filter
        query = query.filter(Job.job_type == job_type_filter.value)
    if start_date:
        query = query.filter(Job.created_at >= start_date)
    if end_date:
        # Add a day to end_date to make it inclusive of the whole day if time is not specified
        # Or adjust based on desired behavior (e.g., end_date < end_date + timedelta(days=1))
        query = query.filter(Job.created_at <= end_date)

    # Order by creation date (newest first)
    query = query.order_by(Job.created_at.desc())

    # Apply pagination
    jobs = query.offset(skip).limit(limit).all()

    logger.info(f"Retrieved {len(jobs)} jobs from history.")

    # Convert Job models to JobResponse schemas
    # Pydantic v2 handles this automatically with from_attributes=True
    return jobs

@router.get("/{job_id}", response_model=JobResponse)
async def read_job(
    # Use Path to ensure job_id is correctly extracted from the URL path
    job_id: str = Path(..., title="The ID of the job to get"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """
    Retrieve details for a specific job by its ID.
    Ensures the current user owns the job (or is an admin - future enhancement).
    """
    set_log_context({"username": current_user.username, "target_job_id": job_id})
    logger.info(f"Fetching details for job ID: {job_id}")

    job = db.query(Job).filter(Job.id == job_id).first()

    if not job:
        logger.warning(f"Job not found", extra={"job_id": job_id})
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Job not found")

    # --- Authorization Check ---
    # Ensure the user requesting the job is the one who created it
    # (Or add admin override logic here if needed)
    if job.created_by != current_user.username: # and not current_user.is_superuser:
        logger.warning(f"Authorization failed: User '{current_user.username}' attempted to access job '{job_id}' owned by '{job.created_by}'")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not authorized to access this job")
    # --- End Authorization Check ---

    # LOGGING: Log the job details being returned, especially target_level and job_type
    logger.info(f"Returning details for job ID: {job_id}", extra={"job_status": job.status, "target_level": job.target_level, "job_type": job.job_type})
    return job # Pydantic will validate against JobResponse

# Use Dict for flexibility, or create a specific StatsResponse schema later if needed
@router.get("/{job_id}/stats", response_model=Dict)
async def read_job_stats(
    job_id: str = Path(..., title="The ID of the job to get stats for"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """
    Retrieve processing statistics for a specific job.
    For REVIEW jobs, this might contain the input hints and merge status.
    """
    set_log_context({"username": current_user.username, "target_job_id": job_id})
    logger.info(f"Fetching statistics for job ID: {job_id}")

    job = db.query(Job).filter(Job.id == job_id).first()

    if not job:
        logger.warning(f"Job not found for stats", extra={"job_id": job_id})
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Job not found")

    # Authorization Check (same as read_job)
    if job.created_by != current_user.username: # and not current_user.is_superuser:
        logger.warning(f"Authorization failed: User '{current_user.username}' attempted to access stats for job '{job_id}' owned by '{job.created_by}'")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not authorized to access stats for this job")

    # LOGGING: Log the raw stats being returned from the database
    logger.info(f"Returning statistics for job ID: {job_id}", extra={"job_type": job.job_type})
    logger.debug(f"Raw stats from DB for job {job_id}: {job.stats}") # Log the actual stats dict

    # The stats are stored as JSON in the Job model
    return job.stats if job.stats else {}


# --- UPDATED: Endpoint for Detailed Results ---
# Now returns JobResultsResponse which includes job_type and Union of result types
@router.get("/{job_id}/results", response_model=JobResultsResponse)
async def read_job_results(
    job_id: str = Path(..., title="The ID of the job to get detailed results for"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """
    Retrieve the detailed classification results for a specific completed job.
    Returns a structure containing the job_id, job_type, and a list of results
    (either JobResultItem or ReviewResultItem depending on the job_type).
    """
    set_log_context({"username": current_user.username, "target_job_id": job_id})
    logger.info(f"Fetching detailed results for job ID: {job_id}")

    job = db.query(Job).filter(Job.id == job_id).first()

    if not job:
        logger.warning(f"Job not found for results", extra={"job_id": job_id})
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Job not found")

    # Authorization Check
    if job.created_by != current_user.username: # and not current_user.is_superuser:
        logger.warning(f"Authorization failed: User '{current_user.username}' attempted to access results for job '{job_id}' owned by '{job.created_by}'")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not authorized to access results for this job")

    # Check if job is completed and has results
    if job.status != JobStatus.COMPLETED.value:
        logger.warning(f"Detailed results requested but job not completed",
                       extra={"job_id": job_id, "status": job.status, "job_type": job.job_type})
        # Return empty list in the correct response structure
        return JobResultsResponse(job_id=job_id, job_type=JobType(job.job_type), results=[]) # Cast job_type to enum

    if not job.detailed_results:
        logger.warning(f"Job {job_id} is completed but has no detailed results stored.", extra={"job_id": job_id, "job_type": job.job_type})
        return JobResultsResponse(job_id=job_id, job_type=JobType(job.job_type), results=[]) # Cast job_type to enum

    # The detailed_results field should contain a list of dicts matching the expected schema.
    # Pydantic will validate this structure upon return based on the response_model.
    # We trust the background task stored the correct structure based on job_type.
    results_count = len(job.detailed_results)
    logger.info(f"Returning {results_count} detailed result items for job ID: {job_id}", extra={"job_type": job.job_type})

    # Pydantic should automatically validate based on the Union in JobResultsResponse
    return JobResultsResponse(job_id=job_id, job_type=JobType(job.job_type), results=job.detailed_results) # Cast job_type to enum
# --- END UPDATED ---


@router.get("/{job_id}/download")
async def download_job_results(
    job_id: str = Path(..., title="The ID of the job to download results for"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """
    Downloads the output Excel file for a completed job.
    Note: Only generates Excel for CLASSIFICATION jobs.
    The file reflects the latest state, including merged review results.
    """
    from fastapi.responses import FileResponse # Import here
    # import os # Already imported above

    set_log_context({"username": current_user.username, "target_job_id": job_id})
    logger.info(f"Request to download results for job ID: {job_id}")

    job = db.query(Job).filter(Job.id == job_id).first()

    if not job:
        logger.warning(f"Job not found for download", extra={"job_id": job_id})
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Job not found")

    # Authorization Check
    if job.created_by != current_user.username: # and not current_user.is_superuser:
        logger.warning(f"Authorization failed: User '{current_user.username}' attempted download for job '{job_id}' owned by '{job.created_by}'")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not authorized to download results for this job")

    # --- Check if download is applicable ---
    if job.job_type == JobType.REVIEW.value:
         logger.warning(f"Download requested for a REVIEW job ({job_id}), which doesn't generate an Excel file.", extra={"job_type": job.job_type})
         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Download is not available for review jobs.")

    if job.status != JobStatus.COMPLETED.value or not job.output_file_name:
        logger.warning(f"Download requested but job not completed or output file missing",
                       extra={"job_id": job_id, "status": job.status, "output_file": job.output_file_name})
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Job not completed or output file not available.")
    # --- End Check ---

    # Construct the full path to the output file
    output_dir = os.path.join(settings.OUTPUT_DATA_DIR, job_id)
    file_path = os.path.join(output_dir, job.output_file_name)

    if not os.path.exists(file_path):
         logger.error(f"Output file record exists in DB but file not found on disk",
                      extra={"job_id": job_id, "expected_path": file_path})
         # Consider regenerating the file here if it's missing? Or just fail.
         # For now, fail. Regeneration should happen on completion/merge.
         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Output file not found.")

    logger.info(f"Streaming output file for download",
                extra={"job_id": job_id, "file_path": file_path})
    return FileResponse(
        path=file_path,
        filename=job.output_file_name, # Suggest filename to browser
        media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )

# --- ADDED: Reclassify Endpoint ---
@router.post("/{original_job_id}/reclassify", response_model=ReclassifyResponse, status_code=status.HTTP_202_ACCEPTED)
async def reclassify_job_items(
    original_job_id: str = Path(..., description="The ID of the original classification job"),
    payload: ReclassifyPayload = ..., # Use the Pydantic model for the request body
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """
    Initiates a re-classification task for specific vendors from an original job,
    using user-provided hints. Creates a new REVIEW job.
    """
    set_log_context({"username": current_user.username, "original_job_id": original_job_id})
    logger.info(f"Received reclassification request for job {original_job_id}", extra={"item_count": len(payload.items)})

    # 1. Find the original job
    original_job = db.query(Job).filter(Job.id == original_job_id).first()
    if not original_job:
        logger.warning(f"Original job {original_job_id} not found for reclassification.")
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Original job not found")

    # 2. Authorization check (user owns the original job)
    if original_job.created_by != current_user.username: # and not current_user.is_superuser:
        logger.warning(f"Authorization failed: User '{current_user.username}' attempted reclassification for job '{original_job_id}' owned by '{original_job.created_by}'")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not authorized to reclassify items for this job")

    # 3. Basic validation (ensure original job was classification, maybe check status?)
    if original_job.job_type != JobType.CLASSIFICATION.value:
         logger.warning(f"Attempted to reclassify based on a non-CLASSIFICATION job.", extra={"original_job_type": original_job.job_type})
         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Reclassification can only be initiated from an original CLASSIFICATION job.")
    if original_job.status != JobStatus.COMPLETED.value:
         logger.warning(f"Attempted to reclassify based on a non-completed job.", extra={"original_job_status": original_job.status})
         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Reclassification can only be initiated from a COMPLETED job.")

    if not payload.items:
        logger.warning("Reclassification request received with no items to process.")
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="No items provided for reclassification.")

    # 4. Create the new Review Job record
    review_job_id = f"review_{uuid.uuid4().hex[:12]}"
    review_job = Job(
        id=review_job_id,
        company_name=original_job.company_name, # Inherit company name
        input_file_name=f"Review of {original_job.input_file_name}", # Indicate source
        output_file_name=None, # Review jobs don't produce downloads
        status=JobStatus.PENDING.value,
        # --- FIX: Use a valid ProcessingStage ---
        current_stage=ProcessingStage.RECLASSIFICATION.value, # Set initial stage to RECLASSIFICATION
        # --- END FIX ---
        progress=0.0,
        created_by=current_user.username,
        target_level=original_job.target_level, # Inherit target level
        job_type=JobType.REVIEW.value, # Mark as REVIEW type
        parent_job_id=original_job_id, # Link back to the original job
        stats={"reclassify_input": [item.model_dump() for item in payload.items]}, # Store input hints/vendors
        detailed_results=None, # Will be populated by the task
        notification_email=original_job.notification_email # Optionally inherit email
    )

    try:
        db.add(review_job)
        db.commit()
        db.refresh(review_job)
        logger.info(f"Created new REVIEW job record", extra={"review_job_id": review_job_id, "parent_job_id": original_job_id})
    except Exception as e:
        db.rollback()
        logger.error("Failed to create REVIEW job record in database", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to initiate reclassification job.")

    # 5. Queue the Celery task
    try:
        logger.info(f"Queuing reclassification task for review job {review_job_id}")
        reclassify_flagged_vendors_task.delay(review_job_id=review_job_id)
        logger.info(f"Reclassification task successfully queued.")
    except Exception as e:
        logger.error(f"Failed to queue Celery reclassification task for review job {review_job_id}", exc_info=True)
        # Attempt to mark the created review job as failed
        review_job.fail(f"Failed to queue background task: {str(e)}")
        db.commit()
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to queue reclassification task.")

    # 6. Return the review job ID
    return ReclassifyResponse(review_job_id=review_job_id)
# --- END ADDED ---

# --- ADDED: Merge Endpoint ---
@router.post("/{review_job_id}/merge", status_code=status.HTTP_200_OK)
async def merge_review_results(
    review_job_id: str = Path(..., description="The ID of the completed REVIEW job to merge"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """
    Merges the results from a completed REVIEW job back into its parent CLASSIFICATION job.
    Updates the parent job's detailed_results and triggers regeneration of its downloadable Excel file.
    """
    set_log_context({"username": current_user.username, "review_job_id": review_job_id})
    logger.info(f"Received request to merge results for review job {review_job_id}")

    # 1. Fetch the REVIEW job
    review_job = db.query(Job).filter(Job.id == review_job_id).first()
    if not review_job:
        logger.warning(f"Review job {review_job_id} not found for merging.")
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Review job not found")

    # 2. Authorization check (user owns the review job)
    if review_job.created_by != current_user.username:
        logger.warning(f"Authorization failed: User '{current_user.username}' attempted merge for job '{review_job_id}' owned by '{review_job.created_by}'")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not authorized to merge this review job")

    # 3. Validation
    if review_job.job_type != JobType.REVIEW.value:
        logger.warning(f"Attempted to merge a non-REVIEW job.", extra={"job_id": review_job_id, "job_type": review_job.job_type})
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Only REVIEW jobs can be merged.")
    if review_job.status != JobStatus.COMPLETED.value:
        logger.warning(f"Attempted to merge a non-completed REVIEW job.", extra={"job_id": review_job_id, "status": review_job.status})
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Review job must be COMPLETED to merge.")
    if not review_job.parent_job_id:
        logger.error(f"Review job {review_job_id} is missing a parent_job_id.", extra={"job_id": review_job_id})
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Review job has no associated parent job.")
    if not review_job.detailed_results:
        logger.warning(f"Review job {review_job_id} has no detailed results to merge.", extra={"job_id": review_job_id})
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Review job has no results to merge.")

    # Check if already merged
    if review_job.stats and review_job.stats.get("merged_at"):
        logger.warning(f"Review job {review_job_id} has already been merged.", extra={"job_id": review_job_id, "merged_at": review_job.stats["merged_at"]})
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="This review job has already been merged.")

    # 4. Fetch the Parent (Original) CLASSIFICATION job
    parent_job = db.query(Job).filter(Job.id == review_job.parent_job_id).first()
    if not parent_job:
        logger.error(f"Parent job {review_job.parent_job_id} not found for merging (referenced by review job {review_job_id}).")
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Parent classification job not found.")
    if parent_job.job_type != JobType.CLASSIFICATION.value:
        logger.error(f"Parent job {parent_job.id} is not a CLASSIFICATION job.", extra={"parent_job_type": parent_job.job_type})
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Parent job is not a classification job.")
    if not parent_job.detailed_results:
        logger.warning(f"Parent job {parent_job.id} has no detailed results to update. This is unusual but proceeding.", extra={"parent_job_id": parent_job.id})
        # Initialize as empty list if missing
        parent_job.detailed_results = []

    set_log_context({"parent_job_id": parent_job.id})
    logger.info(f"Found parent job {parent_job.id} for merging.")

    # 5. Load results and perform the merge
    try:
        # Load review results (List[ReviewResultItem])
        review_results_data: List[ReviewResultItem] = [ReviewResultItem.model_validate(item) for item in review_job.detailed_results]
        logger.info(f"Loaded {len(review_results_data)} items from review job {review_job_id}.")

        # Load original results (List[JobResultItem])
        original_results_data: List[JobResultItem] = [JobResultItem.model_validate(item) for item in parent_job.detailed_results]
        logger.info(f"Loaded {len(original_results_data)} items from parent job {parent_job.id}.")

        # Create a map of original results keyed by vendor_name for efficient updates
        original_results_map: Dict[str, JobResultItem] = {item.vendor_name: item for item in original_results_data}

        # Iterate through review results and update the map
        updated_count = 0
        for review_item in review_results_data:
            vendor_name = review_item.vendor_name
            # The 'new_result' field in ReviewResultItem is already a dict matching JobResultItem structure
            new_result_dict = review_item.new_result
            if vendor_name in original_results_map:
                # Ensure the source is marked correctly in the merged result
                new_result_dict['classification_source'] = 'Review'
                # Validate the new result dict against the schema before replacing
                validated_new_result = JobResultItem.model_validate(new_result_dict)
                original_results_map[vendor_name] = validated_new_result
                updated_count += 1
                logger.debug(f"Updated result for vendor '{vendor_name}' in parent job map.")
            else:
                logger.warning(f"Vendor '{vendor_name}' from review job {review_job_id} not found in parent job {parent_job.id} results. Skipping update for this vendor.")

        logger.info(f"Updated {updated_count} vendor results in the parent job map.")

        # Convert the updated map back into a List[JobResultItem]
        updated_detailed_results_list: List[Dict[str, Any]] = [item.model_dump() for item in original_results_map.values()]

        # 6. Update the parent job's detailed_results
        parent_job.detailed_results = updated_detailed_results_list
        parent_job.updated_at = datetime.now(timezone.utc) # Mark parent job as updated
        logger.info(f"Updated detailed_results field on parent job {parent_job.id}.")

        # 7. Regenerate the Excel file for the parent job
        try:
            logger.info(f"Triggering Excel regeneration for parent job {parent_job.id}...")
            # Call generate_output_file with the updated results list
            # Ensure generate_output_file accepts List[JobResultItem] or adapt here
            new_output_filename = generate_output_file(
                job_id=parent_job.id,
                detailed_results=[JobResultItem.model_validate(item) for item in updated_detailed_results_list] # Pass validated models
            )
            parent_job.output_file_name = new_output_filename
            logger.info(f"Successfully regenerated Excel file for parent job {parent_job.id}: {new_output_filename}")
        except Exception as excel_err:
            logger.error(f"Failed to regenerate Excel file for parent job {parent_job.id} during merge.", exc_info=True)
            # Should we rollback the merge or proceed without the updated file?
            # Let's proceed but log the error prominently. The results are still merged in the DB.
            # Optionally, set output_file_name to None or keep the old one? Keeping old one for now.
            # parent_job.output_file_name = None # Or keep existing?
            # Raise an internal error to signal partial failure?
            # For now, just log and continue with DB commit.

        # 8. Mark the REVIEW job as merged in its stats
        if not review_job.stats:
            review_job.stats = {}
        review_job.stats["merged_at"] = datetime.now(timezone.utc).isoformat()
        logger.info(f"Marked review job {review_job_id} as merged in stats.")

        # 9. Commit changes to both jobs
        db.commit()
        logger.info(f"Successfully committed changes for merge operation (Review Job: {review_job_id}, Parent Job: {parent_job.id}).")

        # 10. Return success response
        return {
            "message": f"Successfully merged results from review job {review_job_id} into parent job {parent_job.id}.",
            "updated_parent_job_id": parent_job.id
        }

    except Exception as e:
        db.rollback()
        logger.error(f"Error during merge operation for review job {review_job_id}", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to merge results: {str(e)}")
# --- END ADDED ---
</file>

<file path='app/api/main.py'>
# app/api/main.py
from fastapi import (
    FastAPI, Depends, HTTPException, UploadFile, File, Form,
    BackgroundTasks, status, Request
)
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.exceptions import RequestValidationError
from pydantic import BaseModel
from typing import Dict, Any, Optional, List
import uuid
import os
import logging
import time
from sqlalchemy.orm import Session

# --- Core Imports ---
from core.logging_config import setup_logging, get_logger
from core.log_context import set_correlation_id, set_user, set_job_id, get_correlation_id
from middleware.logging_middleware import RequestLoggingMiddleware
from core.database import get_db, SessionLocal
from core.initialize_db import initialize_database

# --- Model Imports ---
from models.job import Job, JobStatus, ProcessingStage # Keep top-level imports
from models.user import User

# --- Service Imports ---
from services.file_service import save_upload_file, validate_file_header

# --- Task Imports ---
from tasks.classification_tasks import process_vendor_file # Keep this specific import

# --- Utility Imports ---
from utils.taxonomy_loader import load_taxonomy

# --- Auth Imports ---
from fastapi.security import OAuth2PasswordRequestForm
from api.auth import (
    get_current_user,
    authenticate_user,
    create_access_token,
    get_current_active_user,
    get_current_active_superuser
)

# --- Router Imports ---
from api import jobs as jobs_router
from api import users as users_router
from api import password_reset as password_reset_router
from api import admin as admin_router
from api.health_utils import health_check

# --- Schema Imports ---
from schemas.job import JobResponse
from schemas.user import UserResponse as UserResponseSchema
from core.config import settings

# --- Logging Setup ---
setup_logging(log_level=logging.DEBUG, log_to_file=True, log_dir=settings.TAXONOMY_DATA_DIR.replace('taxonomy', 'logs'))
logger = get_logger("vendor_classification.api")

# --- FastAPI App Initialization ---
app = FastAPI(
    title="NAICS Vendor Classification API",
    description="API for classifying vendors according to NAICS taxonomy",
    version="1.0.0",
)

# --- Middleware ---
app.add_middleware(RequestLoggingMiddleware)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[settings.FRONTEND_URL, "http://localhost:8080", "http://127.0.0.1:8080", f"http://localhost:{settings.FRONTEND_URL.split(':')[-1]}"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Include Routers ---
logger.info("Including API routers...")
app.include_router(
    jobs_router.router,
    prefix="/api/v1/jobs",
    tags=["Jobs"],
    dependencies=[Depends(get_current_user)]
)
logger.info("Included jobs router with prefix /api/v1/jobs")

app.include_router(
    users_router.router,
    prefix="/api/v1/users",
    tags=["Users"],
)
logger.info("Included users router with prefix /api/v1/users")

app.include_router(
    password_reset_router.router,
    prefix="/api/v1/auth",
    tags=["Password Reset"],
)
logger.info("Included password reset router with prefix /api/v1/auth")

app.include_router(
    admin_router.router,
    prefix="/api/v1/admin",
    tags=["Admin"],
    dependencies=[Depends(get_current_active_superuser)]
)
logger.info("Included admin router with prefix /api/v1/admin (superuser required)")
# --- End Include Routers ---

# --- Vue.js Frontend Serving Setup ---
VUE_BUILD_DIR = "/app/frontend/dist"
VUE_INDEX_FILE = os.path.join(VUE_BUILD_DIR, "index.html")
logger.info(f"Attempting to serve Vue frontend from: {VUE_BUILD_DIR}")
if not os.path.exists(VUE_BUILD_DIR):
    logger.error(f"Vue build directory NOT FOUND at {VUE_BUILD_DIR}. Frontend will not be served.")
elif not os.path.exists(VUE_INDEX_FILE):
    logger.error(f"Vue index.html NOT FOUND at {VUE_INDEX_FILE}. Frontend serving might fail.")
else:
    logger.info(f"Vue build directory and index.html found. Static files will be mounted.")

# --- API ROUTES ---

@app.get("/health", tags=["Health"])
async def get_health_status():
    """Provides the system health status."""
    return await health_check()


# --- Exception Handlers ---
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    correlation_id = get_correlation_id() or str(uuid.uuid4())
    try: body_preview = str(await request.body())[:500]
    except Exception: body_preview = "[Could not read request body]"
    logger.error("Request validation failed (422)", extra={
        "error_details": exc.errors(), "request_body_preview": body_preview,
        "request_headers": dict(request.headers), "correlation_id": correlation_id,
        "path": request.url.path
    })
    return JSONResponse(
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        content={"detail": exc.errors()},
        headers={"X-Correlation-ID": correlation_id}
    )

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    correlation_id = get_correlation_id() or str(uuid.uuid4())
    log_level = logging.ERROR if exc.status_code >= 500 else logging.WARNING
    logger.log(log_level, f"HTTP Exception: {exc.status_code} - {exc.detail}", extra={
        "correlation_id": correlation_id,
        "request_headers": dict(request.headers),
        "path": request.url.path,
        "method": request.method,
        "status_code": exc.status_code,
        "detail": exc.detail,
    }, exc_info=(exc.status_code >= 500))

    # --- FIX: Robust header handling ---
    exc_headers = getattr(exc, "headers", None) # Get actual headers or None
    headers = exc_headers if isinstance(exc_headers, dict) else {} # Ensure headers is a dict
    headers["X-Correlation-ID"] = correlation_id # Now this should be safe
    # --- END FIX ---

    return JSONResponse(
        status_code=exc.status_code,
        content={"detail": exc.detail},
        headers=headers, # Pass the modified dict
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    correlation_id = get_correlation_id() or str(uuid.uuid4())
    logger.error(f"Unhandled exception during request to {request.url.path}", exc_info=True, extra={
        "correlation_id": correlation_id, "request_headers": dict(request.headers),
        "path": request.url.path, "method": request.method,
    })
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={"detail": "An internal server error occurred.", "correlation_id": correlation_id},
        headers={"X-Correlation-ID": correlation_id}
    )


# --- Authentication Endpoint ---
@app.post("/token", response_model=Dict[str, Any], tags=["Authentication"])
async def login_for_access_token(
    request: Request,
    form_data: OAuth2PasswordRequestForm = Depends(),
    db: Session = Depends(get_db)
):
    """Handles user login and returns JWT token and user details."""
    correlation_id = str(uuid.uuid4())
    set_correlation_id(correlation_id)
    client_host = request.client.host if request.client else "Unknown"
    logger.info(f"Login attempt", extra={"username": form_data.username, "ip": client_host})

    try:
        user = authenticate_user(db, form_data.username, form_data.password)
        if not user:
            logger.warning(f"Login failed: invalid credentials", extra={"username": form_data.username, "ip": client_host})
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Incorrect username or password",
                headers={"WWW-Authenticate": "Bearer"},
            )

        if not user.is_active:
                logger.warning(f"Login failed: user '{user.username}' is inactive.", extra={"ip": client_host})
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Inactive user.",
                )

        set_user(user)
        access_token = create_access_token(subject=user.username)

        logger.info(f"Login successful, token generated", extra={ "username": user.username, "ip": client_host, "token_expires_in_minutes": settings.ACCESS_TOKEN_EXPIRE_MINUTES})

        return {
            "access_token": access_token,
            "token_type": "bearer",
            "user": UserResponseSchema.model_validate(user)
        }

    except HTTPException as http_exc:
        # Log unexpected HTTP exceptions, but re-raise all HTTP exceptions
        if http_exc.status_code not in [status.HTTP_401_UNAUTHORIZED, status.HTTP_400_BAD_REQUEST]:
                logger.error(f"Unexpected HTTP exception during login for {form_data.username}", exc_info=True)
        raise
    except Exception as e:
        logger.error(f"Unexpected login error", exc_info=True, extra={"error": str(e), "username": form_data.username})
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="An error occurred during the login process."
        )

# --- File Validation Endpoint ---
class FileValidationResponse(BaseModel):
    is_valid: bool
    message: str
    detected_columns: List[str] = []
    missing_mandatory_columns: List[str] = []

@app.post("/api/v1/validate-upload", response_model=FileValidationResponse, status_code=status.HTTP_200_OK, tags=["File Operations"])
async def validate_uploaded_file_header(
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_user)
):
    """
    Quickly validates the header of an uploaded Excel file.
    Checks for the mandatory 'vendor_name' column (case-insensitive).
    Returns validation status and detected columns.
    """
    set_user(current_user)
    validation_uuid = str(uuid.uuid4())[:8]

    log_extra = {
        "validation_id": validation_uuid,
        "uploaded_filename": file.filename,
        "username": current_user.username
    }
    logger.info("File validation request received", extra=log_extra)

    if not file.filename:
        logger.warning("Validation attempt with no filename.", extra=log_extra)
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="No filename provided.")
    if not file.filename.lower().endswith(('.xlsx', '.xls')):
        logger.warning(f"Invalid file type for validation: {file.filename}", extra=log_extra)
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invalid file type. Please upload an Excel file (.xlsx or .xls).")

    try:
        validation_result = validate_file_header(file)

        log_safe_validation_result = {
            "validation_is_valid": validation_result.get("is_valid"),
            "validation_message": validation_result.get("message"),
            "validation_detected_columns": validation_result.get("detected_columns"),
            "validation_missing_columns": validation_result.get("missing_mandatory_columns")
        }
        current_log_extra = {**log_extra, **log_safe_validation_result}
        logger.info(f"File header validation completed", extra=current_log_extra)

        status_code = status.HTTP_200_OK
        # No need to change status code based on validation result

        return JSONResponse(
            status_code=status_code,
            content=validation_result
        )

    except ValueError as ve:
        logger.warning(f"Validation failed due to parsing error: {ve}", extra=log_extra)
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(ve))
    except Exception as e:
        logger.error(f"Unexpected error during file header validation", exc_info=True, extra=log_extra)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Error validating file: {e}")
    finally:
        # Ensure file is closed even if validation fails early
        if hasattr(file, 'close') and callable(file.close):
            try:
                 file.close()
            except Exception:
                logger.warning("Error closing file stream after validation", extra=log_extra, exc_info=False)


# --- UPLOAD ROUTE ---
@app.post("/api/v1/upload", response_model=JobResponse, status_code=status.HTTP_202_ACCEPTED, tags=["File Operations"])
async def upload_vendor_file(
    background_tasks: BackgroundTasks,
    company_name: str = Form(...),
    target_level: int = Form(..., ge=1, le=5, description="Target classification level (1-5)"),
    file: UploadFile = File(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Accepts vendor file upload, creates a job, and queues it for processing.
    Allows specifying the target classification level.
    **Assumes frontend performs pre-validation using /validate-upload.**
    """
    job_id = str(uuid.uuid4())
    set_job_id(job_id)
    set_user(current_user)

    logger.info(f"Upload request received", extra={
        "job_id": job_id,
        "company_name": company_name,
        "target_level": target_level,
        "uploaded_filename": file.filename,
        "content_type": file.content_type,
        "username": current_user.username
    })

    if not file.filename:
        logger.warning("Upload attempt with no filename.", extra={"job_id": job_id})
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="No filename provided.")
    if not file.filename.lower().endswith(('.xlsx', '.xls')):
        logger.warning(f"Invalid file type uploaded: {file.filename}", extra={"job_id": job_id})
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invalid file type. Please upload an Excel file (.xlsx or .xls).")

    saved_file_path = None
    try:
        logger.debug(f"Attempting to save uploaded file for job {job_id}")
        saved_file_path = save_upload_file(file=file, job_id=job_id)
        logger.info(f"File saved successfully for job {job_id}", extra={"saved_path": saved_file_path})
    except IOError as e:
        logger.error(f"Failed to save uploaded file for job {job_id}", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Could not save file: {e}")
    except Exception as e:
        logger.error(f"Unexpected error during file upload/saving for job {job_id}", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Error processing upload: {e}")

    job = None
    try:
        logger.debug(f"Creating database job record for job {job_id}")
        # --- FIX: Explicitly import JobStatus and ProcessingStage here ---
        from models.job import Job, JobStatus, ProcessingStage
        # --- END FIX ---
        job = Job(
            id=job_id,
            company_name=company_name,
            input_file_name=os.path.basename(saved_file_path),
            status=JobStatus.PENDING.value,
            current_stage=ProcessingStage.INGESTION.value,
            created_by=current_user.username,
            target_level=target_level
        )
        db.add(job)
        db.commit()
        db.refresh(job)
        logger.info(f"Database job record created successfully for job {job_id}", extra={"target_level": job.target_level})
    except Exception as e:
        db.rollback()
        logger.error(f"Failed to create database job record for job {job_id}", exc_info=True)
        if saved_file_path and os.path.exists(saved_file_path):
            try: os.remove(saved_file_path)
            except OSError: logger.warning(f"Could not remove file {saved_file_path} after DB error.")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Could not create job record.")

    try:
        logger.info(f"Adding Celery task 'process_vendor_file' to background tasks for job {job_id}")
        # process_vendor_file is already imported at the top level
        background_tasks.add_task(process_vendor_file.delay, job_id=job_id, file_path=saved_file_path, target_level=target_level)
        logger.info(f"Celery task queued successfully for job {job_id}")
    except Exception as e:
        logger.error(f"Failed to queue Celery task for job {job_id}", exc_info=True)
        if job:
            # Need to import JobStatus if not already available locally (it is now due to the fix above)
            job.status = JobStatus.FAILED.value # Manually update status if fail method isn't easily usable
            job.error_message = f"Failed to queue processing task: {str(e)}"
            db.commit()
        else:
             logger.error(f"Job object was None when trying to mark as failed due to Celery queue error.")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to queue job for processing.")

    logger.info(f"Upload request for job {job_id} processed successfully, returning 202 Accepted.")
    return JobResponse.model_validate(job)


# --- Mount Static Files (Vue App) ---
if os.path.exists(VUE_BUILD_DIR) and os.path.exists(VUE_INDEX_FILE):
    logger.info(f"Mounting Vue app from directory: {VUE_BUILD_DIR}")
    app.mount("/assets", StaticFiles(directory=os.path.join(VUE_BUILD_DIR, "assets")), name="assets")

    @app.get("/{full_path:path}", include_in_schema=False)
    async def serve_vue_app(request: Request, full_path: str):
        potential_file_path = os.path.join(VUE_BUILD_DIR, full_path.lstrip('/'))
        # Prevent serving API routes via the static file server
        if full_path.startswith("api/") or full_path.startswith("/api/"):
             logger.warning(f"Request for API path '{full_path}' reached static file fallback. Letting FastAPI handle.")
             # Let FastAPI handle 404s for actual API routes
             return None

        if os.path.isfile(potential_file_path) and os.path.basename(potential_file_path) != 'index.html':
             logger.debug(f"Serving static file directly: {full_path}")
             return FileResponse(potential_file_path)
        else:
            logger.debug(f"Serving index.html for SPA route or missing file: {full_path}")
            if os.path.exists(VUE_INDEX_FILE):
                return FileResponse(VUE_INDEX_FILE)
            else:
                logger.error(f"Vue index.html not found at {VUE_INDEX_FILE} when trying to serve fallback route.")
                return JSONResponse(status_code=500, content={"detail": "Frontend index file missing."})

else:
    logger.error(f"Cannot mount Vue app: Directory {VUE_BUILD_DIR} or index file {VUE_INDEX_FILE} not found.")
    @app.get("/", include_in_schema=False)
    async def missing_frontend():
        return JSONResponse(
            status_code=status.HTTP_404_NOT_FOUND,
            content={"detail": f"Frontend not found. Expected build files in {VUE_BUILD_DIR}"}
        )
# --- END VUE.JS FRONTEND SERVING SETUP ---

# --- Initialize Database on Startup ---
@app.on_event("startup")
async def startup_event():
    logger.info("Application startup: Initializing database...")
    try:
        initialize_database()
        logger.info("Database initialization check complete.")
    except Exception as e:
        logger.error(f"Database initialization failed: {e}", exc_info=True)
# --- END Initialize Database ---
</file>

<file path='app/api/password_reset.py'>
# <file path='app/api/password_reset.py'>
# app/api/password_reset.py
from fastapi import APIRouter, Depends, HTTPException, status, BackgroundTasks
from sqlalchemy.orm import Session
from typing import Any

from core.database import get_db
from core.config import settings
from core.logging_config import get_logger
from schemas.password_reset import PasswordRecoveryRequest, PasswordResetRequest, MessageResponse
from services import user_service
from services import email_service
from api import auth as auth_service # Renamed import for clarity
from models.user import User as UserModel

logger = get_logger("vendor_classification.api.password_reset")

router = APIRouter()

@router.post(
    "/password-recovery",
    response_model=MessageResponse,
    status_code=status.HTTP_200_OK # Return 200 even if user not found to prevent email enumeration
)
async def request_password_recovery(
    recovery_data: PasswordRecoveryRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
) -> Any:
    """
    Initiates the password recovery process for a user based on their email.
    Sends an email with a password reset link if the user exists.
    Always returns a success message to prevent user enumeration.
    """
    email = recovery_data.email
    logger.info(f"Password recovery requested", extra={"email": email})

    user = user_service.get_user_by_email(db, email=email)

    if not user:
        # IMPORTANT: Do not reveal that the user doesn't exist.
        logger.warning(f"Password recovery requested for non-existent email", extra={"email": email})
        # Still return a success-like message.
        return MessageResponse(message="If an account with that email exists, a password reset link has been sent.")

    if not user.is_active:
        logger.warning(f"Password recovery requested for inactive user", extra={"email": email, "username": user.username})
        # You might choose to prevent inactive users from resetting, or allow it.
        # Let's prevent it for now.
        # Still return the generic success message.
        return MessageResponse(message="If an account with that email exists and is active, a password reset link has been sent.")

    # Generate the password reset token
    password_reset_token = auth_service.create_password_reset_token(subject=user.id) # Use user ID as subject

    # Send email in the background
    background_tasks.add_task(
        email_service.send_password_reset_email,
        email_to=user.email,
        username=user.username,
        token=password_reset_token
    )
    logger.info(f"Password recovery email task added to background", extra={"email": email, "username": user.username})

    return MessageResponse(message="If an account with that email exists and is active, a password reset link has been sent.")


@router.post("/reset-password", response_model=MessageResponse)
async def reset_password(
    reset_data: PasswordResetRequest,
    db: Session = Depends(get_db)
) -> Any:
    """
    Resets the user's password using a valid token.
    """
    token = reset_data.token
    new_password = reset_data.new_password
    logger.info(f"Attempting password reset with token", extra={"token_preview": token[:10]+"..."})

    try:
        # Verify the token and get the user ID
        user_id = auth_service.verify_password_reset_token(token)
        if not user_id:
            # This case should be caught by JWTError, but double-check
            logger.warning("Password reset token verification failed (no user_id returned)", extra={"token_preview": token[:10]+"..."})
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Invalid or expired password reset token.",
            )

        logger.info(f"Password reset token verified successfully", extra={"user_id": user_id})

        # Use the user service to update the password
        success = user_service.reset_password(db=db, user_id=user_id, new_password=new_password)

        if not success:
            # This might happen if the user was deleted between token generation and reset attempt
            logger.error(f"Failed to reset password: User not found after token verification", extra={"user_id": user_id})
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="User not found.",
            )

        logger.info(f"Password reset successful", extra={"user_id": user_id})
        return MessageResponse(message="Password has been reset successfully.")

    except HTTPException as http_exc:
        # Re-raise known HTTP exceptions (like 400 from verify_password_reset_token)
        raise http_exc
    except Exception as e:
        # Catch unexpected errors during the process
        logger.error(f"Unexpected error during password reset", exc_info=True, extra={"token_preview": token[:10]+"..."})
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="An error occurred while resetting the password."
        )

</file>

<file path='app/api/users.py'>
# app/api/users.py
from fastapi import APIRouter, Depends, HTTPException, status, Query
from sqlalchemy.orm import Session
from typing import List, Any
import uuid

from core.database import get_db
from schemas.user import UserCreate, UserUpdate, UserResponse
from services import user_service
# --- MODIFIED: Import only necessary auth dependencies ---
from api.auth import get_current_active_user, get_current_active_superuser # Keep these for protected routes
# --- END MODIFIED ---
from models.user import User as UserModel # Import the model for type hinting
from core.logging_config import get_logger
from core.log_context import set_log_context

logger = get_logger("vendor_classification.api.users")

router = APIRouter()

# --- NEW: Public User Registration Endpoint ---
@router.post("/register", response_model=UserResponse, status_code=status.HTTP_201_CREATED)
def register_user(
    *,
    db: Session = Depends(get_db),
    user_in: UserCreate,
    # NO AUTH DEPENDENCY HERE - This is public
):
    """
    Public endpoint to create a new user (register).
    """
    logger.info(f"Public registration attempt for username '{user_in.username}'")
    # Check if username or email already exists (service layer handles this via HTTPException)
    existing_user_by_username = user_service.get_user_by_username(db, username=user_in.username)
    if existing_user_by_username:
        logger.warning(f"Registration failed: Username '{user_in.username}' already taken.")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Username already registered",
        )
    existing_user_by_email = user_service.get_user_by_email(db, email=user_in.email)
    if existing_user_by_email:
        logger.warning(f"Registration failed: Email '{user_in.email}' already registered.")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Email already registered",
        )

    # Set default is_active=True, is_superuser=False for public registration
    user_in.is_active = True
    user_in.is_superuser = False

    # Service layer handles password hashing and potential integrity errors
    user = user_service.create_user(db=db, user_in=user_in)
    logger.info(f"User '{user.username}' registered successfully (Public).")
    # TODO: Consider sending a verification email here in a real application
    return user
# --- END NEW Endpoint ---


@router.post("/", response_model=UserResponse, status_code=status.HTTP_201_CREATED)
def create_user_admin( # Renamed function slightly for clarity
    *,
    db: Session = Depends(get_db),
    user_in: UserCreate,
    current_user: UserModel = Depends(get_current_active_superuser) # Require admin
):
    """
    Create new user. Requires superuser privileges. (Admin Endpoint)
    """
    set_log_context({"admin_user": current_user.username})
    logger.info(f"Admin '{current_user.username}' attempting to create user '{user_in.username}'")
    # Service layer handles potential duplicate username/email via HTTPException
    user = user_service.create_user(db=db, user_in=user_in)
    logger.info(f"User '{user.username}' created successfully by admin '{current_user.username}'")
    return user

@router.get("/", response_model=List[UserResponse])
def read_users(
    db: Session = Depends(get_db),
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=200),
    current_user: UserModel = Depends(get_current_active_superuser) # Require admin
):
    """
    Retrieve users. Requires superuser privileges.
    """
    set_log_context({"admin_user": current_user.username})
    logger.info(f"Admin '{current_user.username}' requesting user list", extra={"skip": skip, "limit": limit})
    users = user_service.get_users(db, skip=skip, limit=limit)
    logger.info(f"Returning {len(users)} users to admin '{current_user.username}'")
    return users

@router.get("/me", response_model=UserResponse)
def read_user_me(
    current_user: UserModel = Depends(get_current_active_user) # Just need active user
):
    """
    Get current user details.
    """
    set_log_context({"requesting_user": current_user.username})
    logger.info(f"User '{current_user.username}' requesting their own details.")
    # The dependency already fetches the user object
    return current_user

@router.get("/{user_id}", response_model=UserResponse)
def read_user_by_id(
    user_id: str,
    current_user: UserModel = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    Get a specific user by ID. Requires admin privileges or the user themselves.
    """
    set_log_context({"requesting_user": current_user.username, "target_user_id": user_id})
    logger.info(f"User '{current_user.username}' requesting details for user ID '{user_id}'")
    user = user_service.get_user(db, user_id=user_id)
    if not user:
        logger.warning(f"Target user not found", extra={"target_user_id": user_id})
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User not found")

    # Check permissions
    if user.id != current_user.id and not current_user.is_superuser:
        logger.warning(f"Authorization failed: User '{current_user.username}' cannot access details for user '{user.username}'")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not enough permissions")

    logger.info(f"Returning details for user '{user.username}'")
    return user

@router.put("/{user_id}", response_model=UserResponse)
def update_user(
    *,
    db: Session = Depends(get_db),
    user_id: str,
    user_in: UserUpdate,
    current_user: UserModel = Depends(get_current_active_user)
):
    """
    Update a user. Requires admin privileges or the user themselves.
    Non-admins cannot change their own is_superuser status or activate/deactivate themselves.
    """
    set_log_context({"requesting_user": current_user.username, "target_user_id": user_id})
    logger.info(f"User '{current_user.username}' attempting to update user ID '{user_id}'")
    db_user = user_service.get_user(db, user_id=user_id)
    if not db_user:
        logger.warning(f"Target user not found for update", extra={"target_user_id": user_id})
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User not found")

    # Check permissions
    if db_user.id != current_user.id and not current_user.is_superuser:
        logger.warning(f"Authorization failed: User '{current_user.username}' cannot update user '{db_user.username}'")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not enough permissions to update this user")

    # Non-admins cannot make themselves superuser or change their active status
    if not current_user.is_superuser:
        if user_in.is_superuser is not None and user_in.is_superuser != db_user.is_superuser:
                logger.warning(f"User '{current_user.username}' attempted to change their own superuser status.")
                raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Cannot change superuser status")
        if user_in.is_active is not None and user_in.is_active != db_user.is_active:
                logger.warning(f"User '{current_user.username}' attempted to change their own active status.")
                raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Cannot change own active status")

    # Service layer handles update logic and potential integrity errors
    updated_user = user_service.update_user(db=db, user_id=user_id, user_in=user_in)
    if not updated_user: # Should be handled by service, but double check
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User not found after update attempt")

    logger.info(f"User '{db_user.username}' updated successfully by '{current_user.username}'")
    return updated_user


@router.delete("/{user_id}", status_code=status.HTTP_200_OK)
def delete_user(
    *,
    db: Session = Depends(get_db),
    user_id: str,
    current_user: UserModel = Depends(get_current_active_superuser) # Require admin
):
    """
    Delete a user. Requires superuser privileges.
    """
    set_log_context({"admin_user": current_user.username, "target_user_id": user_id})
    logger.info(f"Admin '{current_user.username}' attempting to delete user ID '{user_id}'")

    # Prevent admin from deleting themselves?
    if str(current_user.id) == user_id:
            logger.error(f"Admin '{current_user.username}' attempted to delete themselves.")
            raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Admins cannot delete themselves.")

    deleted = user_service.delete_user(db=db, user_id=user_id)
    if not deleted:
        # Service layer already logged warning
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User not found")

    logger.info(f"User ID '{user_id}' deleted successfully by admin '{current_user.username}'")
    return {"message": "User deleted successfully"}

</file>

<file path='app/core/config.py'>
# app/core/config.py
import os
import logging
from pydantic_settings import BaseSettings, SettingsConfigDict
from pydantic import Field
from typing import Optional, List, Union, Dict, Any
import sys
import json

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("vendor_classification.config")

# --- Defaults remain the same ---
DEFAULT_OPENROUTER_PROVISIONING_KEYS = ["REPLACE_WITH_YOUR_VALID_OPENROUTER_PROVISIONING_KEY"]
DEFAULT_TAVILY_KEYS = [
    "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",
    "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",
    "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",
    "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",
    "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",
    "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",
    "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",
    "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"
]

# --- Parsing function remains the same ---
def _parse_string_to_list(value: Optional[str]) -> List[str]:
    """Parses a comma-separated string into a list of strings."""
    if not value:
        return []
    return [k.strip() for k in value.split(',') if k.strip()]

class Settings(BaseSettings):
    """Application settings (excluding manually parsed lists)."""
    model_config = SettingsConfigDict(
        env_file='.env',
        case_sensitive=True,
        extra='ignore'
    )

    # --- REMOVED problematic List fields ---
    # OPENROUTER_PROVISIONING_KEYS: List[str] = ...
    # TAVILY_API_KEYS: List[str] = ...

    # --- Other Settings ---
    API_V1_STR: str = "/api/v1"
    PROJECT_NAME: str = "NAICS Vendor Classification"
    FRONTEND_URL: str = "http://localhost:8080"
    SECRET_KEY: str = "supersecretkey"
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    PASSWORD_RESET_TOKEN_EXPIRE_MINUTES: int = 15
    DATABASE_URL: str = Field("postgresql://user:pass@host:port/db", validation_alias='DATABASE_URL')
    REDIS_URL: str = "redis://localhost:6379/0"
    INPUT_DATA_DIR: str = "/data/input"
    OUTPUT_DATA_DIR: str = "/data/output"
    TAXONOMY_DATA_DIR: str = "/data/taxonomy"
    OPENROUTER_API_BASE: str = "https://openrouter.ai/api/v1"
    OPENROUTER_MODEL: str = "nvidia/llama-3.1-nemotron-ultra-253b-v1:free" #"deepseek/deepseek-chat-v3-0324:free"
    GENERATED_KEY_NAME_PREFIX: str = "auto-gen-vendor-classifier"
    GENERATED_KEY_LABEL: Optional[str] = None
    GENERATED_KEY_CREDIT_LIMIT: Optional[float] = None
    BATCH_SIZE: int = 5
    MAX_RETRIES: int = 10
    RETRY_DELAY: int = 1
    SMTP_HOST: Optional[str] = None
    SMTP_PORT: int = 587
    SMTP_USER: Optional[str] = None
    SMTP_PASSWORD: Optional[str] = None
    SMTP_TLS: bool = True
    EMAIL_FROM: Optional[str] = None
    USE_LLM_CACHE: bool = False

# === Instantiate Settings (loads from .env EXCEPT for the removed fields) ===
try:
    settings = Settings()
    logger.info("Pydantic Settings object initialized successfully (excluding manual keys).")
    logger.info(f"Loaded DATABASE_URL: {settings.DATABASE_URL}") # Example check
    logger.info(f"Loaded USE_LLM_CACHE: {settings.USE_LLM_CACHE}")
except Exception as e:
     logger.error(f"CRITICAL: Failed to initialize Pydantic Settings object: {e}", exc_info=True)
     sys.exit("Failed to initialize settings.")


# === Manual Loading Section (Now assigns to module-level variables) ===
logger.info("Manually loading and parsing API keys from environment variables...")

# OpenRouter Provisioning Keys
openrouter_prov_keys_str = os.getenv('OPENROUTER_PROVISIONING_KEYS')
parsed_prov_keys = _parse_string_to_list(openrouter_prov_keys_str)
MANUAL_OPENROUTER_PROVISIONING_KEYS = parsed_prov_keys if parsed_prov_keys else DEFAULT_OPENROUTER_PROVISIONING_KEYS
if MANUAL_OPENROUTER_PROVISIONING_KEYS == DEFAULT_OPENROUTER_PROVISIONING_KEYS:
     logger.info("Using default OpenRouter Provisioning Keys.")
else:
     logger.info(f"Using {len(MANUAL_OPENROUTER_PROVISIONING_KEYS)} OpenRouter Provisioning Keys from environment.")
# Critical check for placeholders
if any("REPLACE_WITH_YOUR_VALID" in k for k in MANUAL_OPENROUTER_PROVISIONING_KEYS):
    logger.error("CRITICAL: Manually loaded OpenRouter Provisioning Keys contain placeholders!")

# Tavily API Keys
tavily_api_keys_str = os.getenv('TAVILY_API_KEYS')
parsed_tavily_keys = _parse_string_to_list(tavily_api_keys_str)
MANUAL_TAVILY_API_KEYS = parsed_tavily_keys if parsed_tavily_keys else DEFAULT_TAVILY_KEYS
if MANUAL_TAVILY_API_KEYS == DEFAULT_TAVILY_KEYS:
     logger.info("Using default Tavily Keys.")
else:
     logger.info(f"Using {len(MANUAL_TAVILY_API_KEYS)} Tavily Keys from environment.")
# Optional placeholder check
if any("REPLACE_WITH_YOUR_VALID" in k for k in MANUAL_TAVILY_API_KEYS):
    logger.warning("Warning: Manually loaded Tavily Keys may contain placeholders.")


logger.info("Manual API key loading complete.")
logger.info(f"Final Manual Prov Keys count: {len(MANUAL_OPENROUTER_PROVISIONING_KEYS)}")
logger.info(f"Final Manual Tavily Keys count: {len(MANUAL_TAVILY_API_KEYS)}")

</file>

<file path='app/core/database.py'>
import logging
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

from core.config import settings

# Configure logging
logger = logging.getLogger("vendor_classification.database")

logger.info("Initializing database connection")

# Create SQLAlchemy engine
try:
    engine = create_engine(settings.DATABASE_URL)
    logger.info(f"Database engine created successfully for {settings.DATABASE_URL.split('@')[-1]}")
except Exception as e:
    logger.error(f"Failed to create database engine: {e}")
    raise

# Create session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
logger.info("Database session factory created")

# Create base class for models
Base = declarative_base()
logger.info("SQLAlchemy Base declarative_base initialized")

def get_db():
    """Get database session."""
    db = SessionLocal()
    logger.debug("Database session created")
    try:
        yield db
    finally:
        db.close()
        logger.debug("Database session closed")
</file>

<file path='app/core/initialize_db.py'>
# --- file path='app/core/initialize_db.py' ---
import logging
from sqlalchemy import create_engine, inspect as sql_inspect # Added inspect
from sqlalchemy.exc import SQLAlchemyError # Added for specific exception handling
from core.database import Base, SessionLocal, engine # Import engine directly
from core.config import settings
import sys
import uuid
from api.auth import get_password_hash

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("vendor_classification.db_init")

# Import all models to ensure they're registered with SQLAlchemy
logger.info("Importing models for database initialization")
try:
    from models.user import User
    from models.job import Job
    # Import other models here if they exist
    logger.info("Models imported successfully.")
except ImportError as e:
    logger.critical(f"Failed to import models for DB initialization: {e}", exc_info=True)
    sys.exit(1) # Exit if models can't be imported

def create_or_update_admin_user():
    """
    Ensure the 'admin' user exists.
    If no user with username=admin, create one with default password 'password'.
    Otherwise, optionally update its password to ensure a consistent known credential.
    """
    db = None # Initialize db to None
    try:
        db = SessionLocal()
        logger.info("Checking for existing admin user...")
        admin_user = db.query(User).filter(User.username == "admin").first()
        if admin_user:
            logger.info("Admin user already exists.")
            # OPTIONAL: Force-update the password each time:
            # If you do NOT want to re-hash or overwrite the password, remove below lines.
            try:
                logger.info("Attempting to update admin password to default 'password'...")
                admin_user.hashed_password = get_password_hash("password")
                db.commit()
                logger.info("Admin password was updated/reset to default: 'password'.")
            except Exception as hash_err:
                logger.error(f"Failed to update admin password: {hash_err}", exc_info=True)
                db.rollback() # Rollback password change on error
        else:
            logger.info("Admin user not found, creating default admin user...")
            admin_user = User(
                id=str(uuid.uuid4()),
                username="admin",
                email="admin@example.com",
                full_name="Admin User",
                hashed_password=get_password_hash("password"),
                is_active=True,
                is_superuser=True
            )
            db.add(admin_user)
            db.commit()
            logger.info("Created default admin user: admin / password")
    except SQLAlchemyError as e: # Catch specific DB errors
        logger.error(f"Database error during admin user check/creation: {e}", exc_info=True)
        if db: db.rollback()
    except Exception as e: # Catch other errors like hashing
        logger.error(f"Unexpected error ensuring admin user: {e}", exc_info=True)
        if db: db.rollback()
    finally:
        if db:
            db.close()
            logger.info("Admin user check/creation DB session closed.")

    # --- Add sample users user_1 and user_2 ---
    sample_users = [
        {
            "username": "user_1",
            "email": "user_1@example.com",
            "full_name": "User One",
            "password": "user_1",
            "is_superuser": False
        },
        {
            "username": "user_2",
            "email": "user_2@example.com",
            "full_name": "User Two",
            "password": "user_2",
            "is_superuser": False
        }
    ]
    db = None
    try:
        db = SessionLocal()
        for user in sample_users:
            existing_user = db.query(User).filter(User.username == user["username"]).first()
            if existing_user:
                logger.info(f"Sample user '{user['username']}' already exists.")
                # Optionally update password to default
                try:
                    logger.info(f"Attempting to update password for '{user['username']}' to default '{user['password']}'...")
                    existing_user.hashed_password = get_password_hash(user["password"])
                    db.commit()
                    logger.info(f"Password for '{user['username']}' was updated/reset to default: '{user['password']}'.")
                except Exception as hash_err:
                    logger.error(f"Failed to update password for '{user['username']}': {hash_err}", exc_info=True)
                    db.rollback()
            else:
                logger.info(f"Sample user '{user['username']}' not found, creating...")
                new_user = User(
                    id=str(uuid.uuid4()),
                    username=user["username"],
                    email=user["email"],
                    full_name=user["full_name"],
                    hashed_password=get_password_hash(user["password"]),
                    is_active=True,
                    is_superuser=user["is_superuser"]
                )
                db.add(new_user)
                db.commit()
                logger.info(f"Created sample user: {user['username']} / {user['password']}")
    except SQLAlchemyError as e:
        logger.error(f"Database error during sample user check/creation: {e}", exc_info=True)
        if db: db.rollback()
    except Exception as e:
        logger.error(f"Unexpected error ensuring sample users: {e}", exc_info=True)
        if db: db.rollback()
    finally:
        if db:
            db.close()
            logger.info("Sample user check/creation DB session closed.")

def initialize_database():
    """Initialize database by creating all tables, then ensuring 'admin' user exists."""
    max_retries = 5
    retry_delay = 5 # seconds
    for attempt in range(max_retries):
        try:
            logger.info(f"Attempting database initialization (Attempt {attempt + 1}/{max_retries})...")
            # Use the imported engine
            logger.info(f"Using database engine for URL: {settings.DATABASE_URL.split('@')[-1]}")

            # Check connection before creating tables
            with engine.connect() as connection:
                logger.info("Successfully connected to the database.")

            logger.info("Inspecting existing tables...")
            inspector = sql_inspect(engine)
            existing_tables = inspector.get_table_names()
            logger.info(f"Existing tables found: {existing_tables}")

            logger.info("Attempting to create all tables defined in Base.metadata...")
            # Log the tables Base knows about
            logger.info(f"Base.metadata knows about tables: {list(Base.metadata.tables.keys())}")
            Base.metadata.create_all(engine)
            logger.info("Base.metadata.create_all(engine) executed successfully.")

            # Verify tables were created
            logger.info("Re-inspecting tables after create_all...")
            inspector = sql_inspect(engine) # Re-inspect
            new_existing_tables = inspector.get_table_names()
            logger.info(f"Tables found after create_all: {new_existing_tables}")

            # Specifically check for 'users' and 'jobs' tables
            if 'users' not in new_existing_tables:
                logger.error("'users' table NOT FOUND after create_all call!")
            else:
                logger.info("'users' table found after create_all call.")
            if 'jobs' not in new_existing_tables:
                logger.warning("'jobs' table NOT FOUND after create_all call!") # Maybe optional?
            else:
                logger.info("'jobs' table found after create_all call.")

            # Create or update the admin user
            create_or_update_admin_user()

            logger.info("Database initialization appears successful.")
            return True # Success

        except SQLAlchemyError as e:
            logger.error(f"Database connection or table creation error on attempt {attempt + 1}: {e}", exc_info=False) # Don't need full trace every retry
            if attempt + 1 == max_retries:
                logger.critical("Max retries reached. Database initialization failed.", exc_info=True)
                raise # Raise the last exception
            logger.info(f"Retrying in {retry_delay} seconds...")
            time.sleep(retry_delay)
        except Exception as e:
            logger.error(f"Unexpected error during database initialization attempt {attempt + 1}: {e}", exc_info=True)
            # Decide if retry makes sense for unexpected errors, maybe not
            raise # Re-raise immediately for unexpected errors

    logger.error("Database initialization failed after all retries.")
    return False # Should not be reached if exceptions are raised

if __name__ == "__main__":
    import time # Import time for retries
    logger.info("Starting database initialization script directly...")
    try:
        success = initialize_database()
        if success:
            logger.info("Database initialization script completed successfully.")
            sys.exit(0)
        else:
            logger.error("Database initialization script failed.")
            sys.exit(1)
    except Exception as e:
        logger.critical(f"Unhandled exception during database initialization script: {e}", exc_info=True)
        sys.exit(1)
</file>

<file path='app/core/log_context.py'>

# app/core/log_context.py
import threading
import uuid
import json
from typing import Optional, List, Dict, Any

# Create a thread-local storage for correlation IDs and context
local_storage = threading.local()

def set_correlation_id(correlation_id: Optional[str] = None) -> str:
    """Set a correlation ID for the current thread/context."""
    if correlation_id is None:
        correlation_id = str(uuid.uuid4())
    local_storage.correlation_id = correlation_id
    return correlation_id

def get_correlation_id() -> Optional[str]:
    """Get the current correlation ID."""
    return getattr(local_storage, 'correlation_id', None)

def set_request_id(request_id: Optional[str] = None) -> str:
    """Set a request ID for the current thread/context."""
    if request_id is None:
        request_id = str(uuid.uuid4())
    local_storage.request_id = request_id
    return request_id

def get_request_id() -> Optional[str]:
    """Get the current request ID."""
    return getattr(local_storage, 'request_id', None)

def set_job_id(job_id: str) -> str:
    """Set a job ID for the current thread/context."""
    local_storage.job_id = job_id
    return job_id

def get_job_id() -> Optional[str]:
    """Get the current job ID."""
    return getattr(local_storage, 'job_id', None)

def set_user(user: Any) -> Dict[str, Any]:
    """Set user information for the current thread/context, ensuring serializability."""
    user_info = {}
    if isinstance(user, dict):
        user_info = user.copy() # Avoid modifying original dict
    elif hasattr(user, 'username'):
        user_info['username'] = user.username
        user_info['id'] = getattr(user, 'id', None)
    elif user is not None:
        user_info['username'] = str(user)
    else:
        user_info = {'username': 'anonymous'} # Default for None

    # Ensure serializability
    serializable_user_info = {}
    for k, v in user_info.items():
        try:
            json.dumps({k: v})
            serializable_user_info[k] = v
        except TypeError:
            serializable_user_info[k] = str(v)

    local_storage.user = serializable_user_info
    return local_storage.user

def get_user() -> Optional[Dict[str, Any]]:
    """Get the current user information."""
    return getattr(local_storage, 'user', None)

def set_log_context(context_dict: Dict[str, Any]):
    """Add or update context data to logs for the current thread/context."""
    if not hasattr(local_storage, 'context'):
        local_storage.context = {}
    if isinstance(context_dict, dict):
        local_storage.context.update(context_dict)

def get_log_context() -> Dict[str, Any]:
    """Get the current log context dictionary."""
    return getattr(local_storage, 'context', {}).copy()

def clear_log_context(keys: Optional[List[str]] = None):
    """Clear specific or all log context for the current thread/context."""
    if hasattr(local_storage, 'context'):
        if keys:
            for key in keys:
                local_storage.context.pop(key, None)
        else:
            local_storage.context = {}

def set_performance_stats(stats_dict: Dict[str, Any]):
    """Set performance stats data for the current thread/context."""
    local_storage.performance_stats = stats_dict

def get_performance_stats() -> Dict[str, Any]:
    """Get the current performance statistics."""
    return getattr(local_storage, 'performance_stats', {}).copy()

def update_performance_stat(stat_name: str, value: float):
    """Update a single performance stat (e.g., duration)."""
    if not hasattr(local_storage, 'performance_stats'):
        local_storage.performance_stats = {}
    # Simple update, LogTimer in log_utils provides more detail
    local_storage.performance_stats[stat_name] = value

def clear_performance_stats():
    """Clear the performance statistics."""
    if hasattr(local_storage, 'performance_stats'):
        delattr(local_storage, 'performance_stats')

def clear_all_context():
    """Clear all context data (IDs, user, context dict, stats) for the current thread/context."""
    # Iterate through known attributes and remove them
    for attr in ['correlation_id', 'request_id', 'job_id', 'user', 'context', 'performance_stats']:
        if hasattr(local_storage, attr):
            try:
                delattr(local_storage, attr)
            except AttributeError:
                pass # Should not happen with hasattr check, but belt-and-suspenders
</file>

<file path='app/core/log_formatters.py'>

# app/core/log_formatters.py
import logging
import json
import socket
from datetime import datetime
from typing import Dict, Any

# Import context functions from the new module
from .log_context import get_correlation_id, get_job_id, get_request_id, get_user, get_log_context

class JsonFormatter(logging.Formatter):
    """Format logs as JSON for better parsing and analysis."""

    def format(self, record: logging.LogRecord) -> str:
        timestamp = datetime.utcfromtimestamp(record.created).isoformat() + "Z"

        # Base log data
        log_data: Dict[str, Any] = {
            "timestamp": timestamp,
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(), # Ensure message is formatted
        }

        # --- Add Context Fields ---
        context_fields = {}
        correlation_id = get_correlation_id()
        if correlation_id:
            context_fields["correlation_id"] = correlation_id
        job_id = get_job_id()
        if job_id:
            context_fields["job_id"] = job_id
        request_id = get_request_id()
        if request_id:
             context_fields["request_id"] = request_id
        user_info = get_user()
        if user_info:
             # User info should already be serializable from set_user
             context_fields["user"] = user_info

        # Merge context fields
        log_data.update(context_fields)

        # --- Add Caller Info ---
        caller_info = {
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        log_data.update(caller_info)

        # --- Add Process/Thread Info ---
        process_info = {
            "process_id": record.process,
            "thread_id": record.thread,
            "host": socket.gethostname(),
        }
        log_data.update(process_info)

        # --- Add Exception Info ---
        if record.exc_info:
            exc_type, exc_value, exc_traceback = record.exc_info
            exception_info = {
                "type": exc_type.__name__ if exc_type else "Unknown",
                "message": str(exc_value) if exc_value else "",
                "traceback": self.formatException(record.exc_info) if exc_traceback else None
            }
            log_data["exception"] = exception_info

        if record.stack_info:
            log_data["stack_info"] = record.stack_info

        # --- Add Extra Attributes ---
        extra_data = {}
        standard_attrs = set(logging.LogRecord('', '', '', '', '', '', '', '').__dict__.keys()) | {'message', 'asctime', 'relativeCreated', 'exc_text', 'stack_info'} | set(log_data.keys())
        for key, value in record.__dict__.items():
            if key not in standard_attrs:
                extra_data[key] = value

        # Add the renamed function arguments if present in extra_data
        if 'function_args' in extra_data:
             log_data['function_args'] = extra_data.pop('function_args') # Move it to log_data
        if 'result' in extra_data:
             log_data['result'] = extra_data.pop('result') # Move result too

        # Merge remaining extra data, ensuring serializability
        if extra_data:
            for key, value in extra_data.items():
                if key not in log_data:
                    try:
                        json.dumps({key: value}) # Test serialization
                        log_data[key] = value
                    except TypeError:
                        log_data[key] = f"[Unserializable Extra: {type(value).__name__}] {str(value)[:100]}"

        # Add thread-local context dictionary items
        log_context_dict = get_log_context()
        if log_context_dict:
            for key, value in log_context_dict.items():
                if key not in log_data:
                     try:
                        json.dumps({key: value})
                        log_data[key] = value
                     except TypeError:
                        log_data[key] = f"[Unserializable Context: {type(value).__name__}] {str(value)[:100]}"

        try:
            return json.dumps(log_data, default=str) # Use default=str as fallback for non-serializable types
        except Exception as dump_err:
            # Fallback if JSON dumping fails completely
            error_log = {
                 "timestamp": timestamp,
                 "level": "ERROR",
                 "logger": "logging.JsonFormatter",
                 "message": "Failed to serialize log record to JSON.",
                 "original_logger": record.name,
                 "original_level": record.levelname,
                 "error": str(dump_err),
                 "record_preview": str(record.__dict__)[:500]
            }
            return json.dumps(error_log)
</file>

<file path='app/core/log_handlers.py'>
import os
import logging
import json
import gzip
import time
from logging.handlers import RotatingFileHandler, TimedRotatingFileHandler
from typing import Dict, Any, Optional, List
from datetime import datetime

class GzipRotatingFileHandler(RotatingFileHandler):
    """
    Extended version of RotatingFileHandler that compresses logs when they're rotated.
    """
    
    def __init__(self, filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=0):
        """Initialize with standard RotatingFileHandler params."""
        super().__init__(
            filename, mode, maxBytes, backupCount, encoding, delay
        )
    
    def doRollover(self):
        """
        Override doRollover to compress the rotated file.
        """
        # Close the current file
        if self.stream:
            self.stream.close()
            self.stream = None
            
        # Rotate the files as normal
        if self.backupCount > 0:
            # Remove the oldest log file if it exists
            oldest_log = f"{self.baseFilename}.{self.backupCount}.gz"
            if os.path.exists(oldest_log):
                os.remove(oldest_log)
                
            # Shift each log file to the next number
            for i in range(self.backupCount - 1, 0, -1):
                source = f"{self.baseFilename}.{i}"
                if os.path.exists(source):
                    target = f"{self.baseFilename}.{i + 1}.gz"
                    with open(source, 'rb') as f_in:
                        with gzip.open(target, 'wb') as f_out:
                            f_out.writelines(f_in)
                    os.remove(source)
                # Also check if there's already a gzipped version
                source = f"{self.baseFilename}.{i}.gz"
                if os.path.exists(source):
                    target = f"{self.baseFilename}.{i + 1}.gz"
                    os.rename(source, target)
            
            # Compress the most recently rotated file
            source = self.baseFilename
            target = f"{self.baseFilename}.1.gz"
            
            if os.path.exists(self.baseFilename):
                with open(source, 'rb') as f_in:
                    with gzip.open(target, 'wb') as f_out:
                        f_out.writelines(f_in)
        
        # Create a new log file
        if not self.delay:
            self.stream = self._open()

class SizedTimedRotatingFileHandler(TimedRotatingFileHandler):
    """
    A combination of TimedRotatingFileHandler and RotatingFileHandler.
    Rotates logs based on both time and size.
    """
    
    def __init__(
        self, filename, when='h', interval=1, backupCount=0, encoding=None, 
        delay=False, utc=False, atTime=None, maxBytes=0
    ):
        """
        Initialize with standard TimedRotatingFileHandler params plus maxBytes.
        
        Args:
            maxBytes: Maximum file size in bytes before rotation
        """
        super().__init__(
            filename, when, interval, backupCount, encoding, delay, utc, atTime
        )
        self.maxBytes = maxBytes
    
    def shouldRollover(self, record):
        """
        Check if rollover should occur based on either time or size.
        
        Args:
            record: Log record
            
        Returns:
            True if rollover should occur, False otherwise
        """
        # Check if we should rotate based on time
        time_rotate = super().shouldRollover(record)
        
        # Check if we should rotate based on size
        size_rotate = False
        if self.maxBytes > 0:
            if self.stream is None:
                self.stream = self._open()
            if self.stream.tell() + self.computeRollover(record) >= self.maxBytes:
                size_rotate = True
                
        return time_rotate or size_rotate

class JsonLogFileHandler(logging.FileHandler):
    """
    A log handler that writes JSON formatted logs to a file.
    """
    
    def __init__(self, filename, mode='a', encoding=None, delay=False):
        """Initialize with standard FileHandler params."""
        super().__init__(filename, mode, encoding, delay)
    
    def format(self, record):
        """
        Format the record as JSON.
        
        Args:
            record: Log record
            
        Returns:
            JSON formatted log entry
        """
        log_data = {
            "timestamp": datetime.utcfromtimestamp(record.created).isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
            "process": record.process,
            "thread": record.thread
        }
        
        # Add exception info if present
        if record.exc_info:
            exception_type = record.exc_info[0].__name__ if record.exc_info[0] else "Unknown"
            exception_msg = str(record.exc_info[1]) if record.exc_info[1] else ""
            log_data["exception"] = {
                "type": exception_type,
                "message": exception_msg,
                "traceback": self.formatException(record.exc_info)
            }
        
        # Add any extra attributes from the record
        for key, value in record.__dict__.items():
            if key not in [
                'args', 'asctime', 'created', 'exc_info', 'exc_text', 'filename',
                'funcName', 'id', 'levelname', 'levelno', 'lineno', 'module',
                'msecs', 'message', 'msg', 'name', 'pathname', 'process',
                'processName', 'relativeCreated', 'stack_info', 'thread', 'threadName'
            ]:
                log_data[key] = value
        
        return json.dumps(log_data)

class LogBufferHandler(logging.Handler):
    """
    A handler that keeps a buffer of recent log records in memory.
    Useful for accessing recent logs programmatically.
    """
    
    def __init__(self, capacity=1000):
        """
        Initialize with buffer capacity.
        
        Args:
            capacity: Maximum number of log records to keep in buffer
        """
        super().__init__()
        self.capacity = capacity
        self.buffer = []
    
    def emit(self, record):
        """
        Add record to buffer.
        
        Args:
            record: Log record
        """
        self.buffer.append({
            "timestamp": datetime.utcfromtimestamp(record.created).isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage()
        })
        
        # Trim buffer if it exceeds capacity
        if len(self.buffer) > self.capacity:
            self.buffer = self.buffer[-self.capacity:]
    
    def get_logs(self, count=None, level=None, logger=None):
        """
        Get logs from buffer, optionally filtered.
        
        Args:
            count: Maximum number of logs to return
            level: Filter by log level
            logger: Filter by logger name
            
        Returns:
            List of log records
        """
        result = self.buffer
        
        if level:
            result = [r for r in result if r["level"] == level]
        
        if logger:
            result = [r for r in result if r["logger"] == logger]
        
        if count:
            result = result[-count:]
            
        return result
    
    def clear(self):
        """Clear the log buffer."""
        self.buffer = []
</file>

<file path='app/core/logging_config.py'>

# app/core/logging_config.py
import logging
import os
import sys
import uuid
import queue
from logging.handlers import RotatingFileHandler, QueueHandler, QueueListener, TimedRotatingFileHandler
from typing import Optional

# Import from new/refactored modules
from .log_formatters import JsonFormatter
# Context functions are now used implicitly by the formatter or middleware

# Global variable to hold the queue listener instance
_queue_listener: Optional[QueueListener] = None

def get_logger(name: str) -> logging.Logger:
    """Get a logger with the specified name."""
    # This function remains simple, just returns the logger instance.
    # Configuration is handled by setup_logging.
    logger = logging.getLogger(name)
    return logger

def setup_logging(log_level: Optional[int] = None, log_to_file: bool = True, log_dir: str = "/data/logs",
                  log_format: str = "json", async_logging: bool = True,
                  llm_trace_log_file: str = "llm_api_trace.log"):
    """
    Setup application logging using the specified configuration.
    """
    # Determine log level from environment or parameter
    if log_level is None:
        env = os.getenv("ENVIRONMENT", "development").lower()
        log_level_name = os.getenv("LOG_LEVEL", "INFO" if env == "production" else "DEBUG")
        try:
            log_level = getattr(logging, log_level_name.upper())
        except AttributeError:
            print(f"WARNING: Invalid LOG_LEVEL '{log_level_name}'. Defaulting to INFO.")
            log_level = logging.INFO

    # Validate or create log directory
    effective_log_dir = None
    if log_to_file:
        if not log_dir:
            print("ERROR: log_to_file is True, but log_dir is not specified. Disabling file logging.")
            log_to_file = False
        else:
            try:
                abs_log_dir = os.path.abspath(log_dir)
                os.makedirs(abs_log_dir, exist_ok=True)
                # Test write permissions
                test_file_path = os.path.join(abs_log_dir, f"startup_test_{uuid.uuid4()}.log")
                with open(test_file_path, "w") as f:
                    f.write("Write test successful.")
                os.remove(test_file_path)
                effective_log_dir = abs_log_dir
                print(f"Logging directory verified: {effective_log_dir}")
            except OSError as e:
                print(f"ERROR: Could not create or write to logging directory {abs_log_dir}: {e}. Disabling file logging.")
                log_to_file = False
            except Exception as e:
                 print(f"ERROR: Unexpected error verifying logging directory {abs_log_dir}: {e}. Disabling file logging.")
                 log_to_file = False

    # Configure the root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level)

    # Clear any existing handlers to prevent duplicates
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
        if hasattr(handler, 'close') and callable(handler.close):
             try: handler.close()
             except Exception as close_err: print(f"Error closing handler: {close_err}")

    # Select formatter based on format
    if log_format.lower() == 'json':
        formatter = JsonFormatter() # Use the imported formatter
    else:
        # Basic formatter as fallback (though JSON is recommended)
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S,%f'
        )

    handlers = []

    # Create console handler (always add this one)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter) # Use selected formatter for console
    handlers.append(console_handler)

    # Create file handler if requested and directory is valid
    if log_to_file and effective_log_dir:
        try:
            main_log_path = os.path.join(effective_log_dir, "vendor_classification.log")
            print(f"Setting up main log file at: {main_log_path}")
            file_handler = RotatingFileHandler(
                main_log_path,
                maxBytes=10 * 1024 * 1024,  # 10 MB
                backupCount=10
            )
            file_handler.setFormatter(formatter)
            handlers.append(file_handler)

            # Create an error log file that only contains ERROR and higher
            error_log_path = os.path.join(effective_log_dir, "errors.log")
            print(f"Setting up error log file at: {error_log_path}")
            error_file_handler = RotatingFileHandler(
                error_log_path,
                maxBytes=10 * 1024 * 1024,  # 10 MB
                backupCount=10
            )
            error_file_handler.setFormatter(formatter)
            error_file_handler.setLevel(logging.ERROR)
            handlers.append(error_file_handler)

        except Exception as file_handler_err:
            print(f"ERROR: Failed to create file handlers in {effective_log_dir}: {file_handler_err}. File logging disabled.")
            handlers = [h for h in handlers if not isinstance(h, RotatingFileHandler)]
            log_to_file = False # Disable flag if handlers failed

    # --- Async Logging Setup ---
    global _queue_listener
    if _queue_listener:
        print("Stopping existing queue listener...")
        try:
            _queue_listener.stop()
            _queue_listener = None
        except Exception as stop_err:
             print(f"Error stopping existing listener: {stop_err}")

    if async_logging:
        log_queue = queue.Queue(-1) # Use an infinite queue size
        queue_handler = QueueHandler(log_queue)
        root_logger.addHandler(queue_handler) # Add ONLY the queue handler to root
        _queue_listener = QueueListener(log_queue, *handlers, respect_handler_level=True)
        _queue_listener.start()
        print("Async logging configured with QueueListener.")
    else:
        for handler in handlers:
            root_logger.addHandler(handler)
        print("Synchronous logging configured.")
    # --- End Async Logging Setup ---

    # --- LLM TRACE LOGGING SETUP ---
    if log_to_file and effective_log_dir and llm_trace_log_file:
        try:
            llm_trace_logger = logging.getLogger("llm_api_trace")
            llm_trace_logger.setLevel(logging.DEBUG) # Log everything for trace
            llm_trace_logger.propagate = False # Don't send to root logger

            for handler in llm_trace_logger.handlers[:]:
                llm_trace_logger.removeHandler(handler)
                if hasattr(handler, 'close') and callable(handler.close):
                    try: handler.close()
                    except Exception as close_err: print(f"Error closing existing trace handler: {close_err}")

            llm_trace_log_path = os.path.join(effective_log_dir, llm_trace_log_file)
            print(f"Setting up LLM trace log at: {llm_trace_log_path}")
            llm_trace_formatter = JsonFormatter() # Use the same JSON formatter
            llm_trace_handler = TimedRotatingFileHandler(
                 llm_trace_log_path, when='midnight', interval=1, backupCount=7
            )
            llm_trace_handler.setFormatter(llm_trace_formatter)
            llm_trace_logger.addHandler(llm_trace_handler)
            root_logger.info(f"LLM API trace logging initialized", extra={"file": llm_trace_log_path})
            llm_trace_logger.info("LLM_TRACE: Initialization successful.", extra={'correlation_id': 'startup'})
        except Exception as e:
            root_logger.error("Failed to initialize LLM API trace logging", exc_info=True)
            print(f"ERROR: Failed to initialize LLM API trace logging: {e}")
    elif log_to_file:
         root_logger.warning("LLM API trace logging disabled because file logging is disabled or trace filename is empty.")
    # --- END LLM TRACE LOGGING SETUP ---

    # Set specific log levels for noisy libraries
    logging.getLogger("uvicorn").setLevel(logging.INFO)
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
    logging.getLogger("sqlalchemy.engine").setLevel(logging.WARNING)
    logging.getLogger("celery").setLevel(logging.INFO)

    # Log setup completion
    root_logger.info(
        "Logging setup complete",
        extra={
            "log_level": logging.getLevelName(log_level),
            "log_dir": effective_log_dir if log_to_file else None,
            "handlers": [h.__class__.__name__ + (f' ({h.baseFilename})' if hasattr(h, 'baseFilename') else '') for h in handlers],
            "async_mode": async_logging
        }
    )

    return root_logger
</file>

<file path='app/middleware/__init__.py'>
# Import middleware classes to make them available when importing from the package
from .logging_middleware import RequestLoggingMiddleware, RequestBodyLoggingMiddleware, log_request_middleware

__all__ = ['RequestLoggingMiddleware', 'RequestBodyLoggingMiddleware', 'log_request_middleware']
</file>

<file path='app/middleware/db_logging_middleware.py'>
import time
import logging
import sqlalchemy
from sqlalchemy import event
from sqlalchemy.engine import Engine

from core.logging_config import get_logger, set_log_context, LogTimer, get_correlation_id

logger = get_logger("vendor_classification.database")

class SQLQueryLoggingMiddleware:
    """Middleware for logging SQL queries."""
    
    def __init__(self, engine):
        """Initialize the middleware with an SQLAlchemy engine."""
        self.engine = engine
        self.register_events()
        logger.info("SQL query logging middleware initialized")
    
    def register_events(self):
        """Register SQLAlchemy event listeners."""
        event.listen(self.engine, "before_cursor_execute", self.before_cursor_execute)
        event.listen(self.engine, "after_cursor_execute", self.after_cursor_execute)
        event.listen(self.engine, "handle_error", self.handle_error)
        logger.debug("SQLAlchemy event listeners registered")
    
    def before_cursor_execute(self, conn, cursor, statement, parameters, context, executemany):
        """Log query before execution and store start time."""
        conn.info.setdefault('query_start_time', []).append(time.time())
        
        # Truncate long queries for readability
        statement_str = str(statement)
        if len(statement_str) > 1000:
            statement_str = statement_str[:997] + "..."
        
        # Format parameters safely for logging
        params_str = str(parameters)
        if len(params_str) > 500:
            params_str = params_str[:497] + "..."
        
        logger.debug(
            f"Executing SQL query", 
            extra={
                "statement": statement_str,
                "parameters": params_str,
                "executemany": executemany,
                "connection_id": id(conn),
                "correlation_id": get_correlation_id()
            }
        )
    
    def after_cursor_execute(self, conn, cursor, statement, parameters, context, executemany):
        """Log query completion and execution time."""
        if not conn.info.get('query_start_time'):
            return
        
        start_time = conn.info['query_start_time'].pop(-1)
        total_time = time.time() - start_time
        
        # Get result details safely
        row_count = -1
        try:
            row_count = cursor.rowcount
        except:
            pass
        
        # Store query timing in thread-local storage for stats
        statement_type = statement.split(' ')[0].upper() if isinstance(statement, str) else "UNKNOWN"
        
        logger.debug(
            f"SQL query completed", 
            extra={
                "duration": total_time,
                "row_count": row_count,
                "statement_type": statement_type,
                "connection_id": id(conn),
                "correlation_id": get_correlation_id()
            }
        )
        
        # Add to performance stats
        set_log_context({f"db_{statement_type.lower()}_count": 1})
        set_log_context({f"db_{statement_type.lower()}_time": total_time})
    
    def handle_error(self, context):
        """Log database errors."""
        logger.error(
            f"Database error occurred", 
            exc_info=context.original_exception,
            extra={
                "statement": str(context.statement) if context.statement else None,
                "parameters": str(context.parameters) if context.parameters else None,
                "correlation_id": get_correlation_id()
            }
        )

def setup_db_logging(engine=None):
    """Set up database query logging."""
    if engine is None:
        # Get all engines if specific one not provided
        for instance in Engine.__subclasses__():
            for engine in instance.instances:
                SQLQueryLoggingMiddleware(engine)
    else:
        SQLQueryLoggingMiddleware(engine)
    
    logger.info("Database query logging initialized")
</file>

<file path='app/middleware/logging_middleware.py'>

# app/middleware/logging_middleware.py
import time
import json
import uuid
import logging # <<< ADDED IMPORT
from typing import Callable
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.types import ASGIApp, Receive, Scope, Send

# Import context functions from the new module
from core.log_context import (
    set_request_id, get_request_id, set_correlation_id, get_correlation_id,
    set_user, set_log_context, clear_all_context
)
# Import logger and log helpers
from core.logging_config import get_logger
from utils.log_utils import log_duration

# Configure logger for this module
logger = get_logger("vendor_classification.middleware")
# --- ADDED: Log confirmation ---
logger.debug("Successfully imported standard logging module.")
# --- END ADDED ---

class RequestLoggingMiddleware(BaseHTTPMiddleware):
    """Middleware to log all requests and responses."""

    async def dispatch(self, request: Request, call_next):
        # Generate or extract request ID
        request_id = request.headers.get("X-Request-ID") or str(uuid.uuid4())
        # Set request ID and correlation ID
        set_request_id(request_id)
        correlation_id = request.headers.get("X-Correlation-ID")
        if correlation_id:
            set_correlation_id(correlation_id)
        else:
            set_correlation_id(request_id)  # Use request_id as correlation_id if none provided

        # Add context data
        set_log_context({
            "client_ip": request.client.host if request.client else None,
            "user_agent": request.headers.get("user-agent"),
            "path": request.url.path,
            "method": request.method,
        })

        # Log request
        logger.info(
            f"Request started: {request.method} {request.url.path}",
            extra={
                "request_id": request_id,
                "query_params": dict(request.query_params),
                "path_params": request.path_params,
                "headers": { k.lower(): v for k, v in request.headers.items() }
            }
        )

        # Process the request and measure time
        start_time = time.time()
        try:
            response = await call_next(request)

            # Log response
            process_time = time.time() - start_time
            logger.info(
                f"Request completed: {request.method} {request.url.path}",
                extra={
                    "status_code": response.status_code,
                    "duration": process_time,
                    "response_headers": {
                        k.lower(): v for k, v in response.headers.items()
                    }
                }
            )

            # Add the request ID to response headers
            response.headers["X-Request-ID"] = request_id

            return response

        except Exception as exc:
            # Log any unhandled exceptions
            process_time = time.time() - start_time
            logger.exception(
                f"Request failed: {request.method} {request.url.path}",
                extra={
                    "duration": process_time,
                    "error": str(exc)
                }
            )
            raise
        finally:
            # Clear context data to prevent leaks between requests
            clear_all_context()


class RequestBodyLoggingMiddleware(BaseHTTPMiddleware):
    """
    Middleware to log request and response bodies.
    Note: Use only in development/debugging.
    """

    def __init__(
        self,
        app: ASGIApp,
        exclude_paths: list = None,
        max_body_size: int = 10000
    ):
        super().__init__(app)
        self.exclude_paths = exclude_paths or ["/health", "/metrics", "/static"]
        self.max_body_size = max_body_size

    async def dispatch(self, request: Request, call_next):
        # Skip excluded paths
        if any(request.url.path.startswith(path) for path in self.exclude_paths):
            return await call_next(request)

        # Get request ID
        request_id = get_request_id() or str(uuid.uuid4())

        # Clone the request to access the body
        copied_body = await self._get_request_body(request)

        if copied_body:
            body_str = self._get_body_str(copied_body)
            logger.debug(
                f"Request body: {request.method} {request.url.path}",
                extra={
                    "request_id": request_id,
                    "request_body": body_str
                }
            )

        # Process the request
        response = await call_next(request)

        # Try to get response body for certain content types
        if response.status_code != 204 and hasattr(response, "body"):
            body = response.body
            if body:
                body_str = self._get_body_str(body)
                logger.debug(
                    f"Response body: {request.method} {request.url.path}",
                    extra={
                        "request_id": request_id,
                        "response_body": body_str,
                        "status_code": response.status_code
                    }
                )

        return response

    def _get_body_str(self, body: bytes) -> str:
        """Convert body bytes to string, truncating if needed."""
        if len(body) > self.max_body_size:
            return f"{body[:self.max_body_size].decode('utf-8', errors='replace')}... [truncated]"

        try:
            body_str = body.decode('utf-8')
            # Try to pretty-print JSON
            try:
                json_body = json.loads(body_str)
                body_str = json.dumps(json_body, indent=2)
            except:
                pass
            return body_str
        except:
            return f"[binary data, length: {len(body)}]"

    async def _get_request_body(self, request: Request) -> bytes:
        """Get and restore the request body."""
        body = await request.body()
        # Reset the request body
        async def receive():
            return {"type": "http.request", "body": body}
        request._receive = receive
        return body


async def log_request_middleware(request: Request, call_next) -> Response:
    """
    Alternative logging middleware function that can be used with middleware decorator.
    """
    request_id = request.headers.get("X-Request-ID") or str(uuid.uuid4())
    set_request_id(request_id)
    correlation_id = request.headers.get("X-Correlation-ID")
    if correlation_id:
        set_correlation_id(correlation_id)
    else:
        set_correlation_id(request_id)

    # Add context data
    set_log_context({
        "client_ip": request.client.host if request.client else None,
        "user_agent": request.headers.get("user-agent"),
        "path": request.url.path,
        "method": request.method,
    })

    # Log request
    logger.info(
        f"Request started: {request.method} {request.url.path}",
        extra={
            "request_id": request_id,
            "query_params": dict(request.query_params),
            "path_params": request.path_params,
        }
    )

    try:
        with log_duration(logger, f"Request {request.method} {request.url.path}",
                         level=logging.INFO, include_in_stats=True): # Use INFO level for request duration
            # Process the request
            response = await call_next(request)

        # Log response summary
        logger.info(
            f"Request completed: {request.method} {request.url.path}",
            extra={
                "status_code": response.status_code,
            }
        )

        # Add the request ID to response headers
        response.headers["X-Request-ID"] = request_id

        return response

    except Exception as e:
        logger.exception(f"Request failed: {request.method} {request.url.path}")
        raise
    finally:
        # Clear context data to prevent leaks between requests
        clear_all_context()
</file>

<file path='app/models/classification.py'>

# <file path='app/models/classification.py'>
# --- file path='app/models/classification.py' ---
from pydantic import BaseModel, Field
from typing import List, Dict, Optional, Any

class VendorClassification(BaseModel):
    """Vendor classification model."""
    vendor_name: str
    category_id: str
    category_name: str
    confidence: float = Field(ge=0.0, le=1.0)
    notes: Optional[str] = None
    classification_not_possible: bool = False
    classification_not_possible_reason: Optional[str] = None
    sources: Optional[List[Dict[str, str]]] = None
    classification_source: Optional[str] = None # e.g., 'Initial', 'Search'

class ClassificationBatchResponse(BaseModel):
    """Response model for classification batch (expected from LLM)."""
    # --- MODIFIED: Allow level up to 5 ---
    level: int = Field(ge=1, le=5)
    # --- END MODIFIED ---
    batch_id: str
    parent_category_id: Optional[str] = None
    classifications: List[VendorClassification] # LLM should return this structure

class ApiUsage(BaseModel):
    """API usage statistics."""
    # Field names match the keys used in the stats dictionary
    openrouter_calls: int = 0
    openrouter_prompt_tokens: int = 0
    openrouter_completion_tokens: int = 0
    openrouter_total_tokens: int = 0
    tavily_search_calls: int = 0
    cost_estimate_usd: float = 0.0

class ProcessingStats(BaseModel):
    """Processing statistics for a job (stored in Job.stats JSON)."""
    job_id: str
    company_name: str
    start_time: Any # Can be datetime or ISO string
    end_time: Optional[Any] = None
    processing_duration_seconds: Optional[float] = None
    total_vendors: int = 0
    unique_vendors: int = 0
    # --- UPDATED/ADDED Fields ---
    target_level: int # Store the requested target level
    successfully_classified_l4: int = 0 # Keep L4 count for reference/comparison
    successfully_classified_l5: int = 0 # NEW: Total vendors reaching L5 (initial or post-search)
    classification_not_possible_initial: int = 0 # Vendors needing search initially
    invalid_category_errors: int = 0 # Count of times LLM returned invalid category ID
    search_attempts: int = 0 # How many vendors triggered the search path
    search_successful_classifications_l1: int = 0 # Vendors getting L1 via search
    search_successful_classifications_l5: int = 0 # NEW: Vendors getting L5 via search path
    # --- END UPDATED/ADDED ---
    api_usage: ApiUsage = Field(default_factory=ApiUsage)

</file>

<file path='app/models/job.py'>
# <file path='app/models/job.py'>
# --- file path='app/models/job.py' ---
from sqlalchemy import Column, String, Float, DateTime, Enum as SQLEnum, JSON, Text, Integer, ForeignKey, Index # <<< ADDED Index
from sqlalchemy.sql import func
from sqlalchemy.orm import Session # <<< ADDED IMPORT FOR TYPE HINTING
from enum import Enum as PyEnum
from datetime import datetime, timezone # <<< Added timezone
from typing import Optional, Dict, Any, List # <<< ADDED List

from core.database import Base

class JobStatus(str, PyEnum):
    """Job status enum."""
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

class ProcessingStage(str, PyEnum):
    """Processing stage enum."""
    INGESTION = "ingestion"
    NORMALIZATION = "normalization"
    CLASSIFICATION_L1 = "classification_level_1"
    CLASSIFICATION_L2 = "classification_level_2"
    CLASSIFICATION_L3 = "classification_level_3"
    CLASSIFICATION_L4 = "classification_level_4"
    CLASSIFICATION_L5 = "classification_level_5" # ADDED L5 Stage
    SEARCH = "search_unknown_vendors" # This stage now covers search AND recursive post-search classification
    RECLASSIFICATION = "reclassification" # <<< ADDED Reclassification Stage
    RESULT_GENERATION = "result_generation"

# --- ADDED: Job Type Enum ---
class JobType(str, PyEnum):
    """Type of job."""
    CLASSIFICATION = "CLASSIFICATION"
    REVIEW = "REVIEW"
# --- END ADDED ---


class Job(Base):
    """Job model for tracking classification jobs."""

    __tablename__ = "jobs"

    id = Column(String, primary_key=True, index=True)
    company_name = Column(String, nullable=False)
    input_file_name = Column(String, nullable=False)
    output_file_name = Column(String, nullable=True)
    status = Column(String, default=JobStatus.PENDING.value) # Consider adding index if frequently filtered by status
    current_stage = Column(String, default=ProcessingStage.INGESTION.value)
    progress = Column(Float, default=0.0)
    created_at = Column(DateTime(timezone=True), server_default=func.now()) # Consider adding index if frequently sorted/filtered by creation time
    updated_at = Column(DateTime(timezone=True), onupdate=func.now(), server_default=func.now()) # Consider index if filtered by update time (e.g., failed jobs in last X hours)
    completed_at = Column(DateTime(timezone=True), nullable=True)
    notification_email = Column(String, nullable=True)
    error_message = Column(Text, nullable=True)
    stats = Column(JSON, default={}) # Structure defined by ProcessingStats model OR used for review inputs/status
    created_by = Column(String, nullable=False) # Consider adding index if frequently filtered by user
    target_level = Column(Integer, nullable=False, default=5) # Store the desired classification depth (1-5)

    # --- ADDED: Job Type and Parent Link ---
    job_type = Column(String, default=JobType.CLASSIFICATION.value, nullable=False) # Consider adding index if frequently filtered by job type
    parent_job_id = Column(String, ForeignKey("jobs.id"), nullable=True, index=True) # Link to original job for reviews
    # --- END ADDED ---

    # Stores List[JobResultItem] for CLASSIFICATION jobs
    # Stores List[ReviewResultItem] for REVIEW jobs
    detailed_results = Column(JSON, nullable=True)


    # --- ADDED: Potential Indexes for Admin Dashboard Performance ---
    __table_args__ = (
        Index('ix_jobs_status_updated_at', 'status', 'updated_at'), # For failed jobs in last X hours query
        Index('ix_jobs_created_at_desc', created_at.desc()), # For recent jobs query
        Index('ix_jobs_created_by', 'created_by'), # If filtering by user becomes common
        Index('ix_jobs_job_type', 'job_type'), # If filtering by job type becomes common
        # parent_job_id already has an index due to index=True above
    )
    # --- END ADDED ---


    def update_progress(self, progress: float, stage: ProcessingStage, db_session: Optional[Session] = None): # Type hint now valid
        """Update job progress and stage, optionally committing."""
        self.progress = progress
        self.current_stage = stage.value
        self.updated_at = datetime.now(timezone.utc) # Use timezone aware now
        # Optionally commit immediately if session provided
        if db_session:
            try:
                db_session.commit()
            except Exception as e:
                from core.logging_config import get_logger # Local import for safety
                logger = get_logger("vendor_classification.job_model")
                logger.error(f"Failed to commit progress update for job {self.id}", exc_info=True)
                db_session.rollback()


    # --- UPDATED: complete method signature ---
    # detailed_results type hint updated to handle both list types
    def complete(self, output_file_name: Optional[str], stats: Dict[str, Any], detailed_results: Optional[List[Dict[str, Any]]] = None):
    # --- END UPDATED ---
        """Mark job as completed."""
        self.status = JobStatus.COMPLETED.value
        self.progress = 1.0
        # Ensure stage reflects completion (Result Generation for CLASSIFICATION, RECLASSIFICATION for REVIEW)
        self.current_stage = ProcessingStage.RESULT_GENERATION.value if self.job_type == JobType.CLASSIFICATION.value else ProcessingStage.RECLASSIFICATION.value
        self.output_file_name = output_file_name # Can be None for review jobs if no file is generated
        self.completed_at = datetime.now(timezone.utc) # Use timezone aware now
        self.stats = stats
        # --- UPDATED: Save detailed results ---
        self.detailed_results = detailed_results
        # --- END UPDATED ---
        self.updated_at = self.completed_at # Align updated_at with completed_at

    def fail(self, error_message: str):
        """Mark job as failed."""
        self.status = JobStatus.FAILED.value
        # Optionally set progress to 1.0 or leave as is upon failure
        # self.progress = 1.0
        self.error_message = error_message
        self.updated_at = datetime.now(timezone.utc) # Use timezone aware now
        # Ensure completed_at is Null if it failed
        self.completed_at = None
        # --- UPDATED: Ensure detailed_results is Null if it failed ---
        self.detailed_results = None
        # --- END UPDATED ---
</file>

<file path='app/models/taxonomy.py'>
# <file path='app/models/taxonomy.py'>
# --- file path='app/models/taxonomy.py' ---
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Any # <<< ADDED Any
import re # Added import

# --- ADDED: Import logger ---
from core.logging_config import get_logger
logger = get_logger("vendor_classification.taxonomy_model")
# --- END ADDED ---


class TaxonomyCategory(BaseModel):
    """Base taxonomy category model."""
    id: str
    name: str
    description: Optional[str] = None

# --- ADDED: Level 5 Model ---
class TaxonomyLevel5(TaxonomyCategory):
    """Level 5 taxonomy category (most specific - typically 6 digits)."""
    pass
# --- END ADDED ---

class TaxonomyLevel4(TaxonomyCategory):
    """Level 4 taxonomy category (typically 5 digits)."""
    # --- MODIFIED: Add children for Level 5 ---
    children: Dict[str, TaxonomyLevel5] = Field(default_factory=dict)
    # --- END MODIFIED ---

class TaxonomyLevel3(TaxonomyCategory):
    """Level 3 taxonomy category."""
    children: Dict[str, TaxonomyLevel4] = Field(default_factory=dict)

class TaxonomyLevel2(TaxonomyCategory):
    """Level 2 taxonomy category."""
    children: Dict[str, TaxonomyLevel3] = Field(default_factory=dict)

class TaxonomyLevel1(TaxonomyCategory):
    """Level 1 taxonomy category (most general)."""
    children: Dict[str, TaxonomyLevel2] = Field(default_factory=dict)

class Taxonomy(BaseModel):
    """Complete taxonomy model."""
    name: str
    version: str
    description: Optional[str] = None
    categories: Dict[str, TaxonomyLevel1] = Field(default_factory=dict)

    def get_level1_categories(self) -> List[TaxonomyCategory]:
        """Get all level 1 categories."""
        logger.debug(f"get_level1_categories: Retrieving {len(self.categories)} L1 categories.")
        return [
            TaxonomyCategory(id=cat_id, name=cat.name, description=cat.description)
            for cat_id, cat in self.categories.items()
        ]

    def get_level2_categories(self, parent_id: str) -> List[TaxonomyCategory]:
        """Get level 2 categories for a given parent."""
        logger.debug(f"get_level2_categories: Attempting to get children for L1 parent '{parent_id}'.")
        if parent_id not in self.categories:
            logger.warning(f"get_level2_categories: Parent ID '{parent_id}' not found in L1 categories.")
            return []

        level1_cat = self.categories[parent_id]
        if not hasattr(level1_cat, 'children') or not level1_cat.children:
             logger.warning(f"get_level2_categories: Parent L1 category '{parent_id}' has no children dictionary or it is empty.")
             return []

        children_count = len(level1_cat.children)
        logger.debug(f"get_level2_categories: Found {children_count} L2 children for parent '{parent_id}'.")
        return [
            TaxonomyCategory(id=cat_id, name=cat.name, description=cat.description)
            for cat_id, cat in level1_cat.children.items()
        ]

    def get_level3_categories(self, parent_id: str) -> List[TaxonomyCategory]:
        """Get level 3 categories for a given parent ID (expected format: L1.L2 or just L2 ID)."""
        logger.debug(f"get_level3_categories: Attempting to get children for L2 parent '{parent_id}'.")
        level1_id = None
        level2_id = None
        if '.' in parent_id:
            parts = parent_id.split('.')
            if len(parts) == 2:
                level1_id, level2_id = parts[0], parts[1]
            else:
                 logger.error(f"get_level3_categories: Invalid parent ID format '{parent_id}'. Expected 'L1.L2' or 'L2'.")
                 return []
        else:
            # Assume it's just the L2 ID - need to find its L1 parent
            level2_id = parent_id
            for l1_key, l1_node in self.categories.items():
                if level2_id in getattr(l1_node, 'children', {}):
                    level1_id = l1_key
                    break
            if not level1_id:
                logger.warning(f"get_level3_categories: Could not find L1 parent for L2 ID '{level2_id}'.")
                return []

        logger.debug(f"get_level3_categories: Parsed parent ID into L1='{level1_id}', L2='{level2_id}'.")

        if level1_id not in self.categories:
            logger.warning(f"get_level3_categories: L1 parent ID '{level1_id}' not found.")
            return []

        level1_cat = self.categories[level1_id]
        if not hasattr(level1_cat, 'children') or level2_id not in level1_cat.children:
             logger.warning(f"get_level3_categories: L2 parent ID '{level2_id}' not found under L1 '{level1_id}'.")
             return []

        level2_cat = level1_cat.children[level2_id]
        if not hasattr(level2_cat, 'children') or not level2_cat.children:
             logger.warning(f"get_level3_categories: Parent L2 category '{level2_id}' has no children dictionary or it is empty.")
             return []

        children_count = len(level2_cat.children)
        logger.debug(f"get_level3_categories: Found {children_count} L3 children for parent '{parent_id}'.")
        return [
            TaxonomyCategory(id=cat_id, name=cat.name, description=cat.description)
            for cat_id, cat in level2_cat.children.items()
        ]

    def get_level4_categories(self, parent_id: str) -> List[TaxonomyCategory]:
        """Get level 4 categories for a given parent ID (expected format: L1.L2.L3 or just L3 ID)."""
        logger.debug(f"get_level4_categories: Attempting to get children for L3 parent '{parent_id}'.")
        level1_id = None
        level2_id = None
        level3_id = None
        if '.' in parent_id:
            parts = parent_id.split('.')
            if len(parts) == 3:
                level1_id, level2_id, level3_id = parts[0], parts[1], parts[2]
            else:
                 logger.error(f"get_level4_categories: Invalid parent ID format '{parent_id}'. Expected 'L1.L2.L3' or 'L3'.")
                 return []
        else:
            # Assume it's just the L3 ID - need to find its L1/L2 parents
            level3_id = parent_id
            found = False
            for l1_key, l1_node in self.categories.items():
                for l2_key, l2_node in getattr(l1_node, 'children', {}).items():
                    if level3_id in getattr(l2_node, 'children', {}):
                        level1_id = l1_key
                        level2_id = l2_key
                        found = True
                        break
                if found:
                    break
            if not found:
                 logger.warning(f"get_level4_categories: Could not find L1/L2 parents for L3 ID '{level3_id}'.")
                 return []

        logger.debug(f"get_level4_categories: Parsed parent ID into L1='{level1_id}', L2='{level2_id}', L3='{level3_id}'.")

        if level1_id not in self.categories:
            logger.warning(f"get_level4_categories: L1 parent ID '{level1_id}' not found.")
            return []

        level1_cat = self.categories[level1_id]
        if not hasattr(level1_cat, 'children') or level2_id not in level1_cat.children:
            logger.warning(f"get_level4_categories: L2 parent ID '{level2_id}' not found under L1 '{level1_id}'.")
            return []

        level2_cat = level1_cat.children[level2_id]
        if not hasattr(level2_cat, 'children') or level3_id not in level2_cat.children:
            logger.warning(f"get_level4_categories: L3 parent ID '{level3_id}' not found under L2 '{level2_id}'.")
            return []

        level3_cat = level2_cat.children[level3_id]
        if not hasattr(level3_cat, 'children') or not level3_cat.children:
             logger.warning(f"get_level4_categories: Parent L3 category '{level3_id}' has no children dictionary or it is empty.")
             return []

        children_count = len(level3_cat.children)
        logger.debug(f"get_level4_categories: Found {children_count} L4 children for parent '{parent_id}'.")
        return [
            TaxonomyCategory(id=cat_id, name=cat.name, description=cat.description)
            for cat_id, cat in level3_cat.children.items()
        ]

    # --- ADDED: get_level5_categories ---
    def get_level5_categories(self, parent_id: str) -> List[TaxonomyCategory]:
        """Get level 5 categories for a given parent ID (expected format: L1.L2.L3.L4 or just L4 ID)."""
        logger.debug(f"get_level5_categories: Attempting to get children for L4 parent '{parent_id}'.")
        level1_id = None
        level2_id = None
        level3_id = None
        level4_id = None
        if '.' in parent_id:
            parts = parent_id.split('.')
            if len(parts) == 4:
                level1_id, level2_id, level3_id, level4_id = parts[0], parts[1], parts[2], parts[3]
            elif len(parts) == 3: # Handle case where parent_id is L2.L3.L4
                l2_id_part, l3_id_part, l4_id_part = parts[0], parts[1], parts[2]
                found = False
                for l1k, l1n in self.categories.items():
                    if l2_id_part in getattr(l1n, 'children', {}):
                         level1_id = l1k
                         level2_id = l2_id_part
                         level3_id = l3_id_part
                         level4_id = l4_id_part
                         found = True
                         break
                if not found:
                    logger.error(f"get_level5_categories: Could not find L1 parent for L2.L3.L4 format '{parent_id}'.")
                    return []
            elif len(parts) == 2: # Handle case where parent_id is L3.L4
                l3_id_part, l4_id_part = parts[0], parts[1]
                found = False
                for l1k, l1n in self.categories.items():
                    for l2k, l2n in getattr(l1n, 'children', {}).items():
                         if l3_id_part in getattr(l2n, 'children', {}):
                             level1_id = l1k
                             level2_id = l2k
                             level3_id = l3_id_part
                             level4_id = l4_id_part
                             found = True
                             break
                    if found: break
                if not found:
                    logger.error(f"get_level5_categories: Could not find L1/L2 parent for L3.L4 format '{parent_id}'.")
                    return []
            else:
                 logger.error(f"get_level5_categories: Invalid parent ID format '{parent_id}'. Expected 'L1.L2.L3.L4' or 'L4'.")
                 return []
        else:
            # Assume it's just the L4 ID - need to find its parents
            level4_id = parent_id
            found = False
            for l1_key, l1_node in self.categories.items():
                for l2_key, l2_node in getattr(l1_node, 'children', {}).items():
                    for l3_key, l3_node in getattr(l2_node, 'children', {}).items():
                        if level4_id in getattr(l3_node, 'children', {}):
                            level1_id = l1_key
                            level2_id = l2_key
                            level3_id = l3_key
                            found = True
                            break
                    if found: break
                if found: break
            if not found:
                 logger.warning(f"get_level5_categories: Could not find L1/L2/L3 parents for L4 ID '{level4_id}'.")
                 return []

        logger.debug(f"get_level5_categories: Parsed parent ID into L1='{level1_id}', L2='{level2_id}', L3='{level3_id}', L4='{level4_id}'.")

        # Traverse the hierarchy
        if level1_id not in self.categories:
            logger.warning(f"get_level5_categories: L1 parent ID '{level1_id}' not found.")
            return []
        level1_cat = self.categories[level1_id]

        if not hasattr(level1_cat, 'children') or level2_id not in level1_cat.children:
            logger.warning(f"get_level5_categories: L2 parent ID '{level2_id}' not found under L1 '{level1_id}'.")
            return []
        level2_cat = level1_cat.children[level2_id]

        if not hasattr(level2_cat, 'children') or level3_id not in level2_cat.children:
            logger.warning(f"get_level5_categories: L3 parent ID '{level3_id}' not found under L2 '{level2_id}'.")
            return []
        level3_cat = level2_cat.children[level3_id]

        if not hasattr(level3_cat, 'children') or level4_id not in level3_cat.children:
            logger.warning(f"get_level5_categories: L4 parent ID '{level4_id}' not found under L3 '{level3_id}'.")
            return []
        level4_cat = level3_cat.children[level4_id]

        # Get L5 children
        if not hasattr(level4_cat, 'children') or not level4_cat.children:
             logger.warning(f"get_level5_categories: Parent L4 category '{level4_id}' has no children dictionary or it is empty.")
             return []

        children_count = len(level4_cat.children)
        logger.debug(f"get_level5_categories: Found {children_count} L5 children for parent '{parent_id}'.")
        return [
            TaxonomyCategory(id=cat_id, name=cat.name, description=cat.description)
            for cat_id, cat in level4_cat.children.items()
        ]
    # --- END ADDED ---

    # --- ADDED: get_level_dict method ---
    def get_level_dict(self, parent_id_path: Optional[str] = None) -> Dict[str, Any]:
        """
        Returns a dictionary of the direct children categories for a given parent ID path.
        Path format: L1_ID.L2_ID.L3_ID etc. If None, returns Level 1 categories.
        Keys are child IDs, values are dicts with 'name' and 'description'.
        """
        logger.debug(f"get_level_dict called for parent_id_path: {parent_id_path}")
        if not parent_id_path:
            # Return Level 1 categories dictionary
            try:
                return {
                    cat_id: {"name": cat.name, "description": cat.description}
                    for cat_id, cat in self.categories.items()
                }
            except Exception as e:
                logger.error(f"Error formatting Level 1 categories for get_level_dict: {e}", exc_info=True)
                return {}

        parts = parent_id_path.split('.')
        current_level_nodes = self.categories
        node = None

        try:
            # Traverse to the parent node specified by the path
            for i, part_id in enumerate(parts):
                # Ensure we are traversing a dictionary structure
                if not isinstance(current_level_nodes, dict):
                    logger.warning(f"get_level_dict: Structure error - Expected dict, got {type(current_level_nodes)} at level {i} for path '{parent_id_path}'.")
                    return {}

                # Check if the ID exists at the current level
                if part_id not in current_level_nodes:
                    logger.warning(f"get_level_dict: ID '{part_id}' not found at level {i+1} in path '{parent_id_path}'.")
                    return {}

                node = current_level_nodes[part_id]

                # If not the last part, move down to children, checking structure
                if i < len(parts) - 1:
                    if not hasattr(node, 'children') or not isinstance(node.children, dict):
                        logger.warning(f"get_level_dict: Node '{part_id}' at level {i+1} has no valid children dictionary for path '{parent_id_path}'.")
                        return {}
                    current_level_nodes = node.children
                    # Check if children dict is empty, stop if so
                    if not current_level_nodes:
                        logger.warning(f"get_level_dict: Node '{part_id}' at level {i+1} has an empty children dictionary for path '{parent_id_path}'.")
                        return {}

            # After the loop, 'node' is the parent whose children we need
            if node and hasattr(node, 'children') and isinstance(node.children, dict):
                # Return the dictionary of children
                return {
                    child_id: {"name": child.name, "description": child.description}
                    for child_id, child in node.children.items()
                }
            else:
                 # The final node exists but has no children dict or is None
                 logger.warning(f"get_level_dict: Final node for path '{parent_id_path}' either not found, has no children attribute, or children is not a dict.")
                 return {}

        except Exception as e:
             logger.error(f"get_level_dict: Unexpected error traversing path '{parent_id_path}'", exc_info=True)
             return {}
    # --- END ADDED ---

</file>

<file path='app/models/user.py'>
from sqlalchemy import Column, String, Boolean, DateTime, Index # <<< ADDED Index
from sqlalchemy.sql import func

from core.database import Base

class User(Base):
    """User model for authentication."""

    __tablename__ = "users"

    id = Column(String, primary_key=True, index=True)
    username = Column(String, unique=True, index=True, nullable=False)
    email = Column(String, unique=True, index=True, nullable=False)
    full_name = Column(String, nullable=True)
    hashed_password = Column(String, nullable=False)
    is_active = Column(Boolean, default=True)
    is_superuser = Column(Boolean, default=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now()) # Consider index if tracking sign-up trends
    updated_at = Column(DateTime(timezone=True), onupdate=func.now(), server_default=func.now())

    # --- ADDED: Potential Indexes ---
    __table_args__ = (
        Index('ix_users_created_at', 'created_at'), # For potential user sign-up trend analysis
    )
    # --- END ADDED ---
</file>

<file path='app/schemas/admin.py'>
# app/schemas/admin.py
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime

from models.job import JobStatus, JobType # Import enums

# --- Response for /api/v1/admin/stats ---
class SystemStatsResponse(BaseModel):
    total_users: int = Field(..., description="Total number of registered users.")
    total_jobs: int = Field(..., description="Total number of jobs created.")
    pending_jobs: int = Field(..., description="Number of jobs currently in pending state.")
    processing_jobs: int = Field(..., description="Number of jobs currently in processing state.")
    completed_jobs: int = Field(..., description="Total number of completed jobs.")
    failed_jobs_last_24h: int = Field(..., description="Number of jobs that failed in the last 24 hours.")
    estimated_recent_cost: Optional[float] = Field(None, description="Estimated API costs for a recent period (e.g., last 24h). Placeholder.")
    health_status: Dict[str, Any] = Field(..., description="Summary of system health checks (mirrors /health endpoint).")

# --- Response Item for /api/v1/admin/recent-jobs ---
class RecentJobItem(BaseModel):
    id: str = Field(..., description="Job ID.")
    created_by: str = Field(..., description="Username of the user who created the job.")
    company_name: str = Field(..., description="Company name associated with the job.")
    status: JobStatus = Field(..., description="Current status of the job.")
    created_at: datetime = Field(..., description="Timestamp when the job was created.")
    job_type: JobType = Field(..., description="Type of the job (CLASSIFICATION or REVIEW).")

    class Config:
        from_attributes = True # Enable ORM mode
        use_enum_values = True # Use string values for enums

# --- Response for /api/v1/admin/recent-jobs ---
class RecentJobsResponse(BaseModel):
    jobs: List[RecentJobItem] = Field(..., description="List of recent jobs.")
</file>

<file path='app/schemas/job.py'>
# <file path='app/schemas/job.py'>
# app/schemas/job.py
from pydantic import BaseModel, Field, EmailStr
from typing import Optional, Dict, Any, List, Union # <<< ADDED Union
from datetime import datetime
from enum import Enum as PyEnum

from models.job import JobStatus, ProcessingStage, JobType # Import enums from model
from .review import ReviewResultItem # Import the review result schema

# --- UPDATED: Schema for a single detailed result item (for CLASSIFICATION jobs) ---
class JobResultItem(BaseModel):
    vendor_name: str = Field(..., description="Original vendor name")
    level1_id: Optional[str] = Field(None, description="Level 1 Category ID")
    level1_name: Optional[str] = Field(None, description="Level 1 Category Name")
    level2_id: Optional[str] = Field(None, description="Level 2 Category ID")
    level2_name: Optional[str] = Field(None, description="Level 2 Category Name")
    level3_id: Optional[str] = Field(None, description="Level 3 Category ID")
    level3_name: Optional[str] = Field(None, description="Level 3 Category Name")
    level4_id: Optional[str] = Field(None, description="Level 4 Category ID")
    level4_name: Optional[str] = Field(None, description="Level 4 Category Name")
    level5_id: Optional[str] = Field(None, description="Level 5 Category ID")
    level5_name: Optional[str] = Field(None, description="Level 5 Category Name")
    final_confidence: Optional[float] = Field(None, ge=0.0, le=1.0, description="Confidence score of the final classification level achieved (0.0 if not possible)")
    final_status: str = Field(..., description="Overall status ('Classified', 'Not Possible', 'Error')")
    classification_source: Optional[str] = Field(None, description="Source of the final classification ('Initial', 'Search', 'Review')") # Added 'Review'
    classification_notes_or_reason: Optional[str] = Field(None, description="LLM notes or reason for failure/low confidence")
    achieved_level: Optional[int] = Field(None, ge=0, le=5, description="Deepest level successfully classified (0 if none)")

    class Config:
        from_attributes = True # For potential future ORM mapping if results move to separate table
# --- END UPDATED ---


class JobBase(BaseModel):
    company_name: str = Field(..., example="Example Corp")
    target_level: int = Field(default=5, ge=1, le=5, example=5) # Add target_level here
    notification_email: Optional[EmailStr] = Field(None, example="user@example.com")

class JobCreate(JobBase):
    # Fields required specifically on creation, if any (handled by JobBase for now)
    pass

class JobResponse(JobBase):
    id: str = Field(..., example="job_abc123")
    input_file_name: str = Field(..., example="vendors.xlsx")
    output_file_name: Optional[str] = Field(None, example="results_job_abc123.xlsx")
    status: JobStatus = Field(..., example=JobStatus.PROCESSING)
    current_stage: ProcessingStage = Field(..., example=ProcessingStage.CLASSIFICATION_L2)
    progress: float = Field(..., example=0.75)
    created_at: datetime = Field(...)
    updated_at: datetime = Field(...)
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = Field(None, example="Failed during search phase.")
    stats: Dict[str, Any] = Field(default={}, example={"total_vendors": 100, "unique_vendors": 95, "merged_at": None}) # Added merged_at example
    created_by: str = Field(..., example="user@example.com")

    # --- ADDED: Job Type and Parent Link ---
    job_type: JobType = Field(..., example=JobType.CLASSIFICATION)
    parent_job_id: Optional[str] = Field(None, example="job_xyz789")
    # --- END ADDED ---

    # NOTE: We don't include detailed_results here by default to keep this response smaller.
    # It will be fetched via a separate endpoint if needed.

    class Config:
        from_attributes = True # Enable ORM mode for automatic mapping from Job model
        use_enum_values = True # Ensure enum values (strings) are used in the response


# --- ADDED: Schema for the detailed results endpoint response ---
# This allows the endpoint to return either type of result list based on job type
class JobResultsResponse(BaseModel):
    job_id: str
    job_type: JobType
    results: Union[List[JobResultItem], List[ReviewResultItem]] = Field(..., description="List of detailed results, structure depends on job_type")
# --- END ADDED ---
</file>

<file path='app/schemas/password_reset.py'>
# <file path='app/schemas/password_reset.py'>
# app/schemas/password_reset.py
from pydantic import BaseModel, EmailStr, Field

class PasswordRecoveryRequest(BaseModel):
    email: EmailStr

class PasswordResetRequest(BaseModel):
    token: str = Field(..., description="The password reset token received via email")
    new_password: str = Field(..., min_length=8, description="The desired new password")

class MessageResponse(BaseModel):
    """Generic message response"""
    message: str
</file>

<file path='app/schemas/review.py'>
# app/schemas/review.py
from pydantic import BaseModel, Field
from typing import List, Dict, Any

# --- REMOVED: Import JobResultItem to break circular dependency ---
# from .job import JobResultItem
# --- END REMOVED ---

# Schema for items in the reclassify request payload
class ReclassifyRequestItem(BaseModel):
    vendor_name: str = Field(..., description="The exact vendor name to reclassify")
    hint: str = Field(..., description="User-provided hint for reclassification")

# Schema for the reclassify request payload
class ReclassifyPayload(BaseModel):
    items: List[ReclassifyRequestItem] = Field(..., description="List of vendors and hints to reclassify")

# Schema for the reclassify response
class ReclassifyResponse(BaseModel):
    review_job_id: str = Field(..., description="The ID of the newly created review job")
    message: str = Field(default="Re-classification job started.", description="Status message")

# Schema for a single item in the detailed_results of a REVIEW job
# It stores the original result (as a dict) and the new result (as a dict)
class ReviewResultItem(BaseModel):
    vendor_name: str = Field(..., description="Original vendor name")
    hint: str = Field(..., description="Hint provided by the user for this reclassification")
    # --- UPDATED: Use Dict[str, Any] for type hint ---
    # Store the full original result structure (which should match JobResultItem)
    original_result: Dict[str, Any] = Field(..., description="The original classification result for this vendor (as dict)")
    # Store the full new result structure (which should also match JobResultItem)
    new_result: Dict[str, Any] = Field(..., description="The new classification result after applying the hint (as dict)")
    # --- END UPDATED ---

    class Config:
        from_attributes = True # For potential future ORM mapping if results move to separate table
</file>

<file path='app/schemas/user.py'>
# app/schemas/user.py
from pydantic import BaseModel, EmailStr, Field
from typing import Optional
from datetime import datetime
import uuid # Import uuid

# --- Base User Info ---
class UserBase(BaseModel):
    email: EmailStr
    full_name: Optional[str] = None
    is_active: Optional[bool] = True
    is_superuser: Optional[bool] = False
    username: str = Field(..., min_length=3, max_length=50)

# --- Properties to receive via API on creation ---
class UserCreate(UserBase):
    password: str = Field(..., min_length=8)

# --- Properties to receive via API on update ---
class UserUpdate(BaseModel):
    email: Optional[EmailStr] = None
    full_name: Optional[str] = None
    password: Optional[str] = Field(None, min_length=8) # Allow password update
    is_active: Optional[bool] = None
    is_superuser: Optional[bool] = None

# --- Properties stored in DB ---
# This is technically represented by the User model itself,
# but can be useful for internal representation if needed.
class UserInDBBase(UserBase):
    id: uuid.UUID # Use UUID for ID
    hashed_password: str
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True # Pydantic v2 way
        # orm_mode = True # Pydantic v1 way

# --- Properties to return to client ---
class UserResponse(UserBase):
    id: uuid.UUID # Use UUID for ID
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True # Pydantic v2 way
        # orm_mode = True # Pydantic v1 way
</file>

<file path='app/services/email_service.py'>
# app/services/email_service.py
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import Optional

from core.config import settings
from core.logging_config import get_logger

logger = get_logger("vendor_classification.email_service")

# NOTE: For this service to work, you need to install fastapi-mail or handle SMTP directly.
# Example using standard smtplib (requires SMTP server details in config)
# For a real app, consider libraries like fastapi-mail for better integration and features (e.g., templates).

# --- SMTP Configuration (Ensure these are set in your .env or config.py) ---
SMTP_HOST: Optional[str] = getattr(settings, "SMTP_HOST", None)
SMTP_PORT: int = getattr(settings, "SMTP_PORT", 587) # Default TLS port
SMTP_USER: Optional[str] = getattr(settings, "SMTP_USER", None)
SMTP_PASSWORD: Optional[str] = getattr(settings, "SMTP_PASSWORD", None)
SMTP_TLS: bool = getattr(settings, "SMTP_TLS", True) # Use TLS by default
EMAIL_FROM: Optional[str] = getattr(settings, "EMAIL_FROM", None) # Sender email address
FRONTEND_URL: str = getattr(settings, "FRONTEND_URL", "http://localhost:8080") # Base URL for reset link

def is_email_configured() -> bool:
    """Check if essential SMTP settings are configured."""
    configured = bool(SMTP_HOST and SMTP_USER and SMTP_PASSWORD and EMAIL_FROM)
    if not configured:
        logger.warning("Email service is not configured. SMTP_HOST, SMTP_USER, SMTP_PASSWORD, EMAIL_FROM must be set in settings.")
    return configured

def send_email(to_email: str, subject: str, body_html: str) -> bool:
    """Sends an email using configured SMTP settings."""
    if not is_email_configured():
        logger.error("Cannot send email: Email service not configured.")
        return False

    message = MIMEMultipart("alternative")
    message["Subject"] = subject
    message["From"] = EMAIL_FROM
    message["To"] = to_email

    # Create the plain-text and HTML version of your message
    # For simplicity, we'll just use the HTML body here.
    # Consider adding a plain text alternative for email clients that don't support HTML.
    # text = "Please enable HTML viewing to see this message."
    # part1 = MIMEText(text, "plain")
    part2 = MIMEText(body_html, "html")

    # message.attach(part1)
    message.attach(part2)

    try:
        logger.info(f"Attempting to send email", extra={"to_email": to_email, "subject": subject, "smtp_host": SMTP_HOST, "smtp_port": SMTP_PORT})
        with smtplib.SMTP(SMTP_HOST, SMTP_PORT) as server:
            if SMTP_TLS:
                server.starttls() # Secure the connection
            server.login(str(SMTP_USER), str(SMTP_PASSWORD))
            server.sendmail(str(EMAIL_FROM), to_email, message.as_string())
            logger.info(f"Email sent successfully", extra={"to_email": to_email, "subject": subject})
        return True
    except smtplib.SMTPAuthenticationError:
        logger.error("SMTP Authentication Error. Check SMTP_USER and SMTP_PASSWORD.", exc_info=False)
        return False
    except smtplib.SMTPConnectError:
         logger.error(f"SMTP Connection Error. Could not connect to {SMTP_HOST}:{SMTP_PORT}.", exc_info=False)
         return False
    except smtplib.SMTPServerDisconnected:
         logger.error("SMTP Server Disconnected unexpectedly.", exc_info=False)
         return False
    except Exception as e:
        logger.error(f"Failed to send email", exc_info=True, extra={"to_email": to_email, "subject": subject, "error": str(e)})
        return False

def send_password_reset_email(email_to: str, username: str, token: str):
    """Sends the password reset email or logs the link if email is not configured."""
    project_name = settings.PROJECT_NAME
    subject = f"{project_name} - Password Reset Request"
    # IMPORTANT: Adjust the frontend URL path as needed
    reset_url = f"{FRONTEND_URL}/reset-password/{token}" # Ensure this matches your frontend route

    body_html = f"""
    <html>
    <body>
        <p>Hello {username},</p>
        <p>You requested a password reset for your account on {project_name}.</p>
        <p>Click the link below to set a new password:</p>
        <p><a href="{reset_url}">{reset_url}</a></p>
        <p>This link will expire in {settings.PASSWORD_RESET_TOKEN_EXPIRE_MINUTES} minutes.</p>
        <p>If you did not request a password reset, please ignore this email.</p>
        <p>Thanks,</p>
        <p>The {project_name} Team</p>
    </body>
    </html>
    """

    if is_email_configured():
        send_email(email_to, subject, body_html)
    else:
        # --- Fallback for MVP/Testing: Log the reset link ---
        logger.warning("Email service not configured. Logging password reset link instead of sending email.")
        print("-" * 80)
        print(f"PASSWORD RESET SIMULATION:")
        print(f"To: {email_to}")
        print(f"Subject: {subject}")
        print(f"Username: {username}")
        print(f"Reset URL: {reset_url}")
        print("-" * 80)
        # --- End Fallback ---

# Example Usage (for testing):
# if __name__ == "__main__":
#     # Make sure settings are loaded correctly if running standalone
#     # You might need to adjust sys.path or load .env
#     from dotenv import load_dotenv
#     load_dotenv()
#     from core.config import settings # Re-import after load_dotenv
#
#     # Update placeholders with actual values if needed for testing
#     SMTP_HOST = getattr(settings, "SMTP_HOST", "smtp.example.com")
#     SMTP_PORT = getattr(settings, "SMTP_PORT", 587)
#     SMTP_USER = getattr(settings, "SMTP_USER", "user@example.com")
#     SMTP_PASSWORD = getattr(settings, "SMTP_PASSWORD", "password")
#     EMAIL_FROM = getattr(settings, "EMAIL_FROM", "noreply@example.com")
#     FRONTEND_URL = getattr(settings, "FRONTEND_URL", "http://localhost:8080")
#
#     print(f"Email Configured: {is_email_configured()}")
#     if is_email_configured():
#          send_password_reset_email("test@example.com", "TestUser", "dummytoken12345")
#     else:
#          print("Run simulation:")
#          send_password_reset_email("test@example.com", "TestUser", "dummytoken12345")
</file>

<file path='app/services/file_service.py'>
# <file path='app/services/file_service.py'>
# app/services/file_service.py
import os
import pandas as pd
from fastapi import UploadFile
import shutil
from typing import List, Dict, Any, Optional, Set
import uuid
import logging
from datetime import datetime
import io # Added for reading UploadFile in memory

from core.config import settings
# Import logger and context functions from refactored modules
from core.logging_config import get_logger
from core.log_context import set_log_context
# Import log helpers from utils
from utils.log_utils import LogTimer, log_function_call
# Import JobResultItem for type hinting
from schemas.job import JobResultItem

# Configure logger
logger = get_logger("vendor_classification.file_service")

# --- Define expected column names (case-insensitive matching) ---
VENDOR_NAME_COL = 'vendor_name'
# --- ADDED: List of all optional columns for easier checking ---
OPTIONAL_COLS_LOWER = {
    'optional_example_good_serviced_purchased',
    'vendor_address',
    'vendor_website',
    'internal_category',
    'parent_company',
    'spend_category'
}
# --- END ADDED ---

# --- Keep original definitions for reference in read_vendor_file ---
OPTIONAL_EXAMPLE_COL = 'optional_example_good_serviced_purchased'
OPTIONAL_ADDRESS_COL = 'vendor_address'
OPTIONAL_WEBSITE_COL = 'vendor_website'
OPTIONAL_INTERNAL_CAT_COL = 'internal_category'
OPTIONAL_PARENT_CO_COL = 'parent_company'
OPTIONAL_SPEND_CAT_COL = 'spend_category'
# --- End Define expected column names ---


# --- ADDED: Function to Validate File Header ---
@log_function_call(logger, include_args=False) # Keep args=False for UploadFile
def validate_file_header(file: UploadFile) -> Dict[str, Any]:
    """
    Reads only the header of an UploadFile (Excel) to validate its structure.

    Checks for:
    1. Readability as an Excel file.
    2. Presence of the mandatory 'vendor_name' column (case-insensitive).

    Returns a dictionary with validation status and detected columns.
    """
    log_extra = {"uploaded_filename": file.filename} # Renamed from 'filename'
    logger.info("Starting file header validation", extra=log_extra)

    result = {
        "is_valid": False,
        "message": "Validation not completed.",
        "detected_columns": [],
        "missing_mandatory_columns": []
    }

    try:
        # Read only the header row (or first few rows) to get columns
        # Using BytesIO to read from the UploadFile's stream in memory
        # Important: We read the stream here. If this same UploadFile object
        # needs to be read again later (e.g., in the main upload endpoint
        # without re-uploading), its stream position needs to be reset (await file.seek(0)).
        # However, the typical flow is validate -> frontend -> upload, which are separate requests.
        file_content = file.file.read()
        file.file.seek(0) # Reset stream position in case it's needed elsewhere (though unlikely in this flow)

        # --- FIX: Remove 'extra' from LogTimer call ---
        # The LogTimer class does not accept the 'extra' argument based on the TypeError.
        # Context logging should still capture the filename via log_extra used in logger calls.
        with LogTimer(logger, "Header read (pandas)"):
        # --- END FIX ---
            # nrows=0 reads only the header, nrows=1 reads header + first data row etc.
            # Using nrows=0 is sufficient and fastest for just column names.
            df_header = pd.read_excel(io.BytesIO(file_content), header=0, nrows=0)

        detected_columns_raw = list(df_header.columns)
        # Convert all column names to string for safety
        detected_columns = [str(col) for col in detected_columns_raw]
        result["detected_columns"] = detected_columns
        log_extra["detected_columns"] = detected_columns # Add detected columns to log_extra
        logger.debug(f"Detected columns: {detected_columns}", extra=log_extra)

        # --- Perform Validation ---
        normalized_detected_columns = {col.strip().lower(): col for col in detected_columns if isinstance(col, str)}

        # Check for mandatory column
        if VENDOR_NAME_COL not in normalized_detected_columns:
            result["is_valid"] = False
            result["message"] = f"Validation Failed: Mandatory column '{VENDOR_NAME_COL}' is missing (case-insensitive)."
            result["missing_mandatory_columns"] = [VENDOR_NAME_COL]
            logger.warning(f"Mandatory column '{VENDOR_NAME_COL}' missing.", extra=log_extra)
        else:
            result["is_valid"] = True
            result["message"] = f"Validation Successful: Found mandatory column '{normalized_detected_columns[VENDOR_NAME_COL]}'."
            # Optionally list found optional columns
            found_optional = [
                normalized_detected_columns[opt_col]
                for opt_col in OPTIONAL_COLS_LOWER
                if opt_col in normalized_detected_columns
            ]
            if found_optional:
                result["message"] += f" Found optional columns: {', '.join(found_optional)}."
            else:
                 result["message"] += " No optional context columns detected."
            logger.info("Mandatory column found.", extra=log_extra)

    except ValueError as e:
        # More specific error for pandas read errors
        logger.warning(f"Pandas ValueError during header read: {e}", extra=log_extra)
        result["message"] = f"File Read Error: Could not parse Excel header. Ensure it's a valid .xlsx or .xls file. Details: {str(e)[:100]}"
        raise ValueError(result["message"]) # Re-raise to be caught by API endpoint
    except Exception as e:
        logger.error(f"Unexpected error during header validation", exc_info=True, extra=log_extra)
        result["message"] = f"Internal Server Error: An unexpected error occurred during file validation. Details: {str(e)[:100]}"
        # Don't raise generic Exception here, let the endpoint handle it
        # Set is_valid to false as a precaution
        result["is_valid"] = False # Ensure invalid state on unexpected error

    return result
# --- END ADDED: Function to Validate File Header ---


@log_function_call(logger, include_args=False) # Keep args=False for UploadFile
def save_upload_file(file: UploadFile, job_id: str) -> str:
    """
    Save uploaded file to the input directory.
    """
    job_dir = os.path.join(settings.INPUT_DATA_DIR, job_id)
    log_extra = {"job_id": job_id} # Base log extra for this function
    try:
        os.makedirs(job_dir, exist_ok=True)
        logger.debug(f"Ensured job directory exists", extra={**log_extra, "directory": job_dir})
    except OSError as e:
        logger.error(f"Failed to create job directory", exc_info=True, extra={**log_extra, "directory": job_dir})
        raise IOError(f"Could not create directory for job {job_id}: {e}")

    safe_filename = os.path.basename(file.filename or f"upload_{job_id}.tmp")
    if not safe_filename:
         safe_filename = f"upload_{job_id}.tmp"

    file_path = os.path.join(job_dir, safe_filename)
    save_log_extra = {**log_extra, "path": file_path, "original_filename": file.filename}
    logger.info("Attempting to save file", extra=save_log_extra)

    # --- FIX: Remove 'extra' from LogTimer call ---
    with LogTimer(logger, "File saving"): # Removed extra=save_log_extra
    # --- END FIX ---
        try:
            # Ensure stream is at the beginning before copying
            # This is important if the stream was read previously (e.g., by validation
            # IF the same file object instance was somehow reused, which is not the case here)
            # await file.seek(0) # Use await for async file interface if needed, otherwise just file.seek(0)
            # For standard FastAPI UploadFile, file.file is a SpooledTemporaryFile (sync interface)
            file.file.seek(0)
            with open(file_path, "wb") as buffer:
                shutil.copyfileobj(file.file, buffer)
        except Exception as e:
            logger.error("Failed to save uploaded file content", exc_info=True, extra=save_log_extra)
            if os.path.exists(file_path):
                 try: os.remove(file_path)
                 except OSError: logger.warning("Could not remove partially written file on error.", extra=save_log_extra)
            raise IOError(f"Could not save uploaded file content: {e}")
        finally:
            # Close the underlying file handle of UploadFile
            if hasattr(file, 'close') and callable(file.close):
                try:
                    file.close()
                    logger.debug("Closed UploadFile stream after saving.", extra=save_log_extra)
                except Exception as close_err:
                    logger.warning(f"Error closing UploadFile stream: {close_err}", exc_info=False, extra=save_log_extra)


    try:
        file_size = os.path.getsize(file_path)
        logger.info(f"File saved successfully",
                   extra={**save_log_extra, "size_bytes": file_size})
    except OSError as e:
        logger.warning(f"Could not get size of saved file", exc_info=False, extra={**save_log_extra, "error": str(e)})
        file_size = -1

    return file_path


@log_function_call(logger)
def read_vendor_file(file_path: str) -> List[Dict[str, Any]]:
    """
    Read vendor data from Excel file, looking for mandatory 'vendor_name'
    and several optional context columns (case-insensitively).
    """
    log_extra = {"file_path": file_path}
    logger.info(f"Reading Excel file for vendor data", extra=log_extra)

    if not os.path.exists(file_path):
         logger.error(f"Input file not found at path", extra=log_extra)
         raise FileNotFoundError(f"Input file not found at path: {file_path}")

    # --- FIX: Remove 'extra' from LogTimer call ---
    with LogTimer(logger, "Excel file reading", include_in_stats=True): # Removed extra=log_extra
    # --- END FIX ---
        try:
            # Read the entire file now
            df = pd.read_excel(file_path, header=0)
            detected_columns = list(df.columns)
            logger.debug(f"Successfully read Excel file. Columns detected: {detected_columns}", extra=log_extra)
        except Exception as e:
            logger.error(f"Error reading Excel file with pandas", exc_info=True, extra=log_extra)
            raise ValueError(f"Could not parse the Excel file. Please ensure it is a valid .xlsx or .xls file. Error details: {str(e)}")

    # --- Find columns case-insensitively ---
    column_map: Dict[str, Optional[str]] = {
        'vendor_name': None,
        'example': None,
        'address': None,
        'website': None,
        'internal_cat': None,
        'parent_co': None,
        'spend_cat': None
    }
    # Convert all detected columns to string for reliable matching
    normalized_detected_columns = {str(col).strip().lower(): str(col) for col in detected_columns if isinstance(col, (str, int, float))} # Allow numeric cols but treat as str

    # Find vendor_name (mandatory)
    if VENDOR_NAME_COL in normalized_detected_columns:
        column_map['vendor_name'] = normalized_detected_columns[VENDOR_NAME_COL]
        logger.info(f"Found mandatory column '{VENDOR_NAME_COL}' as: '{column_map['vendor_name']}'", extra=log_extra)
    else:
        logger.error(f"Required column '{VENDOR_NAME_COL}' not found in file.",
                    extra={**log_extra, "available_columns": detected_columns})
        # This error should ideally be caught by the pre-validation step now
        raise ValueError(f"Input Excel file must contain a column named '{VENDOR_NAME_COL}' (case-insensitive). Found columns: {', '.join(map(str, detected_columns))}")

    # Find optional columns (using original constants here)
    optional_cols = {
        'example': OPTIONAL_EXAMPLE_COL,
        'address': OPTIONAL_ADDRESS_COL,
        'website': OPTIONAL_WEBSITE_COL,
        'internal_cat': OPTIONAL_INTERNAL_CAT_COL,
        'parent_co': OPTIONAL_PARENT_CO_COL,
        'spend_cat': OPTIONAL_SPEND_CAT_COL
    }
    for key, col_name in optional_cols.items():
        # Check against the lowercased OPTIONAL_COLS_LOWER set for consistency
        if col_name.lower() in normalized_detected_columns:
            column_map[key] = normalized_detected_columns[col_name.lower()]
            logger.info(f"Found optional column '{col_name}' as: '{column_map[key]}'", extra=log_extra)
        else:
            logger.info(f"Optional column '{col_name}' not found.", extra=log_extra)
    # --- End Find columns ---

    # --- Extract data into list of dictionaries ---
    vendors_data: List[Dict[str, Any]] = []
    processed_count = 0
    skipped_count = 0

    try:
        for index, row in df.iterrows():
            vendor_name_raw = row.get(column_map['vendor_name'])
            vendor_name = str(vendor_name_raw).strip() if pd.notna(vendor_name_raw) and str(vendor_name_raw).strip() else None

            if not vendor_name or vendor_name.lower() in ['nan', 'none', 'null']:
                skipped_count += 1
                continue

            vendor_entry: Dict[str, Any] = {'vendor_name': vendor_name}

            # Add optional fields if found
            for key, mapped_col in column_map.items():
                if key != 'vendor_name' and mapped_col: # Check if optional column was found
                    raw_value = row.get(mapped_col)
                    # Ensure value is treated as string, handle potential NaN/None from Pandas
                    value = str(raw_value).strip() if pd.notna(raw_value) and str(raw_value).strip() else None
                    if value and value.lower() not in ['nan', 'none', 'null', '#n/a']: # Additional check for common excel non-values
                        output_key = key # Default key
                        # Map internal key back to original (or desired output) key name
                        if key == 'example': output_key = 'example' # Keep as 'example' if needed, or map to full name
                        elif key == 'address': output_key = 'vendor_address'
                        elif key == 'website': output_key = 'vendor_website'
                        elif key == 'internal_cat': output_key = 'internal_category'
                        elif key == 'parent_co': output_key = 'parent_company'
                        elif key == 'spend_cat': output_key = 'spend_category'
                        vendor_entry[output_key] = value

            vendors_data.append(vendor_entry)
            processed_count += 1

        logger.info(f"Extracted data for {processed_count} vendors. Skipped {skipped_count} rows due to missing/invalid vendor name.", extra=log_extra)
        if not vendors_data:
             logger.warning(f"No valid vendor data found in the file after processing rows.", extra=log_extra)

    except KeyError as e:
        logger.error(f"Internal Error: KeyError accessing column '{e}' after it was seemingly mapped.",
                     extra={**log_extra, "column_map": column_map, "available_columns": detected_columns})
        raise ValueError(f"Internal error accessing column '{e}'.")
    except Exception as e:
        logger.error(f"Error extracting or processing data from file rows", exc_info=True, extra=log_extra)
        raise ValueError(f"Could not extract vendor data. Please check data format. Error: {e}")

    return vendors_data
    # --- End Extract data ---


@log_function_call(logger)
def normalize_vendor_data(vendors_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Normalize vendor names within the list of dictionaries by converting
    to title case and stripping whitespace. Filters out entries with
    empty names after normalization. Preserves other fields.
    """
    start_count = len(vendors_data)
    log_extra = {"original_count": start_count}
    logger.info(f"Normalizing vendor names for {start_count} entries...", extra=log_extra)

    normalized_vendors_data = []
    empty_removed_count = 0

    # --- FIX: Remove 'extra' from LogTimer call ---
    with LogTimer(logger, "Vendor name normalization", include_in_stats=True): # Removed extra=log_extra
    # --- END FIX ---
        for entry in vendors_data:
            original_name = entry.get('vendor_name')
            if isinstance(original_name, str):
                normalized_name = original_name.strip().title()
                if normalized_name:
                    normalized_entry = entry.copy()
                    normalized_entry['vendor_name'] = normalized_name
                    normalized_vendors_data.append(normalized_entry)
                else:
                    empty_removed_count += 1
                    # Avoid logging potentially large 'entry' in warning
                    logger.warning("Skipping vendor entry due to empty name after normalization", extra={"original_name": original_name})
            else:
                # Avoid logging potentially large 'entry' in warning
                logger.warning("Skipping vendor entry due to missing or non-string name during normalization", extra={"original_name": original_name})
                empty_removed_count += 1

    final_count = len(normalized_vendors_data)
    logger.info(f"Vendor names normalized.",
               extra={
                   "original_count": start_count,
                   "normalized_count": final_count,
                   "empty_or_skipped": empty_removed_count
               })

    return normalized_vendors_data


# --- UPDATED: generate_output_file to accept List[JobResultItem] ---
@log_function_call(logger)
def generate_output_file(
    job_id: str,
    detailed_results: List[JobResultItem]
) -> str:
    """
    Generate output Excel file directly from the List[JobResultItem] structure.
    This is used for initial generation and regeneration after merging.
    """
    log_extra = {"job_id": job_id, "result_item_count": len(detailed_results)}
    logger.info(f"Generating output file for job {job_id} using {len(detailed_results)} result items.",
               extra=log_extra)

    output_data = []

    # --- FIX: Remove 'extra' from LogTimer call ---
    with LogTimer(logger, "Processing JobResultItems for Excel"): # Removed extra=log_extra
    # --- END FIX ---
        for item in detailed_results:
            # Determine the reason/notes string based on status
            reason_or_notes = item.classification_notes_or_reason
            if item.final_status == "Not Possible" and not reason_or_notes:
                reason_or_notes = "Classification not possible" # Default reason if none provided
            elif item.final_status == "Error" and not reason_or_notes:
                 reason_or_notes = "Processing error occurred"

            # Determine classification_not_possible flag
            classification_not_possible_flag = item.final_status != "Classified"

            # TODO: How to get original optional fields (address, website, etc.)?
            # The JobResultItem schema currently doesn't store the original optional fields.
            # OPTION 1: Add these fields to JobResultItem schema and ensure they are populated during classification/review.
            # OPTION 2: Modify this function to re-read the original input file (less efficient, requires file path).
            # OPTION 3: Store the original input data alongside detailed_results in the Job model (maybe in stats or a new field).
            # For now, we'll leave these columns blank as the data isn't available in detailed_results.
            # This needs to be addressed for the output file to be complete.
            # --- Placeholder values ---
            original_address = ""
            original_website = ""
            original_internal_cat = ""
            original_parent_co = ""
            original_spend_cat = ""
            original_example = ""
            search_sources_urls = "" # This info is also not directly in JobResultItem, needs adding or separate storage.
            # --- End Placeholder values ---

            row = {
                "vendor_name": item.vendor_name,
                "vendor_address": original_address, # Placeholder
                "vendor_website": original_website, # Placeholder
                "internal_category": original_internal_cat, # Placeholder
                "parent_company": original_parent_co, # Placeholder
                "spend_category": original_spend_cat, # Placeholder
                "Optional_example_good_serviced_purchased": original_example, # Placeholder
                "level1_category_id": item.level1_id or "",
                "level1_category_name": item.level1_name or "",
                "level2_category_id": item.level2_id or "",
                "level2_category_name": item.level2_name or "",
                "level3_category_id": item.level3_id or "",
                "level3_category_name": item.level3_name or "",
                "level4_category_id": item.level4_id or "",
                "level4_category_name": item.level4_name or "",
                "level5_category_id": item.level5_id or "",
                "level5_category_name": item.level5_name or "",
                "final_confidence": item.final_confidence if item.final_confidence is not None else 0.0,
                "classification_not_possible": classification_not_possible_flag,
                "classification_notes_or_reason": reason_or_notes or "",
                "classification_source": item.classification_source or "Unknown",
                "sources": search_sources_urls # Placeholder
            }
            output_data.append(row)

    output_columns = [
        "vendor_name", "vendor_address", "vendor_website", "internal_category", "parent_company", "spend_category",
        "Optional_example_good_serviced_purchased", # Match the exact optional column name
        "level1_category_id", "level1_category_name", "level2_category_id", "level2_category_name",
        "level3_category_id", "level3_category_name", "level4_category_id", "level4_category_name",
        "level5_category_id", "level5_category_name",
        "final_confidence", "classification_not_possible", "classification_notes_or_reason",
        "classification_source", "sources"
    ]
    if not output_data:
        logger.warning("No data rows generated for the output file.", extra=log_extra)
        # Create empty DataFrame with correct columns if no results
        df = pd.DataFrame(columns=output_columns)
    else:
        # --- FIX: Remove 'extra' from LogTimer call ---
        with LogTimer(logger, "Creating DataFrame for output"): # Removed extra=log_extra
        # --- END FIX ---
            df = pd.DataFrame(output_data, columns=output_columns)

    output_dir = os.path.join(settings.OUTPUT_DATA_DIR, job_id)
    try:
        os.makedirs(output_dir, exist_ok=True)
        logger.debug(f"Ensured output directory exists", extra={**log_extra, "directory": output_dir})
    except OSError as e:
        logger.error(f"Failed to create output directory", exc_info=True, extra={**log_extra, "directory": output_dir})
        raise IOError(f"Could not create output directory for job {job_id}: {e}")

    timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    # Use a consistent base name, maybe incorporating 'merged' if applicable?
    output_file_name = f"classification_results_{job_id[:8]}_{timestamp_str}.xlsx"
    output_path = os.path.join(output_dir, output_file_name)

    output_log_extra = {**log_extra, "output_path": output_path, "output_filename": output_file_name}
    logger.info("Attempting to write final results to Excel file.", extra=output_log_extra)
    # --- FIX: Remove 'extra' from LogTimer call ---
    with LogTimer(logger, "Writing Excel file"): # Removed extra=output_log_extra
    # --- END FIX ---
        try:
            df.to_excel(output_path, index=False, engine='xlsxwriter')
        except Exception as e:
            logger.error("Failed to write output Excel file", exc_info=True, extra=output_log_extra)
            raise IOError(f"Could not write output file: {e}")

    try:
        file_size = os.path.getsize(output_path)
        logger.info(f"Output file generated successfully",
                   extra={**output_log_extra, "size_bytes": file_size})
    except OSError as e:
         logger.warning(f"Could not get size of generated output file", exc_info=False, extra={**output_log_extra, "error": str(e)})

    return output_file_name
# --- END UPDATED ---
</file>

<file path='app/services/llm_service.py'>
# app/services/llm_service.py
import httpx
import json
import re
import os
import hashlib
# --- ADDED Tuple ---
from typing import List, Dict, Any, Optional, Set, Tuple
# --- END ADDED ---
import logging
import time
import uuid
from datetime import datetime
from tenacity import retry, stop_after_attempt, wait_exponential, RetryError, TryAgain
from core import config
from core.config import settings
from models.taxonomy import Taxonomy
from core.logging_config import get_logger
from core.log_context import set_log_context, get_correlation_id
from utils.log_utils import LogTimer, log_function_call
from tasks.classification_prompts import generate_batch_prompt, generate_search_prompt

# Configure logger
logger = get_logger("vendor_classification.llm_service")
llm_trace_logger = logging.getLogger("llm_api_trace")

logger.debug("Successfully imported generate_batch_prompt and generate_search_prompt from tasks.classification_prompts.")

# --- Cache Configuration ---
CACHE_DIR = "data/cache"
CACHE_FILE_PATH = os.path.join(CACHE_DIR, "openrouter_dev_cache.json")
logger.info(f"Checking for cache file existence at: {CACHE_FILE_PATH} (Absolute: {os.path.abspath(CACHE_FILE_PATH)})")
CACHE_ENABLED = settings.USE_LLM_CACHE and os.path.exists(CACHE_FILE_PATH) # Enable only if setting is true AND file exists

if CACHE_ENABLED:
    logger.warning(f"--- OpenRouter DEV CACHE ACTIVE --- API calls will be cached in {CACHE_FILE_PATH}")
elif settings.USE_LLM_CACHE and not os.path.exists(CACHE_FILE_PATH):
     logger.warning(f"--- OpenRouter DEV CACHE INACTIVE --- USE_LLM_CACHE is true, but cache file not found at {CACHE_FILE_PATH}. Live API calls will be made. Cache file will be created on first save.")
     # Ensure directory exists if we intend to create the file later
     try:
        os.makedirs(CACHE_DIR, exist_ok=True)
        logger.info(f"Ensured cache directory '{CACHE_DIR}' exists.")
     except Exception as e:
        logger.error(f"Failed to create cache directory '{CACHE_DIR}': {e}")
        # Decide if this is fatal or just disable caching
        # settings.USE_LLM_CACHE = False # Disable caching if dir creation fails
        # logger.warning("Disabling cache due to directory creation failure.")
else:
    logger.info(f"--- OpenRouter DEV CACHE INACTIVE --- USE_LLM_CACHE is false. Live API calls will be made.")


# --- Cache Helper Functions (Unchanged from previous version) ---
def _load_cache() -> Dict[str, Any]:
    """Loads the cache from the JSON file."""
    if not settings.USE_LLM_CACHE: # Check setting first
        return {}
    if not os.path.exists(CACHE_FILE_PATH):
         logger.info(f"Cache file {CACHE_FILE_PATH} not found. Starting with empty cache.")
         return {}
    try:
        with open(CACHE_FILE_PATH, 'r') as f:
            cache_data = json.load(f)
            logger.debug(f"Loaded cache with {len(cache_data)} entries from {CACHE_FILE_PATH}")
            return cache_data
    except json.JSONDecodeError:
        logger.error(f"Error decoding JSON from cache file {CACHE_FILE_PATH}. Returning empty cache.", exc_info=True)
        return {}
    except Exception as e:
        logger.error(f"Error loading cache file {CACHE_FILE_PATH}: {e}", exc_info=True)
        return {}

def _save_cache(cache_data: Dict[str, Any]):
    """Saves the cache data to the JSON file."""
    if not settings.USE_LLM_CACHE: # Only save if cache is enabled
        return
    try:
        # Ensure the cache directory exists
        os.makedirs(os.path.dirname(CACHE_FILE_PATH), exist_ok=True)
        with open(CACHE_FILE_PATH, 'w') as f:
            json.dump(cache_data, f, indent=2)
        logger.debug(f"Saved cache with {len(cache_data)} entries to {CACHE_FILE_PATH}")
    except IOError as e:
        logger.error(f"Error writing cache file {CACHE_FILE_PATH}: {e}", exc_info=True)
    except Exception as e:
        logger.error(f"Unexpected error saving cache file {CACHE_FILE_PATH}: {e}", exc_info=True)

def _generate_cache_key(payload: Dict[str, Any]) -> str:
    """Generates a consistent cache key based on the request payload."""
    # Ensure messages are included correctly for cache key generation
    key_data = {
        "model": payload.get("model"),
        # --- Fixed: Use actual message content for key ---
        "messages": [msg.get("content", "") for msg in payload.get("messages", []) if isinstance(msg, dict)],
        # --- End Fixed ---
        "temperature": payload.get("temperature"),
        "max_tokens": payload.get("max_tokens"),
        "top_p": payload.get("top_p"),
        "response_format": payload.get("response_format")
    }
    stable_string = json.dumps(key_data, sort_keys=True)
    return hashlib.sha256(stable_string.encode('utf-8')).hexdigest()

# --- Helper function for JSON parsing (Unchanged) ---
def _extract_json_from_response(response_content: str) -> Optional[Dict[str, Any]]:
    """Attempts to extract a JSON object from a string, handling common LLM response issues."""
    if not response_content:
        logger.warning("Attempted to parse empty response content.")
        return None

    content = response_content.strip()
    # Regex to find JSON possibly enclosed in markdown code blocks (```json ... ```) or just ``` ... ```
    match = re.search(r"```(?:json)?\s*(\{.*\})\s*```", content, re.DOTALL | re.IGNORECASE)
    if match:
        content = match.group(1).strip()
        logger.debug("Extracted JSON content from within markdown code fences.")
    else:
        # Fallback: find first '{' and last '}'
        start_index = content.find('{')
        end_index = content.rfind('}')
        if start_index != -1 and end_index != -1 and end_index > start_index:
            potential_json = content[start_index:end_index+1]
            # Basic validation: check if braces are balanced within the potential JSON
            # This is a heuristic and might not catch all edge cases
            if potential_json.count('{') == potential_json.count('}'):
                content = potential_json
                logger.debug("Extracted potential JSON content based on first '{' and last '}'.")
            else:
                logger.debug("Found '{' and '}', but braces don't seem balanced. Proceeding with original stripped content.")
        else:
            logger.debug("No markdown fences found, and couldn't reliably find JSON object boundaries. Proceeding with original stripped content.")

    # Final attempt to parse
    try:
        parsed_json = json.loads(content)
        logger.debug("Successfully parsed JSON after cleaning/extraction.")
        return parsed_json
    except json.JSONDecodeError as e:
        # Log the error and a preview of the content that failed to parse
        logger.error("JSONDecodeError after cleaning/extraction attempt.",
                     exc_info=False, # Don't log the full traceback unless needed
                     extra={"error": str(e), "cleaned_content_preview": content[:500]}) # Log preview
        return None
    except Exception as e:
        # Catch other potential errors during parsing
        logger.error("Unexpected error during JSON parsing after cleaning/extraction.",
                     exc_info=True, # Log full traceback for unexpected errors
                     extra={"cleaned_content_preview": content[:500]})
        return None
# --- END HELPER ---

# --- Status codes remain the same ---
GENERATED_KEY_INVALID_STATUS_CODES = {401, 403, 429}
PROVISIONING_RELATED_ERROR_CODES = {500, 502, 503, 504}

class LLMService:
    """Service for interacting with OpenRouter API, using Provisioning Keys."""

    def __init__(self):
        """Initialize the LLM service."""
        logger.info("Initializing LLM service with OpenRouter Provisioning Keys")
        self.provisioning_keys = config.MANUAL_OPENROUTER_PROVISIONING_KEYS
        self.api_base = settings.OPENROUTER_API_BASE
        self.model = settings.OPENROUTER_MODEL
        self.current_provisioning_key_index = 0
        self.active_generated_key: Optional[str] = None
        self.active_generated_key_hash: Optional[str] = None
        self.cache = _load_cache()

        if not self.provisioning_keys:
            logger.critical("OpenRouter Provisioning Key list is empty! LLM calls WILL fail.")

        logger.debug("LLM service initialized",
                    extra={"api_base": self.api_base,
                        "model": self.model,
                        "provisioning_key_count": len(self.provisioning_keys),
                        "cache_enabled": settings.USE_LLM_CACHE,
                        "initial_cache_size": len(self.cache)})

    def _get_current_provisioning_key(self) -> Optional[str]:
        """Gets the current provisioning key based on the index."""
        if not self.provisioning_keys:
            return None
        if self.current_provisioning_key_index >= len(self.provisioning_keys):
            logger.warning(f"Provisioning key index {self.current_provisioning_key_index} out of bounds ({len(self.provisioning_keys)} keys). Resetting to 0.")
            self.current_provisioning_key_index = 0
        # --- FIX: Ensure index is valid before accessing ---
        if 0 <= self.current_provisioning_key_index < len(self.provisioning_keys):
            return self.provisioning_keys[self.current_provisioning_key_index]
        else:
            logger.error(f"Invalid provisioning key index {self.current_provisioning_key_index} after bounds check.")
            return None
        # --- END FIX ---


    def _rotate_provisioning_key(self):
        """Rotates to the next provisioning key in the list."""
        if not self.provisioning_keys or len(self.provisioning_keys) <= 1:
            logger.warning("Cannot rotate Provisioning key: list is empty or has only one key.")
            return False # Indicate rotation didn't happen

        old_index = self.current_provisioning_key_index
        self.current_provisioning_key_index = (self.current_provisioning_key_index + 1) % len(self.provisioning_keys)
        logger.warning(f"Rotated OpenRouter Provisioning Key from index {old_index} to {self.current_provisioning_key_index} due to key generation failure.")
        return True # Indicate rotation happened

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=1, max=5)) # Retry generation few times
    async def _generate_api_key(self) -> bool:
        """
        Generates a new API key using the current provisioning key.
        Rotates provisioning key on failure.
        Returns True if successful, False otherwise.
        """
        provisioning_key = self._get_current_provisioning_key()
        if not provisioning_key:
            logger.error("Cannot generate API key: No provisioning key available.")
            return False

        generation_url = f"{self.api_base}/keys" # Use the correct endpoint from docs
        headers = {
            "Authorization": f"Bearer {provisioning_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "naicsvendorclassification.com", # Optional but good practice
            "X-Title": "NAICS Vendor Classification" # Optional
        }
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        payload = {
            "name": f"{settings.GENERATED_KEY_NAME_PREFIX}-{timestamp}",
        }
        if settings.GENERATED_KEY_LABEL:
            payload["label"] = settings.GENERATED_KEY_LABEL
        if settings.GENERATED_KEY_CREDIT_LIMIT is not None:
             try:
                 payload["limit"] = float(settings.GENERATED_KEY_CREDIT_LIMIT)
             except ValueError:
                 logger.warning(f"Invalid GENERATED_KEY_CREDIT_LIMIT format: '{settings.GENERATED_KEY_CREDIT_LIMIT}'. Ignoring limit.")


        logger.info(f"Attempting to generate new OpenRouter API key using provisioning key index {self.current_provisioning_key_index}")
        llm_trace_logger.info(f"LLM_TRACE: Generating new API key. URL: {generation_url}, ProvKeyIndex: {self.current_provisioning_key_index}", extra={'correlation_id': get_correlation_id()})
        llm_trace_logger.debug(f"LLM_TRACE: Key Generation Payload: {json.dumps(payload)}", extra={'correlation_id': get_correlation_id()})

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(generation_url, json=payload, headers=headers, timeout=30.0)
                llm_trace_logger.debug(f"LLM_TRACE: Key Generation Raw Response (Status: {response.status_code}):\n{response.text}", extra={'correlation_id': get_correlation_id()})
                response.raise_for_status() # Raises HTTPStatusError for 4xx/5xx

                response_data = response.json()
                new_key = response_data.get("key")
                response_data_inner = response_data.get("data", {}) # Get inner dict, default {}
                key_hash = response_data_inner.get("hash") if isinstance(response_data_inner, dict) else None

                if not new_key:
                    logger.error("Key generation response did not contain a 'key' field.", extra={"response": response_data})
                    raise ValueError("Invalid response format from key generation API")
                if not key_hash:
                    logger.warning("Key generation response did not contain a 'hash' field within 'data'.", extra={"response": response_data})

                self.active_generated_key = new_key
                self.active_generated_key_hash = key_hash # Store the hash (could be None)

                key_hash_prefix = f"{key_hash[:8]}..." if key_hash else "N/A" # Use N/A if hash is None
                logger.info(f"Successfully generated new OpenRouter API key (hash: {key_hash_prefix}) using provisioning key index {self.current_provisioning_key_index}")
                llm_trace_logger.info(f"LLM_TRACE: Successfully generated key {key_hash_prefix}", extra={'correlation_id': get_correlation_id()})
                return True # Success

        except httpx.HTTPStatusError as e:
            status_code = e.response.status_code
            response_text = e.response.text[:500]
            logger.error(f"HTTP error during API key generation", exc_info=False,
                        extra={ "status_code": status_code, "response_text": response_text, "provisioning_key_index": self.current_provisioning_key_index })
            llm_trace_logger.error(f"LLM_TRACE: Key Generation HTTP Error: Status={status_code}, Response='{response_text}'", exc_info=True, extra={'correlation_id': get_correlation_id()})
            if status_code in {401, 403} or status_code in PROVISIONING_RELATED_ERROR_CODES:
                rotated = self._rotate_provisioning_key()
                if not rotated and len(self.provisioning_keys) <= 1:
                     logger.critical("Single provisioning key failed, cannot rotate. Key generation will likely keep failing.")
                     return False # Stop retrying if rotation isn't possible/doesn't help
                raise TryAgain # Tell tenacity to retry after rotating
            else:
                 logger.error("Key generation failed with unrecoverable client error.")
                 return False

        except (httpx.RequestError, json.JSONDecodeError, ValueError, Exception) as e:
            key_hash_prefix = f"{self.active_generated_key_hash[:8]}..." if self.active_generated_key_hash else "N/A"
            logger.error(f"Error during API key generation: {e}", exc_info=True,
                         extra={"provisioning_key_index": self.current_provisioning_key_index, "key_hash_used": key_hash_prefix})
            llm_trace_logger.error(f"LLM_TRACE: Key Generation Error: {e}", exc_info=True, extra={'correlation_id': get_correlation_id(), "key_hash_used": key_hash_prefix})
            rotated = self._rotate_provisioning_key()
            if not rotated and len(self.provisioning_keys) <= 1:
                 logger.critical("Single provisioning key failed on error, cannot rotate.")
                 return False
            raise TryAgain # Retry after rotation

        return False # Should not be reached if retry logic works, but acts as default failure

    async def _get_active_key_or_generate(self) -> Optional[str]:
        """Gets the currently active generated key, or generates a new one if needed."""
        if self.active_generated_key:
            return self.active_generated_key

        logger.info("No active generated key found. Attempting to generate a new one.")
        success = await self._generate_api_key()
        if success:
            return self.active_generated_key
        else:
            logger.error("Failed to generate a new API key after multiple attempts.")
            return None

    # --- Main API Call Methods ---

    @retry(stop=stop_after_attempt(settings.MAX_RETRIES), wait=wait_exponential(multiplier=1, min=settings.RETRY_DELAY, max=10))
    @log_function_call(logger, include_args=False)
    async def classify_batch(
        self,
        batch_data: List[Dict[str, Any]],
        level: int,
        taxonomy: Taxonomy,
        parent_category_id: Optional[str] = None,
        search_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Send a batch of vendors to LLM for classification, using generated keys.
        Handles prompt generation internally.
        """
        batch_names = [vd.get('vendor_name', f'Unknown_{i}') for i, vd in enumerate(batch_data)]
        context_type = "Search Context" if search_context else "Initial Data"
        logger.info(f"Classifying vendor batch using {context_type}",
                extra={ "batch_size": len(batch_data), "level": level, "parent_category_id": parent_category_id, "has_search_context": bool(search_context) })
        set_log_context({"vendor_count": len(batch_data), "taxonomy_level": level, "context_type": context_type})
        batch_id = str(uuid.uuid4())
        correlation_id = get_correlation_id()
        llm_trace_logger.debug(f"LLM_TRACE: Starting classify_batch (Batch ID: {batch_id}, Level: {level})", extra={'correlation_id': correlation_id})

        # --- Prompt Generation ---
        with LogTimer(logger, "Prompt creation", include_in_stats=True):
            prompt = generate_batch_prompt(batch_data, level, taxonomy, parent_category_id, batch_id, search_context)
            prompt_length = len(prompt)
            logger.debug(f"Classification prompt created", extra={"prompt_length": prompt_length})
            llm_trace_logger.debug(f"LLM_TRACE: Generated Prompt (Batch ID: {batch_id}):\n-------\n{prompt}\n-------", extra={'correlation_id': correlation_id})

        # --- Payload ---
        payload = {
            "model": self.model, "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.1, "max_tokens": 2048, "top_p": 0.9,
            "frequency_penalty": 0, "presence_penalty": 0,
            "response_format": {"type": "json_object"}
        }

        # --- Call generic LLM method ---
        # This method handles API key, call, error handling, stats, parsing
        parsed_result, usage_data = await self._call_llm_endpoint(
            payload=payload,
            job_id=batch_id, # Use batch_id for tracing this specific call
            call_description=f"Level {level} batch classification"
        )

        # --- Return structure expected by caller ---
        api_result = {
            "result": parsed_result, # The parsed JSON from LLM
            "usage": usage_data # The usage stats collected by _call_llm_endpoint
        }

        # --- SAVE TO CACHE (if successful) ---
        if settings.USE_LLM_CACHE and parsed_result is not None:
            cache_key = _generate_cache_key(payload) # Generate key based on payload
            logger.info(f"--- SAVING TO CACHE --- Storing successful response for batch {batch_id[:8]} (Key: {cache_key[:8]}...)")
            self.cache[cache_key] = api_result # Store the combined result+usage
            _save_cache(self.cache)
        # --- END SAVE TO CACHE ---

        return api_result


    @retry(stop=stop_after_attempt(settings.MAX_RETRIES), wait=wait_exponential(multiplier=1, min=settings.RETRY_DELAY, max=10))
    @log_function_call(logger, include_args=False)
    async def process_search_results(
        self,
        vendor_data: Dict[str, Any],
        search_results: Dict[str, Any],
        taxonomy: Taxonomy
    ) -> Dict[str, Any]:
        """
        Process search results for L1 classification, using generated keys.
        Handles prompt generation internally.
        """
        vendor_name = vendor_data.get('vendor_name', 'UnknownVendor')
        logger.info(f"Processing search results for initial L1 classification",
                extra={ "vendor": vendor_name, "source_count": len(search_results.get("sources", [])) })
        set_log_context({"vendor": vendor_name})
        attempt_id = str(uuid.uuid4())
        correlation_id = get_correlation_id()
        llm_trace_logger.debug(f"LLM_TRACE: Starting process_search_results (Attempt ID: {attempt_id}, Vendor: {vendor_name})", extra={'correlation_id': correlation_id})

        # --- Prompt Generation ---
        with LogTimer(logger, "Search prompt creation", include_in_stats=True):
            prompt = generate_search_prompt(vendor_data, search_results, taxonomy, attempt_id)
            prompt_length = len(prompt)
            logger.debug(f"Search results prompt created", extra={"prompt_length": prompt_length})
            llm_trace_logger.debug(f"LLM_TRACE: Generated Search Prompt (Attempt ID: {attempt_id}):\n-------\n{prompt}\n-------", extra={'correlation_id': correlation_id})

        # --- Payload ---
        payload = {
            "model": self.model, "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.1, "max_tokens": 1024, "top_p": 0.9,
            "frequency_penalty": 0, "presence_penalty": 0,
            "response_format": {"type": "json_object"}
        }

        # --- Call generic LLM method ---
        parsed_result, usage_data = await self._call_llm_endpoint(
            payload=payload,
            job_id=attempt_id, # Use attempt_id for tracing
            call_description=f"Search results processing for {vendor_name}"
        )

        # --- Return structure expected by caller ---
        api_result = {
            "result": parsed_result,
            "usage": usage_data
        }

        # --- SAVE TO CACHE (if successful) ---
        if settings.USE_LLM_CACHE and parsed_result is not None:
            cache_key = _generate_cache_key(payload)
            logger.info(f"--- SAVING TO CACHE --- Storing successful response for search results {attempt_id[:8]} (Key: {cache_key[:8]}...)")
            self.cache[cache_key] = api_result
            _save_cache(self.cache)
        # --- END SAVE TO CACHE ---

        return api_result


    # --- NEW METHOD: Handles generic prompt call ---
    @retry(stop=stop_after_attempt(settings.MAX_RETRIES), wait=wait_exponential(multiplier=1, min=settings.RETRY_DELAY, max=10))
    @log_function_call(logger, include_args=False)
    async def call_llm_with_prompt(
        self,
        prompt: str,
        stats_dict: Dict[str, Any], # Pass the specific dict to update (e.g., final_stats["api_usage"])
        job_id: str, # For logging/tracing
        max_tokens: int = 2048,
        temperature: float = 0.1,
        top_p: float = 0.9,
    ) -> Optional[Dict[str, Any]]:
        """
        Sends a pre-formatted prompt to the LLM, handles API call, stats, and parsing.

        Args:
            prompt: The complete prompt string to send.
            stats_dict: The dictionary where API usage stats should be accumulated
                        (e.g., job_stats['api_usage']). Should have keys like
                        'openrouter_calls', 'openrouter_prompt_tokens', etc.
            job_id: An identifier for logging purposes (e.g., review job ID, batch ID).
            max_tokens: Max tokens for the completion.
            temperature: Sampling temperature.
            top_p: Nucleus sampling parameter.

        Returns:
            The parsed JSON dictionary from the LLM response, or None if an error occurred
            or parsing failed.
        """
        logger.info(f"Calling LLM with pre-formatted prompt",
                    extra={"job_id": job_id, "prompt_length": len(prompt)})
        correlation_id = get_correlation_id() or job_id # Ensure correlation ID
        llm_trace_logger.debug(f"LLM_TRACE: Starting call_llm_with_prompt (Job ID: {job_id})", extra={'correlation_id': correlation_id})
        llm_trace_logger.debug(f"LLM_TRACE: Provided Prompt (Job ID: {job_id}):\n-------\n{prompt}\n-------", extra={'correlation_id': correlation_id})

        # --- Payload Construction ---
        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": temperature,
            "max_tokens": max_tokens,
            "top_p": top_p,
            "frequency_penalty": 0,
            "presence_penalty": 0,
            "response_format": {"type": "json_object"} # Assume JSON output needed
        }

        # --- Call generic LLM endpoint helper ---
        # This helper handles caching, API key, call, errors, basic parsing, and *initial* stats update
        parsed_result, usage_data = await self._call_llm_endpoint(
            payload=payload,
            job_id=job_id,
            call_description="Generic prompt call"
        )

        # --- Accumulate stats ---
        # Update the passed-in stats dictionary
        if isinstance(stats_dict, dict):
            stats_dict["openrouter_calls"] = stats_dict.get("openrouter_calls", 0) + 1
            stats_dict["openrouter_prompt_tokens"] = stats_dict.get("openrouter_prompt_tokens", 0) + usage_data.get("prompt_tokens", 0)
            stats_dict["openrouter_completion_tokens"] = stats_dict.get("openrouter_completion_tokens", 0) + usage_data.get("completion_tokens", 0)
            stats_dict["openrouter_total_tokens"] = stats_dict.get("openrouter_total_tokens", 0) + usage_data.get("total_tokens", 0)
            # Note: Cost calculation should happen *after* all calls, using the final accumulated stats.
        else:
            logger.warning("Stats dictionary was not provided or invalid type, cannot update usage.", extra={"job_id": job_id})

        # --- Return the parsed result ---
        # The caller (reclassification_logic) expects the parsed dictionary
        return parsed_result


    # --- NEW INTERNAL HELPER METHOD ---
    async def _call_llm_endpoint(
        self,
        payload: Dict[str, Any],
        job_id: str, # Identifier for logging/tracing this specific call
        call_description: str = "LLM API call"
    ) -> Tuple[Optional[Dict[str, Any]], Dict[str, int]]:
        """
        Internal helper to handle the actual API call, caching, key management,
        error handling, basic parsing, and returning parsed result + usage.

        Args:
            payload: The complete request payload for the API.
            job_id: Identifier for logging/tracing.
            call_description: Short description for logs.

        Returns:
            A tuple containing:
            - The parsed JSON dictionary response (or None on error/parse failure).
            - A dictionary with usage stats for *this specific call*
              (prompt_tokens, completion_tokens, total_tokens).
        """
        correlation_id = get_correlation_id() or job_id
        default_usage = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}

        # --- CACHE CHECK ---
        cache_key = _generate_cache_key(payload)
        if settings.USE_LLM_CACHE and cache_key in self.cache:
            logger.warning(f"--- CACHE HIT --- Returning cached response for {call_description} ({job_id})")
            llm_trace_logger.info(f"LLM_TRACE: Cache Hit ({call_description}, Job ID: {job_id}, Key: {cache_key[:8]}...)", extra={'correlation_id': correlation_id})
            cached_response = self.cache[cache_key]
            # Ensure cache structure matches expected return format
            parsed_result = cached_response.get("result")
            usage_data = cached_response.get("usage", default_usage)
            return parsed_result, usage_data
        # --- END CACHE CHECK ---

        logger.info(f"--- CACHE MISS --- Preparing LIVE API call for {call_description} ({job_id})")

        # --- Get or Generate API Key ---
        current_api_key = await self._get_active_key_or_generate()
        if not current_api_key:
            logger.error(f"Cannot make live API call for {call_description}: Failed to obtain a generated API key.", extra={"job_id": job_id})
            llm_trace_logger.error(f"LLM_TRACE: LLM API Error ({call_description}, Job ID: {job_id}): Failed to obtain generated key.", extra={'correlation_id': correlation_id})
            return None, default_usage # Return None for result, zero usage

        headers = {
            "Authorization": f"Bearer {current_api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "naicsvendorclassification.com",
            "X-Title": "NAICS Vendor Classification"
        }

        # Log Request Details (Trace Log)
        try:
            log_headers = {k: v for k, v in headers.items() if k.lower() != 'authorization'}
            key_hash_prefix = self.active_generated_key_hash[:8] if self.active_generated_key_hash else "UNKNOWN"
            log_headers['Authorization'] = f'Bearer [REDACTED_GENERATED_KEY_{key_hash_prefix}]'
            llm_trace_logger.debug(f"LLM_TRACE: LLM Request Headers ({call_description}, Job ID: {job_id}):\n{json.dumps(log_headers, indent=2)}", extra={'correlation_id': correlation_id})
            llm_trace_logger.debug(f"LLM_TRACE: LLM Request Payload ({call_description}, Job ID: {job_id}):\n{json.dumps(payload, indent=2)}", extra={'correlation_id': correlation_id})
        except Exception as log_err:
            llm_trace_logger.warning(f"LLM_TRACE: Failed to log LLM request details ({call_description}, Job ID: {job_id}): {log_err}", extra={'correlation_id': correlation_id})

        response_data = None; raw_content = None; response = None; status_code = None; api_duration = 0.0
        parsed_result = None
        usage_data = default_usage.copy()

        try:
            key_hash_prefix = self.active_generated_key_hash[:8] if self.active_generated_key_hash else 'N/A'
            logger.debug(f"Sending request to OpenRouter API for {call_description} using generated key (hash: {key_hash_prefix})", extra={"job_id": job_id})
            start_time = time.time()
            async with httpx.AsyncClient() as client:
                response = await client.post(f"{self.api_base}/chat/completions", json=payload, headers=headers, timeout=90.0) # Adjust timeout if needed
                raw_content = response.text
                status_code = response.status_code
                api_duration = time.time() - start_time
                llm_trace_logger.debug(f"LLM_TRACE: LLM Raw Response ({call_description}, Job ID: {job_id}, Status: {status_code}, Duration: {api_duration:.3f}s):\n-------\n{raw_content or '[No Content Received]'}\n-------", extra={'correlation_id': correlation_id})
                response.raise_for_status()
                response_data = response.json()

            # --- Successful response processing ---
            if response_data and response_data.get("choices") and isinstance(response_data["choices"], list) and len(response_data["choices"]) > 0:
                message = response_data["choices"][0].get("message")
                if message and isinstance(message, dict): content_field = message.get("content")
                else: content_field = None
                if content_field: raw_content = content_field # Use content from message if available
                else: logger.warning("LLM response message object missing 'content' field.", extra={"message_obj": message, "job_id": job_id})
            else: logger.warning("LLM response choice missing 'message' object or structure invalid.", extra={"choice_obj": response_data.get("choices", [{}])[0], "job_id": job_id})

            # Extract usage for this call
            usage = response_data.get("usage", {}) if response_data else {}
            usage_data["prompt_tokens"] = usage.get("prompt_tokens", 0)
            usage_data["completion_tokens"] = usage.get("completion_tokens", 0)
            usage_data["total_tokens"] = usage.get("total_tokens", 0)

            logger.info(f"OpenRouter API response received successfully for {call_description}",
                    extra={ "duration": api_duration, "job_id": job_id, "status_code": status_code, "key_hash_used": key_hash_prefix, **usage_data })

            # Parse the JSON content
            with LogTimer(logger, "JSON parsing and extraction", include_in_stats=True):
                parsed_result = _extract_json_from_response(raw_content) # Use internal helper

            if parsed_result is None:
                llm_trace_logger.error(f"LLM_TRACE: LLM JSON Parse Error ({call_description}, Job ID: {job_id}). Raw content logged above.", extra={'correlation_id': correlation_id})
                raise ValueError(f"LLM response was not valid JSON or could not be extracted. Preview: {str(raw_content)[:200]}")

            try: llm_trace_logger.debug(f"LLM_TRACE: LLM Parsed Response ({call_description}, Job ID: {job_id}):\n{json.dumps(parsed_result, indent=2)}", extra={'correlation_id': correlation_id})
            except Exception as log_err: llm_trace_logger.warning(f"LLM_TRACE: Failed to log LLM parsed response ({call_description}, Job ID: {job_id}): {log_err}", extra={'correlation_id': correlation_id})

            # --- CACHE SAVE (moved to caller methods like classify_batch, call_llm_with_prompt) ---
            # We only cache if the specific calling method requests it, after accumulating stats etc.

            return parsed_result, usage_data

        except httpx.HTTPStatusError as e:
            response_text = raw_content or (e.response.text[:500] if hasattr(e.response, 'text') else "[No Response Body]")
            status_code = e.response.status_code
            key_hash_used_prefix = self.active_generated_key_hash[:8] if self.active_generated_key_hash else 'N/A'
            logger.error(f"HTTP error during {call_description}", exc_info=False,
                        extra={ "status_code": status_code, "response_text": response_text, "job_id": job_id, "key_hash_used": key_hash_used_prefix })
            llm_trace_logger.error(f"LLM_TRACE: LLM API HTTP Error ({call_description}, Job ID: {job_id}): Status={status_code}, Response='{response_text}', KeyHash={key_hash_used_prefix}", exc_info=True, extra={'correlation_id': correlation_id})

            if status_code in GENERATED_KEY_INVALID_STATUS_CODES:
                logger.warning(f"Generated key (hash: {key_hash_used_prefix}) may be invalid due to status {status_code}. Discarding and forcing regeneration on retry.", extra={"job_id": job_id})
                self.active_generated_key = None
                self.active_generated_key_hash = None
            elif status_code in PROVISIONING_RELATED_ERROR_CODES:
                 logger.warning(f"Server error {status_code} encountered for {call_description}. This might indicate an OpenRouter issue.", extra={"job_id": job_id})

            raise # Re-raise for tenacity to handle retry

        except httpx.RequestError as e:
            key_hash_used_prefix = self.active_generated_key_hash[:8] if self.active_generated_key_hash else 'N/A'
            logger.error(f"Network error during {call_description}", exc_info=False,
                        extra={ "error_details": str(e), "job_id": job_id, "key_hash_used": key_hash_used_prefix })
            llm_trace_logger.error(f"LLM_TRACE: LLM API Network Error ({call_description}, Job ID: {job_id}): {e}, KeyHash={key_hash_used_prefix}", exc_info=True, extra={'correlation_id': correlation_id})
            # Optionally discard key here too
            # self.active_generated_key = None
            # self.active_generated_key_hash = None
            raise # Re-raise for tenacity

        except ValueError as ve: # Catch the specific error raised on JSON parse failure
            logger.error(f"LLM response parsing error during {call_description}", exc_info=False,
                        extra={"error": str(ve), "job_id": job_id})
            # Don't discard key for parsing error. Return None for result.
            return None, usage_data # Return None for parsed_result, but include any usage stats obtained

        except Exception as e:
            key_hash_used_prefix = self.active_generated_key_hash[:8] if self.active_generated_key_hash else 'N/A'
            error_context = { "job_id": job_id, "error": str(e), "model": self.model, "key_hash_used": key_hash_used_prefix }
            logger.error(f"Unexpected error during {call_description}", exc_info=True, extra=error_context)
            llm_trace_logger.error(f"LLM_TRACE: LLM Unexpected Error ({call_description}, Job ID: {job_id}): {e}, KeyHash={key_hash_used_prefix}", exc_info=True, extra={'correlation_id': correlation_id})
            raise # Re-raise for tenacity

        # Should only be reached if Tenacity gives up after retries
        logger.error(f"LLM call failed after multiple retries for {call_description}", extra={"job_id": job_id})
        return None, default_usage # Return None, zero usage if all retries fail

</file>

<file path='app/services/search_service.py'>
# app/services/search_service.py

import httpx
import logging
from typing import Dict, Any, List, Optional # Added Optional
from tenacity import retry, stop_after_attempt, wait_exponential, RetryError
import time
import uuid
import json
from core import config
from core.config import settings
from core.logging_config import get_logger
from core.log_context import set_log_context, get_correlation_id
from utils.log_utils import LogTimer, log_function_call

llm_trace_logger = logging.getLogger("llm_api_trace")
logger = get_logger("vendor_classification.search_service")

# --- Status codes that trigger key rotation ---
# UPDATED: Added 432 (Tavily specific usage limit code) to the set
TAVILY_ROTATION_STATUS_CODES = {400, 401, 403, 429, 432, 500, 502, 503, 504}

class SearchService:
    """Service for interacting with Tavily Search API, with key rotation."""

    def __init__(self):
        """Initialize the search service."""
        logger.info("Initializing Tavily Search service with key rotation")
        self.api_keys = config.MANUAL_TAVILY_API_KEYS
        self.base_url = "https://api.tavily.com"
        self.current_key_index = 0

        if not self.api_keys:
            logger.error("Tavily API key list is empty! Search calls will fail.")
            # Optionally raise an exception
            # raise ValueError("Tavily API keys are missing in configuration.")

        logger.debug("Search service initialized",
                   extra={"api_endpoint": self.base_url,
                          "key_count": len(self.api_keys),
                          "rotation_codes": sorted(list(TAVILY_ROTATION_STATUS_CODES))}) # Log rotation codes sorted

    def _get_current_key(self) -> Optional[str]:
        """Gets the current API key based on the index."""
        if not self.api_keys:
            logger.warning("Attempted to get Tavily key, but key list is empty.")
            return None
        # Ensure index is always valid, even if list shrinks dynamically (though unlikely here)
        if self.current_key_index >= len(self.api_keys):
            logger.warning(f"Tavily key index {self.current_key_index} out of bounds ({len(self.api_keys)} keys). Resetting to 0.")
            self.current_key_index = 0
        return self.api_keys[self.current_key_index]

    def _rotate_key(self):
        """Rotates to the next API key in the list."""
        if not self.api_keys or len(self.api_keys) <= 1:
            logger.warning("Cannot rotate Tavily key: list is empty or has only one key.")
            return # No rotation possible

        old_index = self.current_key_index
        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        logger.warning(f"Rotated Tavily API key from index {old_index} to {self.current_key_index} due to API error.")

    # Increased retries slightly for search as it might be less critical than LLM? Or keep same.
    @retry(stop=stop_after_attempt(settings.MAX_RETRIES), wait=wait_exponential(multiplier=1, min=1, max=10))
    @log_function_call(logger)
    async def search_vendor(self, vendor_name: str) -> Dict[str, Any]:
        """
        Search for information about a vendor, with key rotation on failure.
        """
        logger.info(f"Searching for vendor information",
                   extra={"vendor": vendor_name})
        set_log_context({"vendor": vendor_name})
        # Basic query sanitization attempt (remove potential control characters, excessive whitespace)
        sanitized_vendor_name = ' '.join(str(vendor_name).split())
        search_query = f"{sanitized_vendor_name} company business type industry"
        if vendor_name != sanitized_vendor_name:
             logger.debug(f"Sanitized vendor name for search query", extra={"original": vendor_name, "sanitized": sanitized_vendor_name})

        logger.debug(f"Generated search query",
                   extra={"search_query": search_query})

        # --- Get current key ---
        current_api_key = self._get_current_key()
        if not current_api_key:
             logger.error("Cannot perform Tavily search: No API key available.")
             # Return error structure consistent with API failures
             return {
                "vendor": vendor_name, # Return original name here
                "error": "Tavily API key not configured",
                "search_query": search_query,
                "sources": [],
                "summary": None # Ensure summary is None on error
             }
        # --- End get current key ---

        correlation_id = get_correlation_id()
        search_attempt_id = str(uuid.uuid4())
        llm_trace_logger.debug(f"LLM_TRACE: Starting Tavily Search (Attempt ID: {search_attempt_id}, Vendor: {vendor_name})", extra={'correlation_id': correlation_id})

        response = None; raw_content = None; response_data = None; status_code = None
        try:
            logger.debug(f"Sending request to Tavily API using key index {self.current_key_index}")

            # --- Log Request Payload (already present) ---
            payload_for_log = { # Redact key for logging
                "api_key": f"[REDACTED_KEY_INDEX_{self.current_key_index}]",
                "query": search_query,
                "search_depth": "advanced",
                "include_answer": True,
                "max_results": 5
            }
            headers = {"Content-Type": "application/json"}

            # Trace Logging for Request (already present)
            try:
                llm_trace_logger.debug(f"LLM_TRACE: Tavily Request Headers (Attempt ID: {search_attempt_id}):\n{json.dumps(headers, indent=2)}", extra={'correlation_id': correlation_id})
                llm_trace_logger.debug(f"LLM_TRACE: Tavily Request Payload (Attempt ID: {search_attempt_id}):\n{json.dumps(payload_for_log, indent=2)}", extra={'correlation_id': correlation_id})
            except Exception as log_err:
                 llm_trace_logger.warning(f"LLM_TRACE: Failed to log Tavily request details (Attempt ID: {search_attempt_id}): {log_err}", extra={'correlation_id': correlation_id})
            # --- End Log Request Payload ---

            actual_payload = payload_for_log.copy()
            actual_payload["api_key"] = current_api_key # Use the actual key for the request

            async with httpx.AsyncClient() as client:
                with LogTimer(logger, "Tavily API request", include_in_stats=True):
                    start_time = time.time()
                    response = await client.post(
                        f"{self.base_url}/search",
                        json=actual_payload,
                        headers=headers,
                        timeout=30.0
                    )
                    # --- Log Raw Response (already present) ---
                    api_duration = time.time() - start_time
                    raw_content = response.text
                    status_code = response.status_code
                    llm_trace_logger.debug(f"LLM_TRACE: Tavily Raw Response (Attempt ID: {search_attempt_id}, Status: {status_code}, Duration: {api_duration:.3f}s):\n-------\n{raw_content or '[No Content Received]'}\n-------", extra={'correlation_id': correlation_id})
                    # --- End Log Raw Response ---
                    response.raise_for_status() # Raise HTTPStatusError for 4xx/5xx AFTER logging
                    response_data = response.json()

            processed_results = {
                "vendor": vendor_name, # Return original name
                "search_query": search_query,
                "sources": [
                    {
                        "title": result.get("title", ""),
                        "url": result.get("url", ""),
                        "content": result.get("content", "")
                    }
                    for result in response_data.get("results", []) if result.get("url") and result.get("content") # Ensure content exists
                ],
                "summary": response_data.get("answer", ""),
                "error": None
            }
            logger.info(f"Tavily search successful", extra={"vendor": vendor_name, "results_found": len(processed_results["sources"]), "key_index_used": self.current_key_index})
            return processed_results

        except httpx.HTTPStatusError as e:
             response_text = raw_content or (e.response.text[:500] if hasattr(e.response, 'text') else "[No Response Body]")
             status_code = e.response.status_code
             logger.error(f"Tavily API HTTP error for vendor '{vendor_name}'", exc_info=False, # exc_info=False for less noise, trace log has it
                         extra={"status_code": status_code, "response": response_text, "key_index_used": self.current_key_index, "attempt_id": search_attempt_id})
             # Log HTTP Error (already present)
             llm_trace_logger.error(f"LLM_TRACE: Tavily API HTTP Error (Attempt ID: {search_attempt_id}): Status={status_code}, Response='{response_text}'", exc_info=True, extra={'correlation_id': correlation_id})

             # --- Key Rotation Logic (already present) ---
             if status_code in TAVILY_ROTATION_STATUS_CODES:
                 self._rotate_key() # Rotate if the status code matches
             else:
                 logger.warning(f"HTTP Status Code {status_code} not in TAVILY_ROTATION_STATUS_CODES. Key will not be rotated for this error.", extra={"vendor": vendor_name})
             # --- END Key Rotation Logic ---

             # Re-raise *after* potential rotation for tenacity to handle retry
             raise # Re-raise for tenacity

        except httpx.RequestError as e:
             # Network errors (connection, timeout etc.)
             logger.error(f"Tavily API request error for vendor '{vendor_name}'", exc_info=False, # exc_info=False for less noise, trace log has it
                          extra={"error_details": str(e), "key_index_used": self.current_key_index, "attempt_id": search_attempt_id})
             # Log Network Error (already present)
             llm_trace_logger.error(f"LLM_TRACE: Tavily API Network Error (Attempt ID: {search_attempt_id}): {e}", exc_info=True, extra={'correlation_id': correlation_id})
             # Optionally rotate on specific network errors? Less common for key issues.
             # self._rotate_key()
             raise # Re-raise for tenacity

        except json.JSONDecodeError as e:
             # Handle cases where Tavily returns non-JSON response with 200 OK (unlikely but possible)
             logger.error(f"Failed to decode JSON response from Tavily for vendor '{vendor_name}'", exc_info=False,
                          extra={"response_preview": raw_content[:500] if raw_content else "N/A", "key_index_used": self.current_key_index, "attempt_id": search_attempt_id})
             # Log JSON Decode Error (already present)
             llm_trace_logger.error(f"LLM_TRACE: Tavily JSON Decode Error (Attempt ID: {search_attempt_id}): {e}. Raw Content: {raw_content or 'N/A'}", exc_info=True, extra={'correlation_id': correlation_id})
             # Don't rotate key for JSON errors. Re-raise for tenacity.
             # Treat as a failure like other exceptions.
             raise ValueError(f"Tavily response was not valid JSON: {str(e)}") from e

        except Exception as e:
            # Catch any other unexpected errors during the process
            logger.error(f"Unexpected error during Tavily search for vendor '{vendor_name}'", exc_info=True, # Include stack trace for unexpected
                         extra={"key_index_used": self.current_key_index, "attempt_id": search_attempt_id})
            # Log Unexpected Error (already present)
            llm_trace_logger.error(f"LLM_TRACE: Tavily Unexpected Error (Attempt ID: {search_attempt_id}): {e}", exc_info=True, extra={'correlation_id': correlation_id})
            # Optionally rotate on unexpected errors? Could hide other issues.
            # self._rotate_key()
            raise # Re-raise for tenacity
</file>

<file path='app/services/user_service.py'>
# <file path='app/services/user_service.py'>
# app/services/user_service.py
from sqlalchemy.orm import Session
from sqlalchemy.exc import IntegrityError
from fastapi import HTTPException, status
from typing import List, Optional
import uuid
from datetime import datetime, timezone # Added timezone

from models.user import User
from schemas.user import UserCreate, UserUpdate
from api.auth import get_password_hash # Assuming auth.py is in api directory
from core.logging_config import get_logger

logger = get_logger("vendor_classification.user_service")

def create_user(db: Session, user_in: UserCreate) -> User:
    """
    Creates a new user in the database.
    Handles password hashing and potential integrity errors.
    """
    logger.info(f"Attempting to create user", extra={"username": user_in.username, "email": user_in.email})
    hashed_password = get_password_hash(user_in.password)
    db_user = User(
        id=str(uuid.uuid4()), # Generate UUID string for ID
        username=user_in.username,
        email=user_in.email,
        full_name=user_in.full_name,
        hashed_password=hashed_password,
        is_active=user_in.is_active if user_in.is_active is not None else True,
        is_superuser=user_in.is_superuser if user_in.is_superuser is not None else False,
    )
    db.add(db_user)
    try:
        db.commit()
        db.refresh(db_user)
        logger.info(f"User created successfully", extra={"user_id": db_user.id, "username": db_user.username})
        return db_user
    except IntegrityError as e:
        db.rollback()
        logger.warning(f"Failed to create user due to integrity error (duplicate username/email?)",
                        extra={"username": user_in.username, "email": user_in.email, "error": str(e)})
        # Determine if it's username or email conflict (crude check)
        detail = "Username or email already registered."
        if "users_username_key" in str(e).lower():
            detail = f"Username '{user_in.username}' is already taken."
        elif "users_email_key" in str(e).lower():
            detail = f"Email '{user_in.email}' is already registered."
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=detail)
    except Exception as e:
        db.rollback()
        logger.error(f"Unexpected error creating user", exc_info=True, extra={"username": user_in.username})
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Could not create user.")


def get_user(db: Session, user_id: str) -> Optional[User]:
    """Retrieves a user by their ID."""
    logger.debug(f"Fetching user by ID", extra={"user_id": user_id})
    user = db.query(User).filter(User.id == user_id).first()
    if user:
        logger.debug(f"User found", extra={"user_id": user_id, "username": user.username})
    else:
        logger.debug(f"User not found", extra={"user_id": user_id})
    return user

def get_user_by_username(db: Session, username: str) -> Optional[User]:
    """Retrieves a user by their username."""
    logger.debug(f"Fetching user by username", extra={"username": username})
    user = db.query(User).filter(User.username == username).first()
    if user:
        logger.debug(f"User found", extra={"user_id": user.id, "username": username})
    else:
        logger.debug(f"User not found", extra={"username": username})
    return user

def get_user_by_email(db: Session, email: str) -> Optional[User]:
    """Retrieves a user by their email."""
    logger.debug(f"Fetching user by email", extra={"email": email})
    user = db.query(User).filter(User.email == email).first()
    if user:
        logger.debug(f"User found", extra={"user_id": user.id, "username": user.username, "email": email})
    else:
        logger.debug(f"User not found", extra={"email": email})
    return user


def get_users(db: Session, skip: int = 0, limit: int = 100) -> List[User]:
    """Retrieves a list of users with pagination."""
    logger.info(f"Fetching list of users", extra={"skip": skip, "limit": limit})
    users = db.query(User).offset(skip).limit(limit).all()
    logger.info(f"Retrieved {len(users)} users.")
    return users


def update_user(db: Session, user_id: str, user_in: UserUpdate) -> Optional[User]:
    """Updates an existing user."""
    logger.info(f"Attempting to update user", extra={"user_id": user_id})
    db_user = get_user(db, user_id)
    if not db_user:
        logger.warning(f"User not found for update", extra={"user_id": user_id})
        return None

    update_data = user_in.model_dump(exclude_unset=True) # Pydantic v2
    # update_data = user_in.dict(exclude_unset=True) # Pydantic v1

    if "password" in update_data and update_data["password"]:
        logger.info(f"Updating password for user via standard update endpoint", extra={"user_id": user_id})
        hashed_password = get_password_hash(update_data["password"])
        db_user.hashed_password = hashed_password
        del update_data["password"] # Remove plain password from update dict
        # Consider adding a timestamp for when the password was last changed via this method
        # db_user.password_last_changed_at = datetime.now(timezone.utc)

    for field, value in update_data.items():
        setattr(db_user, field, value)

    # Ensure updated_at is set
    db_user.updated_at = datetime.now(timezone.utc)

    try:
        db.commit()
        db.refresh(db_user)
        logger.info(f"User updated successfully", extra={"user_id": user_id})
        return db_user
    except IntegrityError as e:
        db.rollback()
        logger.warning(f"Failed to update user due to integrity error (duplicate username/email?)",
                        extra={"user_id": user_id, "error": str(e)})
        detail = "Username or email already registered by another user."
        if "users_username_key" in str(e).lower():
            detail = f"Username '{update_data.get('username', db_user.username)}' is already taken."
        elif "users_email_key" in str(e).lower():
            detail = f"Email '{update_data.get('email', db_user.email)}' is already registered."
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=detail)
    except Exception as e:
        db.rollback()
        logger.error(f"Unexpected error updating user", exc_info=True, extra={"user_id": user_id})
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Could not update user.")

# --- ADDED: Password Reset Function ---
def reset_password(db: Session, user_id: str, new_password: str) -> bool:
    """
    Updates a user's password after successful reset token verification.
    Returns True if successful, False otherwise.
    """
    logger.info("Attempting to reset password for user", extra={"user_id": user_id})
    db_user = get_user(db, user_id)
    if not db_user:
        logger.warning("User not found for password reset", extra={"user_id": user_id})
        return False

    try:
        hashed_password = get_password_hash(new_password)
        db_user.hashed_password = hashed_password
        db_user.updated_at = datetime.now(timezone.utc) # Update timestamp
        # Optional: Clear any password reset token fields if they exist on the model
        # if hasattr(db_user, 'password_reset_token'):
        #     db_user.password_reset_token = None
        # if hasattr(db_user, 'password_reset_token_expires'):
        #      db_user.password_reset_token_expires = None

        db.commit()
        logger.info("Password reset successful in database", extra={"user_id": user_id})
        return True
    except Exception as e:
        db.rollback()
        logger.error("Error updating password in database during reset", exc_info=True, extra={"user_id": user_id})
        # Raise a specific exception or return False depending on desired handling in the endpoint
        # raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Could not update password.")
        return False


def delete_user(db: Session, user_id: str) -> bool:
    """Deletes a user."""
    logger.info(f"Attempting to delete user", extra={"user_id": user_id})
    db_user = get_user(db, user_id)
    if not db_user:
        logger.warning(f"User not found for deletion", extra={"user_id": user_id})
        return False

    # Prevent deleting the default admin? (Optional safeguard)
    # if db_user.username == 'admin':
    #     logger.error("Attempted to delete the default admin user.", extra={"user_id": user_id})
    #     raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Cannot delete the primary admin user.")

    try:
        db.delete(db_user)
        db.commit()
        logger.info(f"User deleted successfully", extra={"user_id": user_id})
        return True
    except Exception as e:
        db.rollback()
        logger.error(f"Error deleting user", exc_info=True, extra={"user_id": user_id})
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Could not delete user.")

#</file>
</file>

<file path='app/tasks/celery_app.py'>
# app/tasks/celery_app.py
from celery import Celery
import logging
import sys
import os

# Attempt initial logging setup
try:
    from core.logging_config import setup_logging
    log_dir_worker = "/data/logs" if os.path.exists("/data") else "./logs_worker"
    os.makedirs(log_dir_worker, exist_ok=True)
    print(f"WORKER: Attempting initial logging setup to {log_dir_worker}")
    setup_logging(log_to_file=True, log_dir=log_dir_worker, async_logging=False, llm_trace_log_file="llm_api_trace_worker.log")
    print("WORKER: Initial logging setup attempted.")
except Exception as setup_err:
    print(f"WORKER: CRITICAL ERROR during initial logging setup: {setup_err}")
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# Import logger *after* setup attempt
from core.logging_config import get_logger
# Import context functions from the new module
from core.log_context import set_correlation_id, set_job_id, clear_all_context

# Use direct signal imports from celery.signals
from celery.signals import task_prerun, task_postrun, task_failure

logger = get_logger("vendor_classification.celery")

# Log diagnostic information
logger.info(
    f"Initializing Celery app",
    extra={
        "python_executable": sys.executable,
        "python_version": sys.version,
        "python_path": sys.path,
        "cwd": os.getcwd()
    }
)

try:
    from core.config import settings
    logger.info("Successfully imported settings")
except Exception as e:
    logger.error("Error importing settings", exc_info=True)
    raise

# Create Celery app
logger.info("Creating Celery app")
try:
    celery_app = Celery(
        "vendor_classification",
        broker=settings.REDIS_URL,
        backend=settings.REDIS_URL
    )
    logger.info("Celery app created", extra={"broker": settings.REDIS_URL})

    # Configure Celery
    celery_app.conf.update(
        task_serializer="json",
        accept_content=["json"],
        result_serializer="json",
        timezone="UTC",
        enable_utc=True,
        task_track_started=True,
        task_send_sent_event=True,
    )
    logger.info("Celery configuration updated")

    # Signal Handlers
    logger.info("Connecting Celery signal handlers...")

    @task_prerun.connect
    def handle_task_prerun(task_id, task, args, kwargs, **extra_options):
        """Signal handler before task runs."""
        clear_all_context() # Clear any lingering context
        # Determine job_id based on common kwargs patterns
        job_id = kwargs.get('job_id') or kwargs.get('review_job_id') or (args[0] if args else None) or task_id
        set_correlation_id(job_id) # Use job_id as correlation_id
        set_job_id(job_id)
        logger.info(
            "Task about to run",
            extra={
                "signal": "task_prerun",
                "task_id": task_id,
                "task_name": task.name,
                "args": args,
                "kwargs": kwargs
            }
        )

    @task_postrun.connect
    def handle_task_postrun(task_id, task, args, kwargs, retval, state, **extra_options):
        """Signal handler after task completes."""
        logger.info(
            "Task finished running",
            extra={
                "signal": "task_postrun",
                "task_id": task_id,
                "task_name": task.name,
                "retval": repr(retval)[:200],
                "final_state": state
            }
        )
        clear_all_context() # Clean up context

    @task_failure.connect
    def handle_task_failure(task_id, exception, args, kwargs, traceback, einfo, **extra_options):
        """Signal handler if task fails."""
        task_name = getattr(kwargs.get('task'), 'name', None) or getattr(einfo, 'task', {}).get('name', 'UnknownTask')
        logger.error(
            "Task failed",
            exc_info=(type(exception), exception, traceback),
            extra={
                "signal": "task_failure",
                "task_id": task_id,
                "task_name": task_name,
                "args": args,
                "kwargs": kwargs,
                "exception_type": type(exception).__name__,
                "error": str(exception),
                "einfo": str(einfo)[:1000] if einfo else None
            }
        )
        clear_all_context() # Clean up context

    logger.info("Celery signal handlers connected.")

except Exception as e:
    logger.error("Error creating or configuring Celery app", exc_info=True)
    raise

# Import tasks to register them
logger.info("Attempting to import tasks for registration...")
try:
    # Import original classification task
    from tasks.classification_tasks import process_vendor_file
    logger.info("Successfully imported 'tasks.classification_tasks.process_vendor_file'")
    # --- CORRECTED: Import reclassification task from classification_tasks ---
    from tasks.classification_tasks import reclassify_flagged_vendors_task
    logger.info("Successfully imported 'tasks.classification_tasks.reclassify_flagged_vendors_task'")
    # --- END CORRECTED ---
except ImportError as e:
    logger.error("ImportError when importing tasks", exc_info=True)
    logger.error(f"sys.path during task import: {sys.path}")
    raise
except Exception as e:
    logger.error("Unexpected error importing tasks", exc_info=True)
    raise

# Log discovered tasks
logger.info(f"Tasks registered in Celery app: {list(celery_app.tasks.keys())}")

logger.info("Celery app initialization finished.")

if __name__ == "__main__":
    logger.warning("celery_app.py run directly (likely for testing/debugging)")
</file>

<file path='app/tasks/classification_logic.py'>
# <file path='app/tasks/classification_logic.py'>
import asyncio
import time
from datetime import datetime
from typing import List, Dict, Any, Optional, Set
from sqlalchemy.orm import Session
from sqlalchemy.exc import SQLAlchemyError

from core.config import settings
from core.logging_config import get_logger
# Import context functions if needed directly (though often used via logger)
from core.log_context import set_log_context
# Import log helpers from utils
from utils.log_utils import LogTimer, log_function_call, log_duration

from models.job import Job, JobStatus, ProcessingStage
from models.taxonomy import Taxonomy
from services.llm_service import LLMService
from services.search_service import SearchService

logger = get_logger("vendor_classification.classification_logic")

# --- Constants ---
MAX_CONCURRENT_SEARCHES = 10 # Limit concurrent search/LLM processing for unknown vendors
BATCH_PROCESSING_TIMEOUT = 300.0 # Max time (seconds) per classification batch
SEARCH_CLASSIFY_TIMEOUT = 600.0 # Max time (seconds) per vendor search + recursive classification

# --- Helper Functions (Moved from classification_tasks.py) ---

def create_batches(items: List[Any], batch_size: int) -> List[List[Any]]:
    """Create batches from a list of items."""
    if not items: return []
    if not isinstance(items, list):
        logger.warning(f"create_batches expected a list, got {type(items)}. Returning empty list.")
        return []
    if batch_size <= 0:
        logger.warning(f"Invalid batch_size {batch_size}, using default from settings.")
        batch_size = settings.BATCH_SIZE
    return [items[i:i + batch_size] for i in range(0, len(items), batch_size)]

def group_by_parent_category(
    results: Dict[str, Dict],
    parent_level: int,
    vendors_to_group_names: List[str]
) -> Dict[Optional[str], List[str]]:
    """
    Group a specific list of vendor names based on their classification result at the parent_level.
    Only includes vendors that were successfully classified with a valid ID at the parent level.
    Returns a dictionary mapping parent category ID to a list of vendor *names*.
    """
    grouped: Dict[Optional[str], List[str]] = {}
    parent_key = f"level{parent_level}"
    logger.debug(f"group_by_parent_category: Grouping {len(vendors_to_group_names)} vendors based on results from '{parent_key}'.")

    grouped_count = 0
    excluded_count = 0

    for vendor_name in vendors_to_group_names:
        vendor_results = results.get(vendor_name)
        level_result = None
        if vendor_results is not None:
            level_result = vendor_results.get(parent_key)
        else:
            logger.warning(f"group_by_parent_category: Vendor '{vendor_name}' not found in results dictionary.")
            excluded_count += 1
            continue

        if level_result and isinstance(level_result, dict) and not level_result.get("classification_not_possible", True):
            category_id = level_result.get("category_id")
            if category_id and category_id not in ["N/A", "ERROR"]:
                if category_id not in grouped:
                    grouped[category_id] = []
                grouped[category_id].append(vendor_name)
                grouped_count += 1
                # Reduced verbosity: logger.debug(f"  Grouping vendor '{vendor_name}' under parent '{category_id}'.")
            else:
                logger.debug(f"  Excluding vendor '{vendor_name}': classified at '{parent_key}' but has invalid category_id '{category_id}'.")
                excluded_count += 1
        else:
            reason = "Not processed"
            if level_result and isinstance(level_result, dict):
                reason = level_result.get('classification_not_possible_reason', 'Marked not possible')
            elif not level_result:
                    reason = f"No result found for {parent_key}"
            logger.info(f"  Excluding vendor '{vendor_name}' from Level {parent_level + 1}: not successfully classified at '{parent_key}'. Reason: {reason}.")
            excluded_count += 1

    logger.info(f"group_by_parent_category: Finished grouping for Level {parent_level + 1}. Created {len(grouped)} groups, included {grouped_count} vendors, excluded {excluded_count} vendors.")
    return grouped

# --- Core Processing Logic (Moved from classification_tasks.py) ---

@log_function_call(logger, include_args=False) # Keep args=False
async def process_batch(
    batch_data: List[Dict[str, Any]], # Pass list of dicts including optional fields
    level: int,
    parent_category_id: Optional[str],
    taxonomy: Taxonomy,
    llm_service: LLMService,
    stats: Dict[str, Any],
    search_context: Optional[Dict[str, Any]] = None # ADDED: Optional search context
) -> Dict[str, Dict]:
    """
    Process a batch of vendors for a specific classification level (1-5), including taxonomy validation.
    Optionally uses search context for post-search classification attempts.
    Updates stats dictionary in place. Passes full vendor data and context to LLM.
    Returns results for the batch.
    """
    results = {}
    if not batch_data:
        logger.warning(f"process_batch called with empty batch_data for Level {level}, Parent '{parent_category_id}'.")
        return results

    batch_names = [vd.get('vendor_name', f'Unknown_{i}') for i, vd in enumerate(batch_data)] # For logging
    context_type = "Search Context" if search_context else "Initial Data"
    classification_source = "Search" if search_context else "Initial" # Determine source

    logger.info(f"process_batch: Starting Level {level} batch using {context_type}.",
                extra={"batch_size": len(batch_data), "parent_category_id": parent_category_id, "first_vendor": batch_names[0] if batch_names else 'N/A'})

    # --- Get valid category IDs for this level/parent (Updated for L5) ---
    valid_category_ids: Set[str] = set()
    category_id_lookup_error = False
    try:
        logger.debug(f"process_batch: Retrieving valid category IDs for Level {level}, Parent '{parent_category_id}'.")
        categories = []
        if level == 1:
            categories = taxonomy.get_level1_categories()
        elif parent_category_id:
            if level == 2:
                categories = taxonomy.get_level2_categories(parent_category_id)
            elif level == 3:
                categories = taxonomy.get_level3_categories(parent_category_id)
            elif level == 4:
                categories = taxonomy.get_level4_categories(parent_category_id)
            elif level == 5:
                categories = taxonomy.get_level5_categories(parent_category_id)
            else:
                    logger.error(f"process_batch: Invalid level {level} requested.")
                    categories = [] # Should not happen
        else: # level > 1 and no parent_category_id
                logger.error(f"process_batch: Parent category ID is required for Level {level} but was not provided.")
                categories = []

        valid_category_ids = {cat.id for cat in categories}

        if not valid_category_ids:
                if level > 1 and parent_category_id:
                    logger.warning(f"process_batch: No valid child categories found or retrieved for Level {level}, Parent '{parent_category_id}'. LLM cannot classify.")
                elif level == 1:
                    logger.error("process_batch: No Level 1 categories found in taxonomy!")
                    category_id_lookup_error = True
        # else: # Reduced verbosity
                # logger.debug(f"process_batch: Found {len(valid_category_ids)} valid IDs for Level {level}, Parent '{parent_category_id}'. Example: {list(valid_category_ids)[:5]}")

    except Exception as tax_err:
        logger.error(f"process_batch: Error getting valid categories from taxonomy", exc_info=True,
                        extra={"level": level, "parent_category_id": parent_category_id})
        valid_category_ids = set()
        category_id_lookup_error = True

    # --- Call LLM ---
    llm_response_data = None
    try:
        logger.info(f"process_batch: Calling LLM for Level {level}, Parent '{parent_category_id or 'None'}', Context: {context_type}")
        with LogTimer(logger, f"LLM classification - Level {level}, Parent '{parent_category_id or 'None'}' ({context_type})", include_in_stats=True):
            # Note: The actual HTTP call and retries happen inside classify_batch
            llm_response_data = await llm_service.classify_batch(
                batch_data=batch_data,
                level=level,
                taxonomy=taxonomy,
                parent_category_id=parent_category_id,
                search_context=search_context
            )
        logger.info(f"process_batch: LLM call completed for Level {level}, Parent '{parent_category_id or 'None'}'.")

        if llm_response_data and isinstance(llm_response_data.get("usage"), dict):
            usage = llm_response_data["usage"]
            stats["api_usage"]["openrouter_calls"] += 1
            stats["api_usage"]["openrouter_prompt_tokens"] += usage.get("prompt_tokens", 0)
            stats["api_usage"]["openrouter_completion_tokens"] += usage.get("completion_tokens", 0)
            stats["api_usage"]["openrouter_total_tokens"] += usage.get("total_tokens", 0)
            # logger.debug(f"process_batch: LLM API usage updated", extra=usage) # Reduced verbosity
        else:
            logger.warning("process_batch: LLM response missing or has invalid usage data.")

        if llm_response_data is None:
                logger.error("process_batch: Received None response from llm_service.classify_batch. Cannot process results.")
                raise ValueError("LLM service returned None, indicating a failure in the call.")

        llm_result = llm_response_data.get("result", {})
        classifications = llm_result.get("classifications", [])
        if not isinstance(classifications, list):
                logger.warning("LLM response 'classifications' is not a list.", extra={"response_preview": str(llm_result)[:500]})
                classifications = []

        logger.debug(f"process_batch: Received {len(classifications)} classifications from LLM for batch size {len(batch_data)} at Level {level}.")
        if llm_result.get("batch_id_mismatch"):
                logger.warning(f"process_batch: Processing batch despite batch_id mismatch warning from LLM service.")

        # --- Validate and process results ---
        processed_vendors_in_response = set()
        for classification in classifications:
            if not isinstance(classification, dict):
                logger.warning("Invalid classification item format received from LLM (not a dict)", extra={"item": classification})
                continue

            vendor_name = classification.get("vendor_name")
            if not vendor_name:
                logger.warning("Classification received without vendor_name", extra={"classification": classification})
                continue

            target_vendor_name = vendor_name
            processed_vendors_in_response.add(target_vendor_name)

            category_id = classification.get("category_id", "N/A")
            category_name = classification.get("category_name", "N/A")
            confidence = classification.get("confidence", 0.0)
            classification_not_possible = classification.get("classification_not_possible", False)
            reason = classification.get("classification_not_possible_reason")
            notes = classification.get("notes")
            is_valid_category = True

            # --- TAXONOMY VALIDATION ---
            if not classification_not_possible and not category_id_lookup_error and valid_category_ids:
                if category_id not in valid_category_ids:
                    is_valid_category = False
                    logger.warning(f"Invalid category ID '{category_id}' returned by LLM for vendor '{target_vendor_name}' at level {level}, parent '{parent_category_id}'.",
                                    extra={"valid_ids_count": len(valid_category_ids)})
                    classification_not_possible = True
                    reason = f"Invalid category ID '{category_id}' returned by LLM (Valid examples: {list(valid_category_ids)[:3]})"
                    confidence = 0.0
                    category_id = "N/A"
                    category_name = "N/A"
                    stats["invalid_category_errors"] = stats.get("invalid_category_errors", 0) + 1
                # else: # Reduced verbosity
                        # logger.debug(f"Category ID '{category_id}' for '{target_vendor_name}' is valid for Level {level}, Parent '{parent_category_id}'.")
            elif not classification_not_possible and category_id_lookup_error:
                    logger.warning(f"Cannot validate category ID '{category_id}' for '{target_vendor_name}' due to earlier taxonomy lookup error.")
            elif not classification_not_possible and not valid_category_ids and level > 1:
                    logger.warning(f"Cannot validate category ID '{category_id}' for '{target_vendor_name}' because no valid child categories were found for parent '{parent_category_id}'.")
                    is_valid_category = False
                    classification_not_possible = True
                    reason = f"LLM returned category '{category_id}' but no valid children found for parent '{parent_category_id}'."
                    confidence = 0.0
                    category_id = "N/A"; category_name = "N/A"
                    stats["invalid_category_errors"] = stats.get("invalid_category_errors", 0) + 1
            # --- End TAXONOMY VALIDATION ---

            # --- Consistency Checks ---
            if classification_not_possible and confidence > 0.0:
                logger.warning("Correcting confidence to 0.0 for classification_not_possible=true", extra={"vendor": target_vendor_name})
                confidence = 0.0
            if not classification_not_possible and is_valid_category and (category_id == "N/A" or not category_id):
                    logger.warning("Classification marked possible by LLM but category ID is 'N/A' or empty", extra={"vendor": target_vendor_name, "classification": classification})
                    classification_not_possible = True
                    reason = reason or "Missing category ID despite LLM success claim"
                    confidence = 0.0
                    category_id = "N/A"
                    category_name = "N/A"
            # --- End Consistency Checks ---

            results[target_vendor_name] = {
                "category_id": category_id,
                "category_name": category_name,
                "confidence": confidence,
                "classification_not_possible": classification_not_possible,
                "classification_not_possible_reason": reason,
                "notes": notes,
                "vendor_name": target_vendor_name,
                # --- UPDATED: Use classification_source ---
                "classification_source": classification_source
                # --- END UPDATED ---
            }
            # logger.debug(f"process_batch: Processed result for '{target_vendor_name}' at Level {level}. Possible: {not classification_not_possible}, ID: {category_id}") # Reduced verbosity

        # Handle missing vendors from batch
        missing_vendors = set(batch_names) - processed_vendors_in_response
        if missing_vendors:
            logger.warning(f"LLM response did not include results for all vendors in the batch.", extra={"missing_vendors": list(missing_vendors), "level": level})
            for vendor_name in missing_vendors:
                results[vendor_name] = {
                    "category_id": "N/A", "category_name": "N/A", "confidence": 0.0,
                    "classification_not_possible": True,
                    "classification_not_possible_reason": "Vendor missing from LLM response batch",
                    "notes": None,
                    "vendor_name": vendor_name,
                    # --- UPDATED: Use classification_source ---
                    "classification_source": classification_source
                    # --- END UPDATED ---
                }

    # This broad exception catch handles errors from llm_service.classify_batch (like RetryError)
    # or errors during the result processing/validation within this function.
    except Exception as e:
        logger.error(f"Failed to process batch at Level {level} ({context_type})", exc_info=True,
                        extra={"batch_names": batch_names, "error": str(e)})
        # Mark all vendors in the batch as failed
        for vendor_name in batch_names:
            results[vendor_name] = {
                "category_id": "ERROR", "category_name": "ERROR", "confidence": 0.0,
                "classification_not_possible": True,
                "classification_not_possible_reason": f"Batch processing error: {str(e)[:100]}",
                "notes": None,
                "vendor_name": vendor_name,
                # --- UPDATED: Use classification_source ---
                "classification_source": classification_source
                # --- END UPDATED ---
            }
    logger.info(f"process_batch: Finished Level {level} batch for parent '{parent_category_id or 'None'}'. Returning {len(results)} results.")
    return results


@log_function_call(logger, include_args=False)
async def search_and_classify_recursively(
    vendor_data: Dict[str, Any],
    taxonomy: Taxonomy,
    llm_service: LLMService,
    search_service: SearchService,
    stats: Dict[str, Any],
    semaphore: asyncio.Semaphore,
    target_level: int # <<< ADDED target_level
) -> Dict[str, Any]:
    """
    Performs Tavily search, attempts L1 classification, and then recursively
    attempts L2 up to target_level classification using the search context.
    Controlled by semaphore.
    Returns the search_result_data dictionary, potentially augmented with
    classification results (keyed as classification_l1, classification_l2, etc.).
    """
    vendor_name = vendor_data.get('vendor_name', 'UnknownVendor')
    logger.debug(f"search_and_classify_recursively: Waiting to acquire semaphore for vendor '{vendor_name}'.")
    async with semaphore: # Limit concurrency
        logger.info(f"search_and_classify_recursively: Acquired semaphore. Starting for vendor '{vendor_name}' up to Level {target_level}.")
        search_result_data = {
            "vendor": vendor_name,
            "search_query": f"{vendor_name} company business type industry",
            "sources": [],
            "summary": None,
            "error": None,
            # Keys for storing classification results obtained via search
            "classification_l1": None,
            "classification_l2": None,
            "classification_l3": None,
            "classification_l4": None,
            "classification_l5": None
            }

        # --- 1. Perform Tavily Search ---
        try:
            logger.debug(f"search_and_classify_recursively: Calling search_service.search_vendor for '{vendor_name}'.")
            with LogTimer(logger, f"Tavily search for '{vendor_name}'", include_in_stats=True):
                tavily_response = await search_service.search_vendor(vendor_name)
            logger.debug(f"search_and_classify_recursively: search_service.search_vendor returned for '{vendor_name}'.")

            stats["api_usage"]["tavily_search_calls"] += 1
            search_result_data.update(tavily_response) # Update with actual search results or error

            source_count = len(search_result_data.get("sources", []))
            if search_result_data.get("error"):
                logger.warning(f"search_and_classify_recursively: Search failed", extra={"vendor": vendor_name, "error": search_result_data["error"]})
                search_result_data["classification_l1"] = {
                        "classification_not_possible": True,
                        "classification_not_possible_reason": f"Search error: {str(search_result_data['error'])[:100]}",
                        "confidence": 0.0, "vendor_name": vendor_name, "notes": "Search Failed",
                        # --- UPDATED: Add source ---
                        "classification_source": "Search"
                        # --- END UPDATED ---
                }
                logger.debug(f"search_and_classify_recursively: Releasing semaphore early due to search error for '{vendor_name}'.")
                return search_result_data # Stop if search failed
            else:
                logger.info(f"search_and_classify_recursively: Search completed", extra={"vendor": vendor_name, "source_count": source_count, "summary_present": bool(search_result_data.get('summary'))})

        except Exception as search_exc:
            logger.error(f"search_and_classify_recursively: Unexpected error during Tavily search for {vendor_name}", exc_info=True)
            search_result_data["error"] = f"Unexpected search error: {str(search_exc)}"
            search_result_data["classification_l1"] = {
                    "classification_not_possible": True,
                    "classification_not_possible_reason": f"Search task error: {str(search_exc)[:100]}",
                    "confidence": 0.0, "vendor_name": vendor_name, "notes": "Search Failed",
                    # --- UPDATED: Add source ---
                    "classification_source": "Search"
                    # --- END UPDATED ---
                }
            logger.debug(f"search_and_classify_recursively: Releasing semaphore early due to search exception for '{vendor_name}'.")
            return search_result_data # Stop if search failed

        # --- 2. Attempt L1 Classification using Search Results ---
        search_content_available = search_result_data.get("sources") or search_result_data.get("summary")
        if not search_content_available:
            logger.warning(f"search_and_classify_recursively: No usable search results found for vendor, cannot classify", extra={"vendor": vendor_name})
            search_result_data["classification_l1"] = {
                    "classification_not_possible": True,
                    "classification_not_possible_reason": "No search results content found",
                    "confidence": 0.0, "vendor_name": vendor_name, "notes": "No Search Content",
                    # --- UPDATED: Add source ---
                    "classification_source": "Search"
                    # --- END UPDATED ---
            }
            logger.debug(f"search_and_classify_recursively: Releasing semaphore early due to no search content for '{vendor_name}'.")
            return search_result_data # Stop if no content

        valid_l1_category_ids: Set[str] = set(taxonomy.categories.keys())
        llm_response_l1 = None
        try:
            logger.debug(f"search_and_classify_recursively: Calling llm_service.process_search_results (L1) for '{vendor_name}'.")
            with LogTimer(logger, f"LLM L1 classification from search for '{vendor_name}'", include_in_stats=True):
                # This specific function is designed only for L1 from search results
                llm_response_l1 = await llm_service.process_search_results(vendor_data, search_result_data, taxonomy)
            logger.debug(f"search_and_classify_recursively: llm_service.process_search_results (L1) returned for '{vendor_name}'.")

            if llm_response_l1 is None:
                    logger.error("search_and_classify_recursively: Received None response from llm_service.process_search_results. Cannot process L1.")
                    raise ValueError("LLM service (process_search_results) returned None.")

            if isinstance(llm_response_l1.get("usage"), dict):
                usage = llm_response_l1["usage"]
                stats["api_usage"]["openrouter_calls"] += 1
                stats["api_usage"]["openrouter_prompt_tokens"] += usage.get("prompt_tokens", 0)
                stats["api_usage"]["openrouter_completion_tokens"] += usage.get("completion_tokens", 0)
                stats["api_usage"]["openrouter_total_tokens"] += usage.get("total_tokens", 0)

            l1_classification = llm_response_l1.get("result", {})
            if "vendor_name" not in l1_classification: l1_classification["vendor_name"] = vendor_name
            # --- UPDATED: Ensure source is marked ---
            l1_classification["classification_source"] = "Search"
            # --- END UPDATED ---

            # Validate L1 result
            classification_not_possible_l1 = l1_classification.get("classification_not_possible", True)
            category_id_l1 = l1_classification.get("category_id", "N/A")
            is_valid_l1 = True

            if not classification_not_possible_l1 and valid_l1_category_ids:
                if category_id_l1 not in valid_l1_category_ids:
                    is_valid_l1 = False
                    logger.warning(f"Invalid L1 category ID '{category_id_l1}' from search LLM for '{vendor_name}'.", extra={"valid_ids_count": len(valid_l1_category_ids)})
                    l1_classification["classification_not_possible"] = True
                    l1_classification["classification_not_possible_reason"] = f"Invalid L1 category ID '{category_id_l1}' from search."
                    l1_classification["confidence"] = 0.0
                    l1_classification["category_id"] = "N/A"
                    l1_classification["category_name"] = "N/A"
                    stats["invalid_category_errors"] = stats.get("invalid_category_errors", 0) + 1

            if l1_classification.get("classification_not_possible") and l1_classification.get("confidence", 0.0) > 0.0: l1_classification["confidence"] = 0.0
            if not l1_classification.get("classification_not_possible") and not l1_classification.get("category_id", "N/A"):
                    l1_classification["classification_not_possible"] = True
                    l1_classification["classification_not_possible_reason"] = "Missing L1 category ID despite LLM success claim"
                    l1_classification["confidence"] = 0.0
                    l1_classification["category_id"] = "N/A"; l1_classification["category_name"] = "N/A"

            search_result_data["classification_l1"] = l1_classification # Store validated L1 result

        except Exception as llm_err:
                logger.error(f"search_and_classify_recursively: Error during LLM L1 processing for {vendor_name}", exc_info=True)
                search_result_data["error"] = search_result_data.get("error") or f"LLM L1 processing error: {str(llm_err)}"
                search_result_data["classification_l1"] = {
                    "classification_not_possible": True,
                    "classification_not_possible_reason": f"LLM L1 processing error: {str(llm_err)[:100]}",
                    "confidence": 0.0, "vendor_name": vendor_name, "notes": "LLM L1 Error",
                    # --- UPDATED: Add source ---
                    "classification_source": "Search"
                    # --- END UPDATED ---
                }
                logger.debug(f"search_and_classify_recursively: Releasing semaphore early due to L1 LLM exception for '{vendor_name}'.")
                return search_result_data # Stop if L1 classification failed

        # --- 3. Recursive Classification L2 up to target_level using Search Context ---
        current_parent_id = search_result_data["classification_l1"].get("category_id")
        classification_possible = not search_result_data["classification_l1"].get("classification_not_possible", True)

        # --- UPDATED: Loop up to target_level ---
        if classification_possible and current_parent_id and current_parent_id != "N/A" and target_level > 1:
            logger.info(f"search_and_classify_recursively: L1 successful ({current_parent_id}), proceeding to L2-{target_level} for {vendor_name} using search context.")
            for level in range(2, target_level + 1):
        # --- END UPDATED ---
                logger.debug(f"Attempting post-search Level {level} for {vendor_name}, parent {current_parent_id}")
                try:
                    logger.debug(f"search_and_classify_recursively: Calling process_batch (Level {level}) for '{vendor_name}' with search context.")
                    # Use process_batch for consistency in validation and structure
                    # Note: process_batch itself doesn't have an external timeout,
                    # but the overall search_and_classify_recursively task does (added in process_vendors)
                    batch_result_dict = await process_batch(
                        batch_data=[vendor_data], # Batch of one
                        level=level,
                        parent_category_id=current_parent_id,
                        taxonomy=taxonomy,
                        llm_service=llm_service,
                        stats=stats,
                        search_context=search_result_data # Pass the full search results as context
                    )
                    logger.debug(f"search_and_classify_recursively: process_batch (Level {level}) returned for '{vendor_name}'.")

                    level_result = batch_result_dict.get(vendor_name)
                    if level_result:
                        # --- UPDATED: Ensure source is marked (process_batch should already do this) ---
                        level_result["classification_source"] = "Search"
                        # --- END UPDATED ---
                        search_result_data[f"classification_l{level}"] = level_result # Store result
                        if level_result.get("classification_not_possible", True):
                            logger.info(f"Post-search classification stopped at Level {level} for {vendor_name}. Reason: {level_result.get('classification_not_possible_reason')}")
                            break # Stop recursion if classification fails
                        else:
                            current_parent_id = level_result.get("category_id") # Update parent for next level
                            if not current_parent_id or current_parent_id == "N/A":
                                logger.warning(f"Post-search Level {level} successful but returned invalid parent_id '{current_parent_id}' for {vendor_name}. Stopping recursion.")
                                break
                    else:
                        logger.error(f"Post-search Level {level} batch processing did not return result for {vendor_name}. Stopping recursion.")
                        search_result_data[f"classification_l{level}"] = {
                                "classification_not_possible": True,
                                "classification_not_possible_reason": f"Missing result from L{level} post-search batch",
                                "confidence": 0.0, "vendor_name": vendor_name, "notes": f"L{level} Error",
                                # --- UPDATED: Add source ---
                                "classification_source": "Search"
                                # --- END UPDATED ---
                        }
                        break

                except Exception as recursive_err:
                    logger.error(f"search_and_classify_recursively: Error during post-search Level {level} for {vendor_name}", exc_info=True)
                    search_result_data[f"classification_l{level}"] = {
                            "classification_not_possible": True,
                            "classification_not_possible_reason": f"L{level} processing error: {str(recursive_err)[:100]}",
                            "confidence": 0.0, "vendor_name": vendor_name, "notes": f"L{level} Error",
                            # --- UPDATED: Add source ---
                            "classification_source": "Search"
                            # --- END UPDATED ---
                    }
                    break # Stop recursion on error
        else:
            logger.info(f"search_and_classify_recursively: L1 classification failed or not possible for {vendor_name}, or target level is 1. Skipping L2-{target_level}.")

        logger.info(f"search_and_classify_recursively: Finished for vendor", extra={"vendor": vendor_name})
        logger.debug(f"search_and_classify_recursively: Releasing semaphore for vendor '{vendor_name}'.")
        return search_result_data


@log_function_call(logger, include_args=False) # Keep args=False
async def process_vendors(
    unique_vendors_map: Dict[str, Dict[str, Any]], # Pass map containing full vendor data
    taxonomy: Taxonomy,
    results: Dict[str, Dict],
    stats: Dict[str, Any],
    job: Job,
    db: Session,
    llm_service: LLMService,
    search_service: SearchService,
    target_level: int # <<< ADDED target_level
):
    """
    Main orchestration function for processing vendors through the classification workflow (up to target_level),
    including recursive search for unknowns (up to target_level). Updates results and stats dictionaries in place.
    """
    unique_vendor_names = list(unique_vendors_map.keys()) # Get names from map
    total_unique_vendors = len(unique_vendor_names)
    processed_count = 0 # Count unique vendors processed in batches

    logger.info(f"Starting classification loop for {total_unique_vendors} unique vendors up to target Level {target_level}.")

    # --- Initial Hierarchical Classification (Levels 1 to target_level) ---
    vendors_to_process_next_level_names = set(unique_vendor_names) # Start with all unique vendor names for Level 1
    initial_l4_success_count = 0 # Track L4 for stats
    initial_l5_success_count = 0 # Track L5 for stats

    # --- UPDATED: Loop up to target_level ---
    for level in range(1, target_level + 1):
    # --- END UPDATED ---
        if not vendors_to_process_next_level_names:
            logger.info(f"No vendors remaining to process for Level {level}. Skipping.")
            continue # Skip level if no vendors need processing

        current_vendors_for_this_level = list(vendors_to_process_next_level_names) # Copy names for processing this level
        vendors_successfully_classified_in_level_names = set() # Track vendors that pass this level

        stage_enum_name = f"CLASSIFICATION_L{level}"
        if hasattr(ProcessingStage, stage_enum_name):
                job.current_stage = getattr(ProcessingStage, stage_enum_name).value
        else:
                logger.error(f"ProcessingStage enum does not have member '{stage_enum_name}'. Using default.")
                job.current_stage = ProcessingStage.PROCESSING.value # Fallback

        # Adjust progress calculation based on target_level (distribute 0.7 across target_level steps)
        progress_per_level = 0.7 / target_level if target_level > 0 else 0.7
        job.progress = min(0.8, 0.1 + ((level - 1) * progress_per_level))
        logger.info(f"[process_vendors] Committing status update before Level {level}: {job.status}, {job.current_stage}, {job.progress:.3f}")
        try:
            db.commit()
        except Exception as db_err:
            logger.error("Failed to commit status update before level processing", exc_info=True)
            db.rollback() # Rollback if commit fails

        logger.info(f"===== Starting Initial Level {level} Classification =====",
                    extra={ "vendors_to_process": len(current_vendors_for_this_level), "progress": job.progress })

        if level == 1:
            grouped_vendors_names = { None: current_vendors_for_this_level }
            logger.info(f"Level 1: Processing all {len(current_vendors_for_this_level)} vendors.")
        else:
            logger.info(f"Level {level}: Grouping {len(current_vendors_for_this_level)} vendors based on Level {level-1} results.")
            grouped_vendors_names = group_by_parent_category(results, level - 1, current_vendors_for_this_level)
            logger.info(f"Level {level}: Created {len(grouped_vendors_names)} groups for processing.")
            # Reduced verbosity:
            # for parent_id, names in grouped_vendors_names.items():
            #         logger.debug(f"  Group Parent ID '{parent_id}': {len(names)} vendors")

        processed_in_level_count = 0
        batch_counter_for_level = 0
        total_batches_for_level = sum( (len(names) + settings.BATCH_SIZE - 1) // settings.BATCH_SIZE for names in grouped_vendors_names.values() )
        logger.info(f"Level {level}: Total batches to process: {total_batches_for_level}")

        for parent_category_id, group_vendor_names in grouped_vendors_names.items():
            if not group_vendor_names:
                logger.debug(f"Skipping empty group for parent '{parent_category_id}' at Level {level}.")
                continue

            logger.info(f"Processing Level {level} group",
                        extra={"parent_category_id": parent_category_id, "vendor_count": len(group_vendor_names)})

            group_vendor_data = [unique_vendors_map[name] for name in group_vendor_names if name in unique_vendors_map]
            level_batches_data = create_batches(group_vendor_data, batch_size=settings.BATCH_SIZE)
            logger.debug(f"Created {len(level_batches_data)} batches for group '{parent_category_id}' at Level {level}.")

            for i, batch_data in enumerate(level_batches_data):
                batch_counter_for_level += 1
                batch_names = [vd['vendor_name'] for vd in batch_data] # Get names for logging
                logger.info(f"Processing Level {level} batch {i+1}/{len(level_batches_data)} for parent '{parent_category_id or 'None'}'",
                            extra={"batch_size": len(batch_data), "first_vendor": batch_names[0] if batch_names else 'N/A', "batch_num": batch_counter_for_level, "total_batches": total_batches_for_level})
                try:
                    # --- MODIFICATION: Added asyncio.wait_for ---
                    logger.debug(f"Calling process_batch with timeout {BATCH_PROCESSING_TIMEOUT}s")
                    batch_results = await asyncio.wait_for(
                        process_batch(batch_data, level, parent_category_id, taxonomy, llm_service, stats, search_context=None),
                        timeout=BATCH_PROCESSING_TIMEOUT
                    )
                    # --- END MODIFICATION ---
                    logger.debug(f"Level {level} batch {i+1} results received. Count: {len(batch_results)}.")

                    for vendor_name, classification in batch_results.items():
                        if vendor_name in results:
                            # --- UPDATED: Ensure source is set (process_batch should do this) ---
                            classification["classification_source"] = "Initial"
                            # --- END UPDATED ---
                            results[vendor_name][f"level{level}"] = classification
                            processed_in_level_count += 1

                            if not classification.get("classification_not_possible", True):
                                vendors_successfully_classified_in_level_names.add(vendor_name)
                                # logger.debug(f"Vendor '{vendor_name}' successfully classified at Level {level} (ID: {classification.get('category_id')}). Added for L{level+1}.") # Reduced verbosity
                                # Update stats based on the actual level completed
                                if level == 4:
                                    initial_l4_success_count += 1
                                    # logger.debug(f"Incremented initial_l4_success_count for {vendor_name}. Current L4 count: {initial_l4_success_count}") # Reduced verbosity
                                if level == 5:
                                    initial_l5_success_count += 1
                                    # logger.debug(f"Incremented initial_l5_success_count for {vendor_name}. Current L5 count: {initial_l5_success_count}") # Reduced verbosity
                            # else: # Reduced verbosity
                                # logger.debug(f"Vendor '{vendor_name}' not successfully classified at Level {level}. Reason: {classification.get('classification_not_possible_reason', 'Unknown')}. Will not proceed.")
                        else:
                                logger.warning(f"Vendor '{vendor_name}' from batch result not found in main results dictionary.", extra={"level": level})

                # --- MODIFICATION: Catch asyncio.TimeoutError specifically ---
                except asyncio.TimeoutError:
                    logger.error(f"Timeout processing Level {level} batch {i+1} for parent '{parent_category_id or 'None'}' after {BATCH_PROCESSING_TIMEOUT}s.",
                                 extra={"batch_vendors": batch_names})
                    # Mark all vendors in this batch as failed due to timeout
                    for vendor_name in batch_names:
                        if vendor_name in results:
                            # Only add error if not already processed (shouldn't happen with timeout, but defensive)
                            if f"level{level}" not in results[vendor_name]:
                                results[vendor_name][f"level{level}"] = {
                                    "category_id": "ERROR", "category_name": "ERROR", "confidence": 0.0,
                                    "classification_not_possible": True,
                                    "classification_not_possible_reason": f"Batch processing timed out after {BATCH_PROCESSING_TIMEOUT}s",
                                    "vendor_name": vendor_name,
                                    # --- UPDATED: Add source ---
                                    "classification_source": "Initial"
                                    # --- END UPDATED ---
                                }
                                processed_in_level_count += 1 # Count as processed (though failed)
                        else:
                            logger.warning(f"Vendor '{vendor_name}' from timed-out batch not found in main results dictionary.", extra={"level": level})
                # --- END MODIFICATION ---

                except Exception as batch_error:
                    logger.error(f"Error during initial batch processing logic (Level {level}, parent '{parent_category_id or 'None'}')", exc_info=True,
                                    extra={"batch_vendors": batch_names, "error": str(batch_error)})
                    for vendor_name in batch_names:
                            if vendor_name in results:
                                if f"level{level}" not in results[vendor_name]:
                                    results[vendor_name][f"level{level}"] = {
                                        "category_id": "ERROR", "category_name": "ERROR", "confidence": 0.0,
                                        "classification_not_possible": True,
                                        "classification_not_possible_reason": f"Batch processing logic error: {str(batch_error)[:100]}",
                                        "vendor_name": vendor_name,
                                        # --- UPDATED: Add source ---
                                        "classification_source": "Initial"
                                        # --- END UPDATED ---
                                    }
                                    processed_in_level_count += 1
                            else:
                                logger.warning(f"Vendor '{vendor_name}' from failed batch not found in main results dictionary.", extra={"level": level})


                # Update progress within the level (based on batches completed)
                level_progress_fraction = batch_counter_for_level / total_batches_for_level if total_batches_for_level > 0 else 1
                job.progress = min(0.8, 0.1 + ((level - 1) * progress_per_level) + (progress_per_level * level_progress_fraction))
                try:
                    # logger.info(f"[process_vendors] Committing progress update after batch {batch_counter_for_level}/{total_batches_for_level} (Level {level}): {job.progress:.3f}") # Reduced verbosity
                    db.commit()
                except Exception as db_err:
                        logger.error("Failed to commit progress update during batch processing", exc_info=True)
                        db.rollback()

        logger.info(f"===== Initial Level {level} Classification Completed =====")
        logger.info(f"  Processed {processed_in_level_count} vendor results at Level {level}.")
        logger.info(f"  {len(vendors_successfully_classified_in_level_names)} vendors successfully classified and validated at Level {level}, proceeding to L{level+1}.")
        # logger.debug(f"Vendors proceeding to Level {level+1}: {list(vendors_successfully_classified_in_level_names)[:10]}...") # Reduced verbosity
        vendors_to_process_next_level_names = vendors_successfully_classified_in_level_names

    # --- End of Initial Level Loop ---
    logger.info(f"===== Finished Initial Hierarchical Classification Loop (Up to Level {target_level}) =====")

    # --- Identify vendors needing search (those not successfully classified at target_level) ---
    unknown_vendors_data_to_search = []
    for vendor_name in unique_vendor_names:
        is_classified_target = False
        if vendor_name in results:
            target_level_result = results[vendor_name].get(f"level{target_level}")
            if target_level_result and isinstance(target_level_result, dict) and not target_level_result.get("classification_not_possible", True):
                    # Also check for valid ID just in case
                    if target_level_result.get("category_id") and target_level_result.get("category_id") not in ["N/A", "ERROR"]:
                        is_classified_target = True

        if not is_classified_target:
            logger.debug(f"Vendor '{vendor_name}' did not initially reach/pass target Level {target_level} classification. Adding to search list.")
            if vendor_name in unique_vendors_map:
                unknown_vendors_data_to_search.append(unique_vendors_map[vendor_name])
            else:
                logger.warning(f"Vendor '{vendor_name}' marked for search but not found in unique_vendors_map.")
                unknown_vendors_data_to_search.append({'vendor_name': vendor_name}) # Add basic entry

    stats["classification_not_possible_initial"] = len(unknown_vendors_data_to_search)
    stats["successfully_classified_l4"] = initial_l4_success_count # Store initial L4 count
    stats["successfully_classified_l5"] = initial_l5_success_count # Store initial L5 count

    logger.info(f"Initial Classification Summary (Target L{target_level}): {total_unique_vendors - stats['classification_not_possible_initial']} reached target, {stats['classification_not_possible_initial']} did not.")
    if target_level >= 4: logger.info(f"  Ref: {initial_l4_success_count} reached L4 initially.")
    if target_level >= 5: logger.info(f"  Ref: {initial_l5_success_count} reached L5 initially.")

    # --- Search and Recursive Classification for Unknown Vendors (up to target_level) ---
    if unknown_vendors_data_to_search:
        job.current_stage = ProcessingStage.SEARCH.value
        job.progress = 0.8 # Progress after initial classification attempts
        logger.info(f"[process_vendors] Committing status update before Search stage: {job.status}, {job.current_stage}, {job.progress}")
        try:
            db.commit()
        except Exception as db_err:
            logger.error("Failed to commit status update before Search stage", exc_info=True)
            db.rollback()

        logger.info(f"===== Starting Search and Recursive Classification for {stats['classification_not_possible_initial']} Unclassified Vendors (Up to Level {target_level}) =====")

        stats["search_attempts"] = len(unknown_vendors_data_to_search)

        search_tasks = []
        if MAX_CONCURRENT_SEARCHES <= 0:
            logger.error(f"MAX_CONCURRENT_SEARCHES is {MAX_CONCURRENT_SEARCHES}. Cannot proceed with search tasks.")
            raise ValueError("MAX_CONCURRENT_SEARCHES must be positive.")
        search_semaphore = asyncio.Semaphore(MAX_CONCURRENT_SEARCHES)
        logger.info(f"Created search semaphore with concurrency limit: {MAX_CONCURRENT_SEARCHES}")

        # --- MODIFICATION: Added wrapper for search task timeout ---
        for vendor_data in unknown_vendors_data_to_search:
            # Define the coroutine to run with a timeout
            async def timed_search_classify_task(vd):
                vn = vd.get('vendor_name', 'UnknownVendor') # Get name early for logging
                try:
                    logger.debug(f"Calling search_and_classify_recursively for '{vn}' with timeout {SEARCH_CLASSIFY_TIMEOUT}s")
                    return await asyncio.wait_for(
                        search_and_classify_recursively(
                            vd, taxonomy, llm_service, search_service, stats, search_semaphore, target_level
                        ),
                        timeout=SEARCH_CLASSIFY_TIMEOUT
                    )
                except asyncio.TimeoutError:
                    logger.error(f"Timeout (> {SEARCH_CLASSIFY_TIMEOUT}s) during search_and_classify_recursively for vendor: {vn}")
                    # Return an error structure consistent with other failures in search_and_classify_recursively
                    return {
                        "vendor": vn, "search_query": f"{vn} company business type industry", "sources": [], "summary": None,
                        "error": f"Task timed out after {SEARCH_CLASSIFY_TIMEOUT} seconds.",
                        "classification_l1": {
                            "classification_not_possible": True, "classification_not_possible_reason": f"Search/classify task timed out (> {SEARCH_CLASSIFY_TIMEOUT}s)",
                            "confidence": 0.0, "vendor_name": vn, "notes": "Timeout",
                            # --- UPDATED: Add source ---
                            "classification_source": "Search"
                            # --- END UPDATED ---
                        },
                        # Ensure other levels are None
                        "classification_l2": None, "classification_l3": None, "classification_l4": None, "classification_l5": None
                    }
                except Exception as task_exc:
                    # Catch other exceptions within the task execution itself
                    logger.error(f"Exception during search_and_classify_recursively task for vendor {vn}", exc_info=task_exc)
                    return {
                         "vendor": vn, "search_query": f"{vn} company business type industry", "sources": [], "summary": None,
                         "error": f"Task execution error: {str(task_exc)}",
                         "classification_l1": {
                             "classification_not_possible": True, "classification_not_possible_reason": f"Search/classify task error: {str(task_exc)[:100]}",
                             "confidence": 0.0, "vendor_name": vn, "notes": "Task Error",
                             # --- UPDATED: Add source ---
                             "classification_source": "Search"
                             # --- END UPDATED ---
                         },
                         "classification_l2": None, "classification_l3": None, "classification_l4": None, "classification_l5": None
                    }

            # Create the task using the wrapper coroutine
            task = asyncio.create_task(timed_search_classify_task(vendor_data))
            search_tasks.append(task)
        # --- END MODIFICATION ---

        logger.info(f"Gathering results for {len(search_tasks)} search & recursive classification tasks...")
        logger.debug(f"Starting asyncio.gather for {len(search_tasks)} tasks.")
        gather_start_time = time.monotonic()
        # asyncio.gather will now return the result from timed_search_classify_task or any exception raised *by asyncio.create_task itself* (rare)
        # Keep return_exceptions=True for gather errors (e.g., task cancellation)
        search_and_recursive_results = await asyncio.gather(*search_tasks, return_exceptions=True)
        gather_duration = time.monotonic() - gather_start_time
        logger.info(f"Search & recursive classification tasks completed (asyncio.gather finished). Duration: {gather_duration:.3f}s")

        job.progress = 0.95 # Indicate search phase is done, before result processing/generation
        logger.info(f"[process_vendors] Committing progress update after search gather: {job.progress:.3f}")
        try:
            db.commit()
        except Exception as db_err:
            logger.error("Failed to commit progress update after search gather", exc_info=True)
            db.rollback()

        successful_l1_searches = 0
        successful_l5_searches = 0 # Track L5 success via search
        processed_search_count = 0

        logger.info(f"Processing {len(search_and_recursive_results)} results from search/recursive tasks.")
        # --- MODIFICATION: Updated result processing loop to handle timeout/error dicts ---
        for i, result_or_exc in enumerate(search_and_recursive_results):
            processed_search_count += 1
            if i >= len(unknown_vendors_data_to_search):
                    logger.error(f"Search result index {i} out of bounds for unknown_vendors list.")
                    continue
            vendor_data = unknown_vendors_data_to_search[i]
            vendor_name = vendor_data.get('vendor_name', f'UnknownVendor_{i}')

            if vendor_name not in results:
                    logger.warning(f"Vendor '{vendor_name}' from search task not found in main results dict. Initializing.")
                    results[vendor_name] = {}

            results[vendor_name]["search_attempted"] = True # Add flag

            if isinstance(result_or_exc, Exception):
                # This catches errors from asyncio.gather itself (e.g., cancellation)
                logger.error(f"Error returned by asyncio.gather for vendor {vendor_name}", exc_info=result_or_exc)
                results[vendor_name]["search_results"] = {"error": f"Search task gather error: {str(result_or_exc)}"}
                # Mark L1 as failed
                logger.info(f"OVERWRITE_LOG: Search task gather failed for '{vendor_name}'. Marking L1 as failed.")
                results[vendor_name]["level1"] = {
                    "classification_not_possible": True,
                    "classification_not_possible_reason": f"Search task gather error: {str(result_or_exc)[:100]}",
                    "confidence": 0.0, "vendor_name": vendor_name, "notes": "Search Gather Error",
                    # --- UPDATED: Add source ---
                    "classification_source": "Search"
                    # --- END UPDATED ---
                }
                # Clear higher levels
                for lvl in range(2, target_level + 1): results[vendor_name].pop(f"level{lvl}", None)

            elif isinstance(result_or_exc, dict):
                 # This is the normal case OR the error dict returned by timed_search_classify_task
                 search_data = result_or_exc
                 results[vendor_name]["search_results"] = search_data # Store raw search info (including potential timeout/task error)

                 # Check if the dict indicates an error (timeout or task exception captured by the wrapper)
                 if search_data.get("error"):
                     logger.warning(f"Search/classify task for {vendor_name} failed or timed out. Error: {search_data['error']}")
                     # Ensure L1 reflects the failure (using the L1 data from the error dict)
                     l1_error_classification = search_data.get("classification_l1", {
                         "classification_not_possible": True, "classification_not_possible_reason": search_data['error'],
                         "confidence": 0.0, "vendor_name": vendor_name, "notes": "Task Failed/Timeout",
                         # --- UPDATED: Add source ---
                         "classification_source": "Search"
                         # --- END UPDATED ---
                     })
                     logger.info(f"OVERWRITE_LOG: Search task failed/timed out for '{vendor_name}'. Marking L1 as failed.")
                     results[vendor_name]["level1"] = l1_error_classification
                     # Clear higher levels
                     for lvl in range(2, target_level + 1):
                         if f"level{lvl}" in results[vendor_name]:
                             logger.info(f"OVERWRITE_LOG: Clearing L{lvl} for '{vendor_name}' due to search task failure/timeout.")
                             results[vendor_name].pop(f"level{lvl}", None)
                 else:
                     # Process successful result (original logic)
                     l1_classification = search_data.get("classification_l1")
                     if l1_classification:
                         logger.info(f"OVERWRITE_LOG: Processing successful search results for '{vendor_name}'. Target Level: {target_level}.")
                         results[vendor_name]["classified_via_search"] = True # Add flag

                         # Overwrite Level 1 unconditionally with the search result
                         logger.info(f"OVERWRITE_LOG: Overwriting L1 for '{vendor_name}' with search result. Possible: {not l1_classification.get('classification_not_possible', True)}")
                         results[vendor_name]["level1"] = l1_classification # This is the L1 overwrite

                         if not l1_classification.get("classification_not_possible", True):
                             successful_l1_searches += 1
                             logger.debug(f"Vendor '{vendor_name}' successfully classified at L1 via search (ID: {l1_classification.get('category_id')}).")

                             # Overwrite or clear higher levels based on recursive search results
                             for lvl in range(2, target_level + 1):
                                 search_lvl_key = f"classification_l{lvl}"
                                 main_lvl_key = f"level{lvl}"

                                 if search_lvl_key in search_data and search_data[search_lvl_key]:
                                     # Overwrite with the result from the recursive search
                                     lvl_result_data = search_data[search_lvl_key]
                                     logger.info(f"OVERWRITE_LOG: Overwriting L{lvl} for '{vendor_name}' with search result. Possible: {not lvl_result_data.get('classification_not_possible', True)}")
                                     results[vendor_name][main_lvl_key] = lvl_result_data

                                     # Track L5 success specifically if reached via search
                                     if lvl == 5 and not lvl_result_data.get("classification_not_possible", True):
                                         successful_l5_searches += 1
                                         logger.info(f"Vendor '{vendor_name}' reached L5 classification via search.")
                                 else:
                                     # If search path didn't yield a result for this level (stopped early/failed), remove any initial result
                                     if main_lvl_key in results[vendor_name]:
                                         logger.info(f"OVERWRITE_LOG: Clearing L{lvl} for '{vendor_name}' as search path did not provide a result for this level.")
                                         results[vendor_name].pop(main_lvl_key, None)
                                     else:
                                         logger.debug(f"OVERWRITE_LOG: No initial L{lvl} result to clear for '{vendor_name}' and no search result provided.")

                         else: # L1 classification via search failed or wasn't possible
                             reason = l1_classification.get("classification_not_possible_reason", "Search did not yield L1 classification")
                             logger.info(f"Vendor '{vendor_name}' could not be classified via search at L1. Reason: {reason}. Clearing higher levels.")
                             # Clear higher levels as L1 failed post-search
                             for lvl in range(2, target_level + 1):
                                 if f"level{lvl}" in results[vendor_name]:
                                     logger.info(f"OVERWRITE_LOG: Clearing L{lvl} for '{vendor_name}' due to L1 failure post-search.")
                                     results[vendor_name].pop(f"level{lvl}", None)
                     else:
                         # This case should ideally not happen if search_and_classify returns correctly, but handle defensively
                         logger.error(f"Search task for '{vendor_name}' returned dict but missing 'classification_l1'. Marking L1 as failed.")
                         results[vendor_name]["level1"] = { "classification_not_possible": True, "classification_not_possible_reason": "Internal search error (missing L1 result)", "confidence": 0.0, "vendor_name": vendor_name, "notes": "Search Error",
                                                            # --- UPDATED: Add source ---
                                                            "classification_source": "Search"
                                                            # --- END UPDATED ---
                                                            }
                         for lvl in range(2, target_level + 1): results[vendor_name].pop(f"level{lvl}", None)
            else: # Handle unexpected return type from gather
                logger.error(f"Unexpected result type for vendor {vendor_name} search task: {type(result_or_exc)}")
                results[vendor_name]["search_results"] = {"error": f"Unexpected search result type: {type(result_or_exc)}"}
                # Mark L1 as failed
                logger.info(f"OVERWRITE_LOG: Unexpected search result type for '{vendor_name}'. Marking L1 as failed.")
                results[vendor_name]["level1"] = { "classification_not_possible": True, "classification_not_possible_reason": "Internal search error (unexpected type)", "confidence": 0.0, "vendor_name": vendor_name, "notes": "Search Error",
                                                   # --- UPDATED: Add source ---
                                                   "classification_source": "Search"
                                                   # --- END UPDATED ---
                                                   }
                # Clear higher levels
                for lvl in range(2, target_level + 1):
                    if f"level{lvl}" in results[vendor_name]:
                        logger.info(f"OVERWRITE_LOG: Clearing L{lvl} for '{vendor_name}' due to unexpected search result type.")
                        results[vendor_name].pop(f"level{lvl}", None)
        # --- END MODIFICATION ---


        stats["search_successful_classifications_l1"] = successful_l1_searches
        stats["search_successful_classifications_l5"] = successful_l5_searches # Updated stat
        # Update total L5 success count (if target was >= 5)
        # Recalculate final L5 count based on the *final* state of results dict
        final_l5_success_count = 0
        if target_level >= 5:
            for vendor_name in unique_vendor_names:
                l5_res = results.get(vendor_name, {}).get("level5")
                if l5_res and isinstance(l5_res, dict) and not l5_res.get("classification_not_possible", True):
                    final_l5_success_count += 1
            stats["successfully_classified_l5"] = final_l5_success_count
            logger.info(f"Final recalculation: Total vendors successfully classified at L5: {stats['successfully_classified_l5']}")
        else:
            stats["successfully_classified_l5"] = 0 # Ensure it's 0 if target level was lower

        logger.info(f"===== Unknown Vendor Search & Recursive Classification Completed =====")
        logger.info(f"  Attempted search for {stats['search_attempts']} vendors.")
        logger.info(f"  Successfully classified {successful_l1_searches} at L1 via search.")
        if target_level >= 5:
            logger.info(f"  Successfully classified {successful_l5_searches} at L5 via search path.") # L5 count specifically from search path
            logger.info(f"  Total vendors successfully classified at L5 (final state): {stats['successfully_classified_l5']}")
    else:
        logger.info("No unknown vendors required search.")
        job.progress = 0.95 # Set progress high if search wasn't needed
        logger.info(f"[process_vendors] Committing status update as search was skipped: {job.progress:.3f}")
        try:
            db.commit()
        except Exception as db_err:
            logger.error("Failed to commit status update when skipping search", exc_info=True)
            db.rollback()
    logger.info("process_vendors function is returning.")

</file>

<file path='app/tasks/classification_prompts.py'>

# <file path='app/tasks/classification_prompts.py'>
# app/prompts/classification_prompts.py
import json
import logging
from typing import List, Dict, Any, Optional

from models.taxonomy import Taxonomy, TaxonomyCategory

# Configure logger for this module
logger = logging.getLogger("vendor_classification.prompts")

def generate_batch_prompt(
    vendors_data: List[Dict[str, Any]],
    level: int,
    taxonomy: Taxonomy,
    parent_category_id: Optional[str] = None,
    batch_id: str = "unknown-batch",
    search_context: Optional[Dict[str, Any]] = None
) -> str:
    """
    Create an appropriate prompt for the current classification level (1-5),
    optionally including search context for post-search classification.
    """
    context_type = "Search Context" if search_context else "Initial Data"
    logger.debug(f"generate_batch_prompt: Generating prompt for Level {level} using {context_type}",
                extra={ "vendor_count": len(vendors_data), "parent_category_id": parent_category_id, "batch_id": batch_id, "has_search_context": bool(search_context) })

    # --- Build Vendor Data Section ---
    vendor_data_xml = "<vendor_data>\n"
    for i, vendor_entry in enumerate(vendors_data):
        vendor_name = vendor_entry.get('vendor_name', f'UnknownVendor_{i}')
        example = vendor_entry.get('example')
        address = vendor_entry.get('vendor_address')
        website = vendor_entry.get('vendor_website')
        internal_cat = vendor_entry.get('internal_category')
        parent_co = vendor_entry.get('parent_company')
        spend_cat = vendor_entry.get('spend_category')

        vendor_data_xml += f"  <vendor index=\"{i+1}\">\n"
        vendor_data_xml += f"    <name>{vendor_name}</name>\n"
        if example: vendor_data_xml += f"    <example_goods_services>{str(example)[:200]}</example_goods_services>\n"
        if address: vendor_data_xml += f"    <address>{str(address)[:200]}</address>\n"
        if website: vendor_data_xml += f"    <website>{str(website)[:100]}</website>\n"
        if internal_cat: vendor_data_xml += f"    <internal_category>{str(internal_cat)[:100]}</internal_category>\n"
        if parent_co: vendor_data_xml += f"    <parent_company>{str(parent_co)[:100]}</parent_company>\n"
        if spend_cat: vendor_data_xml += f"    <spend_category>{str(spend_cat)[:100]}</spend_category>\n"
        vendor_data_xml += f"  </vendor>\n"
    vendor_data_xml += "</vendor_data>"

    # --- Build Search Context Section ---
    search_context_xml = ""
    if search_context and level > 1: # Only include search context for L2+ post-search attempts
        logger.debug(f"Including search context in prompt for Level {level}", extra={"batch_id": batch_id})
        search_context_xml += "<search_context>\n"
        summary = search_context.get("summary")
        sources = search_context.get("sources")
        if summary:
            search_context_xml += f"  <summary>{str(summary)[:1000]}</summary>\n" # Limit length
        if sources and isinstance(sources, list):
            search_context_xml += "  <sources>\n"
            for j, source in enumerate(sources[:3]): # Limit to top 3 sources for brevity
                title = source.get('title', 'N/A')
                url = source.get('url', 'N/A')
                content_preview = str(source.get('content', ''))[:500] # Limit length
                search_context_xml += f"    <source index=\"{j+1}\">\n"
                search_context_xml += f"      <title>{title}</title>\n"
                search_context_xml += f"      <url>{url}</url>\n"
                search_context_xml += f"      <content_snippet>{content_preview}...</content_snippet>\n"
                search_context_xml += f"    </source>\n"
            search_context_xml += "  </sources>\n"
        else:
             search_context_xml += "  <message>No relevant search results sources were provided.</message>\n"
        search_context_xml += "</search_context>\n"

    # --- Get Category Options ---
    categories: List[TaxonomyCategory] = []
    parent_category_name = "N/A"
    category_lookup_successful = True
    try:
        logger.debug(f"generate_batch_prompt: Retrieving categories via taxonomy methods for Level {level}, Parent: {parent_category_id}")
        parent_obj = None
        if level == 1:
            categories = taxonomy.get_level1_categories()
        elif parent_category_id:
            # --- UPDATED: Use taxonomy methods consistently ---
            if level == 2:
                categories = taxonomy.get_level2_categories(parent_category_id)
                parent_obj = taxonomy.categories.get(parent_category_id)
            elif level == 3:
                categories = taxonomy.get_level3_categories(parent_category_id)
                # Need to find the L2 object to get its name
                l1_id, l2_id = parent_category_id.split('.') if '.' in parent_category_id else (None, parent_category_id)
                if not l1_id:
                    for l1k, l1n in taxonomy.categories.items():
                        if l2_id in getattr(l1n, 'children', {}): l1_id = l1k; break
                if l1_id: parent_obj = taxonomy.categories.get(l1_id, {}).children.get(l2_id)
            elif level == 4:
                categories = taxonomy.get_level4_categories(parent_category_id)
                # Need to find the L3 object to get its name
                # Handle different possible parent_id formats (L1.L2.L3, L2.L3, L3)
                parts = parent_category_id.split('.')
                l1_id, l2_id, l3_id = None, None, None
                if len(parts) == 3: l1_id, l2_id, l3_id = parts[0], parts[1], parts[2]
                elif len(parts) == 2: # L2.L3 format
                    l2_p, l3_p = parts[0], parts[1]
                    for l1k, l1n in taxonomy.categories.items():
                         if l2_p in getattr(l1n, 'children', {}): l1_id = l1k; l2_id = l2_p; l3_id = l3_p; break
                elif len(parts) == 1: # L3 format
                    l3_p = parts[0]
                    for l1k, l1n in taxonomy.categories.items():
                        for l2k, l2n in getattr(l1n, 'children', {}).items():
                            if l3_p in getattr(l2n, 'children', {}): l1_id = l1k; l2_id = l2k; l3_id = l3_p; break
                        if l1_id: break
                if l1_id and l2_id and l3_id:
                    parent_obj = taxonomy.categories.get(l1_id, {}).children.get(l2_id, {}).children.get(l3_id)
            elif level == 5:
                categories = taxonomy.get_level5_categories(parent_category_id)
                # Need to find the L4 object to get its name
                # Handle different possible parent_id formats (L1.L2.L3.L4, L2.L3.L4, L3.L4, L4)
                parts = parent_category_id.split('.')
                l1_id, l2_id, l3_id, l4_id = None, None, None, None
                if len(parts) == 4: l1_id, l2_id, l3_id, l4_id = parts[0], parts[1], parts[2], parts[3]
                elif len(parts) == 3: # L2.L3.L4 format
                    l2_p, l3_p, l4_p = parts[0], parts[1], parts[2]
                    for l1k, l1n in taxonomy.categories.items():
                        if l2_p in getattr(l1n, 'children', {}): l1_id = l1k; l2_id = l2_p; l3_id = l3_p; l4_id = l4_p; break
                elif len(parts) == 2: # L3.L4 format
                    l3_p, l4_p = parts[0], parts[1]
                    for l1k, l1n in taxonomy.categories.items():
                        for l2k, l2n in getattr(l1n, 'children', {}).items():
                             if l3_p in getattr(l2n, 'children', {}): l1_id = l1k; l2_id = l2k; l3_id = l3_p; l4_id = l4_p; break
                        if l1_id: break
                elif len(parts) == 1: # L4 format
                    l4_p = parts[0]
                    for l1k, l1n in taxonomy.categories.items():
                        for l2k, l2n in getattr(l1n, 'children', {}).items():
                            for l3k, l3n in getattr(l2n, 'children', {}).items():
                                if l4_p in getattr(l3n, 'children', {}): l1_id = l1k; l2_id = l2k; l3_id = l3k; l4_id = l4_p; break
                            if l1_id: break
                        if l1_id: break
                if l1_id and l2_id and l3_id and l4_id:
                    parent_obj = taxonomy.categories.get(l1_id, {}).children.get(l2_id, {}).children.get(l3_id, {}).children.get(l4_id)
            # --- END UPDATED ---

            if parent_obj: parent_category_name = parent_obj.name
        else: # level > 1 and no parent_category_id
            logger.error(f"Parent category ID is required for level {level} prompt generation but was not provided.")
            category_lookup_successful = False

        if not categories and level > 1 and parent_category_id:
             logger.warning(f"No subcategories found for Level {level}, Parent '{parent_category_id}'.")
             # Don't mark as failure if parent exists but has no children (valid scenario)
             # category_lookup_successful = False # Removed this line
        elif not categories and level == 1:
             logger.error(f"No Level 1 categories found in taxonomy!")
             category_lookup_successful = False

        logger.debug(f"generate_batch_prompt: Retrieved {len(categories)} categories for Level {level}, Parent '{parent_category_id}' ('{parent_category_name}').")

    except Exception as e:
        logger.error(f"Error retrieving categories for prompt (Level {level}, Parent: {parent_category_id})", exc_info=True)
        category_lookup_successful = False

    # --- Build Category Options Section ---
    category_options_xml = "<category_options>\n"
    if category_lookup_successful:
        category_options_xml += f"  <level>{level}</level>\n"
        if level > 1 and parent_category_id:
            category_options_xml += f"  <parent_id>{parent_category_id}</parent_id>\n"
            category_options_xml += f"  <parent_name>{parent_category_name}</parent_name>\n"
        category_options_xml += "  <categories>\n"
        if categories: # Check if categories list is not empty
            for cat in categories:
                category_options_xml += f"    <category id=\"{cat.id}\" name=\"{cat.name}\"/>\n"
        else:
             category_options_xml += f"    <message>No subcategories available for this level and parent.</message>\n"
        category_options_xml += "  </categories>\n"
    else:
        category_options_xml += f"  <error>Could not retrieve valid categories for Level {level}, Parent '{parent_category_id}'. Classification is not possible.</error>\n"
    category_options_xml += "</category_options>"

    # --- Define Output Format Section ---
    output_format_xml = f"""<output_format>
Respond *only* with a valid JSON object matching this exact schema. Do not include any text before or after the JSON object.

json
{{
  "level": {level},
  "batch_id": "{batch_id}",
  "parent_category_id": {json.dumps(parent_category_id)},
  "classifications": [
    {{
      "vendor_name": "string", // Exact vendor name from input <vendor_data>
      "category_id": "string", // ID from <category_options> or "N/A" if not possible
      "category_name": "string", // Name corresponding to category_id or "N/A"
      "confidence": "float", // 0.0 to 1.0. MUST be 0.0 if classification_not_possible is true.
      "classification_not_possible": "boolean", // true if classification cannot be confidently made from options, false otherwise.
      "classification_not_possible_reason": "string | null", // Brief reason if true (e.g., "Ambiguous", "Insufficient info"), null if false.
      "notes": "string | null" // Optional brief justification or reasoning, especially if confidence is low or not possible.
    }}
    // ... one entry for EACH vendor in <vendor_data>
  ]
}}

</output_format>"""

    # --- Assemble Final Prompt ---
    prompt_base = f"""
<role>You are a precise vendor classification expert using the NAICS taxonomy.</role>

<task>Classify each vendor provided in `<vendor_data>` into **ONE** appropriate NAICS category from the `<category_options>` for Level {level}. {f"Consider that these vendors belong to the parent category '{parent_category_id}: {parent_category_name}'. " if level > 1 and parent_category_id and parent_category_name != 'N/A' else ""}</task>"""

    if search_context_xml:
        prompt_base += f"""
<search_context_instruction>You have been provided with additional context from a web search in `<search_context>`. Use this information, along with the original `<vendor_data>`, to make the most accurate classification decision for Level {level}.</search_context_instruction>"""

    prompt_base += f"""
<instructions>
1.  Analyze each vendor's details in `<vendor_data>` {f"and the supplementary information in `<search_context>`" if search_context_xml else ""}.
2.  Compare the vendor's likely primary business activity against the available categories in `<category_options>`.
3.  Assign the **single most specific and appropriate** category ID and name from the list.
4.  Provide a confidence score (0.0 to 1.0).
5.  **CRITICAL:** If the vendor's primary activity is genuinely ambiguous, cannot be determined from the provided information, or does not fit well into *any* of the specific categories listed in `<category_options>`, **DO NOT GUESS**. Instead: Set `classification_not_possible` to `true`, `confidence` to `0.0`, provide a brief `classification_not_possible_reason`, and set `category_id`/`category_name` to "N/A".
6.  If classification *is* possible (`classification_not_possible: false`), ensure `confidence` > 0.0 and `category_id`/`category_name` are populated correctly from `<category_options>`.
7.  Provide brief optional `notes` for reasoning, especially if confidence is low or classification was not possible.
8.  Ensure the `batch_id` in the final JSON output matches the `batch_id` specified in `<output_format>`.
9.  Ensure the output contains an entry for **every** vendor listed in `<vendor_data>`.
10. Respond *only* with the valid JSON object as specified in `<output_format>`.
</instructions>

{vendor_data_xml}
{search_context_xml if search_context_xml else ""}
{category_options_xml}
{output_format_xml}
"""
    prompt = prompt_base

    # Handle case where category lookup failed (e.g., bad parent ID for L2+)
    if not category_lookup_successful and level > 1:
         prompt = f"""
<role>You are a precise vendor classification expert using the NAICS taxonomy.</role>
<task>Acknowledge that classification is not possible for the vendors in `<vendor_data>` at Level {level} because the necessary subcategories could not be provided (likely due to an invalid or non-existent parent category ID: {parent_category_id}).</task>
<instructions>
1. For **every** vendor listed in `<vendor_data>`, create a classification entry in the final JSON output.
2. In each entry, set `classification_not_possible` to `true`.
3. Set `confidence` to `0.0`.
4. Set `category_id` and `category_name` to "N/A".
5. Set `classification_not_possible_reason` to "No subcategories defined or retrievable for parent {parent_category_id} at Level {level}".
6. Ensure the `batch_id` in the final JSON output matches the `batch_id` specified in `<output_format>`.
7. Respond *only* with the valid JSON object as specified in `<output_format>`.
</instructions>
{vendor_data_xml}
{category_options_xml}
{output_format_xml}
"""
    # Handle case where L1 lookup failed (taxonomy load issue)
    elif not category_lookup_successful and level == 1:
         prompt = f"""
<role>You are a precise vendor classification expert using the NAICS taxonomy.</role>
<task>Acknowledge that classification is not possible for the vendors in `<vendor_data>` at Level 1 because the top-level categories could not be loaded or provided.</task>
<instructions>
1. For **every** vendor listed in `<vendor_data>`, create a classification entry in the final JSON output.
2. In each entry, set `classification_not_possible` to `true`.
3. Set `confidence` to `0.0`.
4. Set `category_id` and `category_name` to "N/A".
5. Set `classification_not_possible_reason` to "Level 1 categories could not be loaded or retrieved.".
6. Ensure the `batch_id` in the final JSON output matches the `batch_id` specified in `<output_format>`.
7. Respond *only* with the valid JSON object as specified in `<output_format>`.
</instructions>
{vendor_data_xml}
{category_options_xml}
{output_format_xml}
"""


    return prompt


def generate_search_prompt(
    vendor_data: Dict[str, Any],
    search_results: Dict[str, Any],
    taxonomy: Taxonomy,
    attempt_id: str = "unknown-attempt"
) -> str:
    """
    Create a prompt for processing search results, aiming for Level 1 classification.
    """
    logger.debug(f"Entering generate_search_prompt for vendor: {vendor_data.get('vendor_name', 'Unknown')}")
    vendor_name = vendor_data.get('vendor_name', 'UnknownVendor')
    example = vendor_data.get('example')
    address = vendor_data.get('vendor_address')
    website = vendor_data.get('vendor_website')
    internal_cat = vendor_data.get('internal_category')
    parent_co = vendor_data.get('parent_company')
    spend_cat = vendor_data.get('spend_category')

    logger.debug(f"Creating search results prompt for vendor",
                extra={ "vendor": vendor_name, "source_count": len(search_results.get("sources", [])), "attempt_id": attempt_id })

    # --- Build Vendor Data Section ---
    vendor_data_xml = "<vendor_data>\n"
    vendor_data_xml += f"  <name>{vendor_name}</name>\n"
    if example: vendor_data_xml += f"  <example_goods_services>{str(example)[:300]}</example_goods_services>\n"
    if address: vendor_data_xml += f"  <address>{str(address)[:200]}</address>\n"
    if website: vendor_data_xml += f"  <website>{str(website)[:100]}</website>\n"
    if internal_cat: vendor_data_xml += f"  <internal_category>{str(internal_cat)[:100]}</internal_category>\n"
    if parent_co: vendor_data_xml += f"  <parent_company>{str(parent_co)[:100]}</parent_company>\n"
    if spend_cat: vendor_data_xml += f"  <spend_category>{str(spend_cat)[:100]}</spend_category>\n"
    vendor_data_xml += "</vendor_data>"

    # --- Build Search Results Section ---
    search_results_xml = "<search_results>\n"
    sources = search_results.get("sources")
    if sources and isinstance(sources, list):
        search_results_xml += "  <sources>\n"
        for i, source in enumerate(sources):
            content_preview = str(source.get('content', ''))[:1500] # Limit length
            search_results_xml += f"    <source index=\"{i+1}\">\n"
            search_results_xml += f"      <title>{source.get('title', 'N/A')}</title>\n"
            search_results_xml += f"      <url>{source.get('url', 'N/A')}</url>\n"
            search_results_xml += f"      <content_snippet>{content_preview}...</content_snippet>\n"
            search_results_xml += f"    </source>\n"
        search_results_xml += "  </sources>\n"
    else:
        search_results_xml += "  <message>No relevant search results sources were found.</message>\n"

    summary_str = search_results.get("summary", "")
    if summary_str:
        search_results_xml += f"  <summary>{summary_str}</summary>\n"
    search_results_xml += "</search_results>"

    # --- Get Level 1 Category Options ---
    categories = taxonomy.get_level1_categories()
    category_options_xml = "<category_options>\n"
    category_options_xml += "  <level>1</level>\n" # Explicitly state Level 1
    category_options_xml += "  <categories>\n"
    for cat in categories:
        category_options_xml += f"    <category id=\"{cat.id}\" name=\"{cat.name}\"/>\n" # Omit description
    category_options_xml += "  </categories>\n"
    category_options_xml += "</category_options>"

    # --- Define Output Format Section ---
    output_format_xml = f"""<output_format>
Respond *only* with a valid JSON object matching this exact schema. Do not include any text before or after the JSON object.

json
{{
  "attempt_id": "{attempt_id}", // ID for this specific attempt
  "vendor_name": "{vendor_name}", // Exact vendor name from input <vendor_data>
  "category_id": "string", // Level 1 ID from <category_options> or "N/A" if not possible
  "category_name": "string", // Name corresponding to category_id or "N/A"
  "confidence": "float", // 0.0 to 1.0. MUST be 0.0 if classification_not_possible is true.
  "classification_not_possible": "boolean", // true if classification cannot be confidently made from options based *only* on provided info, false otherwise.
  "classification_not_possible_reason": "string | null", // Brief reason if true (e.g., "Insufficient info", "Conflicting sources"), null if false.
  "notes": "string | null" // Brief explanation of decision based *only* on the provided context and search results. Reference specific sources if helpful.
}}

</output_format>"""

    # --- Assemble Final Prompt ---
    prompt = f"""
<role>You are a precise vendor classification expert using the NAICS taxonomy.</role>

<task>Analyze the vendor details in `<vendor_data>` and the web search information in `<search_results>` to classify the vendor into **ONE** appropriate **Level 1** NAICS category from `<category_options>`. Base your decision *only* on the provided information.</task>

<instructions>
1.  Carefully review the vendor details in `<vendor_data>` (name, examples, address, website, internal category, parent company, spend category).
2.  Carefully review the search results in `<search_results>` (sources and summary).
3.  Synthesize all provided information to understand the vendor's **primary business activity**. Focus on what the company *does*, not just what it might resell.
4.  Compare this primary activity against the **Level 1** categories listed in `<category_options>`.
5.  Assign the **single most appropriate** Level 1 category ID and name.
6.  Provide a confidence score (0.0 to 1.0) based on the clarity, consistency, and relevance of the provided information.
7.  **CRITICAL:** If the provided information (vendor data + search results) is insufficient, contradictory, irrelevant, focuses only on products sold rather than the business activity, or does not allow for confident determination of the primary business activity *from the listed L1 categories*, **DO NOT GUESS**. Instead: Set `classification_not_possible` to `true`, `confidence` to `0.0`, provide a brief `classification_not_possible_reason`, and set `category_id`/`category_name` to "N/A".
8.  If classification *is* possible (`classification_not_possible: false`), ensure `confidence` > 0.0 and `category_id`/`category_name` are populated correctly from `<category_options>`.
9.  Provide brief optional `notes` explaining your reasoning, referencing specific details from `<vendor_data>` or `<search_results>`.
10. Ensure the `vendor_name` in the final JSON output matches the name in `<vendor_data>`.
11. Respond *only* with the valid JSON object as specified in `<output_format>`.
</instructions>

{vendor_data_xml}

{search_results_xml}

{category_options_xml}

{output_format_xml}
"""
    return prompt
</file>

<file path='app/tasks/classification_tasks.py'>
# <file path='app/tasks/classification_tasks.py'>
# app/tasks/classification_tasks.py
import os
import asyncio
import logging
from datetime import datetime, timezone # <<< Added timezone
from celery import shared_task
from sqlalchemy.orm import Session
from sqlalchemy.exc import SQLAlchemyError
from typing import Dict, Any, List, Optional # <<< ADDED List, Optional

from core.database import SessionLocal
from core.config import settings
from core.logging_config import get_logger
# Import context functions from the new module
from core.log_context import set_correlation_id, set_job_id, set_log_context, clear_all_context
# Import log helpers from utils
from utils.log_utils import LogTimer, log_duration

from models.job import Job, JobStatus, ProcessingStage, JobType # <<< ADDED JobType
from services.file_service import read_vendor_file, normalize_vendor_data, generate_output_file
from services.llm_service import LLMService
from services.search_service import SearchService
from utils.taxonomy_loader import load_taxonomy

# Import the refactored logic
from .classification_logic import process_vendors
# Import the schema for type hinting
from schemas.job import JobResultItem
# Import review schemas/logic if needed (likely handled by separate task)
from schemas.review import ReviewResultItem


# Configure logger
logger = get_logger("vendor_classification.tasks")
# --- ADDED: Log confirmation ---
logger.debug("Successfully imported Dict and Any from typing for classification tasks.")
# --- END ADDED ---


# --- UPDATED: Helper function to process results for DB storage ---
def _prepare_detailed_results_for_storage(
    results_dict: Dict[str, Dict],
    target_level: int # Keep target_level for reference if needed, but we store all levels now
) -> List[Dict[str, Any]]:
    """
    Processes the complex results dictionary (containing level1, level2... sub-dicts)
    into a flat list of dictionaries, where each dictionary represents a vendor
    and contains fields for all L1-L5 classifications, plus final status details.
    Matches the JobResultItem schema.
    THIS IS FOR **CLASSIFICATION** JOBS. Review jobs store results differently.
    """
    processed_list = []
    logger.info(f"Preparing detailed results for CLASSIFICATION job storage. Processing {len(results_dict)} vendors.")

    for vendor_name, vendor_results in results_dict.items():
        # Initialize the flat structure for this vendor
        flat_result: Dict[str, Any] = {
            "vendor_name": vendor_name,
            "level1_id": None, "level1_name": None,
            "level2_id": None, "level2_name": None,
            "level3_id": None, "level3_name": None,
            "level4_id": None, "level4_name": None,
            "level5_id": None, "level5_name": None,
            "final_confidence": None,
            "final_status": "Not Possible", # Default status
            "classification_source": "Initial", # Default source
            "classification_notes_or_reason": None,
            "achieved_level": 0 # Default achieved level
        }

        deepest_successful_level = 0
        final_level_data = None
        final_source = "Initial" # Track the source of the final decision point
        final_notes_or_reason = None

        # Iterate through levels 1 to 5 to populate the flat structure
        for level in range(1, 6):
            level_key = f"level{level}"
            level_data = vendor_results.get(level_key)

            if level_data and isinstance(level_data, dict):
                # Populate the corresponding fields in flat_result
                flat_result[f"level{level}_id"] = level_data.get("category_id")
                flat_result[f"level{level}_name"] = level_data.get("category_name")

                # Track the deepest successful classification
                if not level_data.get("classification_not_possible", True):
                    deepest_successful_level = level
                    final_level_data = level_data # Store data of the deepest successful level
                    # Update source based on the source recorded *at that level*
                    final_source = level_data.get("classification_source", final_source)
                    final_notes_or_reason = level_data.get("notes") # Get notes from successful level
                elif deepest_successful_level == 0: # If no level succeeded yet, track potential failure reasons/notes from L1
                    if level == 1:
                        final_notes_or_reason = level_data.get("classification_not_possible_reason") or level_data.get("notes")
                        # Update source based on L1 source if it exists
                        final_source = level_data.get("classification_source", final_source)

            # If a level wasn't processed (e.g., stopped early), its fields remain None

        # Determine final status, confidence, and notes based on the deepest successful level
        if final_level_data:
            flat_result["final_status"] = "Classified"
            flat_result["final_confidence"] = final_level_data.get("confidence")
            flat_result["achieved_level"] = deepest_successful_level
            flat_result["classification_notes_or_reason"] = final_notes_or_reason # Use notes from final level
        else:
            # No level was successfully classified
            flat_result["final_status"] = "Not Possible"
            flat_result["final_confidence"] = 0.0
            flat_result["achieved_level"] = 0
            # Use the reason/notes captured from L1 failure or search failure
            flat_result["classification_notes_or_reason"] = final_notes_or_reason

        # Set the final determined source
        flat_result["classification_source"] = final_source

        # Handle potential ERROR states explicitly (e.g., if L1 failed with ERROR)
        l1_data = vendor_results.get("level1")
        if l1_data and l1_data.get("category_id") == "ERROR":
            flat_result["final_status"] = "Error"
            flat_result["classification_notes_or_reason"] = l1_data.get("classification_not_possible_reason") or "Processing error occurred"
            # Override source if error occurred
            final_source = l1_data.get("classification_source", "Initial")
            flat_result["classification_source"] = final_source


        # Validate against Pydantic model (optional, but good practice)
        try:
            JobResultItem.model_validate(flat_result)
            processed_list.append(flat_result)
        except Exception as validation_err:
            logger.error(f"Validation failed for prepared result of vendor '{vendor_name}'",
                         exc_info=True, extra={"result_data": flat_result})
            # Optionally append a placeholder error entry or skip
            # For now, let's skip invalid entries
            continue

    logger.info(f"Finished preparing {len(processed_list)} detailed result items for CLASSIFICATION job storage.")
    return processed_list
# --- END UPDATED ---


@shared_task(bind=True)
# --- UPDATED: Added target_level parameter ---
def process_vendor_file(self, job_id: str, file_path: str, target_level: int):
# --- END UPDATED ---
    """
    Celery task entry point for processing a vendor file (CLASSIFICATION job type).
    Orchestrates the overall process by calling the main async helper.

    Args:
        job_id: Job ID
        file_path: Path to vendor file
        target_level: The desired maximum classification level (1-5)
    """
    task_id = self.request.id if self.request and self.request.id else "UnknownTaskID"
    logger.info(f"***** process_vendor_file TASK RECEIVED (CLASSIFICATION) *****",
                extra={
                    "celery_task_id": task_id,
                    "job_id_arg": job_id,
                    "file_path_arg": file_path,
                    "target_level_arg": target_level # Log received target level
                })

    set_correlation_id(job_id) # Set correlation ID early
    set_job_id(job_id)
    set_log_context({"target_level": target_level, "job_type": JobType.CLASSIFICATION.value}) # Add target level and type to context
    logger.info(f"Starting vendor file processing task (inside function)",
                extra={"job_id": job_id, "file_path": file_path, "target_level": target_level})

    # Validate target_level
    if not 1 <= target_level <= 5:
        logger.error(f"Invalid target_level received: {target_level}. Must be between 1 and 5.")
        # Fail the job immediately if level is invalid
        db_fail = SessionLocal()
        try:
            job_fail = db_fail.query(Job).filter(Job.id == job_id).first()
            if job_fail:
                job_fail.fail(f"Invalid target level specified: {target_level}. Must be 1-5.")
                db_fail.commit()
        except Exception as db_err:
            logger.error("Failed to mark job as failed due to invalid target level", exc_info=db_err)
            db_fail.rollback()
        finally:
            db_fail.close()
        clear_all_context() # Clear context before returning
        return # Stop task execution

    # Initialize loop within the task context
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    logger.debug(f"Created and set new asyncio event loop for job {job_id}")

    db = SessionLocal()
    job = None # Initialize job to None

    try:
        job = db.query(Job).filter(Job.id == job_id).first()
        if job:
            # Verify the target level matches the job record (optional sanity check)
            if job.target_level != target_level:
                logger.warning(f"Task received target_level {target_level} but job record has {job.target_level}. Using task value: {target_level}.")
                # Optionally update job record here if desired, or just proceed with task value

            # Ensure job type is CLASSIFICATION
            if job.job_type != JobType.CLASSIFICATION.value:
                 logger.error(f"process_vendor_file task called for a non-CLASSIFICATION job.", extra={"job_id": job_id, "job_type": job.job_type})
                 raise ValueError(f"Job {job_id} is not a CLASSIFICATION job.")


            set_log_context({
                "company_name": job.company_name,
                "creator": job.created_by,
                "file_name": job.input_file_name
                # target_level and job_type already set above
            })
            logger.info(f"Processing file for company",
                        extra={"company": job.company_name})
        else:
            logger.error("Job not found in database at start of task!", extra={"job_id": job_id})
            loop.close() # Close loop if job not found
            db.close() # Close db session
            clear_all_context() # Clear context before returning
            return # Exit task if job doesn't exist

        logger.info(f"About to run async processing for job {job_id}")
        with LogTimer(logger, "Complete file processing", level=logging.INFO, include_in_stats=True):
            # Run the async function within the loop created for this task
            # --- UPDATED: Pass target_level to async helper ---
            loop.run_until_complete(_process_vendor_file_async(job_id, file_path, db, target_level))
            # --- END UPDATED ---

        logger.info(f"Vendor file processing completed successfully (async part finished)")

    except Exception as e:
        logger.error(f"Error processing vendor file task (in main try block)", exc_info=True, extra={"job_id": job_id})
        try:
            # Re-query the job within this exception handler if it wasn't fetched initially or became None
            db_error_session = SessionLocal()
            try:
                job_in_error = db_error_session.query(Job).filter(Job.id == job_id).first()
                if job_in_error:
                    if job_in_error.status != JobStatus.COMPLETED.value:
                        err_msg = f"Task failed: {type(e).__name__}: {str(e)}"
                        job_in_error.fail(err_msg[:2000]) # Limit error message length
                        db_error_session.commit()
                        logger.info(f"Job status updated to failed due to task error",
                                    extra={"error": str(e)})
                    else:
                        logger.warning(f"Task error occurred after job was marked completed, status not changed.",
                                        extra={"error": str(e)})
                else:
                    logger.error("Job not found when trying to mark as failed.", extra={"job_id": job_id})
            except Exception as db_error:
                logger.error(f"Error updating job status during task failure handling", exc_info=True,
                            extra={"original_error": str(e), "db_error": str(db_error)})
                db_error_session.rollback()
            finally:
                    db_error_session.close()
        except Exception as final_db_error:
                logger.critical(f"CRITICAL: Failed even to handle database update in task error handler.", exc_info=final_db_error)

    finally:
        if db: # Close the main session used by the async function
            db.close()
            logger.debug(f"Main database session closed for task.")
        if loop and not loop.is_closed():
            loop.close()
            logger.debug(f"Event loop closed for task.")
        clear_all_context()
        logger.info(f"***** process_vendor_file TASK FINISHED (CLASSIFICATION) *****", extra={"job_id": job_id})


# --- UPDATED: Added target_level parameter ---
async def _process_vendor_file_async(job_id: str, file_path: str, db: Session, target_level: int):
# --- END UPDATED ---
    """
    Asynchronous part of the vendor file processing (CLASSIFICATION job type).
    Sets up services, initializes stats, calls the core processing logic,
    and handles final result generation and job status updates.
    """
    logger.info(f"[_process_vendor_file_async] Starting async processing for job {job_id} to target level {target_level}")

    llm_service = LLMService()
    search_service = SearchService()

    job = db.query(Job).filter(Job.id == job_id).first()

    if not job:
        logger.error(f"[_process_vendor_file_async] Job not found in database", extra={"job_id": job_id})
        return

    # --- Initialize stats (Updated for L5) ---
    start_time = datetime.now(timezone.utc) # Use timezone aware now
    # --- MODIFIED: Type hints added ---
    stats: Dict[str, Any] = {
        "job_id": job.id,
        "company_name": job.company_name,
        "target_level": target_level, # Store target level in stats
        "start_time": start_time.isoformat(),
        "end_time": None,
        "processing_duration_seconds": None,
        "total_vendors": 0,
        "unique_vendors": 0,
        "successfully_classified_l4": 0, # Keep L4 count for reference
        "successfully_classified_l5": 0, # Count successful classifications reaching L5 (if target >= 5)
        "classification_not_possible_initial": 0, # Count initially unclassifiable before search
        "invalid_category_errors": 0, # Track validation errors
        "search_attempts": 0, # Count how many vendors needed search
        "search_successful_classifications_l1": 0, # Count successful L1 classifications *after* search
        "search_successful_classifications_l5": 0, # Count successful L5 classifications *after* search (if target >= 5)
        "api_usage": {
            "openrouter_calls": 0,
            "openrouter_prompt_tokens": 0,
            "openrouter_completion_tokens": 0,
            "openrouter_total_tokens": 0,
            "tavily_search_calls": 0,
            "cost_estimate_usd": 0.0
        }
    }
    # --- END MODIFIED ---
    # --- End Initialize stats ---

    # --- Initialize results dictionary ---
    # This will be populated by process_vendors
    results_dict: Dict[str, Dict] = {}
    # --- UPDATED: This will hold the processed results for DB storage (List[JobResultItem]) ---
    detailed_results_for_db: Optional[List[Dict[str, Any]]] = None
    # --- END UPDATED ---
    # --- End Initialize results dictionary ---

    try:
        job.status = JobStatus.PROCESSING.value
        job.current_stage = ProcessingStage.INGESTION.value
        job.progress = 0.05
        logger.info(f"[_process_vendor_file_async] Committing initial status update: {job.status}, {job.current_stage}, {job.progress}")
        db.commit()
        logger.info(f"Job status updated",
                    extra={"status": job.status, "stage": job.current_stage, "progress": job.progress})

        logger.info(f"Reading vendor file")
        with log_duration(logger, "Reading vendor file"):
            vendors_data = read_vendor_file(file_path)
        logger.info(f"Vendor file read successfully",
                    extra={"vendor_count": len(vendors_data)})

        job.current_stage = ProcessingStage.NORMALIZATION.value
        job.progress = 0.1
        logger.info(f"[_process_vendor_file_async] Committing status update: {job.status}, {job.current_stage}, {job.progress}")
        db.commit()
        logger.info(f"Job status updated",
                    extra={"stage": job.current_stage, "progress": job.progress})

        logger.info(f"Normalizing vendor data")
        with log_duration(logger, "Normalizing vendor data"):
            normalized_vendors_data = normalize_vendor_data(vendors_data)
        logger.info(f"Vendor data normalized",
                    extra={"normalized_count": len(normalized_vendors_data)})

        logger.info(f"Identifying unique vendors")
        # --- MODIFIED: Type hints added ---
        unique_vendors_map: Dict[str, Dict[str, Any]] = {}
        # --- END MODIFIED ---
        for entry in normalized_vendors_data:
            name = entry.get('vendor_name')
            if name and name not in unique_vendors_map:
                unique_vendors_map[name] = entry
        logger.info(f"Unique vendors identified",
                    extra={"unique_count": len(unique_vendors_map)})

        stats["total_vendors"] = len(normalized_vendors_data)
        stats["unique_vendors"] = len(unique_vendors_map)

        logger.info(f"Loading taxonomy")
        with log_duration(logger, "Loading taxonomy"):
            taxonomy = load_taxonomy() # Can raise exceptions
        logger.info(f"Taxonomy loaded",
                    extra={"taxonomy_version": taxonomy.version})

        # Initialize the results dict structure before passing to process_vendors
        results_dict = {vendor_name: {} for vendor_name in unique_vendors_map.keys()}

        logger.info(f"Starting vendor classification process by calling classification_logic.process_vendors up to Level {target_level}")
        # --- Call the refactored logic, passing target_level ---
        # process_vendors will populate the results_dict in place
        await process_vendors(
            unique_vendors_map=unique_vendors_map,
            taxonomy=taxonomy,
            results=results_dict, # Pass the dict to be populated
            stats=stats,
            job=job,
            db=db,
            llm_service=llm_service,
            search_service=search_service,
            target_level=target_level # Pass the target level
        )
        # --- End call to refactored logic ---
        logger.info(f"Vendor classification process completed (returned from classification_logic.process_vendors)")

        logger.info("Starting result generation phase.")

        job.current_stage = ProcessingStage.RESULT_GENERATION.value
        job.progress = 0.98 # Progress after all classification/search
        logger.info(f"[_process_vendor_file_async] Committing status update before result generation: {job.status}, {job.current_stage}, {job.progress}")
        db.commit()
        logger.info(f"Job status updated",
                    extra={"stage": job.current_stage, "progress": job.progress})

        output_file_name = None # Initialize

        # --- Process results for DB Storage ---
        try:
            logger.info("Processing detailed results for database storage.")
            with log_duration(logger, "Processing detailed results"):
                 # --- UPDATED: Call the preparation function ---
                 detailed_results_for_db = _prepare_detailed_results_for_storage(results_dict, target_level)
                 # --- END UPDATED ---
            logger.info(f"Processed {len(detailed_results_for_db)} items for detailed results storage.")
        except Exception as proc_err:
            logger.error("Failed during detailed results processing for DB", exc_info=True)
            # Continue to generate Excel, but log the error. The job won't store detailed results.
            detailed_results_for_db = None # Ensure it's None if processing failed
        # --- End Process results for DB Storage ---

        # --- Generate Excel File ---
        if detailed_results_for_db is not None: # Only generate if DB results were processed successfully
            try:
                    logger.info(f"Generating output file")
                    with log_duration(logger, "Generating output file"):
                        # --- UPDATED: Call generate_output_file with List[JobResultItem] ---
                        # Pass original vendor data as well for optional columns
                        output_file_name = generate_output_file(
                            job_id=job_id,
                            detailed_results=[JobResultItem.model_validate(item) for item in detailed_results_for_db],
                            # original_vendor_data=normalized_vendors_data # Pass original data if needed by generate_output_file
                        )
                        # --- END UPDATED ---
                    logger.info(f"Output file generated", extra={"output_file": output_file_name})
            except Exception as gen_err:
                    logger.error("Failed during output file generation", exc_info=True)
                    # Don't fail the whole job, just log and proceed without the file
                    output_file_name = None # Ensure filename is None if generation failed
                    # Optionally add a note to the job's error message or stats?
                    # For now, just log it. The job can still complete with DB results.
        else:
            logger.warning("Skipping output file generation because detailed results processing failed.")
            output_file_name = None
        # --- End Generate Excel File ---

        # --- Finalize stats ---
        end_time = datetime.now(timezone.utc) # Use timezone aware now
        processing_duration = (end_time - datetime.fromisoformat(stats["start_time"])).total_seconds()
        stats["end_time"] = end_time.isoformat()
        stats["processing_duration_seconds"] = round(processing_duration, 2)
        # Cost calculation remains the same
        cost_input_per_1k = 0.0005
        cost_output_per_1k = 0.0015
        estimated_cost = (stats["api_usage"]["openrouter_prompt_tokens"] / 1000) * cost_input_per_1k + \
                            (stats["api_usage"]["openrouter_completion_tokens"] / 1000) * cost_output_per_1k
        estimated_cost += (stats["api_usage"]["tavily_search_calls"] / 1000) * 4.0
        stats["api_usage"]["cost_estimate_usd"] = round(estimated_cost, 4)
        # --- End Finalize stats ---

        # --- Final Commit Block ---
        try:
            logger.info("Attempting final job completion update in database.")
            # --- UPDATED: Pass the processed detailed_results_for_db to the complete method ---
            job.complete(output_file_name, stats, detailed_results_for_db)
            # --- END UPDATED ---
            job.progress = 1.0 # Ensure progress is 1.0 on completion
            logger.info(f"[_process_vendor_file_async] Committing final job completion status.")
            db.commit()
            logger.info(f"Job completed successfully",
                        extra={
                            "processing_duration": processing_duration,
                            "output_file": output_file_name,
                            "target_level": target_level,
                            # --- UPDATED: Log if detailed results were stored ---
                            "detailed_results_stored": bool(detailed_results_for_db),
                            "detailed_results_count": len(detailed_results_for_db) if detailed_results_for_db else 0,
                            # --- END UPDATED ---
                            "openrouter_calls": stats["api_usage"]["openrouter_calls"],
                            "tokens_used": stats["api_usage"]["openrouter_total_tokens"],
                            "tavily_calls": stats["api_usage"]["tavily_search_calls"],
                            "estimated_cost": stats["api_usage"]["cost_estimate_usd"],
                            "invalid_category_errors": stats.get("invalid_category_errors", 0),
                            "successfully_classified_l5_total": stats.get("successfully_classified_l5", 0)
                        })
        except Exception as final_commit_err:
            logger.error("CRITICAL: Failed to commit final job completion status!", exc_info=True)
            db.rollback()
            try:
                # Re-fetch job in new session to attempt marking as failed
                db_fail_final = SessionLocal()
                job_fail_final = db_fail_final.query(Job).filter(Job.id == job_id).first()
                if job_fail_final:
                    err_msg = f"Failed during final commit: {type(final_commit_err).__name__}: {str(final_commit_err)}"
                    job_fail_final.fail(err_msg[:2000])
                    db_fail_final.commit()
                else:
                    logger.error("Job not found when trying to mark as failed after final commit error.")
                db_fail_final.close()
            except Exception as fail_err:
                logger.error("CRITICAL: Also failed to mark job as failed after final commit error.", exc_info=fail_err)
                # db.rollback() # Already rolled back original session
        # --- End Final Commit Block ---

    except (ValueError, FileNotFoundError, IOError) as file_err:
        logger.error(f"[_process_vendor_file_async] File reading or writing error", exc_info=True,
                    extra={"error": str(file_err)})
        if job:
            err_msg = f"File processing error: {type(file_err).__name__}: {str(file_err)}"
            job.fail(err_msg[:2000])
            db.commit()
        else:
            logger.error("Job object was None during file error handling.")
    except SQLAlchemyError as db_err:
        logger.error(f"[_process_vendor_file_async] Database error during processing", exc_info=True,
                    extra={"error": str(db_err)})
        db.rollback() # Rollback on DB error
        if job:
            # Re-fetch job in new session to attempt marking as failed
            db_fail_db = SessionLocal()
            job_fail_db = db_fail_db.query(Job).filter(Job.id == job_id).first()
            if job_fail_db and job_fail_db.status not in [JobStatus.FAILED.value, JobStatus.COMPLETED.value]:
                    err_msg = f"Database error: {type(db_err).__name__}: {str(db_err)}"
                    job_fail_db.fail(err_msg[:2000])
                    db_fail_db.commit()
            elif job_fail_db:
                    logger.warning(f"Database error occurred but job status was already {job_fail_db.status}. Error: {db_err}")
            else:
                logger.error("Job not found when trying to mark as failed after database error.")
            db_fail_db.close()
        else:
            logger.error("Job object was None during database error handling.")
    except Exception as async_err:
        logger.error(f"[_process_vendor_file_async] Unexpected error during async processing", exc_info=True,
                    extra={"error": str(async_err)})
        db.rollback() # Rollback on unexpected error
        if job:
            # Re-fetch job in new session to attempt marking as failed
            db_fail_unexpected = SessionLocal()
            job_fail_unexpected = db_fail_unexpected.query(Job).filter(Job.id == job_id).first()
            if job_fail_unexpected and job_fail_unexpected.status not in [JobStatus.FAILED.value, JobStatus.COMPLETED.value]:
                err_msg = f"Unexpected error: {type(async_err).__name__}: {str(async_err)}"
                job_fail_unexpected.fail(err_msg[:2000])
                db_fail_unexpected.commit()
            elif job_fail_unexpected:
                logger.warning(f"Unexpected error occurred but job status was already {job_fail_unexpected.status}. Error: {async_err}")
            else:
                logger.error("Job not found when trying to mark as failed after unexpected error.")
            db_fail_unexpected.close()
        else:
            logger.error("Job object was None during unexpected error handling.")
    finally:
        logger.info(f"[_process_vendor_file_async] Finished async processing for job {job_id}")


# --- ADDED: Reclassification Task ---
@shared_task(bind=True)
def reclassify_flagged_vendors_task(self, review_job_id: str):
    """
    Celery task entry point for re-classifying flagged vendors (REVIEW job type).
    Orchestrates the reclassification process.

    Args:
        review_job_id: The ID of the REVIEW job.
    """
    task_id = self.request.id if self.request and self.request.id else "UnknownTaskID"
    logger.info(f"***** reclassify_flagged_vendors_task TASK RECEIVED *****",
                extra={"celery_task_id": task_id, "review_job_id": review_job_id})

    set_correlation_id(review_job_id) # Use review job ID as correlation ID
    set_job_id(review_job_id)
    set_log_context({"job_type": JobType.REVIEW.value})
    logger.info(f"Starting reclassification task", extra={"review_job_id": review_job_id})

    # Initialize loop within the task context
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    logger.debug(f"Created and set new asyncio event loop for review job {review_job_id}")

    db = SessionLocal()
    review_job = None

    try:
        review_job = db.query(Job).filter(Job.id == review_job_id).first()
        if not review_job:
            logger.error("Review job not found in database at start of task!", extra={"review_job_id": review_job_id})
            raise ValueError("Review job not found.")

        # Ensure job type is REVIEW
        if review_job.job_type != JobType.REVIEW.value:
            logger.error(f"reclassify_flagged_vendors_task called for a non-REVIEW job.", extra={"review_job_id": review_job_id, "job_type": review_job.job_type})
            raise ValueError(f"Job {review_job_id} is not a REVIEW job.")

        set_log_context({
            "company_name": review_job.company_name,
            "creator": review_job.created_by,
            "parent_job_id": review_job.parent_job_id
        })
        logger.info(f"Processing review for company", extra={"company": review_job.company_name})

        # --- Call the async reclassification logic ---
        logger.info(f"About to run async reclassification processing for review job {review_job_id}")
        with LogTimer(logger, "Complete reclassification processing", level=logging.INFO, include_in_stats=True):
            loop.run_until_complete(_process_reclassification_async(review_job_id, db))

        logger.info(f"Reclassification processing completed successfully (async part finished)")

    except Exception as e:
        logger.error(f"Error processing reclassification task", exc_info=True, extra={"review_job_id": review_job_id})
        try:
            # Re-query the job within this exception handler
            db_error_session = SessionLocal()
            try:
                job_in_error = db_error_session.query(Job).filter(Job.id == review_job_id).first()
                if job_in_error:
                    if job_in_error.status != JobStatus.COMPLETED.value:
                        err_msg = f"Reclassification task failed: {type(e).__name__}: {str(e)}"
                        job_in_error.fail(err_msg[:2000])
                        db_error_session.commit()
                        logger.info(f"Review job status updated to failed due to task error", extra={"error": str(e)})
                    else:
                        logger.warning(f"Task error occurred after review job was marked completed, status not changed.", extra={"error": str(e)})
                else:
                    logger.error("Review job not found when trying to mark as failed.", extra={"review_job_id": review_job_id})
            except Exception as db_error:
                logger.error(f"Error updating review job status during task failure handling", exc_info=True,
                            extra={"original_error": str(e), "db_error": str(db_error)})
                db_error_session.rollback()
            finally:
                db_error_session.close()
        except Exception as final_db_error:
            logger.critical(f"CRITICAL: Failed even to handle database update in reclassification task error handler.", exc_info=final_db_error)

    finally:
        if db:
            db.close()
            logger.debug(f"Main database session closed for reclassification task.")
        if loop and not loop.is_closed():
            loop.close()
            logger.debug(f"Event loop closed for reclassification task.")
        clear_all_context()
        logger.info(f"***** reclassify_flagged_vendors_task TASK FINISHED *****", extra={"review_job_id": review_job_id})


async def _process_reclassification_async(review_job_id: str, db: Session):
    """
    Asynchronous part of the reclassification task.
    Sets up services, calls the core reclassification logic, stores results.
    """
    logger.info(f"[_process_reclassification_async] Starting async processing for review job {review_job_id}")

    llm_service = LLMService()
    # search_service is not needed for reclassification

    review_job = db.query(Job).filter(Job.id == review_job_id).first()
    if not review_job:
        logger.error(f"[_process_reclassification_async] Review job not found in database", extra={"review_job_id": review_job_id})
        return

    # Import the core logic function here to avoid circular imports at module level
    from .reclassification_logic import process_reclassification

    review_results_list = None
    final_stats = {}
    logic_error_message = None # Variable to store error message from logic

    try:
        review_job.status = JobStatus.PROCESSING.value
        review_job.current_stage = ProcessingStage.RECLASSIFICATION.value
        review_job.progress = 0.1 # Start progress
        logger.info(f"[_process_reclassification_async] Committing initial status update: {review_job.status}, {review_job.current_stage}, {review_job.progress}")
        db.commit()
        logger.info(f"Review job status updated",
                    extra={"status": review_job.status, "stage": review_job.current_stage, "progress": review_job.progress})

        # --- Call the reclassification logic ---
        # This function will handle fetching parent data, calling LLM, etc.
        review_results_list, final_stats = await process_reclassification(
            review_job=review_job,
            db=db,
            llm_service=llm_service
        )
        # --- End call ---

        # --- Check if the logic function reported an error in stats ---
        logic_error_message = final_stats.get("error_message")
        if logic_error_message:
            logger.error(f"Reclassification logic reported an error: {logic_error_message}")
            # Raise an exception to trigger the failure handling block below
            raise Exception(logic_error_message)
        # --- End Check ---

        logger.info(f"Reclassification logic completed. Processed {final_stats.get('total_items_processed', 0)} items.")
        review_job.progress = 0.95 # Mark logic as complete

        # --- Final Commit Block (Only if no error from logic) ---
        try:
            logger.info("Attempting final review job completion update in database.")
            # Pass None for output_file_name as review jobs don't generate one
            # Pass the potentially modified final_stats (e.g., with duration)
            review_job.complete(output_file_name=None, stats=final_stats, detailed_results=review_results_list)
            review_job.progress = 1.0
            logger.info(f"[_process_reclassification_async] Committing final review job completion status.")
            db.commit()
            logger.info(f"Review job completed successfully",
                        extra={
                            "processing_duration": final_stats.get("processing_duration_seconds"),
                            "items_processed": final_stats.get("total_items_processed"),
                            "successful": final_stats.get("successful_reclassifications"),
                            "failed": final_stats.get("failed_reclassifications"),
                            "openrouter_calls": final_stats.get("api_usage", {}).get("openrouter_calls"),
                            "tokens_used": final_stats.get("api_usage", {}).get("openrouter_total_tokens"),
                            "estimated_cost": final_stats.get("api_usage", {}).get("cost_estimate_usd")
                        })
        except Exception as final_commit_err:
            logger.error("CRITICAL: Failed to commit final review job completion status!", exc_info=True)
            db.rollback()
            # Attempt to mark as failed (similar logic as in main task handler)
            try:
                db_fail_final = SessionLocal()
                job_fail_final = db_fail_final.query(Job).filter(Job.id == review_job_id).first()
                if job_fail_final:
                    err_msg = f"Failed during final commit: {type(final_commit_err).__name__}: {str(final_commit_err)}"
                    job_fail_final.fail(err_msg[:2000])
                    db_fail_final.commit()
                db_fail_final.close()
            except Exception as fail_err:
                logger.error("CRITICAL: Also failed to mark review job as failed after final commit error.", exc_info=fail_err)
        # --- End Final Commit Block ---

    # --- UPDATED: Catch specific errors and the generic Exception (including the one raised above) ---
    except (ValueError, FileNotFoundError) as logic_err:
        logger.error(f"[_process_reclassification_async] Data or File error during reclassification logic", exc_info=True,
                    extra={"error": str(logic_err)})
        if review_job:
            err_msg = f"Reclassification data error: {type(logic_err).__name__}: {str(logic_err)}"
            review_job.fail(err_msg[:2000])
            db.commit()
    except SQLAlchemyError as db_err:
         logger.error(f"[_process_reclassification_async] Database error during reclassification processing", exc_info=True,
                     extra={"error": str(db_err)})
         db.rollback()
         # Attempt to mark as failed (similar logic as in main task handler)
         try:
            db_fail_db = SessionLocal()
            job_fail_db = db_fail_db.query(Job).filter(Job.id == review_job_id).first()
            if job_fail_db and job_fail_db.status not in [JobStatus.FAILED.value, JobStatus.COMPLETED.value]:
                 err_msg = f"Database error: {type(db_err).__name__}: {str(db_err)}"
                 job_fail_db.fail(err_msg[:2000])
                 db_fail_db.commit()
            db_fail_db.close()
         except Exception as fail_err:
            logger.error("CRITICAL: Also failed to mark review job as failed after database error.", exc_info=fail_err)

    except Exception as async_err:
        # This catches errors from process_reclassification or other unexpected errors
        logger.error(f"[_process_reclassification_async] Unexpected error during async reclassification processing", exc_info=True,
                    extra={"error": str(async_err)})
        db.rollback()
        # Attempt to mark as failed
        try:
            db_fail_unexpected = SessionLocal()
            job_fail_unexpected = db_fail_unexpected.query(Job).filter(Job.id == review_job_id).first()
            if job_fail_unexpected and job_fail_unexpected.status not in [JobStatus.FAILED.value, JobStatus.COMPLETED.value]:
                # Use the error message captured from logic_error_message if available, otherwise use the current exception
                err_to_report = logic_error_message if logic_error_message else f"Unexpected error: {type(async_err).__name__}: {str(async_err)}"
                job_fail_unexpected.fail(err_to_report[:2000])
                # Add the error message to stats as well before committing failure
                if job_fail_unexpected.stats:
                     job_fail_unexpected.stats['error_message'] = err_to_report[:2000]
                else:
                     job_fail_unexpected.stats = {'error_message': err_to_report[:2000]}
                db_fail_unexpected.commit()
            db_fail_unexpected.close()
        except Exception as fail_err:
            logger.error("CRITICAL: Also failed to mark review job as failed after unexpected error.", exc_info=fail_err)
    # --- END UPDATED ---
    finally:
        logger.info(f"[_process_reclassification_async] Finished async processing for review job {review_job_id}")

# --- END ADDED ---
</file>

<file path='app/tasks/reclassification_logic.py'>
# app/tasks/reclassification_logic.py
import os # Keep the import
import asyncio
import logging
from datetime import datetime, timezone # <<< Added timezone
from sqlalchemy.orm import Session
from typing import Dict, Any, List, Tuple, Optional

from core.database import SessionLocal # Assuming SessionLocal might be needed
from core.logging_config import get_logger
from core.log_context import set_log_context, clear_log_context # Assuming context might be used
from utils.log_utils import LogTimer, log_duration # Assuming logging utils might be used
from utils.taxonomy_loader import load_taxonomy, Taxonomy # Assuming taxonomy is needed
from models.job import Job, JobStatus, ProcessingStage, JobType # Assuming Job model is needed
from services.llm_service import LLMService # Assuming LLM service is needed
from schemas.review import ReclassifyRequestItem, ReviewResultItem # Assuming review schemas are needed
from schemas.job import JobResultItem # Assuming job result schema is needed for structure
from pydantic import ValidationError # Import ValidationError for specific catching

# Import classification prompts if needed for reclassification
from .reclassification_prompts import generate_reclassification_prompt # Example: Assuming a specific prompt exists

logger = get_logger("vendor_classification.reclassification_logic")

async def process_reclassification(
    review_job: Job,
    db: Session,
    llm_service: LLMService
) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
    """
    Processes the reclassification request based on the review job details.
    Fetches original results, applies hints using LLM, and generates new results.
    Returns the results list (empty if major error) and the final stats dict.
    The stats dict will contain an 'error_message' key if a critical error occurred.
    """
    logger.info(f"Starting reclassification logic for review job {review_job.id}")
    set_log_context({"review_job_id": review_job.id, "parent_job_id": review_job.parent_job_id})

    start_time = datetime.now(timezone.utc) # Use timezone aware now
    # Initialize stats structure similar to classification, but focused on review
    final_stats: Dict[str, Any] = {
        "job_id": review_job.id,
        "parent_job_id": review_job.parent_job_id,
        "company_name": review_job.company_name,
        "target_level": review_job.target_level,
        "start_time": start_time.isoformat(),
        "end_time": None,
        "processing_duration_seconds": None,
        "total_items_processed": 0,
        "successful_reclassifications": 0,
        "failed_reclassifications": 0,
        "api_usage": {
            "openrouter_calls": 0,
            "openrouter_prompt_tokens": 0,
            "openrouter_completion_tokens": 0,
            "openrouter_total_tokens": 0,
            "tavily_search_calls": 0, # Should remain 0
            "cost_estimate_usd": 0.0
        },
        "error_message": None # Initialize error message field
    }
    review_results_list: List[Dict[str, Any]] = [] # Holds ReviewResultItem dicts

    try:
        # 1. Validate Input
        if not review_job or not review_job.parent_job_id or not review_job.stats or 'reclassify_input' not in review_job.stats:
            err_msg = "Review job is missing parent job ID or input hints."
            logger.error(err_msg, extra={"job_stats": review_job.stats if review_job else None})
            final_stats["error_message"] = err_msg
            return [], final_stats # Return empty list and stats with error

        # --- FIX: Handle potential non-list or invalid items in reclassify_input ---
        input_items = review_job.stats['reclassify_input']
        items_to_reclassify: List[ReclassifyRequestItem] = []
        if isinstance(input_items, list):
            for item in input_items:
                try:
                    # Validate each item conforms to the Pydantic model
                    items_to_reclassify.append(ReclassifyRequestItem.model_validate(item))
                except ValidationError as item_validation_err: # Catch specific validation error
                    logger.warning(f"Skipping invalid item in reclassify_input: {item}. Error: {item_validation_err}", exc_info=False)
        else:
            err_msg = f"reclassify_input in job stats is not a list: {type(input_items)}"
            logger.error(err_msg, extra={"job_id": review_job.id})
            final_stats["error_message"] = err_msg
            return [], final_stats # Return empty list and stats with error
        # --- END FIX ---

        final_stats["total_items_processed"] = len(items_to_reclassify)
        if not items_to_reclassify:
             logger.warning("No valid items found in reclassify_input stats.")
             # Complete the job successfully but with 0 items processed
             end_time = datetime.now(timezone.utc) # Use timezone aware now
             final_stats["end_time"] = end_time.isoformat()
             final_stats["processing_duration_seconds"] = (end_time - start_time).total_seconds()
             return [], final_stats # Return empty results and stats

        logger.info(f"Found {len(items_to_reclassify)} items to reclassify.")

        # 2. Fetch Parent Job's Detailed Results
        # Use a separate session or ensure the passed `db` session is robust
        parent_job = db.query(Job).filter(Job.id == review_job.parent_job_id).first()
        if not parent_job:
             err_msg = f"Parent job {review_job.parent_job_id} not found."
             logger.error(err_msg)
             final_stats["error_message"] = err_msg
             return [], final_stats
        if not parent_job.detailed_results:
             err_msg = f"Parent job {review_job.parent_job_id} has no detailed results."
             logger.error(err_msg)
             final_stats["error_message"] = err_msg
             return [], final_stats

        original_results_map: Dict[str, JobResultItem] = {}
        try:
            for item_dict in parent_job.detailed_results:
                 # Validate each item conforms to JobResultItem before adding
                 validated_item = JobResultItem.model_validate(item_dict)
                 original_results_map[validated_item.vendor_name] = validated_item
        except ValidationError as validation_err: # Catch specific validation error
             err_msg = "Failed to parse original results from parent job."
             logger.error(f"{err_msg} Error: {validation_err}", exc_info=True)
             final_stats["error_message"] = f"{err_msg} Details: {validation_err}"
             return [], final_stats

        logger.info(f"Loaded {len(original_results_map)} original results from parent job.")

        # 3. Load Taxonomy
        taxonomy = load_taxonomy()

        # 4. Iterate and Reclassify each item
        update_interval = max(1, len(items_to_reclassify) // 10)
        processed_count = 0

        # Prepare batch for LLM if applicable (might call LLM per item or in batches)
        # For simplicity, let's assume one call per item for now
        for item_data in items_to_reclassify:
            vendor_name = item_data.vendor_name
            hint = item_data.hint
            logger.info(f"Reclassifying vendor: '{vendor_name}' with hint: '{hint}'")
            set_log_context({"current_vendor": vendor_name}) # Add vendor to context

            original_result_model = original_results_map.get(vendor_name)

            # --- MODIFIED: Handle missing original result ---
            if not original_result_model:
                logger.warning(f"Vendor '{vendor_name}' from review request not found in parent job results. Skipping.")
                final_stats["failed_reclassifications"] += 1
                # Create a failure entry for this item, ensuring it matches ReviewResultItem structure
                failed_new_result = JobResultItem( # Use JobResultItem for structure consistency
                        vendor_name=vendor_name, level1_id="ERROR", level1_name="ERROR",
                        level2_id=None, level2_name=None, level3_id=None, level3_name=None,
                        level4_id=None, level4_name=None, level5_id=None, level5_name=None,
                        final_confidence=0.0, final_status="Error", classification_source="Review",
                        classification_notes_or_reason="Original result not found in parent job",
                        achieved_level=0
                    )
                # Create a minimal placeholder for the original result if it's missing
                minimal_original = JobResultItem(vendor_name=vendor_name, final_status="Error", classification_notes_or_reason="Original result missing")
                failed_result_item = ReviewResultItem(
                    vendor_name=vendor_name, hint=hint,
                    original_result=minimal_original.model_dump(), # Store dict
                    new_result=failed_new_result.model_dump() # Store dict
                )
                review_results_list.append(failed_result_item.model_dump())
                clear_log_context(["current_vendor"])
                continue
            # --- END MODIFIED ---

            # --- Actual Reclassification LLM Call ---
            new_result_model = None
            try:
                # Fetch original vendor data (assuming it's stored appropriately or derivable)
                # For this example, let's assume original data might be part of the original_result_model
                # or needs fetching separately. We'll use a placeholder if not readily available.
                # A better approach would be to ensure the parent job stores original vendor input data.
                original_vendor_input_data = original_result_model.model_dump() # Use the stored result as a proxy for now
                original_vendor_input_data['vendor_name'] = vendor_name # Ensure name is correct

                # Generate the specific prompt for reclassification
                prompt = generate_reclassification_prompt(
                    original_vendor_data=original_vendor_input_data, # Pass original data
                    user_hint=hint,
                    original_classification=original_result_model.model_dump(), # Pass previous result dict
                    taxonomy=taxonomy, # Pass the whole taxonomy object
                    target_level=review_job.target_level, # Pass the target level for reclassification
                    attempt_id=f"{review_job.id}-{vendor_name}" # Create a unique ID for this attempt
                )

                logger.debug(f"Generated reclassification prompt for '{vendor_name}'") # Prompt content logged by LLM service now

                # --- UPDATED: Call the new LLM service method ---
                # Pass the nested api_usage dict directly for updates
                parsed_llm_output = await llm_service.call_llm_with_prompt(
                    prompt=prompt,
                    stats_dict=final_stats["api_usage"], # Pass the nested dict
                    job_id=review_job.id, # Pass review job ID for logging/cache key
                    max_tokens=1024 # Adjust if needed for reclassification output size
                )
                # --- END UPDATED ---

                logger.debug(f"Parsed LLM response dictionary for '{vendor_name}': {parsed_llm_output}")

                # Extract the classification result for this vendor
                llm_output_data = None # Initialize
                if parsed_llm_output and isinstance(parsed_llm_output, dict):
                    # Check if the response has the expected 'classifications' list structure
                    if "classifications" in parsed_llm_output and isinstance(parsed_llm_output["classifications"], list) and len(parsed_llm_output["classifications"]) > 0:
                        llm_output_data = parsed_llm_output["classifications"][0]
                        logger.debug(f"Extracted classification data from 'classifications' list for '{vendor_name}': {llm_output_data}")
                    # Fallback: Check if the root object itself looks like the classification structure
                    elif "vendor_name" in parsed_llm_output and "level1" in parsed_llm_output:
                         llm_output_data = parsed_llm_output
                         logger.debug(f"Using root LLM response object as classification data for '{vendor_name}': {llm_output_data}")
                    else:
                        logger.warning(f"Parsed LLM output for '{vendor_name}' does not match expected structures ('classifications' list or direct result). Output: {parsed_llm_output}")
                else:
                     logger.warning(f"Failed to get valid dictionary from LLM response for '{vendor_name}'. Response: {parsed_llm_output}")


                # --- More robust check for L1 data from parsed output ---
                l1_data = llm_output_data.get("level1") if llm_output_data else None
                l1_category_id = l1_data.get("category_id") if l1_data else None
                l1_category_name = l1_data.get("category_name") if l1_data else None
                classification_not_possible = l1_data.get("classification_not_possible", True) if l1_data else True

                # Check if we got valid L1 classification data
                if l1_data and l1_category_id and l1_category_name and l1_category_id not in ["ERROR", "N/A"] and not classification_not_possible:
                     # --- Recursive Classification based on Hint ---
                     achieved_level = 0
                     final_confidence = 0.0
                     final_notes = None
                     final_status = "Not Possible" # Default

                     new_result_data = {
                         "vendor_name": vendor_name,
                         "level1_id": None, "level1_name": None,
                         "level2_id": None, "level2_name": None,
                         "level3_id": None, "level3_name": None,
                         "level4_id": None, "level4_name": None,
                         "level5_id": None, "level5_name": None,
                         "final_confidence": 0.0,
                         "final_status": "Not Possible",
                         "classification_source": "Review", # Mark as reviewed
                         "classification_notes_or_reason": None,
                         "achieved_level": 0
                     }

                     # Populate levels from LLM output
                     for level in range(1, review_job.target_level + 1):
                         level_key = f"level{level}"
                         level_data = llm_output_data.get(level_key)
                         if level_data and isinstance(level_data, dict):
                             cat_id = level_data.get("category_id")
                             cat_name = level_data.get("category_name")
                             level_not_possible = level_data.get("classification_not_possible", True)

                             if cat_id and cat_name and cat_id not in ["N/A", "ERROR"] and not level_not_possible:
                                 new_result_data[f"level{level}_id"] = cat_id
                                 new_result_data[f"level{level}_name"] = cat_name
                                 achieved_level = level
                                 final_confidence = level_data.get("confidence", 0.0)
                                 final_notes = level_data.get("notes") # Store notes from the deepest successful level
                                 final_status = "Classified"
                             else:
                                 # Stop populating further levels if this one failed or wasn't possible
                                 if achieved_level == 0 and level == 1: # Capture reason from L1 failure
                                     final_notes = level_data.get("classification_not_possible_reason") or level_data.get("notes")
                                 break # Stop processing levels for this vendor
                         else:
                             # Stop if expected level data is missing
                             if achieved_level == 0 and level == 1:
                                 final_notes = "LLM response missing Level 1 data."
                             break

                     # Finalize the result item
                     new_result_data["achieved_level"] = achieved_level
                     new_result_data["final_status"] = final_status
                     new_result_data["final_confidence"] = final_confidence
                     new_result_data["classification_notes_or_reason"] = final_notes or f"Reclassified based on hint: {hint}"


                     new_result_model = JobResultItem(**new_result_data)
                     final_stats["successful_reclassifications"] += 1
                     logger.info(f"Successfully reclassified '{vendor_name}' to Level {achieved_level}: '{new_result_model.level1_name}{' -> ' + new_result_model.level2_name if achieved_level > 1 else ''}...'.")

                else:
                     # Handle classification_not_possible or ERROR from LLM or missing L1 data
                     reason = "LLM response did not include valid Level 1 data." # Default reason
                     if l1_data:
                         if l1_category_id in ["ERROR", "N/A"]:
                             reason = l1_data.get("classification_not_possible_reason", f"LLM returned '{l1_category_id}' for Level 1")
                         elif classification_not_possible:
                             reason = l1_data.get("classification_not_possible_reason", "LLM indicated Level 1 classification not possible")
                         elif not l1_category_id or not l1_category_name:
                             reason = "LLM response missing Level 1 category_id or category_name."
                     elif llm_output_data is None:
                         # Reason is based on why llm_output_data became None earlier
                         if parsed_llm_output is None:
                             reason = "LLM call failed or response parsing failed."
                         else:
                             reason = "LLM response structure did not match expected format."
                     else: # llm_output_data exists but no l1_data
                         reason = "LLM response missing 'level1' field."


                     logger.warning(f"LLM could not reclassify '{vendor_name}' with hint. Reason: {reason}")
                     final_stats["failed_reclassifications"] += 1
                     new_result_model = JobResultItem(
                         vendor_name=vendor_name,
                         level1_id=None, level1_name=None, # Or ERROR if appropriate
                         level2_id=None, level2_name=None, level3_id=None, level3_name=None,
                         level4_id=None, level4_name=None, level5_id=None, level5_name=None,
                         final_confidence=0.0,
                         final_status="Not Possible", # Or "Error"
                         classification_source="Review",
                         classification_notes_or_reason=f"Reclassification failed: {reason}", # Store the specific reason
                         achieved_level=0
                     )

            # --- MODIFIED: Catch specific validation errors ---
            except ValidationError as pydantic_err:
                # This might happen if the LLM output doesn't match JobResultItem structure
                err_msg = f"Pydantic validation failed processing LLM output for '{vendor_name}'."
                logger.error(err_msg, exc_info=True)
                final_stats["failed_reclassifications"] += 1
                new_result_model = JobResultItem( # Create error result
                    vendor_name=vendor_name, level1_id="ERROR", level1_name="ERROR",
                    level2_id=None, level2_name=None, level3_id=None, level3_name=None,
                    level4_id=None, level4_name=None, level5_id=None, level5_name=None,
                    final_confidence=0.0, final_status="Error", classification_source="Review",
                    classification_notes_or_reason=f"Error processing LLM output: {pydantic_err}",
                    achieved_level=0
                )
            # --- END MODIFIED ---
            except Exception as llm_err:
                logger.error(f"Error during LLM reclassification call or processing for '{vendor_name}'", exc_info=True)
                final_stats["failed_reclassifications"] += 1
                new_result_model = JobResultItem( # Create error result
                    vendor_name=vendor_name,
                    level1_id="ERROR", level1_name="ERROR",
                    level2_id=None, level2_name=None, level3_id=None, level3_name=None,
                    level4_id=None, level4_name=None, level5_id=None, level5_name=None,
                    final_confidence=0.0, final_status="Error", classification_source="Review",
                    classification_notes_or_reason=f"Error during reclassification processing: {llm_err}",
                    achieved_level=0
                )
            # --- End Actual Reclassification LLM Call ---

            # --- MODIFIED: Validate and store the result ---
            try:
                # Ensure original_result_model is not None before dumping
                original_result_dict = original_result_model.model_dump() if original_result_model else {}
                new_result_dict = new_result_model.model_dump() if new_result_model else {}

                # Validate the final ReviewResultItem before appending
                review_item = ReviewResultItem(
                    vendor_name=vendor_name,
                    hint=hint,
                    original_result=original_result_dict,
                    new_result=new_result_dict
                )
                review_results_list.append(review_item.model_dump()) # Append the validated dict
            except ValidationError as final_validation_err:
                 # This is the error that was likely causing the issue
                 err_msg = f"Failed to validate final ReviewResultItem for '{vendor_name}' before storage."
                 logger.error(err_msg, exc_info=True)
                 # Store the error in stats - this indicates a problem saving results
                 final_stats["error_message"] = (final_stats.get("error_message", "") + f"; {err_msg} Details: {final_validation_err}").strip("; ")
                 # Optionally increment failed count again?
                 # final_stats["failed_reclassifications"] += 1 # Maybe double-counts if LLM also failed
                 # Do NOT append the invalid item to review_results_list
            # --- END MODIFIED ---

            processed_count += 1
            if processed_count % update_interval == 0 or processed_count == len(items_to_reclassify):
                 progress = 0.1 + 0.85 * (processed_count / len(items_to_reclassify))
                 # Use try-except for update_progress as the session might become invalid
                 try:
                     review_job.update_progress(progress=min(0.95, progress), stage=ProcessingStage.RECLASSIFICATION, db_session=db)
                     logger.debug(f"Updated review job progress: {progress:.2f}")
                 except Exception as db_update_err:
                      logger.error("Failed to update job progress during reclassification loop", exc_info=db_update_err)
                      db.rollback() # Rollback potential partial commit within update_progress

            clear_log_context(["current_vendor"])


        # 5. Finalize Stats
        end_time = datetime.now(timezone.utc) # Use timezone aware now
        processing_duration = (end_time - start_time).total_seconds()
        final_stats["end_time"] = end_time.isoformat()
        final_stats["processing_duration_seconds"] = round(processing_duration, 2)
        # Calculate final cost based on accumulated API usage
        cost_input_per_1k = 0.0005
        cost_output_per_1k = 0.0015
        api_usage = final_stats["api_usage"]
        estimated_cost = (api_usage["openrouter_prompt_tokens"] / 1000) * cost_input_per_1k + \
                           (api_usage["openrouter_completion_tokens"] / 1000) * cost_output_per_1k
        # No Tavily cost expected here
        api_usage["cost_estimate_usd"] = round(estimated_cost, 4)

        logger.info(f"Reclassification logic finished for review job {review_job.id}. Results: {final_stats}")

    except Exception as e:
        # Catch broader errors (e.g., taxonomy loading, initial DB query)
        err_msg = f"Critical error during reclassification logic for review job {review_job.id}"
        logger.error(err_msg, exc_info=True)
        final_stats["error_message"] = f"{err_msg}: {type(e).__name__}: {str(e)}"
        # Return empty list as results are likely invalid/incomplete
        return [], final_stats
    finally:
        clear_log_context() # Clear job-specific context

    # Return the list of successfully processed ReviewResultItem dicts and stats
    return review_results_list, final_stats
</file>

<file path='app/tasks/reclassification_prompts.py'>
# app/tasks/reclassification_prompts.py
import json
import logging
from typing import Dict, Any, Optional

from models.taxonomy import Taxonomy, TaxonomyCategory
from schemas.job import JobResultItem # To understand the structure of original_result

logger = logging.getLogger("vendor_classification.reclassification_prompts")

def generate_reclassification_prompt(
    original_vendor_data: Dict[str, Any],
    user_hint: str,
    original_classification: Optional[Dict[str, Any]], # Dict matching JobResultItem
    taxonomy: Taxonomy,
    target_level: int, # The target level for this reclassification attempt
    attempt_id: str = "unknown-attempt"
) -> str:
    """
    Create a prompt for re-classifying a single vendor based on original data,
    user hint, and previous classification attempt. Aims for the target_level.
    """
    vendor_name = original_vendor_data.get('vendor_name', 'UnknownVendor')
    logger.debug(f"Generating reclassification prompt for vendor: {vendor_name}",
                extra={"target_level": target_level, "attempt_id": attempt_id})

    # --- Build Original Vendor Data Section ---
    vendor_data_xml = "<original_vendor_data>\n"
    vendor_data_xml += f"  <name>{vendor_name}</name>\n"
    # Include all available fields from the original data
    optional_fields = [
        'example_goods_services', 'address', 'website',
        'internal_category', 'parent_company', 'spend_category'
    ]
    # Map internal keys to XML tags if needed (adjust based on original_vendor_data structure)
    field_map = {
        'example_goods_services': 'example_goods_services',
        'address': 'address',
        'website': 'website',
        'internal_category': 'internal_category',
        'parent_company': 'parent_company',
        'spend_category': 'spend_category',
        # Add mappings if keys in original_vendor_data are different
        'example': 'example_goods_services',
        'vendor_address': 'address',
        'vendor_website': 'website',
    }
    for field_key, xml_tag in field_map.items():
        value = original_vendor_data.get(field_key)
        if value:
            vendor_data_xml += f"  <{xml_tag}>{str(value)[:300]}</{xml_tag}>\n" # Limit length
    vendor_data_xml += "</original_vendor_data>"

    # --- Build User Hint Section ---
    user_hint_xml = f"<user_hint>{user_hint}</user_hint>"

    # --- Build Original Classification Section (Optional but helpful) ---
    original_classification_xml = "<original_classification_attempt>\n"
    if original_classification:
        original_status = original_classification.get('final_status', 'Unknown')
        original_level = original_classification.get('achieved_level', 0)
        original_reason = original_classification.get('classification_notes_or_reason', 'N/A')
        original_classification_xml += f"  <status>{original_status}</status>\n"
        original_classification_xml += f"  <achieved_level>{original_level}</achieved_level>\n"
        original_classification_xml += f"  <reason_or_notes>{original_reason}</reason_or_notes>\n"
        # Include original L1-L5 IDs/Names if available
        for i in range(1, 6):
             id_key = f'level{i}_id'
             name_key = f'level{i}_name'
             cat_id = original_classification.get(id_key)
             cat_name = original_classification.get(name_key)
             if cat_id and cat_name:
                 original_classification_xml += f"  <level_{i}_result id=\"{cat_id}\" name=\"{cat_name}\"/>\n"
    else:
        original_classification_xml += "  <message>No previous classification data available.</message>\n"
    original_classification_xml += "</original_classification_attempt>"

    # --- Define Output Format Section (Standard Classification Result) ---
    # We want the LLM to output the *new* classification in the standard format
    # It needs to perform the hierarchical classification again based on the hint.
    output_format_xml = f"""<output_format>
Respond *only* with a valid JSON object containing the *new* classification result for this vendor, based *primarily* on the <user_hint> and <original_vendor_data>.
The JSON object should represent the full classification attempt up to Level {target_level}, following the standard structure used previously.

```json
{{
  "level": {target_level},
  "attempt_id": "{attempt_id}",
  "vendor_name": "{vendor_name}",
  "classifications": [
    {{
      "vendor_name": "{vendor_name}",
      "level1": {{
        "category_id": "string",
        "category_name": "string",
        "confidence": "float",
        "classification_not_possible": "boolean",
        "classification_not_possible_reason": "string | null",
        "notes": "string | null"
      }},
      "level2": {{
        "category_id": "string",
        "category_name": "string",
        "confidence": "float",
        "classification_not_possible": "boolean",
        "classification_not_possible_reason": "string | null",
        "notes": "string | null"
      }},
      "level3": {{
        "category_id": "string",
        "category_name": "string",
        "confidence": "float",
        "classification_not_possible": "boolean",
        "classification_not_possible_reason": "string | null",
        "notes": "string | null"
      }},
      "level4": {{
        "category_id": "string",
        "category_name": "string",
        "confidence": "float",
        "classification_not_possible": "boolean",
        "classification_not_possible_reason": "string | null",
        "notes": "string | null"
      }},
      "level5": {{
        "category_id": "string",
        "category_name": "string",
        "confidence": "float",
        "classification_not_possible": "boolean",
        "classification_not_possible_reason": "string | null",
        "notes": "string | null"
      }}
    }}
  ]
}}
```

</output_format>"""

    # --- Assemble Final Prompt ---
    prompt = f"""
<role>You are a precise vendor classification expert using the NAICS taxonomy. You are re-evaluating a previous classification based on new user input.</role>

<task>Re-classify the vendor described in `<original_vendor_data>` using the crucial information provided in `<user_hint>`. The previous attempt is in `<original_classification_attempt>` for context. Your goal is to determine the most accurate NAICS classification up to **Level {target_level}** based *primarily* on the user hint combined with the original data.</task>

<instructions>
1.  **Prioritize the `<user_hint>`**. Assume it provides the most accurate context about the vendor's primary business activity for the user's purposes.
2.  Use the `<original_vendor_data>` to supplement the hint if necessary.
3.  Refer to the `<original_classification_attempt>` only for context on why the previous classification might have been incorrect or insufficient. Do not simply repeat the old result unless the hint strongly confirms it.
4.  Perform a hierarchical classification starting from Level 1 up to the target Level {target_level}.
5.  For **each level**:
    a.  Determine the most appropriate category based on the hint and data. Use the provided taxonomy structure (implicitly known or explicitly provided if needed in future versions).
    b.  If a confident classification for the current level is possible, provide the `category_id`, `category_name`, `confidence` (> 0.0), set `classification_not_possible` to `false`, and optionally add `notes`. Proceed to the next level if the target level allows.
    c.  If classification for the current level is **not possible** (due to ambiguity even with the hint, or the hint pointing to an activity outside the available subcategories), set `classification_not_possible` to `true`, `confidence` to `0.0`, provide a `classification_not_possible_reason`, set `category_id`/`category_name` to "N/A", and **stop** the classification process for this vendor (do not include results for subsequent levels).
6.  Structure your response as a **single JSON object** matching the schema in `<output_format>`. Ensure it contains results for all levels attempted up to the point of success or failure. Ensure the JSON is enclosed in ```json ... ```.
7.  The output JSON should represent the *new* classification attempt based on the hint.
8.  Respond *only* with the valid JSON object enclosed in the markdown code fence.
</instructions>

{vendor_data_xml}

{user_hint_xml}

{original_classification_xml}

{output_format_xml}
"""
    # Note: This prompt implicitly relies on the LLM having access to the taxonomy structure
    # or being trained on it. For dynamic taxonomies, the relevant category options for each
    # level would need to be injected similar to the original batch prompt.
    # For now, we assume the LLM can infer the hierarchy and valid IDs based on the target level and task.
    # A future enhancement could involve passing the relevant taxonomy branches.

    return prompt
</file>

<file path='app/utils/log_utils.py'>

# app/utils/log_utils.py
import time
import functools
import uuid
import json
import traceback
import logging # Import standard logging
import inspect # Import inspect
import asyncio # Import asyncio
from typing import Dict, Any, Optional, Callable
from contextlib import contextmanager

# Import context functions from the new module
from core.log_context import (
    local_storage, # Need local_storage for LogTimer stats
    get_correlation_id,
    set_correlation_id, # <<< ADDED IMPORT
    set_log_context,
    get_performance_stats,
    clear_performance_stats
)

# Configure logger for this utility module itself
logger = logging.getLogger("vendor_classification.log_utils")
# --- ADDED: Log confirmation ---
logger.debug("Successfully imported set_correlation_id from core.log_context.")
# --- END ADDED ---

# Timer utility for performance logging
class LogTimer:
    def __init__(self, logger_instance, description="Operation", level=logging.DEBUG,
                 include_in_stats=False, stats_name=None):
        self.logger = logger_instance
        self.description = description
        self.level = level
        self.start_time = None
        self.include_in_stats = include_in_stats
        self.stats_name = stats_name or description.replace(" ", "_").lower()

    def __enter__(self):
        self.start_time = time.monotonic()
        self.logger.log(self.level, f"Starting: {self.description}")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.start_time is None: # Avoid error if __enter__ failed
            return
        elapsed = time.monotonic() - self.start_time

        if self.include_in_stats:
            # Use the imported local_storage
            if not hasattr(local_storage, 'performance_stats'):
                local_storage.performance_stats = {}
            if self.stats_name not in local_storage.performance_stats:
                local_storage.performance_stats[self.stats_name] = { 'count': 0, 'total_time': 0.0, 'min_time': float('inf'), 'max_time': 0.0 }
            stats = local_storage.performance_stats[self.stats_name]
            stats['count'] += 1
            stats['total_time'] += elapsed
            stats['min_time'] = min(stats['min_time'], elapsed)
            stats['max_time'] = max(stats['max_time'], elapsed)

        log_extra = {"duration_seconds": round(elapsed, 3)}
        if exc_type:
            log_extra["error"] = str(exc_val) if exc_val else exc_type.__name__
            self.logger.error(
                f"Failed: {self.description} after {elapsed:.3f}s",
                exc_info=(exc_type, exc_val, exc_tb) if exc_tb else False,
                extra=log_extra
            )
        else:
            self.logger.log(
                self.level,
                f"Completed: {self.description} in {elapsed:.3f}s",
                extra=log_extra
            )

@contextmanager
def log_duration(logger_instance, description="Operation", level=logging.DEBUG, include_in_stats=False):
    """Context manager for logging the duration of a code block using LogTimer."""
    timer = LogTimer(logger_instance, description, level, include_in_stats)
    with timer:
        yield

def log_function_call(logger_instance, level=logging.DEBUG, include_args=True,
                      include_result=False, arg_char_limit=100, result_char_limit=100,
                      include_in_stats=False):
    """
    Decorator to log function calls with parameters and return value.
    Handles both sync and async functions.
    """
    def decorator(func):
        logger_instance.debug(f"Applying @log_function_call decorator to function: {func.__module__}.{func.__name__}")

        @functools.wraps(func)
        def sync_wrapper(*args, **kwargs):
            func_name = func.__name__
            module_name = func.__module__
            full_func_name = f"{module_name}.{func_name}"
            timer_name = full_func_name

            args_repr = ""
            if include_args:
                try:
                    sig = inspect.signature(func)
                    bound_args = sig.bind_partial(*args, **kwargs)
                    bound_args.apply_defaults()
                    arg_items = []
                    for name, value in bound_args.arguments.items():
                        try: value_repr = repr(value)
                        except Exception: value_repr = "[repr error]"
                        if len(value_repr) > arg_char_limit:
                             type_name = type(value).__name__
                             value_repr = f"<{type_name} object>" if type_name != 'object' else value_repr[:arg_char_limit-3] + "..."
                        arg_items.append(f"{name}={value_repr}")
                    args_repr = ", ".join(arg_items)
                except Exception as sig_err:
                    logger_instance.warning(f"Could not format arguments for {full_func_name}: {sig_err}")
                    args_repr = "[Arg formatting error]"

            log_extra_start = {"function_args": args_repr} if include_args else {}
            logger_instance.log(level, f"Calling: {full_func_name}", extra=log_extra_start)

            start_time = time.monotonic()
            try:
                result = func(*args, **kwargs)
                elapsed = time.monotonic() - start_time

                if include_in_stats:
                    if not hasattr(local_storage, 'performance_stats'): local_storage.performance_stats = {}
                    if timer_name not in local_storage.performance_stats: local_storage.performance_stats[timer_name] = {'count': 0, 'total_time': 0.0, 'min_time': float('inf'), 'max_time': 0.0}
                    stats = local_storage.performance_stats[timer_name]
                    stats['count'] += 1; stats['total_time'] += elapsed; stats['min_time'] = min(stats['min_time'], elapsed); stats['max_time'] = max(stats['max_time'], elapsed)

                log_extra_end = {"duration_seconds": round(elapsed, 3)}
                result_repr = ""
                if include_result:
                    try:
                        result_repr = repr(result)
                        if len(result_repr) > result_char_limit:
                             type_name = type(result).__name__
                             result_repr = f"<{type_name} object>" if type_name != 'object' else result_repr[:result_char_limit-3] + "..."
                    except Exception: result_repr = "[repr error]"
                    log_extra_end["result"] = result_repr

                logger_instance.log(
                    level,
                    f"Completed: {full_func_name} in {elapsed:.3f}s",
                    extra=log_extra_end
                )
                return result

            except Exception as e:
                elapsed = time.monotonic() - start_time
                logger_instance.error(
                    f"Failed: {full_func_name} after {elapsed:.3f}s",
                    exc_info=True,
                    extra={"duration_seconds": round(elapsed, 3), "error": str(e)}
                )
                raise

        @functools.wraps(func)
        async def async_wrapper(*args, **kwargs):
            func_name = func.__name__
            module_name = func.__module__
            full_func_name = f"{module_name}.{func_name}"
            timer_name = full_func_name

            args_repr = ""
            if include_args:
                try:
                    sig = inspect.signature(func)
                    bound_args = sig.bind_partial(*args, **kwargs)
                    bound_args.apply_defaults()
                    arg_items = []
                    for name, value in bound_args.arguments.items():
                        try: value_repr = repr(value)
                        except Exception: value_repr = "[repr error]"
                        if len(value_repr) > arg_char_limit:
                            type_name = type(value).__name__
                            value_repr = f"<{type_name} object>" if type_name != 'object' else value_repr[:arg_char_limit-3] + "..."
                        arg_items.append(f"{name}={value_repr}")
                    args_repr = ", ".join(arg_items)
                except Exception as sig_err:
                    logger_instance.warning(f"Could not format arguments for async {full_func_name}: {sig_err}")
                    args_repr = "[Arg formatting error]"

            log_extra_start = {"function_args": args_repr} if include_args else {}
            logger_instance.log(level, f"Calling async: {full_func_name}", extra=log_extra_start)

            start_time = time.monotonic()
            try:
                result = await func(*args, **kwargs) # Await the async function
                elapsed = time.monotonic() - start_time

                if include_in_stats:
                    if not hasattr(local_storage, 'performance_stats'): local_storage.performance_stats = {}
                    if timer_name not in local_storage.performance_stats: local_storage.performance_stats[timer_name] = {'count': 0, 'total_time': 0.0, 'min_time': float('inf'), 'max_time': 0.0}
                    stats = local_storage.performance_stats[timer_name]
                    stats['count'] += 1; stats['total_time'] += elapsed; stats['min_time'] = min(stats['min_time'], elapsed); stats['max_time'] = max(stats['max_time'], elapsed)

                log_extra_end = {"duration_seconds": round(elapsed, 3)}
                result_repr = ""
                if include_result:
                    try:
                        result_repr = repr(result)
                        if len(result_repr) > result_char_limit:
                            type_name = type(result).__name__
                            result_repr = f"<{type_name} object>" if type_name != 'object' else result_repr[:result_char_limit-3] + "..."
                    except Exception: result_repr = "[repr error]"
                    log_extra_end["result"] = result_repr

                logger_instance.log(
                    level,
                    f"Completed async: {full_func_name} in {elapsed:.3f}s",
                    extra=log_extra_end
                )
                return result

            except Exception as e:
                elapsed = time.monotonic() - start_time
                logger_instance.error(
                    f"Failed async: {full_func_name} after {elapsed:.3f}s",
                    exc_info=True,
                    extra={"duration_seconds": round(elapsed, 3), "error": str(e)}
                )
                raise

        if asyncio.iscoroutinefunction(func):
            logger_instance.debug(f"Function {func.__module__}.{func.__name__} is async, using async_wrapper.")
            return async_wrapper
        else:
            logger_instance.debug(f"Function {func.__module__}.{func.__name__} is sync, using sync_wrapper.")
            return sync_wrapper
    return decorator

# --- Other utility functions from the original log_utils.py ---

def log_api_request(service_name: str):
    """
    Decorator to log API requests with detailed metrics.
    (Implementation remains the same as provided in the original log_utils.py)
    """
    def decorator(func):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            request_id = str(uuid.uuid4())
            correlation_id = get_correlation_id() or request_id
            url = kwargs.get("url") or (args[0] if len(args) > 0 and isinstance(args[0], str) else None)
            method = func.__name__
            request_data = kwargs.get("json", {})
            if isinstance(request_data, dict):
                if "api_key" in request_data: request_data["api_key"] = "[REDACTED]"
                if "password" in request_data: request_data["password"] = "[REDACTED]"

            start_time = time.time()
            logger.info(
                f"API request to {service_name} started",
                extra={ "service": service_name, "url": url, "method": method, "request_id": request_id, "correlation_id": correlation_id, "request_data": json.dumps(request_data)[:500] if request_data else None }
            )
            try:
                response = await func(*args, **kwargs)
                duration = time.time() - start_time
                # Update metrics (simplified example)
                set_log_context({f"{service_name}_api_call_count": 1, f"{service_name}_api_call_time": duration})

                status_code = getattr(response, 'status_code', None)
                response_data_str = "[Response data omitted]" # Simplified logging
                logger.info(
                    f"API request to {service_name} completed",
                    extra={ "service": service_name, "url": url, "method": method, "request_id": request_id, "correlation_id": correlation_id, "duration": duration, "status_code": status_code, "response_snippet": response_data_str }
                )
                return response
            except Exception as e:
                duration = time.time() - start_time
                set_log_context({f"{service_name}_api_error_count": 1})
                logger.error(
                    f"API request to {service_name} failed", exc_info=True,
                    extra={ "service": service_name, "url": url, "method": method, "request_id": request_id, "correlation_id": correlation_id, "duration": duration, "error": str(e) }
                )
                raise
        return wrapper
    return decorator

def log_method(level=logging.DEBUG, include_args=True, include_result=False):
    """
    Enhanced method logging decorator for class methods.
    (Implementation remains the same as provided in the original log_utils.py)
    """
    def decorator(method):
        @functools.wraps(method)
        def wrapper(self, *args, **kwargs):
            class_name = self.__class__.__name__
            method_name = method.__name__
            method_logger = getattr(self, 'logger', logger)
            log_level = level or getattr(method_logger, 'level', logging.DEBUG)
            operation = f"{class_name}.{method_name}"
            args_str = ""
            if include_args:
                arg_items = []
                for i, arg in enumerate(args):
                    arg_str = repr(arg); arg_str = arg_str[:97] + "..." if len(arg_str) > 100 else arg_str
                    arg_items.append(f"arg{i+1}={arg_str}")
                for name, value in kwargs.items():
                    value_str = repr(value); value_str = value_str[:97] + "..." if len(value_str) > 100 else value_str
                    arg_items.append(f"{name}={value_str}")
                args_str = ", ".join(arg_items)

            log_msg = f"Calling {operation}" + (f"({args_str})" if args_str else "")
            method_logger.log(log_level, log_msg)

            with LogTimer(method_logger, operation, level=log_level, include_in_stats=True):
                try:
                    result = method(self, *args, **kwargs)
                    result_str = ""
                    if include_result:
                        result_str = repr(result); result_str = result_str[:97] + "..." if len(result_str) > 100 else result_str
                        method_logger.log(log_level, f"{operation} returned: {result_str}")
                    else:
                        method_logger.log(log_level, f"{operation} completed")
                    return result
                except Exception as e:
                    method_logger.error(f"{operation} failed: {str(e)}", exc_info=True, extra={"error_type": type(e).__name__})
                    raise
        return wrapper
    return decorator

def setup_request_context(request=None):
    """
    Set up a new request context with correlation ID and other metadata.
    (Implementation remains the same as provided in the original log_utils.py)
    """
    correlation_id = str(uuid.uuid4())
    set_correlation_id(correlation_id) # Use the imported function
    if request:
        client_ip = request.client.host if hasattr(request, 'client') and request.client else None
        user_agent = request.headers.get('user-agent') if hasattr(request, 'headers') else None
        set_log_context({ 'client_ip': client_ip, 'user_agent': user_agent, 'request_path': getattr(request, 'url', None) })
    return correlation_id

def log_critical_operation(operation_name: str, include_in_stats=True):
    """
    Context manager for logging critical operations with mandatory timing.
    (Implementation remains the same as provided in the original log_utils.py)
    """
    return LogTimer(logger, operation_name, level=logging.INFO, include_in_stats=include_in_stats)
</file>

<file path='app/utils/taxonomy_loader.py'>
# <file path='app/utils/taxonomy_loader.py'>
# --- file path='app/utils/taxonomy_loader.py' ---
import os
import json
import pandas as pd
import re # <<< Added import
from typing import Dict, Any

# --- ADDED: Import logging for the main script part ---
import logging
# --- END ADDED ---

from core.config import settings
# --- MODIFIED IMPORT: Import all level classes including L5 ---
from models.taxonomy import Taxonomy, TaxonomyLevel1, TaxonomyLevel2, TaxonomyLevel3, TaxonomyLevel4, TaxonomyLevel5
# --- END MODIFIED IMPORT ---
from core.logging_config import get_logger

# Configure logger
logger = get_logger("vendor_classification.taxonomy_loader")

# --- Global cache for taxonomy ---
_taxonomy_cache: Taxonomy | None = None

def load_taxonomy(force_reload: bool = False) -> Taxonomy:
    """
    Load taxonomy data, using cache if available unless forced.
    Tries JSON first, then Excel as fallback.

    Args:
        force_reload: If True, bypass cache and reload from file.

    Returns:
        Taxonomy object

    Raises:
        FileNotFoundError: If neither JSON nor Excel file can be found.
        ValueError: If both JSON and Excel loading fail or result in empty taxonomy.
    """
    global _taxonomy_cache
    if _taxonomy_cache is not None and not force_reload:
        logger.info("Returning cached taxonomy.")
        return _taxonomy_cache

    excel_path = os.path.join(settings.TAXONOMY_DATA_DIR, "2022_NAICS_Codes.xlsx")
    json_path = os.path.join(settings.TAXONOMY_DATA_DIR, "naics_taxonomy.json")

    taxonomy = None

    # --- Try JSON first ---
    if os.path.exists(json_path):
        try:
            logger.info(f"Attempting to load taxonomy from JSON: {json_path}")
            with open(json_path, "r") as f:
                taxonomy_data = json.load(f)

            # Validate structure before creating Taxonomy object
            if not taxonomy_data.get("categories"):
                raise ValueError("JSON data is missing the 'categories' key.")

            taxonomy = Taxonomy(**taxonomy_data)
            logger.info(f"Taxonomy loaded successfully from JSON with {len(taxonomy.categories)} top-level categories.")
            _taxonomy_cache = taxonomy # Update cache
            return taxonomy
        except json.JSONDecodeError as json_err:
            logger.error(f"Failed to decode JSON from {json_path}: {json_err}", exc_info=False)
            logger.warning(f"JSON parsing failed. Will attempt fallback to Excel if available.")
        except Exception as e:
            logger.error(f"Error loading taxonomy from JSON: {e}", exc_info=True)
            logger.warning(f"Unexpected error loading JSON. Will attempt fallback to Excel if available.")
            taxonomy = None # Ensure taxonomy is None if JSON loading fails

    # --- Fallback to Excel if JSON failed or didn't exist ---
    if taxonomy is None and os.path.exists(excel_path):
        try:
            logger.warning(f"JSON load failed or file missing, attempting to load taxonomy from Excel: {excel_path}")
            taxonomy = load_taxonomy_from_excel(excel_path)

            # Save as JSON for future use IF successful
            logger.info(f"Saving newly loaded taxonomy to JSON: {json_path}")
            os.makedirs(settings.TAXONOMY_DATA_DIR, exist_ok=True)
            with open(json_path, "w") as f:
                # Use model_dump for Pydantic v2
                json.dump(taxonomy.model_dump(exclude_none=True, mode='json'), f, indent=2) # Added mode='json'

            logger.info(f"Taxonomy loaded successfully from Excel with {len(taxonomy.categories)} top-level categories and saved to JSON.")
            _taxonomy_cache = taxonomy # Update cache
            return taxonomy
        except Exception as e:
            logger.error(f"Error loading taxonomy from Excel after JSON failure: {e}", exc_info=True)
            taxonomy = None # Ensure taxonomy is None if Excel loading also fails

    # --- If both failed, raise error ---
    if taxonomy is None:
        # --- Fallback to Sample Taxonomy ---
        logger.warning(f"Failed to load taxonomy from both JSON and Excel. Falling back to sample taxonomy.")
        try:
            taxonomy = create_sample_taxonomy()
            _taxonomy_cache = taxonomy # Cache the sample
            return taxonomy
        except Exception as sample_err:
            error_msg = f"Failed to load taxonomy from files and also failed to create sample taxonomy: {sample_err}"
            logger.critical(error_msg, exc_info=True)
            raise RuntimeError(error_msg) from sample_err

    # This part should theoretically not be reached if errors are raised correctly
    logger.critical("Reached unexpected end of load_taxonomy function.")
    raise RuntimeError("Taxonomy loading finished in an unexpected state.")


def load_taxonomy_from_excel(file_path: str) -> Taxonomy:
    """
    Load taxonomy from Excel file, building the hierarchical structure up to 5 levels.
    Correctly handles sector range titles.

    Args:
        file_path: Path to Excel file

    Returns:
        Taxonomy object

    Raises:
        FileNotFoundError: If the file_path does not exist.
        ValueError: If the file cannot be parsed or required columns are missing.
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Taxonomy Excel file not found at {file_path}")

    try:
        # Read Excel file
        logger.debug(f"Reading Excel file: {file_path}")

        try:
            # Try reading as Excel first
            df = pd.read_excel(file_path, dtype=str) # Read all as string initially
            logger.debug(f"Successfully read Excel file with {len(df)} rows")
        except Exception as excel_error:
            # Fallback to CSV with pipe delimiter if Excel read fails
            logger.warning(f"Failed to read as Excel ({str(excel_error)}), trying as pipe-delimited text...")
            try:
                # Assuming the Excel file provided might actually be pipe-delimited
                df = pd.read_csv(file_path, delimiter='|', quotechar='"', dtype=str, skipinitialspace=True)
                logger.debug(f"Successfully read pipe-delimited file with {len(df)} rows")
            except Exception as csv_error:
                logger.error(f"Failed to read as pipe-delimited text: {str(csv_error)}")
                raise ValueError(f"Could not parse taxonomy file '{file_path}'. Tried Excel and Pipe-Delimited CSV.") from excel_error

        # --- Column Identification ---
        code_col_options = ['naics code', '2022 naics us code', 'code']
        title_col_options = ['naics title', '2022 naics us title', 'title']
        desc_col_options = ['description', 'desc']

        df_cols_lower = {col.lower().strip(): col for col in df.columns}

        code_column = next((df_cols_lower[opt] for opt in code_col_options if opt in df_cols_lower), None)
        title_column = next((df_cols_lower[opt] for opt in title_col_options if opt in df_cols_lower), None)
        desc_column = next((df_cols_lower[opt] for opt in desc_col_options if opt in df_cols_lower), None)

        if not code_column or not title_column:
            error_msg = f"Could not identify required 'code' and 'title' columns in the taxonomy file. Found columns: {list(df.columns)}"
            logger.error(error_msg)
            raise ValueError(error_msg)
        logger.info(f"Identified taxonomy columns - Code: '{code_column}', Title: '{title_column}', Desc: '{desc_column or 'None'}'")

        # --- Data Cleaning ---
        df = df.dropna(subset=[code_column])
        df[code_column] = df[code_column].astype(str).str.strip()
        df[title_column] = df[title_column].astype(str).str.strip().str.replace(r'\s*T$', '', regex=True) # Remove trailing 'T'

        if desc_column:
            df[desc_column] = df[desc_column].fillna('').astype(str).str.strip()
        else:
            desc_column = 'Description' # Assign a name
            df[desc_column] = ''
            logger.warning("No description column found, descriptions will be empty.")

        # --- Filter out rows with non-standard codes BEFORE processing ranges ---
        valid_code_pattern = r'^(\d{2}-\d{2}|\d+)$'
        original_row_count = len(df)
        df = df[df[code_column].str.match(valid_code_pattern)]
        filtered_row_count = len(df)
        if original_row_count != filtered_row_count:
            logger.warning(f"Filtered out {original_row_count - filtered_row_count} rows with invalid code formats (neither ##-## nor numeric).")

        # --- Build taxonomy structure ---
        categories_level1: Dict[str, TaxonomyLevel1] = {}
        logger.info("Building taxonomy hierarchy...")

        rows_processed = 0
        skipped_rows = 0
        for index, row in df.iterrows():
            code_raw = row[code_column].strip()
            title = row[title_column].strip()
            description = row[desc_column].strip()

            code = code_raw
            original_code = code_raw
            is_range = '-' in code

            # --- Range Handling ---
            if is_range:
                range_match = re.match(r'^(\d{2})-\d{2}$', code)
                if range_match:
                    start_code = range_match.group(1)
                    range_title = title
                    logger.debug(f"Row {index}: Processing range code '{original_code}' ('{range_title}') - Associating title with start code '{start_code}'")
                    if start_code not in categories_level1:
                        categories_level1[start_code] = TaxonomyLevel1(id=start_code, name=range_title, description=description, children={})
                        logger.info(f"Row {index}: Added L1 '{start_code}' using range title '{range_title}'.")
                    else:
                        existing_name = categories_level1[start_code].name
                        if existing_name != range_title:
                            logger.warning(f"Row {index}: L1 '{start_code}' already exists with name '{existing_name}'. Overwriting with range title '{range_title}'.")
                            categories_level1[start_code].name = range_title
                        if not categories_level1[start_code].description and description:
                             categories_level1[start_code].description = description
                             logger.debug(f"Row {index}: Updated empty L1 '{start_code}' description.")
                    rows_processed += 1
                    continue # Skip rest of hierarchy logic for this row
                else:
                    logger.warning(f"Row {index}: Skipping row with unhandled range format code: '{original_code}' ('{title}')")
                    skipped_rows += 1
                    continue
            elif not code.isdigit():
                logger.warning(f"Row {index}: Skipping row with non-numeric/non-range code: '{original_code}' ('{title}')")
                skipped_rows += 1
                continue
            # --- End Range Handling ---

            # --- Hierarchy Building for Numeric Codes ---
            code_length = len(code)
            try:
                if code_length == 2:  # Level 1 (Specific code)
                    if code not in categories_level1:
                        categories_level1[code] = TaxonomyLevel1(id=code, name=title, description=description, children={})
                        logger.debug(f"Row {index}: Added L1: {code} - {title}")
                    elif not categories_level1[code].description and description:
                        categories_level1[code].description = description
                        logger.debug(f"Row {index}: Updated L1 '{code}' description (already existed).")

                elif code_length == 3: # Level 2
                    l1_code = code[:2]
                    if l1_code in categories_level1:
                        l1_cat = categories_level1[l1_code]
                        if code not in l1_cat.children:
                            l1_cat.children[code] = TaxonomyLevel2(id=code, name=title, description=description, children={})
                            logger.debug(f"Row {index}:   Added L2: {code} under {l1_code}")
                    else:
                        logger.warning(f"Row {index}: L1 parent '{l1_code}' not found for L2 code '{code}' ('{title}'). Skipping.")
                        skipped_rows += 1; continue

                elif code_length == 4: # Level 3
                    l1_code = code[:2]; l2_code = code[:3]
                    if l1_code in categories_level1 and l2_code in categories_level1[l1_code].children:
                        l2_cat = categories_level1[l1_code].children[l2_code]
                        if code not in l2_cat.children:
                            l2_cat.children[code] = TaxonomyLevel3(id=code, name=title, description=description, children={})
                            logger.debug(f"Row {index}:     Added L3: {code} under {l2_code}")
                    else:
                        logger.warning(f"Row {index}: L1/L2 parent '{l1_code}/{l2_code}' not found for L3 code '{code}' ('{title}'). Skipping.")
                        skipped_rows += 1; continue

                elif code_length == 5: # Level 4
                    l1_code = code[:2]; l2_code = code[:3]; l3_code = code[:4]
                    if l1_code in categories_level1 and \
                       l2_code in categories_level1[l1_code].children and \
                       l3_code in categories_level1[l1_code].children[l2_code].children:
                        l3_cat = categories_level1[l1_code].children[l2_code].children[l3_code]
                        if code not in l3_cat.children:
                            # Create L4 with empty children dict for potential L5
                            l3_cat.children[code] = TaxonomyLevel4(id=code, name=title, description=description, children={})
                            logger.debug(f"Row {index}:       Added L4: {code} under {l3_code}")
                    else:
                        logger.warning(f"Row {index}: L1/L2/L3 parent '{l1_code}/{l2_code}/{l3_code}' not found for L4 code '{code}' ('{title}'). Skipping.")
                        skipped_rows += 1; continue

                elif code_length == 6: # Level 5
                    l1_code = code[:2]; l2_code = code[:3]; l3_code = code[:4]; l4_code = code[:5]
                    if l1_code in categories_level1 and \
                       l2_code in categories_level1[l1_code].children and \
                       l3_code in categories_level1[l1_code].children[l2_code].children and \
                       l4_code in categories_level1[l1_code].children[l2_code].children[l3_code].children:
                        l4_cat = categories_level1[l1_code].children[l2_code].children[l3_code].children[l4_code]
                        if code not in l4_cat.children:
                            l4_cat.children[code] = TaxonomyLevel5(id=code, name=title, description=description)
                            logger.debug(f"Row {index}:         Added L5: {code} under {l4_code}")
                    else:
                        logger.warning(f"Row {index}: L1/L2/L3/L4 parent '{l1_code}/{l2_code}/{l3_code}/{l4_code}' not found for L5 code '{code}' ('{title}'). Skipping.")
                        skipped_rows += 1; continue
                else:
                     logger.warning(f"Row {index}: Code '{code}' has unhandled length {code_length}. Skipping.")
                     skipped_rows += 1; continue

                rows_processed += 1

            except Exception as hierarchy_error:
                 logger.error(f"Row {index}: Error building hierarchy for code '{code}' ('{title}')", exc_info=True)
                 skipped_rows += 1

        if not categories_level1:
            error_msg = f"No valid Level 1 categories found after processing {rows_processed + skipped_rows} rows from the file."
            logger.error(error_msg)
            raise ValueError(error_msg)

        # Create final taxonomy object
        taxonomy = Taxonomy(
            name="NAICS Taxonomy",
            version="2022", # Or extract from filename/content if possible
            description="North American Industry Classification System", # Or extract
            categories=categories_level1
        )

        # Log final stats including L5
        l1_count = len(taxonomy.categories)
        l2_count = sum(len(getattr(l1, 'children', {})) for l1 in taxonomy.categories.values())
        l3_count = sum(len(getattr(l2, 'children', {})) for l1 in taxonomy.categories.values() for l2 in getattr(l1, 'children', {}).values())
        l4_count = sum(len(getattr(l3, 'children', {})) for l1 in taxonomy.categories.values() for l2 in getattr(l1, 'children', {}).values() for l3 in getattr(l2, 'children', {}).values())
        l5_count = sum(len(getattr(l4, 'children', {})) for l1 in taxonomy.categories.values() for l2 in getattr(l1, 'children', {}).values() for l3 in getattr(l2, 'children', {}).values() for l4 in getattr(l3, 'children', {}).values())
        logger.info(f"Taxonomy hierarchy built with {l1_count} L1, {l2_count} L2, {l3_count} L3, {l4_count} L4, {l5_count} L5 categories from {rows_processed} processed rows ({skipped_rows} skipped).")

        return taxonomy

    except FileNotFoundError: # Raised explicitly above
        raise
    except ValueError as ve: # Raised explicitly above for parsing/column errors
         logger.error(f"Value error processing taxonomy Excel file '{file_path}': {ve}", exc_info=False)
         raise # Re-raise specific error
    except Exception as e:
        logger.error(f"Unexpected error processing taxonomy Excel file '{file_path}': {e}", exc_info=True)
        raise ValueError(f"Could not process taxonomy Excel file: {e}") from e


# --- create_sample_taxonomy function remains unchanged ---
# (It's a fallback and doesn't need L5 for this update)
def create_sample_taxonomy() -> Taxonomy:
    """
    Create a sample NAICS taxonomy for testing or fallback.
    (This function remains unchanged from the original provided code)
    """
    # Level 4 categories
    level4_categories_11 = {
        "111110": TaxonomyLevel4(id="111110", name="Soybean Farming", description="...", children={}), # Add empty children
        "111120": TaxonomyLevel4(id="111120", name="Oilseed (except Soybean) Farming", description="...", children={}),
    }
    # ... other sample L4 categories ...
    level4_categories_23 = { "236115": TaxonomyLevel4(id="236115", name="New Single-Family Housing Construction", description="...", children={}) }
    level4_categories_51 = { "513210": TaxonomyLevel4(id="513210", name="Software Publishers", description="...", children={}) }
    # Sample L5 children for L4 111110
    level5_categories_11111 = {
        "111111": TaxonomyLevel5(id="111111", name="Sample L5 Soybeans"),
        "111112": TaxonomyLevel5(id="111112", name="Sample L5 Other Soybeans"),
    }
    level4_categories_11["111110"].children = level5_categories_11111


    # Create level 3 categories
    level3_categories_11 = {
        "1111": TaxonomyLevel3(id="1111", name="Oilseed and Grain Farming", description="...", children=level4_categories_11),
    }
    level3_categories_23 = { "2361": TaxonomyLevel3(id="2361", name="Residential Building Construction", description="...", children=level4_categories_23) }
    level3_categories_51 = { "5132": TaxonomyLevel3(id="5132", name="Software Publishers", description="...", children=level3_categories_51) }


    # Create level 2 categories
    level2_categories_11 = {
        "111": TaxonomyLevel2(id="111", name="Crop Production", description="...", children=level3_categories_11),
    }
    level2_categories_23 = { "236": TaxonomyLevel2(id="236", name="Construction of Buildings", description="...", children=level3_categories_23) }
    level2_categories_51 = { "513": TaxonomyLevel2(id="513", name="Publishing Industries", description="...", children=level3_categories_51) }

    # Create level 1 categories
    level1_categories = {
        "11": TaxonomyLevel1(id="11", name="Agriculture, Forestry, Fishing and Hunting", description="...", children=level2_categories_11),
        "23": TaxonomyLevel1(id="23", name="Construction", description="...", children=level2_categories_23),
        "51": TaxonomyLevel1(id="51", name="Information", description="...", children=level2_categories_51)
    }

    # Create taxonomy
    taxonomy = Taxonomy(
        name="NAICS Taxonomy (Sample)",
        version="2022_Sample",
        description="Sample North American Industry Classification System",
        categories=level1_categories
    )
    logger.warning("Generated and using a sample taxonomy.")
    return taxonomy


if __name__ == "__main__":
     # --- ADDED: Import logging for test block ---
     import logging
     # --- END ADDED ---
     # Example usage for testing
     print("Testing taxonomy loader...")
     try:
         # Ensure settings are available or provide a default path
         if 'settings' not in locals() and 'settings' not in globals():
              class MockSettings:
                  TAXONOMY_DATA_DIR = os.path.join(os.path.dirname(__file__), '../../data/taxonomy')
              settings = MockSettings()
              print(f"Using mock settings for TAXONOMY_DATA_DIR: {settings.TAXONOMY_DATA_DIR}")
         else:
              if not hasattr(settings, 'TAXONOMY_DATA_DIR') or not settings.TAXONOMY_DATA_DIR:
                   settings.TAXONOMY_DATA_DIR = os.path.join(os.path.dirname(__file__), '../../data/taxonomy')
              print(f"Using settings.TAXONOMY_DATA_DIR: {settings.TAXONOMY_DATA_DIR}")

         # --- Ensure log directory exists for testing ---
         log_test_dir = "./logs_test"
         os.makedirs(log_test_dir, exist_ok=True)
         from core.logging_config import setup_logging
         setup_logging(log_level=logging.DEBUG, log_to_file=True, log_dir=log_test_dir, async_logging=False)
         # ---

         # Force reload from Excel (or CSV fallback)
         tax = load_taxonomy(force_reload=True)
         print(f"\nLoaded taxonomy: {tax.name} - Version: {tax.version}")
         print(f"Number of L1 categories: {len(tax.categories)}")

         # Verification for a specific L5 code (example)
         print("\n--- Verification for L5 Code (e.g., 311111) ---")
         try:
             l1 = tax.categories.get('31')
             l2 = l1.children.get('311') if l1 else None
             l3 = l2.children.get('3111') if l2 else None
             l4 = l3.children.get('31111') if l3 else None
             l5 = l4.children.get('311111') if l4 else None
             if l5:
                 print(f"L5 '311111' FOUND. Name: '{l5.name}'")
             else:
                 print("L5 '311111' NOT FOUND (or parent missing).")
         except Exception as e:
             print(f"Error during L5 verification: {e}")

         # Test get_level5_categories
         print("\n--- Test get_level5_categories('31111') ---")
         l5_children = tax.get_level5_categories('31111')
         if l5_children:
             print(f"Found {len(l5_children)} L5 children for '31111':")
             for child in l5_children[:5]:
                 print(f"  - {child.id}: {child.name}")
         else:
             print("No L5 children found for '31111'.")


     except Exception as e:
         print(f"\nError during testing: {e}")
         import traceback
         traceback.print_exc()
</file>

<file path='app/utils/text_processing.py'>
import re
import unicodedata
from typing import List, Dict, Any

def normalize_vendor_name(name: str) -> str:
    """
    Normalize a vendor name by removing special characters, 
    standardizing whitespace, and converting to lowercase.
    
    Args:
        name: Vendor name to normalize
        
    Returns:
        Normalized vendor name
    """
    if not name or not isinstance(name, str):
        return ""
    
    # Convert to lowercase
    normalized = name.lower()
    
    # Normalize unicode characters
    normalized = unicodedata.normalize('NFKD', normalized)
    normalized = ''.join([c for c in normalized if not unicodedata.combining(c)])
    
    # Remove legal entity indicators
    entity_indicators = [
        r'\bllc\b', r'\binc\b', r'\bltd\b', r'\bcorp\b', r'\bcorporation\b',
        r'\bco\b', r'\bcompany\b', r'\bgroup\b', r'\bholdings\b', r'\bservices\b',
        r'\bsolutions\b', r'\bsystems\b', r'\btechnologies\b', r'\btech\b',
        r'\benterprises\b', r'\blimited\b', r'\bpartners\b', r'\bassociates\b',
        r'\bgmbh\b', r'\bplc\b', r'\bpte\b', r'\bpty\b', r'\bag\b', r'\bsa\b',
        r'\bsrl\b', r'\bs\.r\.l\b', r'\bs\.p\.a\b', r'\bs\.a\b', r'\bs\.a\.s\b',
        r'\bb\.v\b', r'\blp\b', r'\bllp\b', r'\blp\b', r'\bl\.p\b', r'\bl\.l\.c\b',
        r'\bl\.l\.p\b', r'\bincorporated\b'
    ]
    
    for indicator in entity_indicators:
        normalized = re.sub(indicator, '', normalized)
    
    # Remove special characters and replace with space
    normalized = re.sub(r'[^\w\s]', ' ', normalized)
    
    # Replace multiple spaces with a single space
    normalized = re.sub(r'\s+', ' ', normalized)
    
    # Remove leading/trailing whitespace
    normalized = normalized.strip()
    
    return normalized

def normalize_vendor_names(vendors: List[str]) -> List[str]:
    """
    Normalize a list of vendor names.
    
    Args:
        vendors: List of vendor names
        
    Returns:
        List of normalized vendor names
    """
    return [normalize_vendor_name(vendor) for vendor in vendors]

def extract_vendor_names_from_dataframe(df: Any, column_name: str = 'vendor_name') -> List[str]:
    """
    Extract vendor names from a pandas DataFrame.
    
    Args:
        df: Pandas DataFrame
        column_name: Name of the column containing vendor names
        
    Returns:
        List of vendor names
    """
    if column_name not in df.columns:
        # Try to find a column that might contain vendor names
        potential_columns = [col for col in df.columns if 'vendor' in col.lower() or 'company' in col.lower()]
        
        if potential_columns:
            column_name = potential_columns[0]
        else:
            # Use the first column as a fallback
            column_name = df.columns[0]
    
    # Extract vendor names
    vendors = df[column_name].astype(str).tolist()
    
    # Filter out empty or NaN values
    vendors = [vendor for vendor in vendors if vendor and vendor.lower() != 'nan']
    
    return vendors

</file>

<file path='core/config.py'>
# core/config.py
import os
from pydantic_settings import BaseSettings
from pydantic import Field, PostgresDsn, EmailStr, AnyHttpUrl
from typing import List, Optional, Dict, Any
from dotenv import load_dotenv
import json
import logging

# Configure logging for this module
logger = logging.getLogger("vendor_classification.config")

# Load environment variables from .env file if it exists
# This is useful for local development
load_dotenv()

# --- Manual Loading for Early Access ---
# These will be loaded directly from environment variables BEFORE Pydantic Settings
# This allows their use during module import time if needed (e.g., in other modules)
MANUAL_OPENROUTER_PROVISIONING_KEYS: List[str] = []
MANUAL_TAVILY_API_KEYS: List[str] = []

def _load_manual_keys():
    """Loads specific keys manually from environment variables."""
    global MANUAL_OPENROUTER_PROVISIONING_KEYS, MANUAL_TAVILY_API_KEYS

    openrouter_keys_str = os.getenv("OPENROUTER_PROVISIONING_KEYS", "")
    if openrouter_keys_str:
        try:
            # Attempt to parse as JSON list first
            keys = json.loads(openrouter_keys_str)
            if isinstance(keys, list) and all(isinstance(k, str) for k in keys):
                MANUAL_OPENROUTER_PROVISIONING_KEYS = keys
            else:
                # Fallback to comma-separated if JSON parsing fails or type is wrong
                MANUAL_OPENROUTER_PROVISIONING_KEYS = [k.strip() for k in openrouter_keys_str.split(',') if k.strip()]
                logger.warning("OPENROUTER_PROVISIONING_KEYS was not a valid JSON list, parsed as comma-separated.")
        except json.JSONDecodeError:
            # Assume comma-separated if JSON parsing fails
            MANUAL_OPENROUTER_PROVISIONING_KEYS = [k.strip() for k in openrouter_keys_str.split(',') if k.strip()]
            logger.warning("Failed to parse OPENROUTER_PROVISIONING_KEYS as JSON, parsed as comma-separated.")
    else:
        logger.warning("OPENROUTER_PROVISIONING_KEYS environment variable not set or empty.")

    tavily_keys_str = os.getenv("TAVILY_API_KEYS", "")
    if tavily_keys_str:
        try:
            # Attempt to parse as JSON list first
            keys = json.loads(tavily_keys_str)
            if isinstance(keys, list) and all(isinstance(k, str) for k in keys):
                MANUAL_TAVILY_API_KEYS = keys
            else:
                # Fallback to comma-separated if JSON parsing fails or type is wrong
                MANUAL_TAVILY_API_KEYS = [k.strip() for k in tavily_keys_str.split(',') if k.strip()]
                logger.warning("TAVILY_API_KEYS was not a valid JSON list, parsed as comma-separated.")
        except json.JSONDecodeError:
            # Assume comma-separated if JSON parsing fails
            MANUAL_TAVILY_API_KEYS = [k.strip() for k in tavily_keys_str.split(',') if k.strip()]
            logger.warning("Failed to parse TAVILY_API_KEYS as JSON, parsed as comma-separated.")
    else:
        logger.warning("TAVILY_API_KEYS environment variable not set or empty.")

_load_manual_keys()
# --- End Manual Loading ---


class Settings(BaseSettings):
    # --- Core Settings ---
    PROJECT_NAME: str = "NAICS Vendor Classification"
    API_V1_STR: str = "/api/v1"
    SECRET_KEY: str = Field(..., env="SECRET_KEY") # Make secret key mandatory
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 60 * 24 # 1 day expiration
    PASSWORD_RESET_TOKEN_EXPIRE_MINUTES: int = 30 # Password reset token expires in 30 mins

    # --- Database Settings ---
    DATABASE_URL: PostgresDsn = Field(..., env="DATABASE_URL")

    # --- Celery Settings ---
    CELERY_BROKER_URL: str = Field("redis://redis:6379/0", env="CELERY_BROKER_URL")
    CELERY_RESULT_BACKEND: str = Field("redis://redis:6379/0", env="CELERY_RESULT_BACKEND")

    # --- File Paths (relative to project root or absolute) ---
    # Assume TAXONOMY_DATA_DIR is where taxonomy, input, output, logs, cache reside
    TAXONOMY_DATA_DIR: str = "data"
    INPUT_DIR: str = Field(default_factory=lambda: os.path.join(Settings().TAXONOMY_DATA_DIR, "input"))
    OUTPUT_DIR: str = Field(default_factory=lambda: os.path.join(Settings().TAXONOMY_DATA_DIR, "output"))
    LOG_DIR: str = Field(default_factory=lambda: os.path.join(Settings().TAXONOMY_DATA_DIR, "logs"))
    CACHE_DIR: str = Field(default_factory=lambda: os.path.join(Settings().TAXONOMY_DATA_DIR, "cache"))
    TAXONOMY_FILE_PATH: str = Field(default_factory=lambda: os.path.join(Settings().TAXONOMY_DATA_DIR, "taxonomy", "2022_NAICS_Structure.xlsx"))

    # --- Frontend Settings ---
    FRONTEND_URL: str = "http://localhost:8080" # Default for local dev Vue server

    # --- LLM & Search API Settings ---
    # These are loaded via Pydantic Settings but also manually above for early access
    OPENROUTER_PROVISIONING_KEYS: List[str] = Field(default_factory=lambda: MANUAL_OPENROUTER_PROVISIONING_KEYS)
    TAVILY_API_KEYS: List[str] = Field(default_factory=lambda: MANUAL_TAVILY_API_KEYS)
    OPENROUTER_API_BASE: Optional[str] = "https://openrouter.ai/api/v1"
    # --- FIX: Add TAVILY_API_URL ---
    TAVILY_API_URL: Optional[str] = "https://api.tavily.com/search"
    # --- END FIX ---
    USE_LLM_CACHE: bool = True # Enable/disable simple file-based cache for OpenRouter calls
    LLM_CACHE_FILE: str = Field(default_factory=lambda: os.path.join(Settings().CACHE_DIR, "openrouter_dev_cache.json"))
    LLM_DEFAULT_MODEL: str = "anthropic/claude-3.5-sonnet"
    LLM_FALLBACK_MODEL: Optional[str] = "anthropic/claude-3-haiku" # Optional fallback
    LLM_MAX_RETRIES: int = 3
    LLM_RETRY_DELAY_SECONDS: int = 5
    LLM_REQUEST_TIMEOUT_SECONDS: int = 120 # Timeout for individual LLM API calls

    # --- Email Settings (Optional) ---
    SMTP_HOST: Optional[str] = None
    SMTP_PORT: int = 587
    SMTP_USER: Optional[str] = None
    SMTP_PASSWORD: Optional[str] = None
    SMTP_TLS: bool = True
    EMAIL_FROM: Optional[EmailStr] = None

    # --- Initial Admin User ---
    ADMIN_USERNAME: str = "admin"
    ADMIN_EMAIL: EmailStr = "admin@example.com"
    ADMIN_PASSWORD: str = "password" # Default password, CHANGE IN PRODUCTION

    class Config:
        env_file = ".env" # Load .env file if present
        env_file_encoding = 'utf-8'
        case_sensitive = True # Environment variables are case-sensitive

# Instantiate settings
try:
    settings = Settings()
    logger.info("Pydantic Settings object initialized successfully (excluding manual keys).")
    logger.info(f"Loaded DATABASE_URL: {settings.DATABASE_URL.host}:{settings.DATABASE_URL.port}/{settings.DATABASE_URL.path}") # Hide user/pass
    logger.info(f"Loaded USE_LLM_CACHE: {settings.USE_LLM_CACHE}")
except Exception as e:
    logger.error(f"Failed to initialize Pydantic Settings: {e}", exc_info=True)
    raise

# Log manually loaded keys after Pydantic init for completeness
logger.info("Manually loading and parsing API keys from environment variables...")
# The loading happens before Settings instantiation, log the result here
logger.info(f"Using {len(MANUAL_OPENROUTER_PROVISIONING_KEYS)} OpenRouter Provisioning Keys from environment.")
if not MANUAL_OPENROUTER_PROVISIONING_KEYS: logger.warning("OPENROUTER_PROVISIONING_KEYS was empty or not set.")
if any("REPLACE_WITH_YOUR_VALID" in k for k in MANUAL_OPENROUTER_PROVISIONING_KEYS): logger.warning("OpenRouter keys seem to contain placeholders.")

logger.info(f"Using {len(MANUAL_TAVILY_API_KEYS)} Tavily Keys from environment.")
if not MANUAL_TAVILY_API_KEYS: logger.warning("TAVILY_API_KEYS was empty or not set.")
if any("REPLACE_WITH_YOUR_VALID" in k for k in MANUAL_TAVILY_API_KEYS): logger.warning("Tavily keys seem to contain placeholders.")

logger.info("Manual API key loading complete.")
# Log final counts again for clarity
logger.info(f"Final Manual Prov Keys count: {len(settings.OPENROUTER_PROVISIONING_KEYS)}")
logger.info(f"Final Manual Tavily Keys count: {len(settings.TAVILY_API_KEYS)}")
</file>

<file path='docker-compose.yml'>
# docker-compose.yaml
services:
  web:
    build:
      context: .
      dockerfile: Dockerfile.web
    ports:
      - "${WEB_PORT:-8001}:8000"
    volumes:
      # - ./app:/app          # Keep commented out unless backend hot-reloading is needed
      - ./data:/data
    # --- ADDED env_file ---
    env_file:
      - .env # Tells Docker Compose to load variables from the .env file in the context root
    # --- END ADDED env_file ---
    environment:
      # You can keep these if they are specific overrides or not in .env
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/vendor_classification
      - REDIS_URL=redis://redis:6379/0
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=DEBUG
      # Note: Variables defined here in 'environment' will OVERRIDE those in .env if they have the same name.
      # It's generally better to define DATABASE_URL, REDIS_URL etc. in .env as well
      # and remove them from here unless you specifically need to override.
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - app-network
    command: sh -c "echo '>>> [Web CMD Start] Waiting briefly for DB...' && sleep 5 && echo '>>> [Web CMD Start] Running DB Initialization...' && python core/initialize_db.py && echo '>>> [Web CMD Start] Starting Uvicorn...' && uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload --log-level debug"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 45s

  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    volumes:
      # - ./app:/app # Keep commented out unless worker hot-reloading is needed
      - ./data:/data
    # --- ADDED env_file ---
    env_file:
      - .env # Tells Docker Compose to load variables from the .env file in the context root
    # --- END ADDED env_file ---
    environment:
      # Same note as above: prefer defining these in .env and removing from here
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/vendor_classification
      - REDIS_URL=redis://redis:6379/0
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=DEBUG
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - app-network

  db:
    image: postgres:14
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=vendor_classification
    ports:
      - "5433:5432"
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d vendor_classification"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7
    ports:
      - "6379:6379"
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

networks:
  app-network:
    driver: bridge

volumes:
  postgres_data:
</file>

<file path='docs/1_response_solution design.md'>
# docs/1_response_solution design.md
# NAICS Vendor Classification System Design Document

## 1. Executive Summary

#### Problem Statement
Organizations struggle to efficiently classify their vendors according to industry standards like NAICS (North American Industry Classification System). Manual classification is time-consuming, inconsistent, and prone to errors, making it difficult to maintain accurate vendor databases for analytics, reporting, and compliance purposes.

#### Proposed Solution Overview
Naicsvendorclassification.com is a specialized web application that automates the vendor classification process using advanced AI. The system ingests vendor lists from spreadsheets, normalizes the data, and leverages large language models to accurately categorize vendors according to a four-level hierarchical taxonomy. For vendors that cannot be immediately classified, the system conducts automated web searches to gather additional information before making a determination.

#### Key Benefits and Success Metrics
**Benefits:**
- Reduces vendor classification time from days/weeks to hours
- Provides consistent, standardized categorization
- Enhances data quality for procurement analytics and reporting
- Minimizes manual effort through intelligent automation
- Securely processes vendor information

**Success Metrics:**
- Classification accuracy (>95% target)
- Processing throughput (1,000+ vendors per hour)
- Reduction in manual classification effort (>80%)
- System reliability and uptime (99.9%)
- User satisfaction ratings (>4.5/5)

## 2. System Architecture

#### High-level Architecture Diagram

```
┌────────────────┐     ┌────────────────────┐     ┌──────────────────────┐
│                │     │                    │     │                      │
│  Web Interface │────▶│  Application Core  │────▶│  Processing Engine   │
│                │     │                    │     │                      │
└────────────────┘     └────────────────────┘     └──────────────────────┘
                              │      ▲                   │        ▲
                              │      │                   │        │
                              ▼      │                   ▼        │
┌────────────────┐     ┌────────────────────┐     ┌──────────────────────┐
│                │     │                    │     │                      │
│  File Storage  │◀───▶│  Security Layer    │     │  External APIs       │
│                │     │                    │     │  - OpenRouter        │
└────────────────┘     └────────────────────┘     │  - Tavily Search     │
                                                  └──────────────────────┘
```

#### Key Components and Their Interactions

1. **Web Interface**
   - Simple, intuitive UI for file upload and download
   - Progress monitoring dashboard
   - Authentication system
   - Email notification integration

2. **Application Core**
   - Job management and orchestration
   - File handling and validation
   - User session management
   - Email notification service

3. **Processing Engine**
   - Data ingestion and normalization
   - Vendor batching logic
   - Classification workflow orchestration
   - LLM prompt engineering and response handling
   - Result generation and validation

4. **File Storage**
   - Secure storage for input files
   - Temporary processing data
   - Output files and logs
   - Usage statistics

5. **Security Layer**
   - Authentication and authorization
   - Data sanitization
   - PII/sensitive data filtering
   - Encryption management

6. **External APIs**
   - OpenRouter for vendor classification
   - Tavily Search API for unknown vendor research

#### Technology Stack Recommendations

**Backend:**
- Python 3.11+ for core processing
- FastAPI for RESTful API endpoints
- Pydantic for data validation and modeling
- Celery for asynchronous task processing
- Redis for job queue and caching
- Docker and Docker Compose for containerization

**Frontend:**
- HTML, CSS, JavaScript (Vanilla JS used in current implementation)
- Bootstrap for responsive styling

**Cloud Infrastructure (Example - AWS):**
- EC2 for application hosting
- S3 for file storage
- SES for email delivery
- CloudWatch for monitoring
- IAM for access control

**External Services:**
- OpenRouter for language model processing
- Tavily API for web searches

#### Data Flow Diagram

**Main Processing Flow:**
```
┌───────────┐    ┌───────────────┐    ┌──────────────┐    ┌────────────┐    ┌────────────┐
│           │    │               │    │              │    │            │    │            │
│  Upload   │───▶│  Validation & │───▶│  Normalize & │───▶│  Process   │───▶│  Generate  │
│  Excel    │    │  Sanitization │    │  Deduplicate │    │  Batches   │    │  Output    │
│           │    │               │    │              │    │            │    │            │
└───────────┘    └───────────────┘    └──────────────┘    └────────────┘    └────────────┘
                                                               │
                                                               ▼
┌──────────────────────────────────────────────────────────────────────────────────────────┐
│                                                                                          │
│                               Classification Processing                                  │
│                                                                                          │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐    ┌──────────────┐           │
│  │              │    │              │    │              │    │              │           │
│  │   Level 1    │───▶│   Level 2    │───▶│   Level 3    │───▶│   Level 4    │           │
│  │ Classification│    │ Classification│    │ Classification│    │ Classification│           │
│  │              │    │              │    │              │    │              │           │
│  └──────────────┘    └──────────────┘    └──────────────┘    └──────────────┘           │
│           │                 │                  │                   │                     │
│           ▼                 ▼                  ▼                   ▼                     │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐    ┌──────────────┐           │
│  │  Validate &  │    │  Validate &  │    │  Validate &  │    │  Validate &  │           │
│  │   Process    │    │   Process    │    │   Process    │    │   Process    │           │
│  │  Responses   │    │  Responses   │    │  Responses   │    │  Responses   │           │
│  └──────────────┘    └──────────────┘    └──────────────┘    └──────────────┘           │
│                                                                                          │
└──────────────────────────────────────────────────────────────────────────────────────────┘
                                               │
                                               ▼
                                       ┌─────────────────┐
                                       │                 │
                                       │  Handle Unknown │
                                       │  Vendors with   │
                                       │  Tavily Search  │
                                       │                 │
                                       └─────────────────┘
```

## 3. Detailed Technical Specifications

#### Component Specifications

**1. File Ingestion and Preprocessing Component**

This component handles the initial file upload, validation, and data extraction:

- **Functionality:**
  - Accept Excel files (.xlsx, .xls) containing vendor data
  - Validate file format and required columns (primarily `vendor_name`)
  - Extract vendor names and specified optional context fields (e.g., `vendor_address`, `vendor_website`, `internal_category`, `parent_company`, `spend_category`, `optional_example_good_serviced_purchased`)
  - Normalize vendor names (standardize case, remove duplicates, etc.)
  - Store sanitized data for further processing

- **Input Handling:**
  ```python
  def process_input_file(file_path: str) -> Dict[str, Any]:
      """Process the input Excel file and extract sanitized vendor data."""
      try:
          # Read Excel file
          df = pd.read_excel(file_path)

          # Check required columns
          if 'vendor_name' not in df.columns: # Case-insensitive check done in implementation
              raise ValueError("Required column 'vendor_name' not found")

          # Extract vendor name and optional context fields
          vendors_data = []
          # ... logic to extract based on file_service.py ...

          # Normalize vendor names (title case, remove duplicates)
          normalized_vendors_data = normalize_vendor_data(vendors_data) # Preserves other fields
          unique_vendors_map = {entry['vendor_name']: entry for entry in normalized_vendors_data}
          unique_vendors_list = list(unique_vendors_map.values())

          return {
              "total_records": len(df),
              "unique_vendors": len(unique_vendors_list),
              "vendors_data": unique_vendors_list # List of dicts with unique names and context
          }
      except Exception as e:
          logging.error(f"Error processing input file: {e}")
          raise
  ```

**2. Vendor Classification Component**

This component manages the hierarchical classification process:

- **Functionality:**
  - Create batches of vendors (including context data) for processing
  - Generate appropriate prompts for the LLM using vendor name and optional context
  - Send batches to OpenRouter API
  - Validate responses using Pydantic models and clean/parse JSON
  - Handle the 4-level hierarchical classification process
  - Manage unknown vendor resolution via Tavily Search

- **Classification Workflow:**
  ```python
  async def classify_vendors(vendors_data: List[Dict[str, Any]], taxonomy: Taxonomy) -> Dict[str, Any]:
      """Execute the full vendor classification workflow."""
      # Initialize results storage based on unique vendors
      unique_vendors_map = {vd['vendor_name']: vd for vd in vendors_data}
      results = {vendor_name: {} for vendor_name in unique_vendors_map.keys()}
      stats = {"api_calls": 0, "tokens": 0, "tavily_searches": 0} # Simplified stats example

      # Level 1 classification for all unique vendors
      # Batches contain full vendor dicts
      level1_batches_data = create_batches(list(unique_vendors_map.values()), batch_size=settings.BATCH_SIZE)
      level1_results = await process_level(level1_batches_data, 1, None, taxonomy, llm_service, stats) # Pass services/stats

      # Update results with Level 1 classifications
      for vendor_name, classification in level1_results.items():
          results[vendor_name]["level1"] = classification

      # Process subsequent levels (2-4) based on previous level groupings
      vendors_to_process_next_names = list(unique_vendors_map.keys())
      for level in range(2, 5):
          # Group vendor *names* by previous level classification
          grouped_vendors_names = group_by_parent_category(results, level-1, vendors_to_process_next_names)
          vendors_classified_in_level_names = []

          # Process each group separately
          for parent_category_id, group_vendor_names in grouped_vendors_names.items():
              if not group_vendor_names: continue
              # Get full data for vendors in this group
              group_vendor_data = [unique_vendors_map[name] for name in group_vendor_names if name in unique_vendors_map]
              level_batches_data = create_batches(group_vendor_data, batch_size=settings.BATCH_SIZE)
              level_results = await process_level(
                  level_batches_data, level, parent_category_id, taxonomy, llm_service, stats # Pass services/stats
              )

              # Update results with this level's classifications
              for vendor_name, classification in level_results.items():
                  results[vendor_name][f"level{level}"] = classification
                  if not classification.get("classification_not_possible", False):
                      vendors_classified_in_level_names.append(vendor_name)

          vendors_to_process_next_names = vendors_classified_in_level_names # Update list for next iteration

      # Handle unknown vendors that couldn't be classified
      unknown_vendors_data_to_search = identify_unknown_vendors(results, unique_vendors_map)
      if unknown_vendors_data_to_search:
          unknown_results = await process_unknown_vendors(unknown_vendors_data_to_search, taxonomy, llm_service, search_service, stats) # Pass services/stats
          # Update results with findings from Tavily searches
          for vendor_name, search_result in unknown_results.items():
              results[vendor_name]["search_results"] = search_result

      return {"classifications": results, "stats": stats}
  ```

**3. LLM Integration Component**

This component handles all interactions with OpenRouter:

- **Functionality:**
  - Format appropriate prompts based on taxonomy level and vendor data (name + optional context)
  - Send requests to OpenRouter API
  - Parse and validate JSON responses, handling potential LLM formatting issues (e.g., markdown fences, extra text)
  - Handle errors and retries
  - Track token usage and performance

- **Sample Prompt Generation (Level 1 - Updated):**
  ```python
  def create_classification_prompt(
      vendors_data: List[Dict[str, Any]], # List of vendor dicts
      level: int,
      parent_category: Optional[str] = None,
      taxonomy: Taxonomy,
      batch_id: str = "unique-id"
  ) -> str:
      """Create an appropriate prompt for the current classification level."""
      vendor_list_str = ""
      for i, vendor_entry in enumerate(vendors_data):
          vendor_name = vendor_entry.get('vendor_name', f'UnknownVendor_{i}')
          # Add optional fields (address, website, example, internal_cat, parent_co, spend_cat) if present
          # ... logic from llm_service.py ...
          vendor_list_str += f"\n{i+1}. Vendor Name: {vendor_name}"
          # ... add context lines ...

      if level == 1:
          categories = get_level1_categories(taxonomy)
          categories_str = "\n".join(f"- {cat.id}: {cat.name}" for cat in categories)

          prompt = f"""
          You are a vendor classification expert. Below is a list of vendors with optional context.
          Please classify each vendor according to the following Level 1 categories:

          {categories_str}

          For each vendor, provide:
          1. The most appropriate category ID and name
          2. A confidence level (0.0-1.0)
          Use the provided context (Examples, Address, Website, etc.) if available.

          If you cannot determine a category with reasonable confidence, mark it as "classification_not_possible".

          Vendor list:
          {vendor_list_str}

          **Output Format:** Respond *only* with a valid JSON object matching this exact schema. Do not include any text before or after the JSON object.
          ```json
          {{
            "level": 1,
            "batch_id": "{batch_id}",
            "parent_category_id": null,
            "classifications": [
              {{
                "vendor_name": "Vendor Name",
                "category_id": "ID or N/A",
                "category_name": "Category Name or N/A",
                "confidence": 0.95,
                "classification_not_possible": false,
                "classification_not_possible_reason": null
              }}
              // ... more classifications
            ]
          }}
          ```
          Ensure every vendor from the list is included in the `classifications` array with the exact vendor name provided. Ensure the `batch_id` in the response matches "{batch_id}".
          """
      else:
          # Similar logic for levels 2-4, including the explicit JSON output instruction
          # ...

      return prompt
  ```

**4. Tavily Search Integration Component**

This component handles research for unknown vendors:

- **Functionality:**
  - Format appropriate search queries for unknown vendors
  - Send requests to Tavily API
  - Process search results
  - Feed relevant information back to LLM for classification attempts
  - Track search usage and effectiveness

- **Tavily Integration:**
  ```python
  async def search_vendor_information(vendor_name: str) -> Dict[str, Any]:
      """Search for information about an unknown vendor using Tavily API."""
      search_query = f"{vendor_name} company business type industry"

      try:
          # Use httpx directly as in search_service.py
          payload = {
              "api_key": settings.TAVILY_API_KEY,
              "query": search_query,
              # ... other parameters ...
          }
          async with httpx.AsyncClient() as client:
              response = await client.post(f"{settings.TAVILY_API_BASE}/search", json=payload, timeout=30.0) # Assuming TAVILY_API_BASE is set
              response.raise_for_status()
              search_results = response.json()

          # Extract relevant information from search results
          processed_results = {
              "vendor": vendor_name,
              "search_query": search_query,
              "sources": [
                  {
                      "title": result.get("title", ""),
                      "url": result.get("url", ""),
                      "content": result.get("content", "")[:1500] # Increased limit for LLM
                  }
                  for result in search_results.get("results", []) if result.get("url")
              ],
              "summary": search_results.get("answer", ""),
              "error": None
          }

          return processed_results

      except Exception as e:
          logging.error(f"Tavily API error for vendor '{vendor_name}': {e}")
          return {
              "vendor": vendor_name,
              "error": str(e),
              "search_query": search_query,
              "sources": []
          }
  ```

**5. Result Generation Component**

This component compiles and formats the final output:

- **Functionality:**
  - Aggregate classification results from all levels
  - Format data according to output specifications, including original optional fields provided in input
  - Generate the output Excel file
  - Create logs and usage statistics

- **Result Compilation:**
  ```python
  def generate_output_file(
      original_vendor_data: List[Dict[str, Any]], # Original list of dicts from input
      classification_results: Dict[str, Dict], # Results keyed by unique, normalized name
      output_path: str
  ) -> None:
      """Generate the final output Excel file with classification results."""
      # Prepare data for Excel
      output_data = []

      for original_entry in original_vendor_data:
          vendor_name = original_entry.get('vendor_name') # Use the normalized name
          result = classification_results.get(vendor_name, {})

          # Combine original context with classification results
          row = {
              "vendor_name": vendor_name,
              # Include original optional fields (address, website, example, etc.) from original_entry
              "vendor_address": original_entry.get("vendor_address", ""),
              "vendor_website": original_entry.get("vendor_website", ""),
              "internal_category": original_entry.get("internal_category", ""),
              "parent_company": original_entry.get("parent_company", ""),
              "spend_category": original_entry.get("spend_category", ""),
              "Optional_example_good_serviced_purchased": original_entry.get("example", ""),
              # Classification results
              "level1_category_id": result.get("level1", {}).get("category_id", ""),
              "level1_category_name": result.get("level1", {}).get("category_name", ""),
              "level2_category_id": result.get("level2", {}).get("category_id", ""),
              "level2_category_name": result.get("level2", {}).get("category_name", ""),
              "level3_category_id": result.get("level3", {}).get("category_id", ""),
              "level3_category_name": result.get("level3", {}).get("category_name", ""),
              "level4_category_id": result.get("level4", {}).get("category_id", ""),
              "level4_category_name": result.get("level4", {}).get("category_name", ""),
              # Determine final confidence/status based on logic in file_service.py
              # ... final confidence, classification_not_possible, notes/reason ...
              "sources": ", ".join(
                  source.get("url", "") for source in result.get("search_results", {}).get("sources", []) if isinstance(source, dict) and source.get("url")
              ) if isinstance(result.get("search_results", {}).get("sources"), list) else ""
          }
          output_data.append(row)

      # Create DataFrame and write to Excel using explicit column order
      output_columns = [
          "vendor_name", "vendor_address", "vendor_website", "internal_category",
          "parent_company", "spend_category", "Optional_example_good_serviced_purchased",
          "level1_category_id", "level1_category_name", "level2_category_id", "level2_category_name",
          "level3_category_id", "level3_category_name", "level4_category_id", "level4_category_name",
          "final_confidence", "classification_not_possible", "classification_notes_or_reason", "sources"
      ]
      df = pd.DataFrame(output_data, columns=output_columns)
      df.to_excel(output_path, index=False)
  ```

#### API Definitions and Interfaces

**1. REST API Endpoints**

```
POST /api/v1/upload
- Purpose: Upload vendor Excel file for processing
- Request: multipart/form-data with file and company_name
- Response: {job_id: str, status: str, message: str, created_at: datetime, progress: float, current_stage: str}

GET /api/v1/jobs/{job_id}
- Purpose: Check job status
- Response: {
    job_id: str,
    status: str,
    progress: float,
    current_stage: str,
    created_at: datetime,
    updated_at: datetime,
    estimated_completion: Optional[datetime],
    error_message: Optional[str]
  }

GET /api/v1/jobs/{job_id}/download
- Purpose: Download job results
- Response: Excel file stream

POST /api/v1/jobs/{job_id}/notify
- Purpose: Request email notification when job completes
- Request: {email: str}
- Response: {success: bool, message: str}

GET /api/v1/jobs/{job_id}/stats
- Purpose: Get job processing statistics
- Response: {
    vendors_processed: int,
    unique_vendors: int,
    api_calls: int,
    tokens_used: int,
    tavily_searches: int,
    processing_time: float
  }

POST /token
- Purpose: Authenticate user and get JWT token
- Request: OAuth2PasswordRequestForm (username, password)
- Response: {access_token: str, token_type: str, username: str}

GET /health
- Purpose: Health check endpoint
- Response: {status: str, ...}
```

**2. Internal Component Interfaces**

```python
# TaskQueue Interface (Simplified via Celery)
# LLM Service Interface
class LLMService:
    async def classify_batch(
        self,
        batch_data: List[Dict[str, Any]], # List of vendor dicts
        level: int,
        taxonomy: Taxonomy,
        parent_category: Optional[str] = None
    ) -> Dict[str, Any]:
        """Send a batch of vendors (with context) to LLM for classification."""
        pass

    async def process_search_results(
        self,
        vendor_data: Dict[str, Any], # Vendor dict with context
        search_results: Dict[str, Any],
        taxonomy: Taxonomy
    ) -> Dict[str, Any]:
        """Process search results to determine classification."""
        pass

# Search Service Interface
class SearchService:
    async def search_vendor(self, vendor_name: str) -> Dict[str, Any]:
        """Search for information about a vendor."""
        pass
```

#### Data Models and Schema

**1. Taxonomy Model**

```python
from pydantic import BaseModel, Field
from typing import Dict, List, Optional

class TaxonomyCategory(BaseModel):
    id: str
    name: str
    description: Optional[str] = None

class TaxonomyLevel4(TaxonomyCategory):
    pass

class TaxonomyLevel3(TaxonomyCategory):
    children: Dict[str, TaxonomyLevel4]

class TaxonomyLevel2(TaxonomyCategory):
    children: Dict[str, TaxonomyLevel3]

class TaxonomyLevel1(TaxonomyCategory):
    children: Dict[str, TaxonomyLevel2]

class Taxonomy(BaseModel):
    name: str
    version: str
    description: Optional[str] = None
    categories: Dict[str, TaxonomyLevel1]
```

**2. Classification Models**

```python
class VendorClassification(BaseModel):
    vendor_name: str
    category_id: str
    category_name: str
    confidence: float = Field(ge=0.0, le=1.0)
    notes: Optional[str] = None
    classification_not_possible: bool = False
    classification_not_possible_reason: Optional[str] = None
    sources: Optional[List[Dict[str, str]]] = None

class ClassificationBatchResponse(BaseModel):
    level: int = Field(ge=1, le=4)
    batch_id: str
    parent_category_id: Optional[str] = None
    classifications: List[VendorClassification]
```

**3. Job Models**

```python
from enum import Enum
from datetime import datetime
from sqlalchemy import Column, String, Float, DateTime, Enum as SQLEnum, JSON, Text
from sqlalchemy.sql import func
from core.database import Base # Assuming Base is defined in database.py

class JobStatus(str, Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

class ProcessingStage(str, Enum):
    INGESTION = "ingestion"
    NORMALIZATION = "normalization"
    CLASSIFICATION_L1 = "classification_level_1"
    CLASSIFICATION_L2 = "classification_level_2"
    CLASSIFICATION_L3 = "classification_level_3"
    CLASSIFICATION_L4 = "classification_level_4"
    SEARCH = "search_unknown_vendors"
    RESULT_GENERATION = "result_generation"

class Job(Base): # SQLAlchemy model
    __tablename__ = "jobs"

    id = Column(String, primary_key=True, index=True)
    company_name = Column(String, nullable=False)
    input_file_name = Column(String, nullable=False)
    output_file_name = Column(String, nullable=True)
    status = Column(String, default=JobStatus.PENDING.value)
    current_stage = Column(String, default=ProcessingStage.INGESTION.value)
    progress = Column(Float, default=0.0)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now(), server_default=func.now())
    completed_at = Column(DateTime(timezone=True), nullable=True)
    notification_email = Column(String, nullable=True)
    error_message = Column(Text, nullable=True)
    stats = Column(JSON, default={})
    created_by = Column(String, nullable=False) # Store username of creator

    # Methods to update status/progress/completion/failure
```

**4. Usage Statistics Model**

```python
from typing import Any # For start/end time flexibility

class ApiUsage(BaseModel):
    openrouter_calls: int = 0 # Renamed from azure_openai_calls
    openrouter_prompt_tokens: int = 0 # Renamed
    openrouter_completion_tokens: int = 0 # Renamed
    openrouter_total_tokens: int = 0 # Renamed
    tavily_search_calls: int = 0
    cost_estimate_usd: float = 0.0

class ProcessingStats(BaseModel): # Used within the Job model's JSON field
    job_id: str
    company_name: str
    start_time: Any # Can be datetime or ISO string
    end_time: Optional[Any] = None
    processing_duration_seconds: Optional[float] = None
    total_vendors: int = 0
    unique_vendors: int = 0
    successfully_classified: int = 0 # This may need refinement (e.g., initially vs after search)
    classification_not_possible: int = 0 # See above
    tavily_searches: int = 0
    tavily_search_successful_classifications: int = 0
    api_usage: ApiUsage = Field(default_factory=ApiUsage)
```

#### Security Considerations

**1. Data Protection**

- **Input Data Sanitization:**
  - Automated scanning for PII (SSNs, credit cards, etc.) - *Future Enhancement*
  - Field validation to ensure only necessary data is retained (e.g., vendor name, optional context)
  - Input scrubbing to remove potential injection attacks

- **Storage Security:**
  - All data stored with AES-256 encryption at rest (S3 default or equivalent)
  - Storage bucket policies restricting access
  - Temporary file management with secure deletion

- **Access Controls:**
  - Strict IAM roles and permissions (if using cloud provider)
  - Least privilege access principles
  - Regular access audits

**2. API Security**

- **Authentication:**
  - JWT-based authentication for all API endpoints
  - Token expiration and rotation
  - Rate limiting to prevent abuse

- **External API Protection:**
  - Secure storage of API keys (currently hardcoded, move to environment variables or secrets manager)
  - Regular rotation of API credentials
  - API access monitoring and alerting

**3. Compliance and Privacy**

- **Data Retention:**
  - Automated purging of data after processing (configurable retention period) - *Future Enhancement*
  - Clear data handling policies
  - Audit logs for all data access and operations

- **Transmission Security:**
  - TLS 1.3 for all data in transit
  - Secure headers configuration
  - CORS policy implementation

#### Performance Requirements

**1. Scalability**
- Support for processing files with up to 10,000 vendor entries
- Ability to handle multiple concurrent jobs via Celery workers
- Dynamic batch sizing based on system load (currently fixed)

**2. Processing Speed**
- Average processing time target: <5 seconds per vendor
- Complete job turnaround target: < 1 hour for files with up to 1,000 vendors

**3. API Usage Efficiency**
- Optimal batch sizing to minimize API calls (currently fixed at 5)
- Caching of common vendors to reduce duplicate searches - *Future Enhancement*
- Intelligent retry mechanisms for failed API calls (using Tenacity)

**4. Resource Requirements**
- Minimum EC2 instance (or equivalent): t3.medium for web service and worker (separate or combined depends on load)
- Recommended: t3.large for production workloads
- Memory: Minimum 4GB RAM per service
- Storage: 20GB base + ~1MB per job (input/output/logs)

## 4. Implementation Plan

#### Development Phases

**Phase 1: Core Infrastructure (2 weeks)** - Done
**Phase 2: Data Processing Pipeline (3 weeks)** - Done
**Phase 3: LLM Integration (2 weeks)** - Done (using OpenRouter)
**Phase 4: Unknown Vendor Resolution (2 weeks)** - Done (using Tavily)
**Phase 5: Web Interface and Job Management (2 weeks)** - Done (basic UI/Job tracking)
**Phase 6: Testing and Optimization (2 weeks)** - Ongoing
**Phase 7: Deployment and Monitoring (1 week)** - Done (basic Docker deployment)

#### Dependencies and Prerequisites

**1. Technical Dependencies** - Met
**2. Data Dependencies** - Met (using provided NAICS JSON)
**3. Knowledge Requirements** - Met by current team
**4. External Services Setup** - Met (OpenRouter/Tavily keys hardcoded for now)

## 5. Risks and Mitigation Strategies

#### Technical Risks

| Risk | Impact | Likelihood | Mitigation Strategy |
|------|--------|------------|---------------------|
| LLM response inconsistency/invalid category/format | High | Medium | Implement structured prompts with explicit JSON-only instruction, JSON response format request, robust JSON parsing (handling fences/extra text), post-validation against taxonomy, error handling for invalid JSON/structure, review workflows for low-confidence classifications. |
| API rate limiting or downtime | High | Medium | Use Tenacity for robust retries with exponential backoff, implement API call monitoring, consider fallback mechanisms if critical. |
| Performance bottlenecks with large files | Medium | Medium | Use Celery for asynchronous processing, optimize Pandas operations, monitor resource usage, consider database indexing. |
| Data format inconsistencies in input | Medium | High | Implement robust input validation (e.g., checking for `vendor_name`), flexible parsing (case-insensitive columns), clear error messages to user. |

#### Security Risks

| Risk | Impact | Likelihood | Mitigation Strategy |
|------|--------|------------|---------------------|
| Sensitive data exposure in input/output | Critical | Medium | Remove unnecessary columns during ingestion (`file_service.py`), implement data sanitization checks (*Future*), strict access controls, encryption at rest/transit. |
| API credential compromise | High | Low | Move API keys from config to environment variables/secrets manager, implement credential rotation, add access logging. |
| Unauthorized system access | High | Low | Implement strong authentication (JWT), role-based access (*Future*), security monitoring, regular dependency scanning. |
| Data retention compliance issues | Medium | Medium | Create clear data retention policies with automated enforcement (*Future*), ensure secure deletion of job files. |

#### Operational Risks

| Risk | Impact | Likelihood | Mitigation Strategy |
|------|--------|------------|---------------------|
| Cost overruns from API usage | Medium | Medium | Implement detailed usage tracking per job (stats), monitor API costs, optimize batch sizes/prompts, set budget alerts. |
| Classification accuracy below expectations | High | Medium | Develop feedback mechanisms (*Future*), continuous prompt improvement based on errors/low confidence results, allow manual override (*Future*). |
| User adoption challenges | Medium | Medium | Create intuitive UI, provide clear instructions, add error handling feedback, offer user support channel. |
| Dependency on external APIs | High | Medium | Add caching mechanisms (*Future*), monitor API status, have contingency plans if APIs become unavailable. |

#### Mitigation Approaches

**For LLM Classification Accuracy:**
- Validate LLM category IDs against the loaded taxonomy at each level.
- Set confidence thresholds for flagging uncertain results.
- Log failed/low-confidence classifications for prompt tuning.
- *Future:* Implement user feedback loop or manual review queue.

**For API Dependency Issues:**
- Use Tenacity for retries on network/server errors.
- Implement health checks for external services (*Future*).
- Log detailed API request/response metrics for troubleshooting.

**For Security and Compliance:**
- Regularly update dependencies (e.g., `pip-audit`).
- Move secrets out of code into environment variables or a secrets manager.
- Implement data lifecycle management (*Future*).

**For Cost Management:**
- Track token usage per job in the `Job.stats` field.
- Analyze usage patterns to potentially optimize prompts or batching.
- Set up billing alerts for cloud provider and API services.

</file>

<file path='docs/moving_to_AWS_diagram.md'>
+-------------------------+      +-------------------------+      +-----------------------------+
|   1. Local Dev & Prep   |----->| 2. Containerize & Push  |----->|   3. Provision Core Infra   |
|-------------------------|      |-------------------------|      |-----------------------------|
| - Adapt code for AWS:   |      | - Build Docker images   |      | - Setup VPC & Subnets       |
|   - S3 (boto3)          |      |   (web, worker)         |      |   (Public/Private)          |
|   - RDS (SQLAlchemy)    |      | - Create ECR Repos      |      | - Configure Security Groups |
|   - ElastiCache (Redis) |      | - Authenticate Docker   |      | - Create S3 Bucket          |
|   - SES (boto3)         |      |   with ECR              |      | - Setup Secrets Manager     |
|   - Secrets Mgr/Env Vars|      | - Tag images            |      | - Setup SES (Verification)  |
| - Finalize Dockerfiles  |      | - Push images to ECR    |      |                             |
| - Update requirements.txt|      |                         |      |                             |
|   (add boto3, etc.)     |      |                         |      |                             |
|                         |      |                         |      |                             |
| PAIN POINTS:            |      | PAIN POINTS:            |      | PAIN POINTS:                |
| - Modifying code logic  |      | - Docker build issues   |      | - Complex Networking        |
| - Ensuring AWS SDKs are |      | - ECR auth failures     |      |   (Subnets, Routing)        |
|   correctly used        |      | - Large image sizes     |      | - Security Group rules      |
| - Local testing mock AWS|      | - Slow uploads          |      |   (Overly permissive/restrictive)|
|                         |      |                         |      | - IAM Permissions (Least    |
|                         |      |                         |      |   Privilege is hard)        |
|                         |      |                         |      | - SES domain verification   |
+-----------┬-------------+      +-----------┬-------------+      +--------------┬--------------+
            │                          │                                     │
            ▼                          ▼                                     ▼
+-------------------------+      +-------------------------+      +-----------------------------+
|  4. Provision Compute   |----->| 5. Deploy Application   |----->|  6. Operations & Monitor    |
|      & Services         |      |-------------------------|      |-----------------------------|
|-------------------------|      | - Create ECS Cluster    |      | - Setup CloudWatch Alarms   |
| - Provision RDS Instance|      |   (Fargate)             |      |   (CPU, Memory, Errors)     |
|   (e.g., PostgreSQL)    |      | - Create Task Defs      |      | - Monitor Logs (CW Logs)    |
| - Provision ElastiCache |      |   (web, worker)         |      | - Monitor Costs (Billing)   |
|   (Redis)               |      |   - Link ECR images     |      | - Backup Strategy (RDS, S3) |
| - Create App Load Balancer|      |   - Define resources    |      | - CI/CD Pipeline (Optional) |
|   (ALB)                 |      |   - Inject secrets (Env)|      |   (e.g., CodePipeline)      |
| - Configure Target Groups|      | - Create ECS Services   |      |                             |
|                         |      |   (web -> ALB, worker)  |      |                             |
|                         |      |   - Set desired counts  |      |                             |
|                         |      |   - Networking config   |      |                             |
|                         |      | - Point DNS to ALB      |      |                             |
|                         |      |                         |      |                             |
| PAIN POINTS:            |      | PAIN POINTS:            |      | PAIN POINTS:                |
| - Choosing correct      |      | - ECS Task Def errors   |      | - Log analysis complexity   |
|   instance sizes (Cost) |      |   (Syntax, Permissions) |      | - Alert fatigue/noise       |
| - DB/Cache connectivity |      | - Container startup fails|      | - Unexpected costs          |
|   from ECS              |      |   (Check CloudWatch Logs)|      | - CI/CD setup complexity    |
| - ALB health checks     |      | - Secrets not injected  |      | - Scaling configuration     |
|   failing               |      |   correctly             |      |   tuning                    |
| - IAM roles for tasks   |      | - Networking/SG issues  |      |                             |
|                         |      |   preventing connections|      |                             |
+-------------------------+      +-------------------------+      +-----------------------------+

</file>

<file path='frontend/vue_frontend/README.md'>
# vue_frontend

This template should help get you started developing with Vue 3 in Vite.

## Recommended IDE Setup

[VSCode](https://code.visualstudio.com/) + [Volar](https://marketplace.visualstudio.com/items?itemName=Vue.volar) (and disable Vetur).

## Type Support for `.vue` Imports in TS

TypeScript cannot handle type information for `.vue` imports by default, so we replace the `tsc` CLI with `vue-tsc` for type checking. In editors, we need [Volar](https://marketplace.visualstudio.com/items?itemName=Vue.volar) to make the TypeScript language service aware of `.vue` types.

## Customize configuration

See [Vite Configuration Reference](https://vite.dev/config/).

## Project Setup

```sh
npm install
```

### Compile and Hot-Reload for Development

```sh
npm run dev
```

### Type-Check, Compile and Minify for Production

```sh
npm run build
```

</file>

<file path='frontend/vue_frontend/env.d.ts'>
/// <reference types="vite/client" />

// Add this declaration for *.vue files
declare module '*.vue' {
    import type { DefineComponent } from 'vue'
    const component: DefineComponent<{}, {}, any>
    export default component
  }
</file>

<file path='frontend/vue_frontend/index.html'>
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <link rel="icon" href="/favicon.ico"> <!-- Make sure favicon.ico exists in public/ -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NAICS Vendor Classification</title>
  </head>
  <body>
    <div id="app">
        <!-- Vue app mounts here -->
        <div style="text-align: center; padding: 50px; font-family: sans-serif; color: #666;">Loading Application...</div>
    </div>

    <!-- Vite injects built JS here -->
    <script type="module" src="/src/main.ts"></script>
  </body>
</html>
</file>

<file path='frontend/vue_frontend/postcss.config.js'>
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}

</file>

<file path='frontend/vue_frontend/src/App.vue'>
<template>
  <div class="flex flex-col min-h-screen">
    <Navbar
      :is-logged-in="authStore.isAuthenticated"
      :username="authStore.username"
      @logout="handleLogout"
    />

    <!-- Main content area -->
    <main role="main" class="flex-grow w-full mx-auto pt-16"> <!-- Added pt-16 for fixed navbar -->
      <!-- Render based on viewStore and potentially route -->
      <LandingPage
        v-if="viewStore.currentView === 'landing' && !isResetPasswordRoute"
        @login-successful="handleLoginSuccess"
      />
      <div v-else-if="isResetPasswordRoute" class="max-w-xl mx-auto px-4 sm:px-6 lg:px-8 py-12">
        <!-- ResetPassword component rendered directly based on route -->
        <ResetPassword
          :token="resetToken"
          @close="navigateToLanding"
          @show-login="navigateToLanding"
          @show-forgot-password="navigateToForgotPassword"
        />
      </div>
      <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8" v-else-if="viewStore.currentView === 'app'">
        <!-- AppContent manages JobUpload, JobHistory, JobStatus -->
        <AppContent />
      </div>
      <!-- === UPDATED: Render AdminDashboard for 'admin' view === -->
      <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8" v-else-if="viewStore.currentView === 'admin'">
        <AdminDashboard />
        <!-- Note: UserManagement might be moved *inside* AdminDashboard or accessed via a sub-route/tab there -->
      </div>
      <!-- === END UPDATED === -->
    </main>

    <Footer />
  </div>
</template>

<script setup lang="ts">
import { ref, computed, onMounted, watch } from 'vue';
import Navbar from './components/Navbar.vue';
import LandingPage from './components/LandingPage.vue';
import AppContent from './components/AppContent.vue';
import Footer from './components/Footer.vue';
// import UserManagement from './components/UserManagement.vue'; // Keep if needed elsewhere, remove if only in AdminDashboard
import AdminDashboard from './components/AdminDashboard.vue'; // <<< Import AdminDashboard
import ResetPassword from './components/ResetPassword.vue'; // Import ResetPassword
import { useAuthStore } from './stores/auth';
import { useJobStore } from './stores/job';
import { useViewStore } from './stores/view';

const authStore = useAuthStore();
const jobStore = useJobStore();
const viewStore = useViewStore();

// --- Password Reset Route Handling ---
// This simulates basic routing without Vue Router.
// For a real app, use Vue Router for proper route handling.
const currentPath = ref(window.location.pathname);
const currentSearch = ref(window.location.search); // Track query params
const resetToken = ref('');

const isResetPasswordRoute = computed(() => {
  const match = currentPath.value.match(/^\/reset-password\/(.+)/);
  if (match && match[1]) {
    resetToken.value = match[1]; // Extract token from path
    return true;
  }
  resetToken.value = '';
  return false;
});

// Function to update path on navigation (e.g., history API changes)
const updateRouteInfo = () => {
  currentPath.value = window.location.pathname;
  currentSearch.value = window.location.search;
  console.log("App.vue: Route updated - Path:", currentPath.value, "Search:", currentSearch.value); // Debugging
};

// Simulate navigation (replace with router.push in a real app)
const navigateTo = (path: string, searchParams: URLSearchParams | null = null) => {
    let url = path;
    if (searchParams && searchParams.toString()) {
        url += `?${searchParams.toString()}`;
    }
    window.history.pushState({}, '', url);
    updateRouteInfo(); // Update internal state
    // Reset view store if navigating away from app/admin
    if (path === '/' || path === '/forgot-password') {
        if (!authStore.isAuthenticated) {
            viewStore.setView('landing');
        } else if (viewStore.currentView === 'admin') {
            // If navigating away from admin, switch back to app view
            viewStore.setView('app');
        }
    }
    // If navigating to the main app view, check for job_id
    if (path === '/') { // Assuming '/' is the main app view when logged in
        handleAppNavigation(searchParams);
    }
};

const navigateToLanding = () => navigateTo('/');
const navigateToForgotPassword = () => {
    // In LandingPage, this would typically show the ForgotPassword modal/component
    // Since we don't have full routing, we might just navigate to '/' and rely on LandingPage state
    navigateTo('/');
    // You might need a way to signal LandingPage to show the forgot password form immediately
    // e.g., using a query parameter or a temporary state variable (less ideal)
    // For simplicity, just navigate to landing. The user clicks "Forgot Password" again there.
};


// Update path when browser back/forward buttons are used
window.addEventListener('popstate', updateRouteInfo);

onMounted(() => {
  updateRouteInfo(); // Initial route check
});
// --- End Password Reset Route Handling ---

// --- App Navigation Logic ---
const handleAppNavigation = (searchParams: URLSearchParams | null) => {
    const params = searchParams || new URLSearchParams(currentSearch.value);
    const jobIdFromUrl = params.get('job_id');
    console.log("App.vue: Handling app navigation. Job ID from URL:", jobIdFromUrl); // Debugging
    // If authenticated and a job ID is present, set it in the store
    // Let the store decide if it's a new ID or a refresh
    if (authStore.isAuthenticated && jobIdFromUrl) {
        console.log(`App.vue: Setting Job ID from URL: ${jobIdFromUrl}`);
        jobStore.setCurrentJobId(jobIdFromUrl);
    } else if (authStore.isAuthenticated && !jobIdFromUrl && jobStore.currentJobId) {
         // If authenticated and URL has no job_id, but store has one, clear it
         console.log(`App.vue: URL has no job_id, clearing store's currentJobId.`);
         jobStore.setCurrentJobId(null);
    }
};


const handleLogout = () => {
  authStore.logout();
  jobStore.clearJob();
  viewStore.setView('landing');
  navigateToLanding(); // Go to landing page URL
};

const handleLoginSuccess = () => {
  console.log('Login successful, App.vue notified.');
  viewStore.setView('app'); // Default to app view on login
  authStore.fetchCurrentUserDetails();
  // Check URL for job_id immediately after login
  const urlParams = new URLSearchParams(window.location.search);
  handleAppNavigation(urlParams);
};

// Watch auth state to set initial view (excluding reset password route)
watch(() => authStore.isAuthenticated, (isAuth, wasAuth) => {
  console.log("App.vue: Auth state changed:", isAuth); // Debugging
  if (!isResetPasswordRoute.value) { // Only change view if not on reset password page
    if (isAuth && viewStore.currentView === 'landing') {
      console.log("App.vue: Auth true, setting view to 'app'");
      viewStore.setView('app'); // Default to app view
      // Check URL for job_id when becoming authenticated
      const urlParams = new URLSearchParams(window.location.search);
      handleAppNavigation(urlParams);
    } else if (!isAuth && wasAuth) { // Only switch to landing if user was previously authenticated (i.e., logged out)
      console.log("App.vue: Auth false, setting view to 'landing'");
      viewStore.setView('landing');
    }
  }
}, { immediate: false }); // Change immediate to false to avoid race conditions on initial load

// Watch for route changes (path or search) to potentially update view or job ID
watch([currentPath, currentSearch], ([newPath, newSearch], [_oldPath, oldSearch]) => {
    console.log("App.vue: Route watcher triggered. New Path:", newPath, "New Search:", newSearch); // Debugging
    if (!isResetPasswordRoute.value && !authStore.isAuthenticated) {
        console.log("App.vue: Not reset route, not authenticated, setting view to landing.");
        viewStore.setView('landing');
    } else if (authStore.isAuthenticated && viewStore.currentView !== 'admin') { // Only adjust job ID if not in admin view
        // If already in the app view, check if the job_id param changed
        const oldParams = new URLSearchParams(oldSearch);
        const newParams = new URLSearchParams(newSearch);
        const oldJobId = oldParams.get('job_id');
        const newJobId = newParams.get('job_id');

        if (newJobId !== oldJobId) {
             console.log(`App.vue: job_id param changed from ${oldJobId} to ${newJobId}. Updating store.`);
             jobStore.setCurrentJobId(newJobId); // Let the store handle null/new value
        }
    }
    // Add other route-based view logic if needed
}, { deep: true }); // Use deep watch if needed, though path/search are primitive


onMounted(() => {
    authStore.checkAuthStatus();
    // Rely on the watcher for isAuthenticated to handle logic after status check

    // Initial setup based on current state after checkAuthStatus might have run
    console.log("App.vue: onMounted - Initial state check. Auth state:", authStore.isAuthenticated);
    updateRouteInfo(); // Ensure route info is current
    if (authStore.isAuthenticated) {
      authStore.fetchCurrentUserDetails();
      // Set initial view based on auth state *after* checking auth
      if (!isResetPasswordRoute.value) {
          // Don't force 'app' view here if 'admin' might be intended (e.g., from Navbar click)
          // The Navbar click handler should set the view correctly.
          // If landing page is shown initially, the auth watcher will switch to 'app'.
          if (viewStore.currentView === 'landing') {
              viewStore.setView('app');
          }
      }
      handleAppNavigation(null); // Check URL for job_id after auth check
    } else {
       if (!isResetPasswordRoute.value) {
         viewStore.setView('landing');
       }
    }
});

// Cleanup listener on unmount
import { onUnmounted } from 'vue';
onUnmounted(() => {
  window.removeEventListener('popstate', updateRouteInfo);
});
</script>

<style>
/* Ensure html, body, and #app take full height if needed */
html, body, #app {
  height: 100%;
  margin: 0;
}
/* Add padding to the top of the main content area to account for the fixed navbar */
main[role="main"] {
  padding-top: 4rem; /* Adjust this value based on your navbar's height (h-16 = 4rem) */
}
</style>
</file>

<file path='frontend/vue_frontend/src/assets/base.css'>
/* color palette from <https://github.com/vuejs/theme> */
:root {
  --vt-c-white: #ffffff;
  --vt-c-white-soft: #f8f8f8;
  --vt-c-white-mute: #f2f2f2;

  --vt-c-black: #181818;
  --vt-c-black-soft: #222222;
  --vt-c-black-mute: #282828;

  --vt-c-indigo: #2c3e50;

  --vt-c-divider-light-1: rgba(60, 60, 60, 0.29);
  --vt-c-divider-light-2: rgba(60, 60, 60, 0.12);
  --vt-c-divider-dark-1: rgba(84, 84, 84, 0.65);
  --vt-c-divider-dark-2: rgba(84, 84, 84, 0.48);

  --vt-c-text-light-1: var(--vt-c-indigo);
  --vt-c-text-light-2: rgba(60, 60, 60, 0.66);
  --vt-c-text-dark-1: var(--vt-c-white);
  --vt-c-text-dark-2: rgba(235, 235, 235, 0.64);
}

/* semantic color variables for this project */
:root {
  --color-background: var(--vt-c-white);
  --color-background-soft: var(--vt-c-white-soft);
  --color-background-mute: var(--vt-c-white-mute);

  --color-border: var(--vt-c-divider-light-2);
  --color-border-hover: var(--vt-c-divider-light-1);

  --color-heading: var(--vt-c-text-light-1);
  --color-text: var(--vt-c-text-light-1);

  --section-gap: 160px;
}

@media (prefers-color-scheme: dark) {
  :root {
    --color-background: var(--vt-c-black);
    --color-background-soft: var(--vt-c-black-soft);
    --color-background-mute: var(--vt-c-black-mute);

    --color-border: var(--vt-c-divider-dark-2);
    --color-border-hover: var(--vt-c-divider-dark-1);

    --color-heading: var(--vt-c-text-dark-1);
    --color-text: var(--vt-c-text-dark-2);
  }
}

*,
*::before,
*::after {
  box-sizing: border-box;
  margin: 0;
  font-weight: normal;
}

body {
  min-height: 100vh;
  color: var(--color-text);
  background: var(--color-background);
  transition:
    color 0.5s,
    background-color 0.5s;
  line-height: 1.6;
  font-family:
    Inter,
    -apple-system,
    BlinkMacSystemFont,
    'Segoe UI',
    Roboto,
    Oxygen,
    Ubuntu,
    Cantarell,
    'Fira Sans',
    'Droid Sans',
    'Helvetica Neue',
    sans-serif;
  font-size: 15px;
  text-rendering: optimizeLegibility;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

</file>

<file path='frontend/vue_frontend/src/assets/main.css'>
@import './base.css';

#app {
  max-width: 1280px;
  margin: 0 auto;
  padding: 2rem;
  font-weight: normal;
}

a,
.green {
  text-decoration: none;
  color: hsla(160, 100%, 37%, 1);
  transition: 0.4s;
  padding: 3px;
}

@media (hover: hover) {
  a:hover {
    background-color: hsla(160, 100%, 37%, 0.2);
  }
}

@media (min-width: 1024px) {
  body {
    display: flex;
    place-items: center;
  }

  #app {
    display: grid;
    grid-template-columns: 1fr 1fr;
    padding: 0 2rem;
  }
}

</file>

<file path='frontend/vue_frontend/src/assets/styles.css'>
@tailwind base;
@tailwind components;
@tailwind utilities;

/* Optional: Add any global base styles here if needed */
body {
  @apply font-sans antialiased bg-light text-gray-800; /* Example base styles using tailwind */
   padding-top: 4rem; /* Adjust for fixed navbar height */
}
</file>

<file path='frontend/vue_frontend/src/components/AdminDashboard.vue'>
<template>
  <div class="space-y-8">
    <h1 class="text-3xl font-bold text-gray-800">Admin Dashboard</h1>

    <!-- System Stats Section -->
    <section>
      <h2 class="text-xl font-semibold text-gray-700 mb-4">System Overview</h2>
      <div v-if="adminStore.loadingStats" class="text-center py-4">
        <p class="text-gray-500">Loading system statistics...</p>
        <!-- Optional: Add a spinner -->
      </div>
      <div v-else-if="adminStore.errorStats" class="bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded relative" role="alert">
        <strong class="font-bold">Error!</strong>
        <span class="block sm:inline"> Could not load system statistics: {{ adminStore.errorStats }}</span>
      </div>
      <div v-else-if="adminStore.systemStats" class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-4 gap-4">
        <!-- Stat Cards -->
        <StatCard title="Total Users" :value="adminStore.systemStats.total_users" icon="users" />
        <StatCard title="Total Jobs" :value="adminStore.systemStats.total_jobs" icon="briefcase" />
        <StatCard title="Active Jobs" :value="adminStore.systemStats.pending_jobs + adminStore.systemStats.processing_jobs" icon="cog" />
        <StatCard title="Failed Jobs (24h)" :value="adminStore.systemStats.failed_jobs_last_24h" icon="exclamation-triangle" :error="adminStore.systemStats.failed_jobs_last_24h > 0" />
        <StatCard title="Completed Jobs" :value="adminStore.systemStats.completed_jobs" icon="check-circle" />
        <!-- Add more cards as needed, e.g., for cost -->
      </div>
    </section>

    <!-- Recent Jobs Section -->
    <section>
      <h2 class="text-xl font-semibold text-gray-700 mb-4">Recent Jobs</h2>
       <div v-if="adminStore.loadingJobs" class="text-center py-4">
        <p class="text-gray-500">Loading recent jobs...</p>
      </div>
      <div v-else-if="adminStore.errorJobs" class="bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded relative" role="alert">
        <strong class="font-bold">Error!</strong>
        <span class="block sm:inline"> Could not load recent jobs: {{ adminStore.errorJobs }}</span>
      </div>
      <div v-else-if="adminStore.recentJobs && adminStore.recentJobs.length > 0" class="overflow-x-auto bg-white shadow rounded-lg">
        <table class="min-w-full divide-y divide-gray-200">
          <thead class="bg-gray-50">
            <tr>
              <th scope="col" class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Job ID</th>
              <th scope="col" class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Company</th>
              <th scope="col" class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">User</th>
              <th scope="col" class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Type</th>
              <th scope="col" class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Status</th>
              <th scope="col" class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Created At</th>
            </tr>
          </thead>
          <tbody class="bg-white divide-y divide-gray-200">
            <tr v-for="job in adminStore.recentJobs" :key="job.id">
              <td class="px-6 py-4 whitespace-nowrap text-sm font-medium text-gray-900 truncate" :title="job.id">
                {{ job.id.substring(0, 8) }}...
              </td>
               <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500 truncate" :title="job.company_name">
                {{ job.company_name }}
              </td>
              <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500">
                {{ job.created_by }}
              </td>
              <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500">
                <span :class="['px-2 inline-flex text-xs leading-5 font-semibold rounded-full', jobTypeClass(job.job_type)]">
                  {{ job.job_type }}
                </span>
              </td>
              <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500">
                <span :class="['px-2 inline-flex text-xs leading-5 font-semibold rounded-full', statusClass(job.status)]">
                  {{ job.status }}
                </span>
              </td>
              <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500">
                {{ formatDateTime(job.created_at) }}
              </td>
            </tr>
          </tbody>
        </table>
      </div>
       <div v-else class="text-center py-4">
        <p class="text-gray-500">No recent jobs found.</p>
      </div>
    </section>

    <!-- Health Check Section -->
     <section>
      <h2 class="text-xl font-semibold text-gray-700 mb-4">System Health</h2>
        <div v-if="adminStore.loadingStats" class="text-center py-4">
            <p class="text-gray-500">Loading health status...</p>
        </div>
        <div v-else-if="adminStore.errorStats" class="bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded relative" role="alert">
            <strong class="font-bold">Error!</strong>
            <span class="block sm:inline"> Could not load health status: {{ adminStore.errorStats }}</span>
        </div>
        <div v-else-if="adminStore.systemStats?.health_status" class="bg-white shadow rounded-lg p-4 space-y-2">
            <div v-for="(value, key) in adminStore.systemStats.health_status" :key="key" class="flex justify-between items-center text-sm">
                <span class="text-gray-600 capitalize">{{ key.replace(/_/g, ' ') }}:</span>
                <span :class="['font-medium', healthStatusClass(key, value)]">
                    {{ formatHealthValue(value) }}
                </span>
            </div>
        </div>
     </section>

     <!-- Consider adding User Management here as a sub-section -->
     <!-- <section>
        <h2 class="text-xl font-semibold text-gray-700 mb-4">User Management</h2>
        <UserManagement />
     </section> -->

  </div>
</template>

<script setup lang="ts">
import { onMounted } from 'vue';
import { useAdminStore } from '@/stores/admin'; // Ensure this path is correct
import StatCard from './StatCard.vue'; // Assuming you create this component
// import UserManagement from './UserManagement.vue'; // Import if embedding UserManagement

const adminStore = useAdminStore();

onMounted(() => {
  adminStore.fetchSystemStats();
  adminStore.fetchRecentJobs();
});

// --- Helper Functions for Display ---

const formatDateTime = (isoString: string | Date): string => {
  if (!isoString) return 'N/A';
  try {
    const date = typeof isoString === 'string' ? new Date(isoString) : isoString;
    return date.toLocaleString(undefined, {
      year: 'numeric', month: 'short', day: 'numeric',
      hour: '2-digit', minute: '2-digit'
    });
  } catch (e) {
    console.error("Error formatting date:", isoString, e);
    return 'Invalid Date';
  }
};

const statusClass = (status: string): string => {
  switch (status?.toLowerCase()) {
    case 'completed': return 'bg-green-100 text-green-800';
    case 'processing': return 'bg-blue-100 text-blue-800';
    case 'pending': return 'bg-yellow-100 text-yellow-800';
    case 'failed': return 'bg-red-100 text-red-800';
    default: return 'bg-gray-100 text-gray-800';
  }
};

const jobTypeClass = (type: string): string => {
  switch (type?.toUpperCase()) {
    case 'CLASSIFICATION': return 'bg-purple-100 text-purple-800';
    case 'REVIEW': return 'bg-pink-100 text-pink-800';
    default: return 'bg-gray-100 text-gray-800';
  }
};

const formatHealthValue = (value: any): string => {
    if (typeof value === 'boolean') {
        return value ? 'Yes' : 'No';
    }
    if (value === null || value === undefined) {
        return 'N/A';
    }
    if (typeof value === 'string' && value.startsWith('error:')) {
        return value.substring(6); // Remove 'error: ' prefix for display
    }
    // Truncate long strings (like detailed error messages)
    if (typeof value === 'string' && value.length > 50) {
        return value.substring(0, 47) + '...';
    }
    return String(value);
};

// --- UPDATED: Prefixed unused 'key' parameter with underscore ---
const healthStatusClass = (_key: string, value: any): string => {
    const stringValue = String(value).toLowerCase();

    if (stringValue.includes('error') || stringValue.includes('failed') || stringValue === 'missing' || value === false) {
        return 'text-red-600';
    }
    if (stringValue.includes('unknown') || stringValue.includes('placeholder')) {
        return 'text-yellow-600';
    }
    if (stringValue.includes('connected') || stringValue.includes('healthy') || stringValue === 'found' || stringValue === 'configured' || stringValue === 'api functional' || value === true) {
        return 'text-green-600';
    }
    return 'text-gray-700'; // Default
};
// --- END UPDATED ---

</script>

<style scoped>
/* Add any specific styles if needed */
.truncate {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}
</style>
</file>

<file path='frontend/vue_frontend/src/components/AppContent.vue'>
<template>
  <div class="space-y-8 md:space-y-12"> <!-- Adds vertical space between children -->
      <!-- Upload Form Section -->
      <section aria-labelledby="upload-heading">
          <div class="max-w-2xl mx-auto">
              <h2 id="upload-heading" class="sr-only">Upload Vendor File</h2> <!-- Screen reader heading -->
              <UploadForm @upload-successful="handleUploadSuccess" />
          </div>
      </section>

       <!-- Job Status Section (for currently selected job) -->
      <section aria-labelledby="status-heading" v-if="jobStore.currentJobId">
          <div class="max-w-4xl mx-auto">
              <h2 id="status-heading" class="sr-only">Current Job Status and Results</h2> <!-- Screen reader heading -->
              <JobStatus :key="jobStore.currentJobId" />
              <!-- key forces re-render if job ID changes -->
          </div>
      </section>

      <!-- Placeholder if no job active and logged in -->
      <div v-else class="text-center py-16 text-gray-500 bg-white rounded-lg shadow border border-gray-200 max-w-4xl mx-auto">
          <p class="text-lg mb-2">No active job selected.</p>
          <p>Upload a file above to start a new classification, or select a job from the history below.</p>
      </div>

      <!-- Job History Section -->
      <section aria-labelledby="history-heading">
          <div class="max-w-6xl mx-auto"> <!-- Wider container for table -->
               <h2 id="history-heading" class="sr-only">Job History</h2> <!-- Screen reader heading -->
               <JobHistory />
          </div>
      </section>

  </div>
</template>

<script setup lang="ts">
import UploadForm from './UploadForm.vue';
import JobStatus from './JobStatus.vue';
import JobHistory from './JobHistory.vue'; // <-- Import JobHistory
import { useJobStore } from '@/stores/job';

const jobStore = useJobStore();

const handleUploadSuccess = (jobId: string) => {
  console.log(`AppContent: Received upload-successful event for job ${jobId}`);
  jobStore.setCurrentJobId(jobId);
  // Optionally trigger a refresh of the history list after a short delay
  setTimeout(() => {
      jobStore.fetchJobHistory({ limit: 100 });
  }, 1500);
};
</script>

<style scoped>
/* No scoped styles needed */
</style>
</file>

<file path='frontend/vue_frontend/src/components/Footer.vue'>
<template>
  <footer class="mt-auto py-4 bg-gray-100 border-t border-gray-200">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
      <span class="text-sm text-gray-500">© {{ currentYear }} Vendor Classification Inc. All Rights Reserved.</span>
    </div>
  </footer>
</template>

<script setup lang="ts">
import { computed } from 'vue';
const currentYear = computed(() => new Date().getFullYear());
</script>

<style scoped>
/* Footer is simple, scoped styles likely not needed */
</style>
</file>

<file path='frontend/vue_frontend/src/components/ForgotPassword.vue'>

<template>
    <div class="bg-white rounded-lg shadow-md overflow-hidden border border-gray-200">
    <div class="bg-gray-100 p-4 border-b border-gray-200 flex justify-between items-center">
        <h4 class="text-lg font-semibold text-gray-700 mb-0">Forgot Password</h4>
        <button @click="$emit('close')" class="text-gray-500 hover:text-gray-700 text-xl">&times;</button>
    </div>
    <div class="p-6">
        <p class="text-sm text-gray-600 mb-4">
        Enter the email address associated with your account, and we'll send you a link to reset your password.
        </p>
        <form @submit.prevent="handleRequestReset">
        <div class="mb-4">
            <label for="email" class="block text-sm font-medium text-gray-700 mb-1">Email Address</label>
            <input
            type="email"
            class="block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-50"
            id="email"
            v-model="email"
            required
            :disabled="isLoading || emailSent"
            placeholder="you@example.com"
            />
        </div>

        <button
            type="submit"
            class="w-full flex justify-center items-center px-4 py-2.5 border border-transparent rounded-md shadow-sm text-base font-medium text-white bg-primary hover:bg-primary-hover focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-primary disabled:opacity-50 disabled:cursor-not-allowed"
            :disabled="isLoading || emailSent"
        >
            <svg v-if="isLoading" class="animate-spin -ml-1 mr-3 h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
            <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
            <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
            </svg>
            {{ buttonText }}
        </button>

        <!-- Success/Error Messages -->
        <div v-if="message" :class="['mt-4 p-3 rounded-md text-center text-sm', messageType === 'success' ? 'bg-green-100 border border-green-300 text-green-700' : 'bg-red-100 border border-red-300 text-red-700']">
            {{ message }}
        </div>
        </form>
        <div class="mt-4 text-center">
            <button @click="$emit('show-login')" class="text-sm text-primary hover:underline">
            Back to Login
            </button>
        </div>
    </div>
    </div>
</template>

<script setup lang="ts">
import { ref, computed } from 'vue';
import apiService from '@/services/api'; // Adjust path as needed

const emit = defineEmits(['close', 'show-login']);

const email = ref('');
const isLoading = ref(false);
const message = ref<string | null>(null);
const messageType = ref<'success' | 'error'>('success'); // 'success' or 'error'
const emailSent = ref(false); // Flag to disable form after success

const buttonText = computed(() => {
    if (isLoading.value) return 'Sending...';
    if (emailSent.value) return 'Instructions Sent';
    return 'Send Reset Link';
});

const handleRequestReset = async () => {
    isLoading.value = true;
    message.value = null;
    messageType.value = 'success';

    try {
    const response = await apiService.requestPasswordRecovery(email.value);
    message.value = response.message; // Use message from API
    messageType.value = 'success';
    emailSent.value = true; // Disable form on success
    // Optionally close the form after a delay
    // setTimeout(() => emit('close'), 5000);
    } catch (error: any) {
    console.error('Forgot Password error:', error);
    message.value = error.message || 'An unexpected error occurred.';
    messageType.value = 'error';
    emailSent.value = false; // Keep form enabled on error
    } finally {
    isLoading.value = false;
    }
};
</script>

<style scoped>
/* Add any specific styles if needed */
</style>
</file>

<file path='frontend/vue_frontend/src/components/HintInputModal.vue'>
<template>
  <TransitionRoot as="template" :show="open">
    <Dialog as="div" class="relative z-10" @close="closeModal">
      <TransitionChild as="template" enter="ease-out duration-300" enter-from="opacity-0" enter-to="opacity-100" leave="ease-in duration-200" leave-from="opacity-100" leave-to="opacity-0">
        <div class="fixed inset-0 bg-gray-500 bg-opacity-75 transition-opacity" />
      </TransitionChild>

      <div class="fixed inset-0 z-10 overflow-y-auto">
        <div class="flex min-h-full items-end justify-center p-4 text-center sm:items-center sm:p-0">
          <TransitionChild as="template" enter="ease-out duration-300" enter-from="opacity-0 translate-y-4 sm:translate-y-0 sm:scale-95" enter-to="opacity-100 translate-y-0 sm:scale-100" leave="ease-in duration-200" leave-from="opacity-100 translate-y-0 sm:scale-100" leave-to="opacity-0 translate-y-4 sm:translate-y-0 sm:scale-95">
            <DialogPanel class="relative transform overflow-hidden rounded-lg bg-white text-left shadow-xl transition-all sm:my-8 sm:w-full sm:max-w-lg">
              <div class="bg-white px-4 pb-4 pt-5 sm:p-6 sm:pb-4">
                <div class="sm:flex sm:items-start">
                  <div class="mx-auto flex h-12 w-12 flex-shrink-0 items-center justify-center rounded-full bg-blue-100 sm:mx-0 sm:h-10 sm:w-10">
                    <PencilSquareIcon class="h-6 w-6 text-blue-600" aria-hidden="true" />
                  </div>
                  <div class="mt-3 text-center sm:ml-4 sm:mt-0 sm:text-left w-full">
                    <DialogTitle as="h3" class="text-base font-semibold leading-6 text-gray-900">Provide Reclassification Hint</DialogTitle>
                    <div class="mt-2">
                      <p class="text-sm text-gray-600 mb-1">For Vendor: <strong class="font-medium">{{ vendorName }}</strong></p>
                      <p class="text-sm text-gray-500">
                        Please provide a concise hint to help the system re-classify this vendor accurately. Examples: "supplier of laboratory chemicals", "provides marketing consulting services", "industrial fastener manufacturer".
                      </p>
                      <div class="mt-4">
                        <label for="hint" class="sr-only">Hint</label>
                        <textarea
                          id="hint"
                          name="hint"
                          rows="3"
                          v-model="localHint"
                          class="block w-full rounded-md border-0 py-1.5 text-gray-900 shadow-sm ring-1 ring-inset ring-gray-300 placeholder:text-gray-400 focus:ring-2 focus:ring-inset focus:ring-primary sm:text-sm sm:leading-6"
                          placeholder="Enter hint here..."
                        />
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div class="bg-gray-50 px-4 py-3 sm:flex sm:flex-row-reverse sm:px-6">
                <button
                  type="button"
                  class="inline-flex w-full justify-center rounded-md bg-primary px-3 py-2 text-sm font-semibold text-white shadow-sm hover:bg-primary-dark focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-primary sm:ml-3 sm:w-auto disabled:opacity-50"
                  @click="saveHint"
                  :disabled="!localHint || localHint.trim() === ''"
                >
                  Save Hint
                </button>
                <button
                  type="button"
                  class="mt-3 inline-flex w-full justify-center rounded-md bg-white px-3 py-2 text-sm font-semibold text-gray-900 shadow-sm ring-1 ring-inset ring-gray-300 hover:bg-gray-50 sm:mt-0 sm:w-auto"
                  @click="closeModal"
                  ref="cancelButtonRef"
                >
                  Cancel
                </button>
              </div>
            </DialogPanel>
          </TransitionChild>
        </div>
      </div>
    </Dialog>
  </TransitionRoot>
</template>

<script setup lang="ts">
import { ref, watch, type PropType } from 'vue'
import { Dialog, DialogPanel, DialogTitle, TransitionChild, TransitionRoot } from '@headlessui/vue'
import { PencilSquareIcon } from '@heroicons/vue/24/outline'

const props = defineProps({
  open: {
    type: Boolean,
    required: true,
  },
  vendorName: {
    type: String,
    required: true,
  },
  initialHint: {
    type: String as PropType<string | null>,
    default: null,
  },
})

const emit = defineEmits(['close', 'save'])

const localHint = ref(props.initialHint || '');

watch(() => props.initialHint, (newVal) => {
  localHint.value = newVal || '';
});

watch(() => props.open, (newVal) => {
  if (newVal) {
    // Reset local hint when modal opens, based on potentially updated prop
    localHint.value = props.initialHint || '';
  }
});


const closeModal = () => {
  emit('close');
}

const saveHint = () => {
  if (localHint.value && localHint.value.trim() !== '') {
    emit('save', localHint.value.trim());
    closeModal();
  }
}
</script>
</file>

<file path='frontend/vue_frontend/src/components/JobHistory.vue'>
<template>
    <div class="mt-10 bg-white rounded-lg shadow-lg overflow-hidden border border-gray-200">
      <div class="bg-gray-100 text-gray-800 p-4 sm:p-5 border-b border-gray-200">
        <h4 class="text-xl font-semibold mb-0">Job History</h4>
      </div>
      <div class="p-6 sm:p-8">
        <!-- Loading State -->
        <div v-if="historyLoading" class="text-center text-gray-500 py-8">
          <svg class="animate-spin inline-block h-6 w-6 text-primary mr-2" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
            <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
            <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
          </svg>
          <span>Loading job history...</span>
        </div>

        <!-- Error State -->
        <div v-else-if="historyError" class="p-4 bg-red-100 border border-red-300 text-red-800 rounded-md text-sm flex items-center">
          <ExclamationTriangleIcon class="h-5 w-5 mr-2 text-red-600 flex-shrink-0"/>
          <span>Error loading history: {{ historyError }}</span>
        </div>

        <!-- Empty State -->
        <div v-else-if="!jobHistory || jobHistory.length === 0" class="text-center text-gray-500 py-8">
          <p>No job history found.</p>
          <p class="text-sm">Upload a file to start your first job.</p>
        </div>

        <!-- History Table -->
        <div v-else class="overflow-x-auto">
          <table class="min-w-full divide-y divide-gray-200">
            <thead class="bg-gray-50">
              <tr>
                <th scope="col" class="px-4 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Job ID
                </th>
                <th scope="col" class="px-4 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Type
                </th>
                <th scope="col" class="px-4 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Company
                </th>
                <th scope="col" class="px-4 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Status
                </th>
                <th scope="col" class="px-4 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Created
                </th>
                <th scope="col" class="px-4 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                  Actions
                </th>
              </tr>
            </thead>
            <tbody class="bg-white divide-y divide-gray-200">
              <tr v-for="job in jobHistory" :key="job.id" class="hover:bg-gray-50 cursor-pointer" @click="selectJob(job.id)">
                <td class="px-4 py-3 whitespace-nowrap text-xs font-mono text-gray-700">
                  {{ job.id.substring(0, 8) }}...
                </td>
                <td class="px-4 py-3 whitespace-nowrap">
                     <span v-if="job.job_type === 'REVIEW'" class="inline-block px-1.5 py-0.5 rounded text-xs font-semibold bg-purple-100 text-purple-800 align-middle">REVIEW</span>
                     <span v-else-if="job.job_type === 'CLASSIFICATION'" class="inline-block px-1.5 py-0.5 rounded text-xs font-semibold bg-blue-100 text-blue-800 align-middle">CLASSIFICATION</span>
                     <span v-else class="text-xs text-gray-500">{{ job.job_type }}</span>
                 </td>
                <td class="px-4 py-3 whitespace-nowrap text-sm text-gray-800 font-medium">
                  {{ job.company_name }}
                </td>
                <td class="px-4 py-3 whitespace-nowrap">
                  <span class="px-2.5 py-0.5 rounded-full text-xs font-bold uppercase tracking-wide" :class="getStatusBadgeClass(job.status)">
                    {{ job.status }}
                  </span>
                </td>
                <td class="px-4 py-3 whitespace-nowrap text-sm text-gray-500">
                  {{ formatDateTime(job.created_at) }}
                </td>
                <td class="px-4 py-3 whitespace-nowrap text-right text-sm font-medium">
                  <!-- Download only for completed CLASSIFICATION jobs -->
                  <button
                    v-if="job.status === 'completed' && job.job_type === 'CLASSIFICATION'"
                    @click.stop="downloadResults(job.id, $event)"
                    :disabled="isDownloadLoading(job.id)"
                    class="text-primary hover:text-primary-hover disabled:opacity-50 disabled:cursor-not-allowed inline-flex items-center"
                    title="Download Results"
                  >
                     <svg v-if="isDownloadLoading(job.id)" class="animate-spin h-4 w-4 text-primary" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                        <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                        <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                     </svg>
                     <ArrowDownTrayIcon v-else class="h-4 w-4" />
                    <!-- <span class="ml-1">Download</span> -->
                  </button>
                  <span v-else-if="job.status === 'failed'" class="text-red-500 text-xs italic" title="Job Failed">Failed</span>
                  <span v-else-if="job.job_type === 'REVIEW' && job.status === 'completed'" class="text-gray-400 text-xs italic" title="Review Job Completed (No Download)">Merged/Done</span>
                  <span v-else class="text-gray-400 text-xs italic" title="Processing or Pending">In Progress</span>
                  <!-- Add View Details button if needed -->
                  <!-- <button @click.stop="selectJob(job.id)" class="text-indigo-600 hover:text-indigo-900 ml-3">View</button> -->
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <!-- TODO: Add Pagination Controls if needed -->

      </div>
    </div>
  </template>

  <script setup lang="ts">
  import { computed, onMounted, ref } from 'vue';
  import { useJobStore } from '@/stores/job';
  import { ExclamationTriangleIcon, ArrowDownTrayIcon } from '@heroicons/vue/20/solid';
  import apiService from '@/services/api';

  const jobStore = useJobStore();

  const jobHistory = computed(() => jobStore.jobHistory);
  const historyLoading = computed(() => jobStore.historyLoading);
  const historyError = computed(() => jobStore.historyError);

  // State for managing individual download button loading
  const downloadingJobs = ref<Set<string>>(new Set());
  const downloadErrors = ref<Record<string, string | null>>({});

  const isDownloadLoading = (jobId: string) => downloadingJobs.value.has(jobId);

  const fetchHistory = async () => {
    await jobStore.fetchJobHistory({ limit: 100 }); // Fetch latest 100 jobs on mount
  };

  const selectJob = (jobId: string) => {
    console.log(`JobHistory: Selecting job ${jobId}`);
    jobStore.setCurrentJobId(jobId);
    // Optional: Scroll to the top or to the JobStatus component
    window.scrollTo({ top: 0, behavior: 'smooth' });
  };

  const formatDateTime = (isoString: string | null | undefined): string => {
    if (!isoString) return 'N/A';
    try {
      return new Date(isoString).toLocaleString(undefined, {
        year: 'numeric', month: 'short', day: 'numeric',
        hour: 'numeric', minute: '2-digit', hour12: true
      });
    } catch {
      return 'Invalid Date';
    }
  };

  const getStatusBadgeClass = (status: string | undefined) => {
    switch (status) {
      case 'completed': return 'bg-green-100 text-green-800';
      case 'failed': return 'bg-red-100 text-red-800';
      case 'processing': return 'bg-blue-100 text-blue-800';
      default: return 'bg-gray-100 text-gray-800';
    }
  };

  const downloadResults = async (jobId: string, event: Event) => {
     event.stopPropagation(); // Prevent row click when clicking button
     if (!jobId || downloadingJobs.value.has(jobId)) return;

     downloadingJobs.value.add(jobId);
     downloadErrors.value[jobId] = null;

    try {
      const { blob, filename } = await apiService.downloadResults(jobId);
      const url = window.URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.style.display = 'none';
      a.href = url;
      a.download = filename;
      document.body.appendChild(a);
      a.click();
      window.URL.revokeObjectURL(url);
      document.body.removeChild(a);
    } catch (error: any) {
      console.error(`Download failed for job ${jobId}:`, error);
      downloadErrors.value[jobId] = `Download failed: ${error.message || 'Error'}`;
      // Optionally clear the error message after a delay
      setTimeout(() => { downloadErrors.value[jobId] = null; }, 5000);
    } finally {
      downloadingJobs.value.delete(jobId);
    }
  };


  onMounted(() => {
    fetchHistory();
  });
  </script>

  <style scoped>
  /* Add specific styles if needed */
  tbody tr:hover {
    background-color: #f9fafb; /* Tailwind gray-50 */
  }
  </style>
</file>

<file path='frontend/vue_frontend/src/components/JobResultsTable.vue'>
<template>
  <div class="mt-8 p-4 sm:p-6 bg-gray-50 rounded-lg border border-gray-200 shadow-inner">
    <h5 class="text-lg font-semibold text-gray-800 mb-4">
      {{ isIntegratedView ? 'Integrated Classification Results' : 'Detailed Classification Results' }}
    </h5>
    <p v-if="isIntegratedView" class="text-sm text-gray-600 mb-4">
      Showing original classification results alongside the latest reviewed results (if available). Target level: **Level {{ targetLevel }}**.
    </p>
     <p v-else class="text-sm text-gray-600 mb-4">
      Target classification level for this job was **Level {{ targetLevel }}**. You can flag items to start a review.
    </p>

    <!-- Search Input -->
    <div class="mb-4">
      <label for="results-search" class="sr-only">Search Results</label>
      <div class="relative rounded-md shadow-sm">
         <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
            <MagnifyingGlassIcon class="h-5 w-5 text-gray-400" aria-hidden="true" />
          </div>
        <input
          type="text"
          id="results-search"
          v-model="searchTerm"
          placeholder="Search Vendor, Category, ID, Hint, Notes..."
          class="block w-full pl-10 pr-3 py-2 border border-gray-300 rounded-md placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm"
        />
      </div>
    </div>

    <!-- Action Buttons (Submit Flags) -->
    <div class="mb-4 text-right" v-if="jobStore.hasFlaggedItems">
        <button
          type="button"
          @click="submitFlags"
          :disabled="jobStore.reclassifyLoading"
          class="inline-flex items-center rounded-md bg-primary px-3 py-2 text-sm font-semibold text-white shadow-sm hover:bg-primary-dark focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-primary disabled:opacity-50"
        >
          <ArrowPathIcon v-if="jobStore.reclassifyLoading" class="animate-spin -ml-0.5 mr-1.5 h-5 w-5" aria-hidden="true" />
          <PaperAirplaneIcon v-else class="-ml-0.5 mr-1.5 h-5 w-5" aria-hidden="true" />
          Submit {{ jobStore.flaggedForReview.size }} Flag{{ jobStore.flaggedForReview.size !== 1 ? 's' : '' }} for Re-classification
        </button>
         <p v-if="jobStore.reclassifyError" class="text-xs text-red-600 mt-1 text-right">{{ jobStore.reclassifyError }}</p>
    </div>


    <!-- Loading/Error States -->
    <div v-if="loading" class="text-center py-5 text-gray-500">
      <svg class="animate-spin h-6 w-6 text-primary mx-auto" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
        <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
        <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
      </svg>
      <p class="mt-2 text-sm">Loading detailed results...</p>
    </div>
    <div v-else-if="error" class="p-4 bg-red-100 border border-red-300 text-red-800 rounded-md text-sm">
      Error loading results: {{ error }}
    </div>
    <div v-else-if="!originalResults || originalResults.length === 0" class="text-center py-5 text-gray-500">
      No detailed results found for this job.
    </div>

    <!-- Results Table -->
    <div v-else class="overflow-x-auto border border-gray-200 rounded-md">
      <table class="min-w-full divide-y divide-gray-200">
        <thead class="bg-gray-100">
          <tr>
            <!-- Flag Column (Sticky) -->
            <th scope="col" class="sticky left-0 z-10 bg-gray-100 px-2 py-3 text-center text-xs font-medium text-gray-600 uppercase tracking-wider w-12">Flag</th>
            <!-- Dynamically generate headers -->
            <th v-for="header in dynamicHeaders" :key="header.key"
                scope="col"
                @click="header.sortable ? sortBy(header.key) : null"
                :class="[
                  'px-3 py-3 text-left text-xs font-medium text-gray-600 uppercase tracking-wider whitespace-nowrap',
                   header.sortable ? 'cursor-pointer hover:bg-gray-200' : '',
                   header.sticky ? 'sticky left-[48px] z-10 bg-gray-100' : '', // Adjusted left offset for flag column
                   header.minWidth ? `min-w-[${header.minWidth}]` : '',
                   header.isOriginal && isIntegratedView ? 'bg-blue-50' : '', // Style original columns only in integrated view
                   header.isNew ? 'bg-green-50' : '', // Style new columns
                ]">
              {{ header.label }}
              <SortIcon v-if="header.sortable" :direction="sortKey === header.key ? sortDirection : null" />
            </th>
          </tr>
        </thead>
        <tbody class="bg-white divide-y divide-gray-200">
          <tr v-if="filteredAndSortedItems.length === 0">
            <td :colspan="dynamicHeaders.length + 1" class="px-4 py-4 whitespace-nowrap text-sm text-gray-500 text-center">No results match your search criteria.</td>
          </tr>
          <!-- Iterate through combined/processed items -->
          <tr v-for="(item, index) in filteredAndSortedItems" :key="item.vendor_name + '-' + index" class="hover:bg-gray-50 align-top" :class="{'bg-indigo-50': jobStore.isFlagged(item.vendor_name)}">
             <!-- Flag Button Cell (Sticky) -->
             <td class="sticky left-0 z-10 bg-white px-2 py-2 text-center align-middle" :class="{'bg-indigo-50': jobStore.isFlagged(item.vendor_name)}">
                 <button
                    @click="toggleFlag(item.vendor_name, item.review_hint)"
                    :title="jobStore.isFlagged(item.vendor_name) ? 'Edit hint or remove flag' : 'Flag for re-classification'"
                    class="p-1 rounded-full hover:bg-gray-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-primary"
                    :class="jobStore.isFlagged(item.vendor_name) ? 'text-primary' : 'text-gray-400 hover:text-primary-dark'"
                  >
                    <FlagIconSolid v-if="jobStore.isFlagged(item.vendor_name)" class="h-5 w-5" aria-hidden="true" />
                    <FlagIconOutline v-else class="h-5 w-5" aria-hidden="true" />
                    <span class="sr-only">Flag item</span>
                  </button>
             </td>
             <!-- Vendor Name Cell (Sticky) -->
             <td class="sticky left-[48px] z-10 bg-white px-3 py-2 whitespace-nowrap text-sm font-medium text-gray-900" :class="{'bg-indigo-50': jobStore.isFlagged(item.vendor_name)}">{{ item.vendor_name }}</td>

             <!-- Hint Cell (Only in Integrated View) -->
             <td v-if="isIntegratedView" class="px-3 py-2 text-xs text-gray-600 max-w-xs break-words">
                 <span v-if="!jobStore.isFlagged(item.vendor_name)">{{ item.review_hint || '-' }}</span>
                 <!-- Inline Hint Editor when Flagged -->
                 <div v-else>
                    <label :for="'hint-' + index" class="sr-only">Hint for {{ item.vendor_name }}</label>
                    <textarea :id="'hint-' + index"
                              rows="2"
                              :value="jobStore.getHint(item.vendor_name)"
                              @input="updateHint(item.vendor_name, ($event.target as HTMLTextAreaElement).value)"
                              placeholder="Enter hint..."
                              class="block w-full text-xs rounded-md border-gray-300 shadow-sm focus:border-primary focus:ring-primary"
                    ></textarea>
                    <p v-if="!jobStore.getHint(item.vendor_name)" class="text-red-600 text-xs mt-1">Hint required for submission.</p>
                 </div>
             </td>

             <!-- Original Classification Columns -->
             <td class="px-3 py-2 whitespace-nowrap text-xs font-mono" :class="[getCellClass(item.original_result, 1), isIntegratedView ? 'bg-blue-50' : '']">{{ item.original_result?.level1_id || '-' }}</td>
             <td class="px-3 py-2 text-xs" :class="[getCellClass(item.original_result, 1), isIntegratedView ? 'bg-blue-50' : '']">{{ item.original_result?.level1_name || '-' }}</td>
             <td class="px-3 py-2 whitespace-nowrap text-xs font-mono" :class="[getCellClass(item.original_result, 2), isIntegratedView ? 'bg-blue-50' : '']">{{ item.original_result?.level2_id || '-' }}</td>
             <td class="px-3 py-2 text-xs" :class="[getCellClass(item.original_result, 2), isIntegratedView ? 'bg-blue-50' : '']">{{ item.original_result?.level2_name || '-' }}</td>
             <td class="px-3 py-2 whitespace-nowrap text-xs font-mono" :class="[getCellClass(item.original_result, 3), isIntegratedView ? 'bg-blue-50' : '']">{{ item.original_result?.level3_id || '-' }}</td>
             <td class="px-3 py-2 text-xs" :class="[getCellClass(item.original_result, 3), isIntegratedView ? 'bg-blue-50' : '']">{{ item.original_result?.level3_name || '-' }}</td>
             <td class="px-3 py-2 whitespace-nowrap text-xs font-mono" :class="[getCellClass(item.original_result, 4), isIntegratedView ? 'bg-blue-50' : '']">{{ item.original_result?.level4_id || '-' }}</td>
             <td class="px-3 py-2 text-xs" :class="[getCellClass(item.original_result, 4), isIntegratedView ? 'bg-blue-50' : '']">{{ item.original_result?.level4_name || '-' }}</td>
             <td class="px-3 py-2 whitespace-nowrap text-xs font-mono" :class="[getCellClass(item.original_result, 5), isIntegratedView ? 'bg-blue-50' : '']">{{ item.original_result?.level5_id || '-' }}</td>
             <td class="px-3 py-2 text-xs" :class="[getCellClass(item.original_result, 5), isIntegratedView ? 'bg-blue-50' : '']">{{ item.original_result?.level5_name || '-' }}</td>
             <td class="px-3 py-2 whitespace-nowrap text-sm text-center" :class="isIntegratedView ? 'bg-blue-50' : ''">
               <span v-if="item.original_result?.final_confidence !== null && item.original_result?.final_confidence !== undefined"
                     :class="getConfidenceClass(item.original_result.final_confidence)">
                 {{ (item.original_result.final_confidence * 100).toFixed(1) }}%
               </span>
               <span v-else class="text-gray-400 text-xs">N/A</span>
             </td>
             <td class="px-3 py-2 whitespace-nowrap text-xs text-center" :class="isIntegratedView ? 'bg-blue-50' : ''">
                <span class="px-2 inline-flex text-xs leading-5 font-semibold rounded-full"
                     :class="getStatusClass(item.original_result?.final_status)">
                 {{ item.original_result?.final_status }}
               </span>
             </td>
              <td class="px-3 py-2 whitespace-nowrap text-xs text-center" :class="isIntegratedView ? 'bg-blue-50' : ''">
               <span class="px-2 inline-flex text-xs leading-5 font-semibold rounded-full"
                     :class="getSourceClass(item.original_result?.classification_source)">
                 {{ item.original_result?.classification_source }}
               </span>
             </td>
             <td class="px-3 py-2 text-xs text-gray-500 max-w-xs break-words" :class="isIntegratedView ? 'bg-blue-50' : ''">
                  <!-- Show hint input if flagged AND NOT in integrated view, otherwise original notes -->
                  <div v-if="jobStore.isFlagged(item.vendor_name) && !isIntegratedView">
                     <label :for="'hint-' + index" class="sr-only">Hint for {{ item.vendor_name }}</label>
                     <textarea :id="'hint-' + index"
                               rows="2"
                               :value="jobStore.getHint(item.vendor_name)"
                               @input="updateHint(item.vendor_name, ($event.target as HTMLTextAreaElement).value)"
                               placeholder="Enter hint..."
                               class="block w-full text-xs rounded-md border-gray-300 shadow-sm focus:border-primary focus:ring-primary"
                     ></textarea>
                     <p v-if="!jobStore.getHint(item.vendor_name)" class="text-red-600 text-xs mt-1">Hint required for submission.</p>
                  </div>
                  <span v-else>{{ item.original_result?.classification_notes_or_reason || '-' }}</span>
             </td>

             <!-- New Classification Columns (Only in Integrated View) -->
             <template v-if="isIntegratedView">
                <td class="px-3 py-2 whitespace-nowrap text-xs font-mono bg-green-50" :class="getCellClass(item.new_result, 1)">{{ item.new_result?.level1_id || '-' }}</td>
                <td class="px-3 py-2 text-xs bg-green-50" :class="getCellClass(item.new_result, 1)">{{ item.new_result?.level1_name || '-' }}</td>
                <td class="px-3 py-2 whitespace-nowrap text-xs font-mono bg-green-50" :class="getCellClass(item.new_result, 2)">{{ item.new_result?.level2_id || '-' }}</td>
                <td class="px-3 py-2 text-xs bg-green-50" :class="getCellClass(item.new_result, 2)">{{ item.new_result?.level2_name || '-' }}</td>
                <td class="px-3 py-2 whitespace-nowrap text-xs font-mono bg-green-50" :class="getCellClass(item.new_result, 3)">{{ item.new_result?.level3_id || '-' }}</td>
                <td class="px-3 py-2 text-xs bg-green-50" :class="getCellClass(item.new_result, 3)">{{ item.new_result?.level3_name || '-' }}</td>
                <td class="px-3 py-2 whitespace-nowrap text-xs font-mono bg-green-50" :class="getCellClass(item.new_result, 4)">{{ item.new_result?.level4_id || '-' }}</td>
                <td class="px-3 py-2 text-xs bg-green-50" :class="getCellClass(item.new_result, 4)">{{ item.new_result?.level4_name || '-' }}</td>
                <td class="px-3 py-2 whitespace-nowrap text-xs font-mono bg-green-50" :class="getCellClass(item.new_result, 5)">{{ item.new_result?.level5_id || '-' }}</td>
                <td class="px-3 py-2 text-xs bg-green-50" :class="getCellClass(item.new_result, 5)">{{ item.new_result?.level5_name || '-' }}</td>
                <td class="px-3 py-2 whitespace-nowrap text-sm text-center bg-green-50">
                  <span v-if="item.new_result?.final_confidence !== null && item.new_result?.final_confidence !== undefined"
                        :class="getConfidenceClass(item.new_result.final_confidence)">
                    {{ (item.new_result.final_confidence * 100).toFixed(1) }}%
                  </span>
                  <span v-else class="text-gray-400 text-xs">N/A</span>
                </td>
                <td class="px-3 py-2 whitespace-nowrap text-xs text-center bg-green-50">
                   <span class="px-2 inline-flex text-xs leading-5 font-semibold rounded-full"
                        :class="getStatusClass(item.new_result?.final_status)">
                    {{ item.new_result?.final_status }}
                  </span>
                </td>
                 <td class="px-3 py-2 whitespace-nowrap text-xs text-center bg-green-50">
                   <span class="px-2 inline-flex text-xs leading-5 font-semibold rounded-full"
                        :class="getSourceClass(item.new_result?.classification_source)">
                    {{ item.new_result?.classification_source }}
                  </span>
                 </td>
                <td class="px-3 py-2 text-xs text-gray-500 max-w-xs break-words bg-green-50">
                  {{ item.new_result?.classification_notes_or_reason || '-' }}
                </td>
             </template>
          </tr>
        </tbody>
      </table>
    </div>

     <!-- Row Count -->
    <div class="mt-3 text-xs text-gray-500">
      Showing {{ filteredAndSortedItems.length }} of {{ originalResults?.length || 0 }} results.
    </div>

  </div>
</template>

<script setup lang="ts">
import { ref, computed, type PropType, watch } from 'vue';
import { useJobStore, type JobResultItem, type ReviewResultItem } from '@/stores/job';
import { FlagIcon as FlagIconOutline, MagnifyingGlassIcon, PaperAirplaneIcon, ArrowPathIcon } from '@heroicons/vue/24/outline';
import { FlagIcon as FlagIconSolid, ChevronUpIcon, ChevronDownIcon, ChevronUpDownIcon } from '@heroicons/vue/20/solid';

// --- Define Header Interface ---
interface TableHeader {
  key: string; // Use string for complex/nested keys or combined fields
  label: string;
  sortable: boolean;
  sticky?: boolean;
  minWidth?: string;
  isOriginal?: boolean; // Flag for styling/grouping
  isNew?: boolean;      // Flag for styling/grouping
}

// --- Define Combined Item Interface for internal use ---
interface CombinedResultItem {
    vendor_name: string;
    original_result: JobResultItem;
    review_hint: string | null; // Hint from review job
    new_result: JobResultItem | null; // New result from review job (can be null if not reviewed)
}

// --- Props ---
const props = defineProps({
  // Use JobResultItem[] for original results (always expected for CLASSIFICATION job view)
  originalResults: {
    type: Array as PropType<JobResultItem[] | null>,
    required: true,
  },
  // Use ReviewResultItem[] for related review results (optional)
  reviewResults: {
    type: Array as PropType<ReviewResultItem[] | null>,
    default: null,
  },
  loading: {
    type: Boolean,
    default: false,
  },
  error: {
    type: String as PropType<string | null>,
    default: null,
  },
  targetLevel: {
    type: Number,
    required: true,
  }
});

const emit = defineEmits(['submit-flags']);

// --- Store ---
const jobStore = useJobStore();

// --- Internal State ---
const searchTerm = ref('');
const sortKey = ref<string | null>('vendor_name'); // Default sort key
const sortDirection = ref<'asc' | 'desc' | null>('asc');

// --- Computed Properties ---

const isIntegratedView = computed(() => !!props.reviewResults && props.reviewResults.length > 0);

// Combine original and review results into a single structure for easier iteration/filtering/sorting
const combinedItems = computed((): CombinedResultItem[] => {
    if (!props.originalResults) return [];

    const reviewMap = new Map<string, ReviewResultItem>();
    if (props.reviewResults) {
        props.reviewResults.forEach(reviewItem => {
            reviewMap.set(reviewItem.vendor_name, reviewItem);
        });
    }

    return props.originalResults.map(originalItem => {
        const reviewItem = reviewMap.get(originalItem.vendor_name);
        return {
            vendor_name: originalItem.vendor_name,
            original_result: originalItem,
            review_hint: reviewItem ? reviewItem.hint : null,
            // Ensure new_result from reviewItem is used
            new_result: reviewItem ? reviewItem.new_result : null,
        };
    });
});

// Generate dynamic headers based on whether it's an integrated view
const dynamicHeaders = computed((): TableHeader[] => {
    const baseHeaders: TableHeader[] = [
        { key: 'vendor_name', label: 'Vendor Name', sortable: true, sticky: true, minWidth: '150px' },
    ];

    const originalResultHeaders: TableHeader[] = [
        { key: 'original_result.level1_id', label: 'L1 ID', sortable: true, minWidth: '80px', isOriginal: true },
        { key: 'original_result.level1_name', label: 'L1 Name', sortable: true, minWidth: '120px', isOriginal: true },
        { key: 'original_result.level2_id', label: 'L2 ID', sortable: true, minWidth: '80px', isOriginal: true },
        { key: 'original_result.level2_name', label: 'L2 Name', sortable: true, minWidth: '120px', isOriginal: true },
        { key: 'original_result.level3_id', label: 'L3 ID', sortable: true, minWidth: '80px', isOriginal: true },
        { key: 'original_result.level3_name', label: 'L3 Name', sortable: true, minWidth: '120px', isOriginal: true },
        { key: 'original_result.level4_id', label: 'L4 ID', sortable: true, minWidth: '80px', isOriginal: true },
        { key: 'original_result.level4_name', label: 'L4 Name', sortable: true, minWidth: '120px', isOriginal: true },
        { key: 'original_result.level5_id', label: 'L5 ID', sortable: true, minWidth: '80px', isOriginal: true },
        { key: 'original_result.level5_name', label: 'L5 Name', sortable: true, minWidth: '120px', isOriginal: true },
        { key: 'original_result.final_confidence', label: 'Confidence', sortable: true, minWidth: '100px', isOriginal: true },
        { key: 'original_result.final_status', label: 'Status', sortable: true, minWidth: '100px', isOriginal: true },
        { key: 'original_result.classification_source', label: 'Source', sortable: true, minWidth: '80px', isOriginal: true },
        { key: 'original_result.classification_notes_or_reason', label: 'Notes/Reason', sortable: false, minWidth: '200px', isOriginal: true }, // Combined column for original notes
    ];

    const reviewHintHeader: TableHeader = { key: 'review_hint', label: 'User Hint', sortable: true, minWidth: '180px' };

    const newResultHeaders: TableHeader[] = [
        { key: 'new_result.level1_id', label: 'New L1 ID', sortable: true, minWidth: '80px', isNew: true },
        { key: 'new_result.level1_name', label: 'New L1 Name', sortable: true, minWidth: '120px', isNew: true },
        { key: 'new_result.level2_id', label: 'New L2 ID', sortable: true, minWidth: '80px', isNew: true },
        { key: 'new_result.level2_name', label: 'New L2 Name', sortable: true, minWidth: '120px', isNew: true },
        { key: 'new_result.level3_id', label: 'New L3 ID', sortable: true, minWidth: '80px', isNew: true },
        { key: 'new_result.level3_name', label: 'New L3 Name', sortable: true, minWidth: '120px', isNew: true },
        { key: 'new_result.level4_id', label: 'New L4 ID', sortable: true, minWidth: '80px', isNew: true },
        { key: 'new_result.level4_name', label: 'New L4 Name', sortable: true, minWidth: '120px', isNew: true },
        { key: 'new_result.level5_id', label: 'New L5 ID', sortable: true, minWidth: '80px', isNew: true },
        { key: 'new_result.level5_name', label: 'New L5 Name', sortable: true, minWidth: '120px', isNew: true },
        { key: 'new_result.final_confidence', label: 'New Confidence', sortable: true, minWidth: '100px', isNew: true },
        { key: 'new_result.final_status', label: 'New Status', sortable: true, minWidth: '100px', isNew: true },
        { key: 'new_result.classification_source', label: 'New Source', sortable: true, minWidth: '80px', isNew: true },
        { key: 'new_result.classification_notes_or_reason', label: 'New Notes/Reason', sortable: false, minWidth: '200px', isNew: true },
    ];

    if (isIntegratedView.value) {
        // Modify original notes header label
        const origNotesHeader = originalResultHeaders.find(h => h.key === 'original_result.classification_notes_or_reason');
        if (origNotesHeader) origNotesHeader.label = 'Orig Notes/Reason';

        return [
            ...baseHeaders,
            reviewHintHeader, // Add hint column
            ...originalResultHeaders,
            ...newResultHeaders
        ];
    } else {
        // Modify original notes header label and make it the hint column if flagged
        const origNotesHeader = originalResultHeaders.find(h => h.key === 'original_result.classification_notes_or_reason');
        if (origNotesHeader) origNotesHeader.label = 'Hint / Notes / Reason';
        return [
            ...baseHeaders,
            ...originalResultHeaders
        ];
    }
});

// Helper to get nested values for filtering/sorting
const getNestedValue = (obj: any, path: string): any => {
  if (!obj) return null;
  // Handle direct keys first
  if (path.indexOf('.') === -1) {
      return obj[path] ?? null;
  }
  // Handle nested keys
  return path.split('.').reduce((value, key) => (value && value[key] !== undefined && value[key] !== null ? value[key] : null), obj);
};

const filteredAndSortedItems = computed(() => {
  let filtered = combinedItems.value;

  // Filtering
  if (searchTerm.value) {
    const lowerSearchTerm = searchTerm.value.toLowerCase();
    filtered = filtered.filter(item => {
        // Search direct fields
        if (item.vendor_name?.toLowerCase().includes(lowerSearchTerm)) return true;
        if (isIntegratedView.value && item.review_hint?.toLowerCase().includes(lowerSearchTerm)) return true;

        // Search original result fields (using header keys for consistency)
        const originalHeaders = dynamicHeaders.value.filter(h => h.isOriginal);
        for (const header of originalHeaders) {
             const value = getNestedValue(item, header.key);
             if (value && String(value).toLowerCase().includes(lowerSearchTerm)) return true;
        }

        // Search new result fields if integrated view
        if (isIntegratedView.value) {
            const newHeaders = dynamicHeaders.value.filter(h => h.isNew);
            for (const header of newHeaders) {
                const value = getNestedValue(item, header.key);
                if (value && String(value).toLowerCase().includes(lowerSearchTerm)) return true;
            }
        }
        // Search hint if flagged (even in non-integrated view)
        if (jobStore.isFlagged(item.vendor_name) && jobStore.getHint(item.vendor_name)?.toLowerCase().includes(lowerSearchTerm)) return true;

        return false; // No match
    });
  }

  // Sorting
  if (sortKey.value && sortDirection.value) {
    const key = sortKey.value;
    const direction = sortDirection.value === 'asc' ? 1 : -1;

    // Special handling for the hint column in non-integrated view
    const effectiveSortKey = (!isIntegratedView.value && key === 'original_result.classification_notes_or_reason') ? 'hint_or_notes' : key;

    filtered = filtered.slice().sort((a, b) => {
      let valA: any;
      let valB: any;

      if (effectiveSortKey === 'hint_or_notes') {
          valA = jobStore.isFlagged(a.vendor_name) ? jobStore.getHint(a.vendor_name) : a.original_result?.classification_notes_or_reason;
          valB = jobStore.isFlagged(b.vendor_name) ? jobStore.getHint(b.vendor_name) : b.original_result?.classification_notes_or_reason;
      } else {
          valA = getNestedValue(a, key);
          valB = getNestedValue(b, key);
      }

      const aIsNull = valA === null || valA === undefined || valA === '';
      const bIsNull = valB === null || valB === undefined || valB === '';

      if (aIsNull && bIsNull) return 0;
      if (aIsNull) return 1 * direction;
      if (bIsNull) return -1 * direction;

      if (typeof valA === 'string' && typeof valB === 'string') {
        return valA.localeCompare(valB) * direction;
      }
      if (typeof valA === 'number' && typeof valB === 'number') {
        return (valA - valB) * direction;
      }

      const strA = String(valA).toLowerCase();
      const strB = String(valB).toLowerCase();
      if (strA < strB) return -1 * direction;
      if (strA > strB) return 1 * direction;
      return 0;
    });
  }

  return filtered;
});

// --- Methods ---

function sortBy(key: string) {
  if (sortKey.value === key) {
    if (sortDirection.value === 'asc') sortDirection.value = 'desc';
    else if (sortDirection.value === 'desc') {
        sortDirection.value = null; // Cycle to no sort
        sortKey.value = null;
    } else { // Was null
        sortDirection.value = 'asc';
        sortKey.value = key; // Re-apply key
    }
  } else {
    sortKey.value = key;
    sortDirection.value = 'asc';
  }
}

function getConfidenceClass(confidence: number | null | undefined): string {
  if (confidence === null || confidence === undefined) return 'text-gray-400';
  if (confidence >= 0.8) return 'text-green-700 font-medium';
  if (confidence >= 0.5) return 'text-yellow-700';
  return 'text-red-700';
}

function getStatusClass(status: string | null | undefined): string {
    switch(status?.toLowerCase()){
        case 'classified': return 'bg-green-100 text-green-800';
        case 'not possible': return 'bg-yellow-100 text-yellow-800';
        case 'error': return 'bg-red-100 text-red-800';
        default: return 'bg-gray-100 text-gray-800';
    }
}

function getSourceClass(source: string | null | undefined): string {
    switch(source?.toLowerCase()){
        case 'initial': return 'bg-green-100 text-green-800';
        case 'search': return 'bg-blue-100 text-blue-800';
        case 'review': return 'bg-purple-100 text-purple-800'; // Added style for review source
        default: return 'bg-gray-100 text-gray-800';
    }
}

// Highlight cells based on achieved level vs current level, and target level
function getCellClass(item: JobResultItem | null | undefined, level: number): string {
    const baseClass = 'text-gray-700';
    const beyondDepthClass = 'text-gray-400 italic';
    const nullClass = 'text-gray-400';

    if (!item) return nullClass;

    const levelIdKey = `level${level}_id` as keyof JobResultItem;
    const hasId = item[levelIdKey] !== null && item[levelIdKey] !== undefined && String(item[levelIdKey]).trim() !== '';

    if (!hasId) return nullClass;

    // Check if the classification stopped before this level
    const achievedLevel = item.achieved_level ?? 0;
    if (level > achievedLevel) {
        // Style differently if classification didn't reach this level (e.g., L2 failed, styling L3 cell)
        // This might overlap with beyondDepthClass if targetLevel was also lower
        return beyondDepthClass; // Use the same style for simplicity
    }

    // Check if this level is beyond the job's target level
    if (level > props.targetLevel) {
        return beyondDepthClass;
    }

    return baseClass;
}

// --- Flagging and Hint Handling ---
function toggleFlag(vendorName: string, reviewHint: string | null) {
    if (jobStore.isFlagged(vendorName)) {
        jobStore.unflagVendor(vendorName);
    } else {
        // Pre-populate hint with the review hint if available in integrated view, otherwise null
        const initialHint = isIntegratedView.value ? reviewHint : null;
        jobStore.flagVendor(vendorName, initialHint);
    }
}

function updateHint(vendorName: string, hint: string) {
    jobStore.setHint(vendorName, hint);
}

async function submitFlags() {
    emit('submit-flags'); // Notify parent
}


// --- Helper Component for Sort Icons ---
const SortIcon = {
  props: {
    direction: {
      type: String as PropType<'asc' | 'desc' | null>,
      default: null,
    },
  },
  components: { ChevronUpIcon, ChevronDownIcon, ChevronUpDownIcon },
  template: `
    <span class="inline-block ml-1 w-4 h-4 align-middle">
      <ChevronUpIcon v-if="direction === 'asc'" class="w-4 h-4 text-gray-700" />
      <ChevronDownIcon v-else-if="direction === 'desc'" class="w-4 h-4 text-gray-700" />
      <ChevronUpDownIcon v-else class="w-4 h-4 text-gray-400 opacity-50" />
    </span>
  `,
};

// Watch for prop changes to potentially clear sort/filter (optional)
watch(() => [props.originalResults, props.reviewResults], () => {
    console.log("Results props changed, resetting sort/filter");
    searchTerm.value = '';
    sortKey.value = 'vendor_name';
    sortDirection.value = 'asc';
});

</script>

<style scoped>
/* Ensure sticky header cells have appropriate background */
thead th.sticky {
  position: sticky;
  background-color: #f3f4f6; /* bg-gray-100 */
}

/* Ensure sticky body cells have appropriate background */
tbody td.sticky {
    position: sticky;
    background-color: inherit; /* Inherit from parent tr */
}
/* Ensure flagged rows inherit sticky background correctly */
tbody tr.bg-indigo-50 td.sticky {
    background-color: #e0e7ff; /* bg-indigo-50 */
}


/* Add slight borders for visual separation in integrated view */
th.isOriginal, td.isOriginal {
    border-left: 1px solid #e5e7eb; /* gray-200 */
}
th.isNew, td.isNew {
    border-left: 1px solid #e5e7eb; /* gray-200 */
}
th:first-child, td:first-child { /* Flag column */
    border-left: none;
}
th:nth-child(2), td:nth-child(2) { /* Vendor name column */
     border-left: none;
}
/* Adjust border for hint column if it's the first after vendor name */
th:nth-child(3), td:nth-child(3) {
    border-left: v-bind("isIntegratedView ? '1px solid #e5e7eb' : 'none'");
}

/* REMOVED empty ruleset */
/* Style for cells beyond requested depth */
/* .text-gray-400.italic { */
    /* background-color: #f9fafb; */
/* } */
</style>
</file>

<file path='frontend/vue_frontend/src/components/JobStats.vue'>
<!-- <file path='frontend/vue_frontend/src/components/JobStats.vue'> -->
    <template>
        <div class="mt-6 bg-gray-50 rounded-lg p-6 border border-gray-200 shadow-inner">
          <h5 class="text-lg font-semibold text-gray-700 mb-5 border-b border-gray-200 pb-3">
              Processing Statistics
              <!-- ADDED: Display Target Level -->
              <span v-if="jobTargetLevel" class="text-sm font-normal text-gray-500 ml-2">(Target Level: {{ jobTargetLevel }})</span>
          </h5>
          <div v-if="isLoading" class="text-center text-gray-500 py-4">
                <svg class="animate-spin inline-block h-5 w-5 text-primary mr-2" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                   <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                   <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                </svg>
                <span>Loading stats...</span>
          </div>
          <div v-else-if="error" class="p-3 bg-yellow-100 border border-yellow-300 text-yellow-800 rounded-md text-sm">
              {{ error }}
          </div>
          <div v-else-if="stats" class="grid grid-cols-1 sm:grid-cols-2 gap-x-8 gap-y-4 text-sm">
              <!-- Column 1: Vendor & Classification Stats -->
              <div class="space-y-2.5">
                  <p class="flex justify-between">
                      <strong class="text-gray-600 font-medium">Total Vendors:</strong>
                      <span class="text-gray-800 font-semibold">{{ stats.total_vendors?.toLocaleString() ?? 'N/A' }}</span>
                  </p>
                  <p class="flex justify-between">
                      <strong class="text-gray-600 font-medium">Unique Vendors:</strong>
                      <span class="text-gray-800 font-semibold">{{ stats.unique_vendors?.toLocaleString() ?? 'N/A' }}</span>
                  </p>
                  <!-- UPDATED: Display L5 Success -->
                  <p v-if="jobTargetLevel && jobTargetLevel >= 5" class="flex justify-between">
                      <strong class="text-gray-600 font-medium">Successfully Classified (L5):</strong>
                      <span class="text-green-700 font-semibold">{{ stats.successfully_classified_l5?.toLocaleString() ?? 'N/A' }}</span>
                  </p>
                  <!-- UPDATED: Display L5 Search Success (Corrected field name) -->
                  <p v-if="jobTargetLevel && jobTargetLevel >= 5" class="flex justify-between">
                      <strong class="text-gray-600 font-medium">Search Assisted (L5):</strong>
                      <span class="text-gray-800 font-semibold">{{ stats.search_successful_classifications_l5?.toLocaleString() ?? 'N/A' }}</span>
                  </p>
                  <!-- Keep L4 for reference if target level was >= 4 -->
                   <p v-if="jobTargetLevel && jobTargetLevel >= 4" class="flex justify-between text-xs text-gray-500">
                      <strong class="font-normal">Ref: Classified (L4):</strong>
                      <span class="font-normal">{{ stats.successfully_classified_l4?.toLocaleString() ?? 'N/A' }}</span>
                  </p>
                  <p class="flex justify-between">
                      <strong class="text-gray-600 font-medium">Invalid Category Errors:</strong>
                      <span :class="(stats.invalid_category_errors ?? 0) > 0 ? 'text-red-600 font-semibold' : 'text-gray-800 font-semibold'">
                          {{ stats.invalid_category_errors?.toLocaleString() ?? 'N/A' }}
                      </span>
                  </p>
              </div>
               <!-- Column 2: API & Time Stats -->
               <div class="space-y-2.5">
                  <!-- UPDATED: Access nested fields -->
                  <p class="flex justify-between">
                      <strong class="text-gray-600 font-medium">LLM API Calls:</strong>
                      <span class="text-gray-800 font-semibold">{{ stats.api_usage?.openrouter_calls?.toLocaleString() ?? 'N/A' }}</span>
                  </p>
                  <p class="flex justify-between">
                      <strong class="text-gray-600 font-medium">LLM Tokens Used:</strong>
                      <span class="text-gray-800 font-semibold">{{ stats.api_usage?.openrouter_total_tokens?.toLocaleString() ?? 'N/A' }}</span>
                  </p>
                  <p class="flex justify-between">
                      <strong class="text-gray-600 font-medium">Search API Calls:</strong>
                      <span class="text-gray-800 font-semibold">{{ stats.api_usage?.tavily_search_calls?.toLocaleString() ?? 'N/A' }}</span>
                  </p>
                  <p class="flex justify-between pt-2 mt-1 border-t border-gray-200">
                      <strong class="text-gray-600 font-medium">Processing Time:</strong>
                      <!-- UPDATED: Use correct field name -->
                      <span class="text-gray-800 font-semibold">{{ formattedTime }}</span>
                  </p>
               </div>
          </div>
           <div v-else class="text-gray-500 text-center py-4 text-sm">No statistics available for this job.</div>
        </div>
      </template>
    
    <script setup lang="ts">
    import { ref, onMounted, watch, computed } from 'vue';
    import apiService, { type JobStatsData } from '@/services/api';
    // ADDED: Import job store to access target level
    import { useJobStore } from '@/stores/job';
    
    // Define the component props
    interface Props {
        jobId: string | null | undefined; // Allow jobId to be potentially null or undefined
    }
    const props = defineProps<Props>();
    
    // ADDED: Access job store
    const jobStore = useJobStore();
    
    // Reactive state variables
    const stats = ref<JobStatsData | null>(null); // Use the imported type
    const isLoading = ref(false);
    const error = ref<string | null>(null);
    
    // ADDED: Computed property to get target level from store OR stats
    const jobTargetLevel = computed(() => {
        // Prefer the target level stored directly in the stats if available
        if (stats.value?.target_level != null) {
            return stats.value.target_level;
        }
        // Fallback to the job details from the store
        return jobStore.jobDetails?.target_level;
    });
    
    // Computed property to format processing time nicely
    const formattedTime = computed(() => {
        // UPDATED: Access correct field name
        if (stats.value?.processing_duration_seconds == null) return 'N/A'; // Check for null or undefined
        const seconds = stats.value.processing_duration_seconds;
        if (seconds < 0) return 'N/A'; // Handle potential negative values if they occur
        if (seconds < 1) return `${(seconds * 1000).toFixed(0)} ms`;
        if (seconds < 60) return `${seconds.toFixed(1)} seconds`;
        const minutes = Math.floor(seconds / 60);
        const remainingSeconds = (seconds % 60).toFixed(0);
        return `${minutes} min ${remainingSeconds} sec`;
    });
    
    /**
     * Fetches job statistics from the API for the given job ID.
     * @param {string | null | undefined} id - The job ID to fetch stats for.
     */
    const fetchStats = async (id: string | null | undefined) => {
      // Only proceed if id is a non-empty string
      if (!id) {
          console.log("JobStats: fetchStats called with no ID, skipping."); // Logging
          stats.value = null; // Clear previous stats if ID is null/undefined
          error.value = null;
          isLoading.value = false;
          return;
      }
    
      isLoading.value = true;
      error.value = null;
      // Don't clear stats immediately, only on successful fetch or error
      // stats.value = null;
    
      try {
          console.log(`JobStats: Fetching stats for job ID: ${id}`); // Logging
          // The API service now returns the updated structure
          stats.value = await apiService.getJobStats(id);
          // LOGGING: Log the received stats structure after fetch
          console.log(`JobStats: Received and assigned stats:`, JSON.parse(JSON.stringify(stats.value)));
      } catch (err: any) {
          console.error(`JobStats: Error fetching stats for ${id}:`, err); // Logging
          error.value = err.message || 'Failed to load statistics.';
          stats.value = null; // Clear stats on error
      } finally {
          isLoading.value = false;
      }
    };
    
    // Fetch stats when the component mounts
    onMounted(() => {
        console.log(`JobStats: Mounted with initial jobId: ${props.jobId}`); // Logging
        fetchStats(props.jobId);
    });
    
    // Watch for changes in the jobId prop and refetch stats
    watch(() => props.jobId,
      (newJobId: string | null | undefined) => {
        console.log(`JobStats: Watched jobId changed to: ${newJobId}`); // Logging
        fetchStats(newJobId); // fetchStats handles null/undefined check internally
      },
      { immediate: false } // Don't run immediately, onMounted handles initial fetch
    );
    </script>
    
    <style scoped>
      .shadow-inner {
          box-shadow: inset 0 2px 4px 0 rgba(0, 0, 0, 0.05);
      }
      /* Add any other specific styles if needed */
    </style>
</file>

<file path='frontend/vue_frontend/src/components/JobStatus.vue'>
<template>
    <div v-if="jobStore.currentJobId" class="bg-white rounded-lg shadow-lg overflow-hidden border border-gray-200">
      <div class="bg-gray-100 text-gray-800 p-4 sm:p-5 border-b border-gray-200 flex justify-between items-center">
        <h4 class="text-xl font-semibold mb-0">Job Status</h4>
         <!-- Link to Parent Job (if this is a Review Job) -->
         <button v-if="jobDetails?.job_type === 'REVIEW' && jobDetails.parent_job_id"
                @click="viewParentJob"
                title="View Original Classification Job"
                class="text-xs inline-flex items-center px-2.5 py-1.5 border border-gray-300 shadow-sm font-medium rounded text-gray-700 bg-white hover:bg-gray-50 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-primary">
            <ArrowUturnLeftIcon class="h-4 w-4 mr-1.5 text-gray-500"/>
            View Original Job
        </button>
      </div>
      <div class="p-6 sm:p-8 space-y-6"> <!-- Increased spacing -->

        <!-- Error Message (Polling/General) -->
        <div v-if="errorMessage" class="p-3 bg-yellow-100 border border-yellow-300 text-yellow-800 rounded-md text-sm flex items-center">
            <ExclamationTriangleIcon class="h-5 w-5 mr-2 text-yellow-600 flex-shrink-0"/>
            <span>{{ errorMessage }}</span>
        </div>

        <!-- Reclassification Started Message -->
        <div v-if="showReclassifySuccessMessage && jobStore.lastReviewJobId" class="p-3 bg-green-100 border border-green-300 text-green-800 rounded-md text-sm flex items-center justify-between">
             <div class="flex items-center">
                 <CheckCircleIcon class="h-5 w-5 mr-2 text-green-600 flex-shrink-0"/>
                 <span>Re-classification job started successfully (ID: {{ jobStore.lastReviewJobId }}).</span>
             </div>
             <button @click="viewReviewJob(jobStore.lastReviewJobId!)" class="ml-4 text-xs font-semibold text-green-700 hover:text-green-900 underline">View Review Job</button>
        </div>

        <!-- Merge Action Feedback -->
        <div v-if="jobStore.mergeError" class="p-3 bg-red-100 border border-red-300 text-red-800 rounded-md text-sm flex items-center">
            <ExclamationTriangleIcon class="h-5 w-5 mr-2 text-red-600 flex-shrink-0"/>
            <span>Merge Error: {{ jobStore.mergeError }}</span>
        </div>
        <div v-if="showMergeSuccessMessage" class="p-3 bg-green-100 border border-green-300 text-green-800 rounded-md text-sm flex items-center justify-between">
             <div class="flex items-center">
                 <CheckCircleIcon class="h-5 w-5 mr-2 text-green-600 flex-shrink-0"/>
                 <span>Results successfully merged into original job.</span>
             </div>
             <button v-if="jobDetails?.parent_job_id" @click="viewParentJob" class="ml-4 text-xs font-semibold text-green-700 hover:text-green-900 underline">View Updated Original Job</button>
        </div>


        <!-- Job ID & Status Row -->
        <div class="grid grid-cols-1 md:grid-cols-2 gap-4 text-sm border-b border-gray-100 pb-4">
          <div>
             <strong class="text-gray-600 block mb-1">Job ID:</strong>
             <span class="text-gray-900 font-mono text-xs bg-gray-100 px-2 py-1 rounded break-all">{{ jobStore.currentJobId }}</span>
             <span v-if="jobDetails?.job_type === 'REVIEW'" class="ml-2 inline-block px-1.5 py-0.5 rounded text-xs font-semibold bg-purple-100 text-purple-800 align-middle">REVIEW</span>
             <span v-else-if="jobDetails?.job_type === 'CLASSIFICATION'" class="ml-2 inline-block px-1.5 py-0.5 rounded text-xs font-semibold bg-blue-100 text-blue-800 align-middle">CLASSIFICATION</span>
          </div>
           <div class="flex items-center space-x-2">
             <strong class="text-gray-600">Status:</strong>
             <span class="px-2.5 py-0.5 rounded-full text-xs font-bold uppercase tracking-wide" :class="statusBadgeClass">
                 {{ jobDetails?.status || 'Loading...' }}
             </span>
             <span v-if="jobDetails?.job_type === 'REVIEW' && jobStore.isMerged" class="ml-2 inline-block px-1.5 py-0.5 rounded text-xs font-semibold bg-gray-200 text-gray-700 align-middle" title="Results have been merged into the original job">
                <CheckCircleIcon class="h-3 w-3 inline-block mr-0.5 text-gray-600"/> Merged
             </span>
           </div>
        </div>

        <!-- Stage & Error (if failed) -->
        <div class="text-sm">
            <strong class="text-gray-600 block mb-1">Current Stage:</strong>
            <span class="text-gray-800 font-medium">{{ formattedStage }}</span>
            <div v-if="jobDetails?.status === 'failed' && jobDetails?.error_message" class="mt-3 p-4 bg-red-50 border border-red-200 text-red-800 rounded-md text-xs shadow-sm">
              <strong class="block mb-1 font-semibold">Error Details:</strong>
              <p class="whitespace-pre-wrap">{{ jobDetails.error_message }}</p> <!-- Preserve whitespace -->
            </div>
        </div>

        <!-- Progress Bar -->
        <div>
          <label class="block text-sm font-medium text-gray-600 mb-1.5">Progress:</label>
          <div class="w-full bg-gray-200 rounded-full h-3 overflow-hidden"> <!-- Slimmer progress bar -->
            <div
              class="h-3 rounded-full transition-all duration-500 ease-out"
              :class="progressColorClass"
              :style="{ width: progressPercent + '%' }"
              ></div>
          </div>
          <div class="text-right text-xs text-gray-500 mt-1">{{ progressPercent }}% Complete</div>
        </div>

        <!-- Timestamps Row -->
        <div class="grid grid-cols-1 md:grid-cols-3 gap-4 text-xs text-gray-500 border-t border-gray-100 pt-5">
            <div>
                 <strong class="block text-gray-600 mb-0.5">Created:</strong>
                 <span>{{ formattedCreatedAt }}</span>
            </div>
            <div>
                 <strong class="block text-gray-600 mb-0.5">Updated:</strong>
                 <span>{{ formattedUpdatedAt }}</span>
            </div>
             <div>
                <strong class="block text-gray-600 mb-0.5">Est. Completion:</strong>
                <span>{{ formattedEstimatedCompletion }}</span>
            </div>
        </div>

        <!-- Notification Section -->
        <div v-if="canRequestNotify" class="pt-5 border-t border-gray-100">
            <label for="notificationEmail" class="block text-sm font-medium text-gray-700 mb-1.5">Get Notified Upon Completion</label>
            <div class="flex flex-col sm:flex-row sm:space-x-2">
                <input type="email"
                       class="mb-2 sm:mb-0 flex-grow block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-60 disabled:bg-gray-100"
                       id="notificationEmail"
                       placeholder="Enter your email"
                       v-model="notificationEmail"
                       :disabled="isNotifyLoading" />
                <button
                    type="button"
                    @click="requestNotification"
                    :disabled="isNotifyLoading || !notificationEmail"
                    class="w-full sm:w-auto inline-flex justify-center items-center px-4 py-2 border border-gray-300 rounded-md shadow-sm text-sm font-medium text-gray-700 bg-white hover:bg-gray-50 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-primary disabled:opacity-50 disabled:cursor-not-allowed"
                >
                    <svg v-if="isNotifyLoading" class="animate-spin -ml-1 mr-2 h-4 w-4 text-gray-700" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                       <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                       <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                    </svg>
                     <EnvelopeIcon v-else class="h-4 w-4 mr-2 -ml-1 text-gray-500"/>
                    {{ isNotifyLoading ? 'Sending...' : 'Notify Me' }}
                </button>
            </div>
            <!-- Notification Feedback -->
            <p v-if="notifyMessage" :class="notifyMessageIsError ? 'text-red-600' : 'text-green-600'" class="mt-2 text-xs">{{ notifyMessage }}</p>
        </div>

        <!-- Download Section (Only for completed CLASSIFICATION jobs) -->
        <div v-if="jobDetails?.status === 'completed' && jobDetails?.job_type === 'CLASSIFICATION'" class="pt-5 border-t border-gray-100">
          <button @click="downloadResults"
                  class="w-full flex justify-center items-center px-4 py-2.5 border border-transparent rounded-md shadow-sm text-base font-medium text-white bg-green-600 hover:bg-green-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-green-500 disabled:opacity-50 disabled:cursor-not-allowed"
                  :disabled="isDownloadLoading">
             <svg v-if="isDownloadLoading" class="animate-spin -ml-1 mr-3 h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
             </svg>
             <ArrowDownTrayIcon v-else class="h-5 w-5 mr-2 -ml-1" />
            {{ isDownloadLoading ? ' Preparing Download...' : 'Download Excel Results' }}
          </button>
          <p v-if="downloadError" class="mt-2 text-xs text-red-600 text-center">{{ downloadError }}</p>
        </div>

        <!-- Merge Section (Only for completed REVIEW jobs that are not yet merged) -->
        <div v-if="jobDetails?.status === 'completed' && jobDetails?.job_type === 'REVIEW' && !jobStore.isMerged" class="pt-5 border-t border-gray-100">
          <button @click="handleMergeResults"
                  class="w-full flex justify-center items-center px-4 py-2.5 border border-transparent rounded-md shadow-sm text-base font-medium text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500 disabled:opacity-50 disabled:cursor-not-allowed"
                  :disabled="jobStore.mergeLoading">
             <svg v-if="jobStore.mergeLoading" class="animate-spin -ml-1 mr-3 h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
             </svg>
             <ArrowPathIcon v-else class="h-5 w-5 mr-2 -ml-1" /> <!-- Using ArrowPathIcon for merge -->
            {{ jobStore.mergeLoading ? ' Merging Results...' : 'Merge Results into Original Job' }}
          </button>
          <p class="mt-2 text-xs text-gray-600 text-center">This will update the original classification job with the results shown below.</p>
        </div>


        <!-- Stats Section (Rendered within JobStatus when complete) -->
         <JobStats v-if="jobDetails?.status === 'completed' && jobDetails?.id" :job-id="jobDetails.id" />

        <!-- ***** UPDATED: Conditional Detailed Results Table Section ***** -->
        <!-- Show CLASSIFICATION results table (potentially integrated view) -->
        <JobResultsTable
            v-if="jobDetails?.status === 'completed' && jobDetails?.id && jobDetails?.job_type === 'CLASSIFICATION'"
            :original-results="jobStore.jobResults as JobResultItem[] | null"
            :review-results="jobStore.relatedReviewResults"
            :loading="jobStore.resultsLoading"
            :error="jobStore.resultsError"
            :target-level="jobDetails.target_level || 5"
            @submit-flags="handleSubmitFlags" /> <!-- Listen for submit event -->

        <!-- Show REVIEW results table -->
        <ReviewResultsTable
            v-if="jobDetails?.status === 'completed' && jobDetails?.id && jobDetails?.job_type === 'REVIEW'"
            :results="jobStore.jobResults as ReviewResultItem[] | null"
            :loading="jobStore.resultsLoading"
            :error="jobStore.resultsError"
            :target-level="jobDetails.target_level || 5"
            @submit-flags="handleSubmitFlags" /> <!-- Listen for submit event -->
        <!-- ***** END UPDATED Section ***** -->

      </div>
    </div>
      <div v-else class="text-center py-10 text-gray-500">
        <!-- Message shown when no job is selected -->
        <!-- Select a job from the history or upload a new file. -->
      </div>
  </template>

  <script setup lang="ts">
  import { ref, computed, onMounted, onUnmounted, watch } from 'vue';
  import apiService from '@/services/api';
  // --- UPDATED: Removed JobDetails from this import ---
  import { useJobStore, type JobResultItem, type ReviewResultItem } from '@/stores/job';
  // --- END UPDATED ---
  import JobStats from './JobStats.vue';
  // Import both results tables
  import JobResultsTable from './JobResultsTable.vue';
  import ReviewResultsTable from './ReviewResultsTable.vue';
  import { EnvelopeIcon, ArrowDownTrayIcon, ExclamationTriangleIcon, ArrowUturnLeftIcon, CheckCircleIcon, ArrowPathIcon } from '@heroicons/vue/20/solid';

  const POLLING_INTERVAL = 5000; // Poll every 5 seconds
  const jobStore = useJobStore();
  const jobDetails = computed(() => jobStore.jobDetails); // Use jobDetails directly from the store
  const isLoading = ref(false); // Tracks if a poll request is currently in flight
  const errorMessage = ref<string | null>(null); // Stores polling or general errors
  const pollingIntervalId = ref<number | null>(null); // Stores the ID from setInterval
  const showReclassifySuccessMessage = ref(false); // Control visibility of success message
  const showMergeSuccessMessage = ref(false); // Control visibility of merge success message

  // --- Notification State ---
  const notificationEmail = ref('');
  const isNotifyLoading = ref(false);
  const notifyMessage = ref<string | null>(null);
  const notifyMessageIsError = ref(false);

  // --- Download State ---
  const isDownloadLoading = ref(false);
  const downloadError = ref<string | null>(null);

  // --- Computed Properties ---
  const formattedStage = computed(() => {
    const stage = jobDetails.value?.current_stage;
    const status = jobDetails.value?.status;
    if (status === 'completed') return 'Completed';
    if (status === 'failed') return 'Failed';
    if (status === 'pending') return 'Pending Start';
    if (!stage) return 'Loading...';
    const stageNames: { [key: string]: string } = {
      'ingestion': 'Ingesting File', 'normalization': 'Normalizing Data',
      'classification_level_1': 'Classifying (L1)', 'classification_level_2': 'Classifying (L2)',
      'classification_level_3': 'Classifying (L3)', 'classification_level_4': 'Classifying (L4)',
      'classification_level_5': 'Classifying (L5)', 'search_unknown_vendors': 'Researching Vendors',
      'reclassification': 'Re-classifying', 'result_generation': 'Generating Results',
      'pending': 'Pending Start',
    };
    return stageNames[stage] || stage;
  });

  const progressPercent = computed(() => {
    const status = jobDetails.value?.status;
    const progress = jobDetails.value?.progress ?? 0;
    if (status === 'completed') return 100;
    if (status === 'pending') return 0;
    return Math.max(0, Math.min(100, Math.round(progress * 100)));
  });

  const statusBadgeClass = computed(() => {
      switch (jobDetails.value?.status) {
          case 'completed': return 'bg-green-100 text-green-800';
          case 'failed': return 'bg-red-100 text-red-800';
          case 'processing': return 'bg-blue-100 text-blue-800 animate-pulse';
          default: return 'bg-gray-100 text-gray-800';
      }
  });

  const progressColorClass = computed(() => {
    const status = jobDetails.value?.status;
    if (status === 'completed') return 'bg-green-500';
    if (status === 'failed') return 'bg-red-500';
    return 'bg-primary animate-pulse';
  });

  const formatDateTime = (isoString: string | null | undefined): string => {
      if (!isoString) return 'N/A';
      try {
          return new Date(isoString).toLocaleString(undefined, {
              year: 'numeric', month: 'short', day: 'numeric',
              hour: 'numeric', minute: '2-digit', hour12: true
          });
      } catch { return 'Invalid Date'; }
  };

  const formattedCreatedAt = computed(() => formatDateTime(jobDetails.value?.created_at));
  const formattedUpdatedAt = computed(() => formatDateTime(jobDetails.value?.updated_at));

  const formattedEstimatedCompletion = computed(() => {
      const status = jobDetails.value?.status;
      if (status === 'completed' && jobDetails.value?.completed_at) {
          return formatDateTime(jobDetails.value.completed_at);
      }
      const estCompletion = jobDetails.value?.estimated_completion;
      if (status === 'processing' && estCompletion) {
          return `${formatDateTime(estCompletion)} (est.)`;
      }
      if (status === 'processing') return 'Calculating...';
      if (status === 'failed') return 'N/A';
      if (status === 'pending') return 'Pending Start';
      return 'N/A';
  });

  const canRequestNotify = computed(() => {
      const status = jobDetails.value?.status;
      return status === 'pending' || status === 'processing';
  });

  // --- Methods ---
  const pollJobStatus = async (jobId: string | null | undefined) => {
     if (!jobId || jobStore.currentJobId !== jobId) {
         console.log(`JobStatus: [pollJobStatus] Stopping polling. Reason: Job ID mismatch or null. (Poll ID: ${jobId}, Store ID: ${jobStore.currentJobId})`);
         stopPolling();
         return;
     }
     if (isLoading.value) {
         console.log(`JobStatus: [pollJobStatus] Skipping poll for ${jobId} - already in progress.`);
         return;
     }

     isLoading.value = true;
     console.log(`JobStatus: [pollJobStatus] Polling status for job ${jobId}...`);
    try {
        const data = await apiService.getJobStatus(jobId);
        if (jobStore.currentJobId === jobId) {
            console.log(`JobStatus: [pollJobStatus] Received status for ${jobId}: Status=${data.status}, Progress=${data.progress}, Type=${data.job_type}`);
            const previousStatus = jobStore.jobDetails?.status; // Store previous status before update
            jobStore.updateJobDetails(data); // Update details in store
            errorMessage.value = null;

            // Check if job just completed or failed
            const justCompleted = data.status === 'completed' && previousStatus !== 'completed';
            const justFailed = data.status === 'failed' && previousStatus !== 'failed';

            if (justCompleted || justFailed) {
                console.log(`JobStatus: [pollJobStatus] Job ${jobId} reached terminal state (${data.status}). Stopping polling.`);
                stopPolling();
                if (justCompleted) {
                    console.log(`JobStatus: [pollJobStatus] Job ${jobId} completed. Triggering fetchCurrentJobResults and fetchJobStats.`);
                    // Fetch results AND stats when completed
                    if (!jobStore.resultsLoading && !jobStore.jobResults && !jobStore.relatedReviewResults) {
                         jobStore.fetchCurrentJobResults();
                    } else {
                         console.log(`JobStatus: [pollJobStatus] Job ${jobId} completed, but results already loading or present. Skipping fetch.`);
                    }
                    // Fetch stats for completed job (needed for merge status check)
                    jobStore.fetchJobStats(jobId);
                }
            }
        } else {
             console.log(`JobStatus: [pollJobStatus] Job ID changed during API call for ${jobId}. Ignoring stale data.`);
        }
    } catch (error: any) {
        console.error(`JobStatus: [pollJobStatus] Error polling status for ${jobId}:`, error);
        if (jobStore.currentJobId === jobId) {
            errorMessage.value = `Polling Error: ${error.message || 'Failed to fetch status.'}`;
        }
        stopPolling();
    } finally {
        if (jobStore.currentJobId === jobId) {
            isLoading.value = false;
        }
    }
  };

  const startPolling = (jobId: string | null | undefined) => {
    if (!jobId) {
        console.log("JobStatus: [startPolling] Cannot start polling, no jobId provided.");
        return;
    }
    stopPolling();
    console.log(`JobStatus: [startPolling] Starting polling for job ${jobId}.`);
    pollJobStatus(jobId); // Poll immediately

    pollingIntervalId.value = window.setInterval(() => {
        console.log(`JobStatus: [setInterval] Checking poll condition for ${jobId}. Current store ID: ${jobStore.currentJobId}, Status: ${jobStore.jobDetails?.status}`);
        if (jobStore.currentJobId === jobId && jobStore.jobDetails?.status !== 'completed' && jobStore.jobDetails?.status !== 'failed') {
            pollJobStatus(jobId);
        } else {
            console.log(`JobStatus: [setInterval] Condition not met for job ${jobId}, stopping polling.`);
            stopPolling();
        }
    }, POLLING_INTERVAL);
  };

  const stopPolling = () => {
    if (pollingIntervalId.value !== null) {
        console.log(`JobStatus: [stopPolling] Stopping polling interval ID ${pollingIntervalId.value}.`);
        clearInterval(pollingIntervalId.value);
        pollingIntervalId.value = null;
    }
  };

  const requestNotification = async () => {
     const currentId = jobDetails.value?.id;
     if (!currentId || !notificationEmail.value) return;
     isNotifyLoading.value = true;
     notifyMessage.value = null;
     notifyMessageIsError.value = false;
     console.log(`JobStatus: Requesting notification for ${currentId} to ${notificationEmail.value}`);
    try {
        const response = await apiService.requestNotification(currentId, notificationEmail.value);
        console.log(`JobStatus: Notification request successful:`, response);
        notifyMessage.value = response.message || 'Notification request sent!';
        notificationEmail.value = '';
    } catch (error: any) {
        console.error(`JobStatus: Notification request failed:`, error);
        notifyMessage.value = `Error: ${error.message || 'Failed to send request.'}`;
        notifyMessageIsError.value = true;
    } finally {
        isNotifyLoading.value = false;
        setTimeout(() => { notifyMessage.value = null; }, 5000);
    }
  };

  const downloadResults = async () => {
     const currentId = jobDetails.value?.id;
     if (!currentId) return;
     isDownloadLoading.value = true;
     downloadError.value = null;
     console.log(`JobStatus: Attempting download for ${currentId}`);
    try {
        const { blob, filename } = await apiService.downloadResults(currentId);
        console.log(`JobStatus: Download blob received, filename: ${filename}`);
        const url = window.URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.style.display = 'none'; a.href = url; a.download = filename;
        document.body.appendChild(a); a.click();
        window.URL.revokeObjectURL(url); document.body.removeChild(a);
        console.log(`JobStatus: Download triggered for ${filename}`);
    } catch (error: any) {
        console.error(`JobStatus: Download failed:`, error);
        downloadError.value = `Download failed: ${error.message || 'Could not download results.'}`;
    } finally {
        isDownloadLoading.value = false;
    }
  };

  // --- Reclassification Submission Handler ---
  const handleSubmitFlags = async () => {
    console.log("JobStatus: Handling submit flags event...");
    const reviewJobId = await jobStore.submitFlagsForReview();
    if (reviewJobId) {
        showReclassifySuccessMessage.value = true;
        setTimeout(() => { showReclassifySuccessMessage.value = false; }, 7000);
        jobStore.fetchJobHistory(); // Refresh history list
    } else {
        console.log("JobStatus: Flag submission failed (error handled in store/table).");
        // Optionally show a generic error message here if needed, though specific errors are better shown near the button
    }
  };

  // --- Merge Results Handler ---
  const handleMergeResults = async () => {
      const currentId = jobDetails.value?.id;
      if (!currentId || jobDetails.value?.job_type !== 'REVIEW') return;
      console.log(`JobStatus: Handling merge results for review job ${currentId}`);
      const success = await jobStore.mergeReviewResults(currentId);
      if (success) {
          showMergeSuccessMessage.value = true;
          setTimeout(() => { showMergeSuccessMessage.value = false; }, 7000);
          // Optionally refresh job history or parent job view
          jobStore.fetchJobHistory();
          // Refresh stats for the current (review) job to show merged status
          jobStore.fetchJobStats(currentId);
      } else {
           console.log("JobStatus: Merge failed (error handled in store).");
           // Error message is displayed via jobStore.mergeError
      }
  };

  // --- Navigation ---
  const viewParentJob = () => {
      if (jobDetails.value?.parent_job_id) {
          jobStore.setCurrentJobId(jobDetails.value.parent_job_id);
      }
  };

  const viewReviewJob = (reviewJobId: string) => {
       jobStore.setCurrentJobId(reviewJobId);
       showReclassifySuccessMessage.value = false; // Hide message on navigation
  };

  // --- Fetch Initial Data Function ---
  const fetchInitialData = (jobId: string) => {
      errorMessage.value = null; // Clear previous errors
      const currentDetails = jobStore.jobDetails;

      // Fetch details if they are missing OR if the ID matches but type/status might be stale
      if (!currentDetails || currentDetails.id !== jobId) {
           console.log(`JobStatus: Fetching initial details and starting polling for ${jobId}`);
           startPolling(jobId); // Poll will fetch details
      } else if (currentDetails.status === 'completed') {
           console.log(`JobStatus: Job ${jobId} already completed. Fetching results and stats if needed.`);
           stopPolling();
           // Fetch results if needed
           if (!jobStore.resultsLoading && !jobStore.jobResults && !jobStore.relatedReviewResults) {
                jobStore.fetchCurrentJobResults();
           }
           // Fetch stats if needed (e.g., to check merge status)
           if (!jobStore.statsLoading && !jobStore.jobStats) {
                jobStore.fetchJobStats(jobId);
           }
      } else if (currentDetails.status === 'failed') {
           console.log(`JobStatus: Job ${jobId} already failed. Not polling or fetching results.`);
           stopPolling();
      } else {
           // Status is pending or processing, start polling
           console.log(`JobStatus: Job ${jobId} is ${currentDetails.status}. Starting polling.`);
           startPolling(jobId);
      }
  };

  // --- Lifecycle Hooks ---
  onMounted(() => {
      console.log(`JobStatus: Mounted. Current job ID from store: ${jobStore.currentJobId}`);
      if (jobStore.currentJobId) {
          fetchInitialData(jobStore.currentJobId);
      }
  });

  onUnmounted(() => {
      console.log("JobStatus: Unmounted, stopping polling.");
      stopPolling();
  });

  // --- Watchers ---
  watch(() => jobStore.currentJobId, (newJobId, oldJobId) => {
      console.log(`JobStatus: Watched currentJobId changed from ${oldJobId} to: ${newJobId}`);
      showReclassifySuccessMessage.value = false; // Hide success message on job change
      showMergeSuccessMessage.value = false; // Hide merge success message
      if (newJobId) {
          // Reset component state related to the specific job
          errorMessage.value = null;
          downloadError.value = null;
          notifyMessage.value = null;
          notificationEmail.value = '';
          isDownloadLoading.value = false;
          isNotifyLoading.value = false;
          // Fetch data for the new job
          fetchInitialData(newJobId);
      } else {
          // Job ID was cleared
          console.log("JobStatus: Job ID cleared, stopping polling.");
          stopPolling();
      }
  }, { immediate: false }); // Don't run immediately on mount, let onMounted handle initial load

  // Watch for the job status changing to completed (handles updates from polling)
  watch(() => jobStore.jobDetails?.status, (newStatus, oldStatus) => {
      const currentId = jobStore.currentJobId;
      if (!currentId || newStatus === oldStatus || jobStore.jobDetails?.id !== currentId) return; // Only act on change for the current job

      console.log(`JobStatus: Watched job status changed from ${oldStatus} to: ${newStatus} for job ${currentId}`);

      if (newStatus === 'completed') {
          console.log(`JobStatus: Job ${currentId} completed (detected by status watcher). Ensuring results & stats are fetched.`);
          stopPolling(); // Ensure polling is stopped
          // Fetch results if not already loading/present
          if (!jobStore.resultsLoading && !jobStore.jobResults && !jobStore.relatedReviewResults) {
            jobStore.fetchCurrentJobResults();
          }
          // Fetch stats if not already loading/present
          if (!jobStore.statsLoading && !jobStore.jobStats) {
            jobStore.fetchJobStats(currentId);
          }
      } else if (newStatus === 'failed') {
          console.log(`JobStatus: Job ${currentId} failed (detected by status watcher). Ensuring polling is stopped.`);
          stopPolling();
      }
  });

  </script>
</file>

<file path='frontend/vue_frontend/src/components/LandingPage.vue'>
<template>
    <div>
        <!-- Hero Section -->
        <section id="hero" class="relative overflow-hidden bg-gradient-to-br from-primary via-blue-700 to-indigo-800 text-white pt-24 pb-20 md:pt-32 md:pb-28">
        <!-- Subtle overlay -->
        <div class="absolute inset-0 bg-black opacity-10"></div>
        <div class="relative max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 text-center z-10">
            <h1 class="text-4xl md:text-5xl lg:text-6xl font-bold tracking-tight mb-5">
            Stop Guessing. Start Classifying.
            </h1>
            <p class="text-lg md:text-xl text-indigo-100 mb-10 max-w-3xl mx-auto">
            Transform your messy vendor lists into actionable, NAICS-classified data in minutes, not weeks. Leverage AI for unmatched accuracy and gain deeper procurement insights.
            </p>
            <div class="flex flex-col sm:flex-row justify-center items-center space-y-4 sm:space-y-0 sm:space-x-4">
            <a href="#loginCardAnchor"
                @click.prevent="scrollToLogin"
                class="inline-block bg-white text-primary font-semibold py-3 px-8 rounded-md shadow-lg hover:bg-gray-100 transition duration-300 text-lg transform hover:scale-105">
                Get Started Now
            </a>
                <!-- Optional Secondary CTA -->
                <!--
                <a href="#features" @click.prevent="scrollToFeatures"
                class="inline-block text-white font-medium py-3 px-8 rounded-md hover:bg-white/10 transition duration-300">
                Learn More
            </a>
            -->
            </div>
        </div>
            <!-- Optional: Subtle background pattern or graphic -->
            <!-- <div class="absolute bottom-0 left-0 w-full h-32 bg-gradient-to-t from-light to-transparent"></div> -->
        </section>

        <!-- Logos / Social Proof (Placeholder) -->
        <section class="py-8 bg-gray-50">
            <div class="max-w-5xl mx-auto px-4 sm:px-6 lg:px-8">
                <p class="text-center text-sm font-semibold text-gray-500 tracking-wider uppercase">
                    Trusted by leading procurement teams
                </p>
                <div class="mt-6 grid grid-cols-2 gap-4 md:grid-cols-4 lg:grid-cols-5 items-center">
                    <!-- Replace with actual logos -->
                    <div class="flex justify-center col-span-1"> <span class="text-gray-400 text-2xl italic">Logo Inc</span> </div>
                    <div class="flex justify-center col-span-1"> <span class="text-gray-400 text-2xl italic">VendorBase</span> </div>
                    <div class="flex justify-center col-span-1"> <span class="text-gray-400 text-2xl italic">SupplyCo</span> </div>
                    <div class="flex justify-center col-span-1"> <span class="text-gray-400 text-2xl italic">Analytics Ltd</span> </div>
                    <div class="flex justify-center col-span-1 hidden lg:flex"> <span class="text-gray-400 text-2xl italic">Insight Corp</span> </div>
                </div>
            </div>
        </section>

        <!-- Problem / Solution Section -->
        <section id="problem-solution" class="py-16 md:py-20">
            <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 grid md:grid-cols-2 gap-12 items-center">
                <!-- Problem -->
                <div class="text-center md:text-left">
                    <span class="inline-block bg-red-100 text-red-700 text-xs font-semibold px-3 py-1 rounded-full mb-3">The Challenge</span>
                    <h2 class="text-3xl font-semibold mb-4">Manual Classification is Broken</h2>
                    <p class="text-gray-600 mb-6">
                        Spending hours manually assigning NAICS codes? Dealing with inconsistent data, costly errors, and missed insights? Your team's valuable time is wasted on tedious tasks instead of strategic sourcing.
                    </p>
                    <ul class="space-y-2 text-left text-gray-600">
                        <li class="flex items-start"><CheckCircleIcon class="h-5 w-5 text-red-500 mr-2 mt-0.5 flex-shrink-0" /><span>Time-consuming & resource-intensive</span></li>
                        <li class="flex items-start"><CheckCircleIcon class="h-5 w-5 text-red-500 mr-2 mt-0.5 flex-shrink-0" /><span>Prone to inconsistencies and errors</span></li>
                        <li class="flex items-start"><CheckCircleIcon class="h-5 w-5 text-red-500 mr-2 mt-0.5 flex-shrink-0" /><span>Leads to unreliable reporting & analytics</span></li>
                    </ul>
                </div>
                <!-- Solution -->
                <div class="text-center md:text-left bg-gradient-to-br from-blue-50 to-primary/10 p-8 rounded-lg shadow-lg border border-primary/20">
                    <span class="inline-block bg-green-100 text-green-700 text-xs font-semibold px-3 py-1 rounded-full mb-3">The Solution</span>
                    <h2 class="text-3xl font-semibold text-primary mb-4">AI-Powered Automation</h2>
                    <p class="text-gray-700 mb-6">
                        NAICS Classify uses cutting-edge AI to analyze your vendor data, perform intelligent web searches, and deliver accurate, multi-level NAICS codes automatically. Reclaim your time and unlock data potential.
                    </p>
                    <ul class="space-y-2 text-left text-gray-700">
                        <li class="flex items-start"><CheckCircleIcon class="h-5 w-5 text-green-500 mr-2 mt-0.5 flex-shrink-0" /><span>Classify thousands of vendors in minutes</span></li>
                        <li class="flex items-start"><CheckCircleIcon class="h-5 w-5 text-green-500 mr-2 mt-0.5 flex-shrink-0" /><span>Achieve >95% accuracy with AI & search</span></li>
                        <li class="flex items-start"><CheckCircleIcon class="h-5 w-5 text-green-500 mr-2 mt-0.5 flex-shrink-0" /><span>Get consistent, reliable data for insights</span></li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- How It Works (Refined Visually) -->
        <section id="how-it-works" class="py-16 bg-gray-50">
            <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <h2 class="text-3xl font-semibold text-center mb-12">Get Results in 3 Simple Steps</h2>
            <div class="relative">
                <!-- Connecting Line (optional decorative element) -->
                    <div class="hidden md:block absolute top-1/2 left-0 w-full h-0.5 bg-gray-300 transform -translate-y-1/2 -z-1"></div>

                <div class="grid md:grid-cols-3 gap-8 relative">
                    <!-- Step 1 -->
                    <div class="bg-white p-6 rounded-lg shadow-lg border border-gray-200 text-center z-10">
                            <div class="relative inline-block">
                                <div class="inline-flex items-center justify-center w-16 h-16 mb-5 font-bold text-2xl text-white bg-primary rounded-full shadow-md">1</div>
                                <!-- Arrow pointing right (decorative) -->
                                <div class="hidden md:block absolute top-1/2 left-full ml-4 transform -translate-y-1/2 text-gray-300">
                                    <ArrowRightIcon class="h-8 w-8" />
                                </div>
                            </div>
                            <h4 class="text-lg font-semibold text-gray-800 mb-3">Upload Your List</h4>
                            <p class="text-sm text-gray-600">Drag & drop or select your Excel file (.xlsx/.xls) with a 'vendor_name' column. Add optional context columns for even better results.</p>
                    </div>
                        <!-- Step 2 -->
                        <div class="bg-white p-6 rounded-lg shadow-lg border border-gray-200 text-center z-10">
                        <div class="relative inline-block">
                                <div class="inline-flex items-center justify-center w-16 h-16 mb-5 font-bold text-2xl text-white bg-primary rounded-full shadow-md">2</div>
                                <!-- Arrow pointing right (decorative) -->
                                <div class="hidden md:block absolute top-1/2 left-full ml-4 transform -translate-y-1/2 text-gray-300">
                                    <ArrowRightIcon class="h-8 w-8" />
                                </div>
                            </div>
                        <h4 class="text-lg font-semibold text-gray-800 mb-3">AI Processing Magic</h4>
                        <p class="text-sm text-gray-600">Our intelligent engine analyzes names, utilizes context, performs web searches if needed, and assigns accurate NAICS codes.</p>
                        </div>
                        <!-- Step 3 -->
                        <div class="bg-white p-6 rounded-lg shadow-lg border border-gray-200 text-center z-10">
                            <div class="inline-flex items-center justify-center w-16 h-16 mb-5 font-bold text-2xl text-white bg-primary rounded-full shadow-md">3</div>
                        <h4 class="text-lg font-semibold text-gray-800 mb-3">Download Enriched Data</h4>
                        <p class="text-sm text-gray-600">Receive your original spreadsheet back, now enriched with precise Level 1-4 NAICS classifications, ready for analysis.</p>
                        </div>
                </div>
            </div>
            </div>
        </section>

        <!-- Features Section (Improved Layout) -->
        <section id="features" class="py-16 md:py-20">
            <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
                <h2 class="text-3xl font-semibold text-center mb-12">Powerful Features, Tangible Benefits</h2>
                <div class="grid md:grid-cols-2 lg:grid-cols-3 gap-8">
                    <!-- Feature Card -->
                    <div class="bg-white p-6 rounded-lg shadow-md border border-gray-100 hover:shadow-lg transition duration-300">
                        <div class="flex items-center mb-3">
                            <BeakerIcon class="h-7 w-7 text-primary mr-3" />
                            <h5 class="text-lg font-semibold">Unmatched AI Accuracy</h5>
                        </div>
                        <p class="text-sm text-gray-600">Leverages advanced LLMs trained on vast datasets for industry-leading classification precision.</p>
                    </div>
                    <!-- Feature Card -->
                    <div class="bg-white p-6 rounded-lg shadow-md border border-gray-100 hover:shadow-lg transition duration-300">
                        <div class="flex items-center mb-3">
                            <MagnifyingGlassIcon class="h-7 w-7 text-primary mr-3" />
                            <h5 class="text-lg font-semibold">Intelligent Web Search</h5>
                        </div>
                        <p class="text-sm text-gray-600">Automatically researches ambiguous vendors online, filling data gaps and boosting classification rates.</p>
                    </div>
                    <!-- Feature Card -->
                    <div class="bg-white p-6 rounded-lg shadow-md border border-gray-100 hover:shadow-lg transition duration-300">
                        <div class="flex items-center mb-3">
                            <Bars4Icon class="h-7 w-7 text-primary mr-3" />
                            <h5 class="text-lg font-semibold">Multi-Level Hierarchy</h5>
                        </div>
                        <p class="text-sm text-gray-600">Provides detailed NAICS codes up to Level 4, enabling granular spend analysis and reporting.</p>
                    </div>
                    <!-- Feature Card -->
                    <div class="bg-white p-6 rounded-lg shadow-md border border-gray-100 hover:shadow-lg transition duration-300">
                        <div class="flex items-center mb-3">
                            <ArrowUpTrayIcon class="h-7 w-7 text-primary mr-3" />
                            <h5 class="text-lg font-semibold">Simple Excel Workflow</h5>
                        </div>
                        <p class="text-sm text-gray-600">Integrates seamlessly with your existing spreadsheets. Just upload, process, and download.</p>
                    </div>
                    <!-- Feature Card -->
                    <div class="bg-white p-6 rounded-lg shadow-md border border-gray-100 hover:shadow-lg transition duration-300">
                        <div class="flex items-center mb-3">
                            <ClockIcon class="h-7 w-7 text-primary mr-3" />
                            <h5 class="text-lg font-semibold">Rapid Processing</h5>
                        </div>
                        <p class="text-sm text-gray-600">Asynchronous backend handles large files quickly, freeing up your team's time immediately.</p>
                    </div>
                    <!-- Feature Card -->
                    <div class="bg-white p-6 rounded-lg shadow-md border border-gray-100 hover:shadow-lg transition duration-300">
                        <div class="flex items-center mb-3">
                            <LockClosedIcon class="h-7 w-7 text-primary mr-3" />
                            <h5 class="text-lg font-semibold">Secure & Confidential</h5>
                        </div>
                        <p class="text-sm text-gray-600">Your data is encrypted and handled with strict security protocols throughout the process.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Testimonial Section (Placeholder) -->
        <section id="testimonials" class="py-16 bg-gradient-to-r from-gray-50 to-blue-50">
            <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
                <h2 class="text-3xl font-semibold mb-8">Don't Just Take Our Word For It</h2>
                <div class="relative p-8 bg-white rounded-lg shadow-xl border border-gray-200">
                    <!-- Quote Icon -->
                    <div class="absolute top-0 left-0 -mt-4 -ml-4 text-primary/20">
                        <svg class="h-16 w-16" fill="currentColor" viewBox="0 0 32 32">
                            <path d="M9.333 7h-2.667c-1.835 0-3.333 1.498-3.333 3.333v11.333c0 1.835 1.498 3.333 3.333 3.333h6.667v-8h-4v-4c0-1.102.897-2 2-2h2v-4zM25.333 7h-2.667c-1.835 0-3.333 1.498-3.333 3.333v11.333c0 1.835 1.498 3.333 3.333 3.333h6.667v-8h-4v-4c0-1.102.897-2 2-2h2v-4z" />
                        </svg>
                    </div>
                    <blockquote class="relative italic text-gray-700 text-lg">
                        "NAICS Classify saved us countless hours. What used to take a week now takes minutes, and the accuracy is fantastic. It's essential for our vendor management."
                    </blockquote>
                    <footer class="mt-6">
                        <p class="font-semibold text-gray-900">Jane Doe</p>
                        <p class="text-sm text-gray-500">Procurement Manager, Tech Solutions Inc.</p>
                    </footer>
                </div>
            </div>
        </section>


        <!-- Login / Forgot Password / Register Card Section -->
        <section id="loginCardAnchor" class="py-16">
            <div class="max-w-lg mx-auto px-4">
                <!-- Conditionally render Login, ForgotPassword, or Register -->
                <Login
                    v-if="!showForgotPassword && !showRegisterForm"
                    @login-successful="handleLogin"
                    @show-forgot-password="showForgotPasswordFormFunc"
                    @show-register="showRegisterFormFunc"
                />
                <ForgotPassword
                    v-else-if="showForgotPassword"
                    @close="hideForgotPasswordFormFunc"
                    @show-login="hideForgotPasswordFormFunc"
                />
                 <Register
                    v-else-if="showRegisterForm"
                    @registration-successful="handleRegistrationSuccess"
                    @show-login="hideRegisterFormFunc"
                />
            </div>
        </section>
    </div>
    </template>

    <script setup lang="ts">
    import { ref } from 'vue';
    import Login from './Login.vue';
    import ForgotPassword from './ForgotPassword.vue';
    import Register from './Register.vue'; // Import Register component
    // Import necessary icons from Heroicons (ensure @heroicons/vue is installed)
    import {
        CheckCircleIcon,
        ArrowRightIcon,
        BeakerIcon,
        MagnifyingGlassIcon,
        Bars4Icon,
        ArrowUpTrayIcon,
        ClockIcon,
        LockClosedIcon
    } from '@heroicons/vue/24/outline'; // Using outline style

    const emit = defineEmits(['login-successful']);

    // --- State for showing Login vs Forgot Password vs Register ---
    const showForgotPassword = ref(false);
    const showRegisterForm = ref(false); // Added state for registration form

    const showForgotPasswordFormFunc = () => {
        showRegisterForm.value = false; // Ensure register form is hidden
        showForgotPassword.value = true;
    };

    const hideForgotPasswordFormFunc = () => {
        showForgotPassword.value = false;
    };

    const showRegisterFormFunc = () => {
        showForgotPassword.value = false; // Ensure forgot password form is hidden
        showRegisterForm.value = true;
    };

    const hideRegisterFormFunc = () => {
        showRegisterForm.value = false;
    };

    const handleRegistrationSuccess = () => {
        // After successful registration, switch back to the login form
        // You might want to show a success message here or rely on the Register component's message
        console.log("LandingPage: Registration successful, showing login form.");
        hideRegisterFormFunc();
        // Optionally scroll back to the login card
        smoothScrollTo('loginCardAnchor');
    };
    // --- End State ---

    const handleLogin = () => {
        emit('login-successful');
    };

    // Helper for scrolling smoothly to sections
    const smoothScrollTo = (elementId: string) => {
        const element = document.getElementById(elementId);
        if (element) {
            const navbarHeight = 70; // Estimate navbar height
            const elementPosition = element.getBoundingClientRect().top;
            const offsetPosition = elementPosition + window.pageYOffset - navbarHeight;
            window.scrollTo({ top: offsetPosition, behavior: 'smooth' });
        }
    }

    const scrollToLogin = (event: Event) => {
        event.preventDefault();
        smoothScrollTo('loginCardAnchor');
        // Ensure login form is shown if user clicks "Get Started"
        hideForgotPasswordFormFunc();
        hideRegisterFormFunc();
    }

    // Optional: Scroll to features
    // const scrollToFeatures = (event: Event) => {
    //       event.preventDefault();
    //       smoothScrollTo('features');
    // }

    </script>

    <style scoped>
    /* Optional: Add subtle background patterns or animations if desired */
    /* Example: Subtle pattern for hero */
    /* #hero::before {
        content: '';
        position: absolute;
        inset: 0;
        background-image: url('path/to/your/subtle-pattern.svg');
        background-repeat: repeat;
        opacity: 0.05;
        z-index: 0;
    } */

    /* Ensure high z-index for step numbers if using lines */
    #how-it-works .relative > .grid { /* Target the grid directly inside the relative div */
        position: relative; /* Ensure grid items can be positioned relative to this */
        z-index: 10; /* Place grid items above the line */
    }
    #how-it-works .relative > .absolute { /* Target the line */
        z-index: 1; /* Place line behind grid items */
    }
    </style>
</file>

<file path='frontend/vue_frontend/src/components/Login.vue'>
<template>
  <div class="bg-white rounded-lg shadow-md mb-5 overflow-hidden border border-gray-200">
    <div class="bg-primary text-white p-4">
      <h4 class="text-xl font-semibold mb-0 text-center">Login to Access Service</h4>
    </div>
    <div class="p-6">
      <form @submit.prevent="handleLogin">
        <div class="mb-4">
          <label for="username" class="block text-sm font-medium text-gray-700 mb-1">Username</label>
          <input
              type="text"
              class="block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-50"
              id="username"
              v-model="username"
              required
              :disabled="isLoading"
              placeholder="admin"
          >
          <p class="mt-1 text-xs text-gray-500">Default: admin</p>
        </div>
        <div class="mb-4"> <!-- Reduced bottom margin -->
          <label for="password" class="block text-sm font-medium text-gray-700 mb-1">Password</label>
          <input
              type="password"
              class="block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-50"
              id="password"
              v-model="password"
              required
              :disabled="isLoading"
              placeholder="password"
          >
           <p class="mt-1 text-xs text-gray-500">Default: password</p>
        </div>
         <!-- Forgot Password Link -->
        <div class="text-right mb-4">
            <button
                type="button"
                @click="$emit('show-forgot-password')"
                class="text-sm font-medium text-primary hover:text-primary-hover focus:outline-none"
                :disabled="isLoading"
            >
                Forgot Password?
            </button>
        </div>
        <!-- End Forgot Password Link -->
        <button type="submit" class="w-full flex justify-center items-center px-4 py-2.5 border border-transparent rounded-md shadow-sm text-base font-medium text-white bg-primary hover:bg-primary-hover focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-primary disabled:opacity-50 disabled:cursor-not-allowed" :disabled="isLoading">
           <svg v-if="isLoading" class="animate-spin -ml-1 mr-3 h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
              <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
              <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
           </svg>
           {{ isLoading ? ' Logging in...' : 'Login' }}
        </button>
         <!-- Tailwind Alert -->
        <div v-if="errorMessage" class="mt-4 p-3 bg-red-100 border border-red-300 text-red-700 rounded-md text-center text-sm">{{ errorMessage }}</div>
      </form>

       <!-- ADDED: Register Link -->
       <div class="mt-4 text-center">
        <p class="text-sm text-gray-600">
          Don't have an account?
          <button
            @click="$emit('show-register')"
            class="font-medium text-primary hover:text-primary-hover focus:outline-none"
            :disabled="isLoading"
          >
            Create one now
          </button>
        </p>
      </div>
      <!-- END ADDED: Register Link -->

    </div>
  </div>
</template>

<script setup lang="ts">
   import { ref } from 'vue';
   import { useAuthStore } from '@/stores/auth';

   const username = ref('admin');
   const password = ref('password');
   const isLoading = ref(false);
   const errorMessage = ref<string | null>(null);

   const authStore = useAuthStore();
   // Define emits including the new one
   const emit = defineEmits(['login-successful', 'show-forgot-password', 'show-register']); // Added 'show-register'

   const handleLogin = async () => {
     isLoading.value = true;
     errorMessage.value = null;
     try {
       await authStore.login(username.value, password.value);
       console.log('Login component: Login successful.');
       emit('login-successful');
     } catch (error: any) {
       console.error('Login component error:', error);
       // Ensure error.message exists and is a string
       errorMessage.value = (error && typeof error.message === 'string') ? error.message : 'An unexpected error occurred during login.';
     } finally {
       isLoading.value = false;
     }
   };
</script>

<style scoped>
 /* No scoped styles needed */
</style>
</file>

<file path='frontend/vue_frontend/src/components/Navbar.vue'>

<template>
  <nav class="bg-primary shadow-md fixed top-0 left-0 right-0 z-50">
  <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
      <div class="flex items-center justify-between h-16">
      <!-- Branding -->
      <div class="flex-shrink-0">
          <a class="text-white text-xl font-bold flex items-center cursor-pointer" @click="goHome">
              <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" class="h-6 w-6 mr-2" viewBox="0 0 16 16">
              <path fill-rule="evenodd" d="M6 3.5A1.5 1.5 0 0 1 7.5 2h1A1.5 1.5 0 0 1 10 3.5v1A1.5 1.5 0 0 1 8.5 6v1H14a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-1 0V8h-5v.5a.5.5 0 0 1-1 0V8h-5v.5a.5.5 0 0 1-1 0v-1A.5.5 0 0 1 2 7h5.5V6A1.5 1.5 0 0 1 6 4.5zM8.5 7H14v1h-5.5zM2 8h5.5v1H2zm9.5 4.5a1.5 1.5 0 0 0-1.5-1.5h-1a1.5 1.5 0 0 0-1.5 1.5v1a1.5 1.5 0 0 0 1.5 1.5h1a1.5 1.5 0 0 0 1.5-1.5zm-1.5 2.5a.5.5 0 0 1-.5.5h-1a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h1a.5.5 0 0 1 .5.5zM2 12.5a.5.5 0 0 1 .5-.5h1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-1a.5.5 0 0 1-.5-.5zM11 12.5a.5.5 0 0 1 .5-.5h1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-1a.5.5 0 0 1-.5-.5z"/>
              </svg>
          NAICS Classify
          </a>
      </div>

      <!-- User Info / Admin / Logout Section -->
      <div v-if="authStore.isAuthenticated" class="flex items-center space-x-4">
          <!-- Admin Link (Conditional) -->
          <button
          v-if="authStore.isSuperuser"
          @click="toggleAdminView"
          :class="[
              'px-3 py-1 text-sm font-medium rounded-md focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-primary focus:ring-white',
              isAdminViewActive ? 'bg-indigo-700 text-white' : 'text-gray-200 hover:bg-indigo-500 hover:text-white'
          ]"
          >
          Admin Panel
          </button>

          <!-- Welcome Message -->
          <span class="text-gray-200 text-sm hidden sm:inline">
          Welcome, <span class="font-semibold text-white">{{ authStore.username || 'User' }}</span>
          </span>

          <!-- Logout Button -->
          <button
          @click="emitLogout"
          class="px-3 py-1 border border-transparent text-sm font-medium rounded-md text-primary bg-white hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-primary focus:ring-white"
          >
          Logout
          </button>
      </div>
      <!-- Optional Login button if needed -->
      </div>
  </div>
  </nav>
</template>

<script setup lang="ts">
import { useAuthStore } from '@/stores/auth';
import { useViewStore } from '@/stores/view'; // Assuming a view store exists
import { computed } from 'vue';

const authStore = useAuthStore();
const viewStore = useViewStore(); // Use the view store

const emit = defineEmits(['logout']);
const emitLogout = () => emit('logout');

// Computed property to check if the admin view is currently active
const isAdminViewActive = computed(() => viewStore.currentView === 'admin');

const toggleAdminView = () => {
  if (viewStore.currentView === 'admin') {
      viewStore.setView('app'); // Switch back to the main app view
  } else {
      viewStore.setView('admin'); // Switch to the admin view
  }
};

const goHome = () => {
  // If logged in, go to app view, otherwise landing page (handled by App.vue)
  if (authStore.isAuthenticated) {
      viewStore.setView('app');
  }
  // If not logged in, clicking the brand might implicitly take them "home"
  // which is the landing page in the current App.vue setup.
  // If using router, this would be router.push('/');
};
</script>
</file>

<file path='frontend/vue_frontend/src/components/Register.vue'>
<template>
  <div class="bg-white rounded-lg shadow-md mb-5 overflow-hidden border border-gray-200">
    <div class="bg-primary text-white p-4">
      <h4 class="text-xl font-semibold mb-0 text-center">Create New Account</h4>
    </div>
    <div class="p-6">
      <form @submit.prevent="handleRegister">
        <!-- Username -->
        <div class="mb-4">
          <label for="reg-username" class="block text-sm font-medium text-gray-700 mb-1">Username <span class="text-red-500">*</span></label>
          <input
            type="text"
            class="block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-50"
            id="reg-username"
            v-model="formData.username"
            required
            minlength="3"
            maxlength="50"
            :disabled="isLoading"
            placeholder="Choose a username"
          />
        </div>

        <!-- Email -->
        <div class="mb-4">
          <label for="reg-email" class="block text-sm font-medium text-gray-700 mb-1">Email Address <span class="text-red-500">*</span></label>
          <input
            type="email"
            class="block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-50"
            id="reg-email"
            v-model="formData.email"
            required
            :disabled="isLoading"
            placeholder="you@example.com"
          />
        </div>

        <!-- Full Name (Optional) -->
        <div class="mb-4">
          <label for="reg-fullname" class="block text-sm font-medium text-gray-700 mb-1">Full Name (Optional)</label>
          <input
            type="text"
            class="block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-50"
            id="reg-fullname"
            v-model="formData.full_name"
            :disabled="isLoading"
            placeholder="Your full name"
          />
        </div>

        <!-- Password -->
        <div class="mb-4">
          <label for="reg-password" class="block text-sm font-medium text-gray-700 mb-1">Password <span class="text-red-500">*</span></label>
          <input
            type="password"
            class="block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-50"
            id="reg-password"
            v-model="formData.password"
            required
            minlength="8"
            :disabled="isLoading"
            placeholder="Minimum 8 characters"
          />
        </div>

        <!-- Confirm Password -->
        <div class="mb-6">
          <label for="reg-confirmPassword" class="block text-sm font-medium text-gray-700 mb-1">Confirm Password <span class="text-red-500">*</span></label>
          <input
            type="password"
            class="block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-50"
            id="reg-confirmPassword"
            v-model="confirmPassword"
            required
            :disabled="isLoading"
          />
          <p v-if="passwordMismatch" class="mt-1 text-xs text-red-500">Passwords do not match.</p>
        </div>

        <!-- Submit Button -->
        <button
          type="submit"
          class="w-full flex justify-center items-center px-4 py-2.5 border border-transparent rounded-md shadow-sm text-base font-medium text-white bg-primary hover:bg-primary-hover focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-primary disabled:opacity-50 disabled:cursor-not-allowed"
          :disabled="isLoading || passwordMismatch"
        >
          <svg v-if="isLoading" class="animate-spin -ml-1 mr-3 h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
            <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
            <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
          </svg>
          {{ isLoading ? 'Creating Account...' : 'Register' }}
        </button>

        <!-- Error/Success Message -->
        <div v-if="message" :class="['mt-4 p-3 rounded-md text-center text-sm', messageType === 'success' ? 'bg-green-100 border border-green-300 text-green-700' : 'bg-red-100 border border-red-300 text-red-700']">
          {{ message }}
        </div>
      </form>

      <!-- Back to Login Link -->
      <div class="mt-4 text-center">
        <button @click="$emit('show-login')" class="text-sm text-primary hover:underline">
          Already have an account? Login
        </button>
      </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, computed } from 'vue';
import apiService, { type UserCreateData } from '@/services/api'; // Adjust path as needed

const emit = defineEmits(['registration-successful', 'show-login']);

const formData = ref<UserCreateData>({
  username: '',
  email: '',
  full_name: '',
  password: '',
  // Defaults for new users (backend handles these, but good practice)
  is_active: true,
  is_superuser: false,
});
const confirmPassword = ref('');
const isLoading = ref(false);
const message = ref<string | null>(null);
const messageType = ref<'success' | 'error'>('success');

const passwordMismatch = computed<boolean>(() => {
  return (
    formData.value.password!.length > 0 && // Use non-null assertion as password is required
    confirmPassword.value.length > 0 &&
    formData.value.password !== confirmPassword.value
  );
});

const handleRegister = async () => {
  if (passwordMismatch.value) {
    message.value = "Passwords do not match.";
    messageType.value = 'error';
    return;
  }
  if (!formData.value.password || formData.value.password.length < 8) {
    message.value = "Password is required and must be at least 8 characters.";
    messageType.value = 'error';
    return;
  }

  isLoading.value = true;
  message.value = null;
  messageType.value = 'success';

  // Prepare data, ensuring full_name is null if empty
  const dataToSend: UserCreateData = {
    ...formData.value,
    full_name: formData.value.full_name?.trim() || null,
  };

  try {
    const newUser = await apiService.registerUser(dataToSend);
    message.value = `Registration successful for ${newUser.username}! You can now log in.`;
    messageType.value = 'success';
    // Optionally clear form or emit success immediately
    // formData.value = { username: '', email: '', full_name: '', password: '' }; // Reset form
    // confirmPassword.value = '';
    emit('registration-successful'); // Notify parent

  } catch (error: any) {
    console.error('Registration error:', error);
    message.value = error.message || 'An unexpected error occurred during registration.';
    messageType.value = 'error';
  } finally {
    isLoading.value = false;
  }
};
</script>

<style scoped>
/* Add any specific styles if needed */
</style>
</file>

<file path='frontend/vue_frontend/src/components/ResetPassword.vue'>
<template>
  <div class="bg-white rounded-lg shadow-md overflow-hidden border border-gray-200">
    <div class="bg-gray-100 p-4 border-b border-gray-200 flex justify-between items-center">
      <h4 class="text-lg font-semibold text-gray-700 mb-0">Reset Your Password</h4>
       <button @click="$emit('close')" class="text-gray-500 hover:text-gray-700 text-xl">&times;</button>
    </div>
    <div class="p-6">
      <p v-if="!tokenValid" class="text-sm text-red-600 mb-4">
        The password reset link is invalid or has expired. Please request a new one.
      </p>
      <form v-else @submit.prevent="handleResetPassword">
        <p class="text-sm text-gray-600 mb-4">
          Enter your new password below.
        </p>
        <div class="mb-4">
          <label for="newPassword" class="block text-sm font-medium text-gray-700 mb-1">New Password</label>
          <input
            type="password"
            class="block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-50"
            id="newPassword"
            v-model="newPassword"
            required
            minlength="8"
            :disabled="isLoading || resetSuccessful"
          />
           <p class="mt-1 text-xs text-gray-500">Minimum 8 characters.</p>
        </div>
         <div class="mb-6">
          <label for="confirmPassword" class="block text-sm font-medium text-gray-700 mb-1">Confirm New Password</label>
          <input
            type="password"
            class="block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-50"
            id="confirmPassword"
            v-model="confirmPassword"
            required
            :disabled="isLoading || resetSuccessful"
          />
           <p v-if="passwordMismatch" class="mt-1 text-xs text-red-500">Passwords do not match.</p>
        </div>

        <button
          type="submit"
          class="w-full flex justify-center items-center px-4 py-2.5 border border-transparent rounded-md shadow-sm text-base font-medium text-white bg-primary hover:bg-primary-hover focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-primary disabled:opacity-50 disabled:cursor-not-allowed"
          :disabled="isLoading || resetSuccessful || passwordMismatch"
        >
          <svg v-if="isLoading" class="animate-spin -ml-1 mr-3 h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
            <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
            <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
          </svg>
          {{ buttonText }}
        </button>

        <!-- Success/Error Messages -->
        <div v-if="message" :class="['mt-4 p-3 rounded-md text-center text-sm', messageType === 'success' ? 'bg-green-100 border border-green-300 text-green-700' : 'bg-red-100 border border-red-300 text-red-700']">
          {{ message }}
        </div>
         <div v-if="resetSuccessful" class="mt-4 text-center">
            <button @click="$emit('show-login')" class="text-sm text-primary hover:underline">
                Proceed to Login
            </button>
         </div>
      </form>
       <div v-if="!tokenValid" class="mt-4 text-center">
          <button @click="$emit('show-forgot-password')" class="text-sm text-primary hover:underline">
            Request New Reset Link
          </button>
           <span class="mx-2 text-gray-400">|</span>
          <button @click="$emit('show-login')" class="text-sm text-primary hover:underline">
            Back to Login
          </button>
        </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, onMounted } from 'vue';
import apiService from '@/services/api'; // Adjust path as needed

const props = defineProps({
  token: {
    type: String,
    required: true,
  },
});

const emit = defineEmits(['close', 'show-login', 'show-forgot-password']);

const newPassword = ref('');
const confirmPassword = ref('');
const isLoading = ref(false);
const message = ref<string | null>(null);
const messageType = ref<'success' | 'error'>('success');
const resetSuccessful = ref(false);
const tokenValid = ref(true);

const passwordMismatch = computed<boolean>(() => {
  // Force a boolean so that TypeScript never sees `""`
  return (
    newPassword.value.length > 0 &&
    confirmPassword.value.length > 0 &&
    newPassword.value !== confirmPassword.value
  );
});

const buttonText = computed(() => {
  if (isLoading.value) return 'Resetting...';
  if (resetSuccessful.value) return 'Password Reset';
  return 'Reset Password';
});

onMounted(() => {
  if (!props.token) {
    tokenValid.value = false;
    message.value = "No reset token provided in the link.";
    messageType.value = 'error';
  }
});

const handleResetPassword = async () => {
  if (passwordMismatch.value) {
    message.value = "Passwords do not match.";
    messageType.value = 'error';
    return;
  }
  if (!props.token) {
     message.value = "Reset token is missing.";
     messageType.value = 'error';
     tokenValid.value = false;
     return;
  }

  isLoading.value = true;
  message.value = null;
  messageType.value = 'success';

  try {
    const response = await apiService.resetPassword(props.token, newPassword.value);
    message.value = response.message;
    messageType.value = 'success';
    resetSuccessful.value = true;
  } catch (error: any) {
    console.error('Reset Password error:', error);
    message.value = error.message || 'An unexpected error occurred.';
    messageType.value = 'error';
    resetSuccessful.value = false;
    if (error.message && (error.message.includes('Invalid') || error.message.includes('expired'))) {
        tokenValid.value = false;
    }
  } finally {
    isLoading.value = false;
  }
};
</script>
</file>

<file path='frontend/vue_frontend/src/components/ReviewResultsTable.vue'>
<template>
  <div class="mt-8 p-4 sm:p-6 bg-gray-50 rounded-lg border border-gray-200 shadow-inner">
    <h5 class="text-lg font-semibold text-gray-800 mb-4">Reviewed Classification Results</h5>
    <p class="text-sm text-gray-600 mb-4">
      Showing results after applying user hints. Target classification level for this review was **Level {{ targetLevel }}**. You can flag items again to start another review cycle (hints will be asked for again during submission).
    </p>

    <!-- Search Input -->
    <div class="mb-4">
      <label for="review-results-search" class="sr-only">Search Reviewed Results</label>
      <div class="relative rounded-md shadow-sm">
        <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
          <MagnifyingGlassIcon class="h-5 w-5 text-gray-400" aria-hidden="true" />
        </div>
        <input
          type="text"
          id="review-results-search"
          v-model="searchTerm"
          placeholder="Search Vendor, Hint, Category, ID, Notes..."
          class="block w-full pl-10 pr-3 py-2 border border-gray-300 rounded-md placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm"
        />
      </div>
    </div>

     <!-- Action Buttons (Submit Flags) -->
    <div class="mb-4 text-right" v-if="jobStore.hasFlaggedItems">
        <button
          type="button"
          @click="submitFlags"
          :disabled="jobStore.reclassifyLoading"
          class="inline-flex items-center rounded-md bg-primary px-3 py-2 text-sm font-semibold text-white shadow-sm hover:bg-primary-dark focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-primary disabled:opacity-50"
        >
          <ArrowPathIcon v-if="jobStore.reclassifyLoading" class="animate-spin -ml-0.5 mr-1.5 h-5 w-5" aria-hidden="true" />
          <PaperAirplaneIcon v-else class="-ml-0.5 mr-1.5 h-5 w-5" aria-hidden="true" />
          Submit {{ jobStore.flaggedForReview.size }} Flag{{ jobStore.flaggedForReview.size !== 1 ? 's' : '' }} for Re-classification
        </button>
        <p class="mt-1 text-xs text-gray-600 text-right">Hints will be collected when submitting flags from the original job view.</p>
        <p v-if="jobStore.reclassifyError" class="text-xs text-red-600 mt-1 text-right">{{ jobStore.reclassifyError }}</p>
    </div>

    <!-- Loading/Error States -->
    <div v-if="loading" class="text-center py-5 text-gray-500">
      <svg class="animate-spin h-6 w-6 text-primary mx-auto" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
        <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
        <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
      </svg>
      <p class="mt-2 text-sm">Loading reviewed results...</p>
    </div>
    <div v-else-if="error" class="p-4 bg-red-100 border border-red-300 text-red-800 rounded-md text-sm">
      Error loading reviewed results: {{ error }}
    </div>
    <div v-else-if="!results || results.length === 0" class="text-center py-5 text-gray-500">
      No reviewed results found for this job.
    </div>

    <!-- Results Table -->
    <div v-else class="overflow-x-auto border border-gray-200 rounded-md">
      <table class="min-w-full divide-y divide-gray-200">
        <thead class="bg-gray-100">
          <tr>
            <!-- Flag Column -->
            <th scope="col" class="sticky left-0 z-10 bg-gray-100 px-2 py-3 text-center text-xs font-medium text-gray-600 uppercase tracking-wider w-12">Flag</th>
            <!-- Dynamically generate headers -->
            <th v-for="header in headers" :key="header.key"
                scope="col"
                @click="header.sortable ? sortBy(header.key) : null"
                :class="[
                  'px-3 py-3 text-left text-xs font-medium text-gray-600 uppercase tracking-wider whitespace-nowrap',
                   header.sortable ? 'cursor-pointer hover:bg-gray-200' : '',
                   header.sticky ? 'sticky left-[48px] z-10 bg-gray-100' : '', // Adjusted left offset for flag column
                   header.minWidth ? `min-w-[${header.minWidth}]` : '',
                   header.isOriginal ? 'bg-blue-50' : '', // Style original columns
                   header.isNew ? 'bg-green-50' : '', // Style new columns
                ]">
              {{ header.label }}
              <SortIcon v-if="header.sortable" :direction="sortKey === header.key ? sortDirection : null" />
            </th>
          </tr>
        </thead>
        <tbody class="bg-white divide-y divide-gray-200">
          <tr v-if="filteredAndSortedResults.length === 0">
            <td :colspan="headers.length + 1" class="px-4 py-4 whitespace-nowrap text-sm text-gray-500 text-center">No results match your search criteria.</td>
          </tr>
          <tr v-for="(item, index) in filteredAndSortedResults" :key="item.vendor_name + '-' + index" class="hover:bg-gray-50 align-top" :class="{'bg-indigo-50': jobStore.isFlagged(item.vendor_name)}">
            <!-- Flag Button Cell (Sticky) -->
            <td class="sticky left-0 z-10 bg-white px-2 py-2 text-center align-middle" :class="{'bg-indigo-50': jobStore.isFlagged(item.vendor_name)}">
                 <button
                    @click="toggleFlag(item.vendor_name)"
                    :title="jobStore.isFlagged(item.vendor_name) ? 'Remove flag' : 'Flag for next review cycle'"
                    class="p-1 rounded-full hover:bg-gray-200 focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-primary"
                    :class="jobStore.isFlagged(item.vendor_name) ? 'text-primary' : 'text-gray-400 hover:text-primary-dark'"
                  >
                    <FlagIconSolid v-if="jobStore.isFlagged(item.vendor_name)" class="h-5 w-5" aria-hidden="true" />
                    <FlagIconOutline v-else class="h-5 w-5" aria-hidden="true" />
                    <span class="sr-only">Flag item</span>
                  </button>
            </td>
            <!-- Vendor Name Cell (Sticky) -->
            <td class="sticky left-[48px] z-10 bg-white px-3 py-2 whitespace-nowrap text-sm font-medium text-gray-900" :class="{'bg-indigo-50': jobStore.isFlagged(item.vendor_name)}">{{ item.vendor_name }}</td>
            <!-- Hint Cell (Display Only) -->
            <td class="px-3 py-2 text-xs text-gray-600 max-w-xs break-words">
                <span>{{ item.hint }}</span>
                <!-- Removed Hint Input Textarea -->
            </td>
            <!-- Original Classification -->
            <td class="px-3 py-2 whitespace-nowrap text-xs font-mono text-gray-500 bg-blue-50">{{ item.original_result?.level1_id || '-' }}</td>
            <td class="px-3 py-2 text-xs text-gray-500 bg-blue-50">{{ item.original_result?.level1_name || '-' }}</td>
            <td class="px-3 py-2 whitespace-nowrap text-xs font-mono text-gray-500 bg-blue-50">{{ item.original_result?.level2_id || '-' }}</td>
            <td class="px-3 py-2 text-xs text-gray-500 bg-blue-50">{{ item.original_result?.level2_name || '-' }}</td>
            <td class="px-3 py-2 whitespace-nowrap text-xs font-mono text-gray-500 bg-blue-50">{{ item.original_result?.level3_id || '-' }}</td>
            <td class="px-3 py-2 text-xs text-gray-500 bg-blue-50">{{ item.original_result?.level3_name || '-' }}</td>
            <td class="px-3 py-2 whitespace-nowrap text-xs font-mono text-gray-500 bg-blue-50">{{ item.original_result?.level4_id || '-' }}</td>
            <td class="px-3 py-2 text-xs text-gray-500 bg-blue-50">{{ item.original_result?.level4_name || '-' }}</td>
            <td class="px-3 py-2 whitespace-nowrap text-xs font-mono text-gray-500 bg-blue-50">{{ item.original_result?.level5_id || '-' }}</td>
            <td class="px-3 py-2 text-xs text-gray-500 bg-blue-50">{{ item.original_result?.level5_name || '-' }}</td>
            <td class="px-3 py-2 whitespace-nowrap text-xs text-center text-gray-500 bg-blue-50">
                <span class="px-2 inline-flex text-xs leading-5 font-semibold rounded-full"
                      :class="getStatusClass(item.original_result?.final_status)">
                    {{ item.original_result?.final_status }}
                </span>
            </td>
            <td class="px-3 py-2 whitespace-nowrap text-xs text-center text-gray-500 bg-blue-50">
               <span class="px-2 inline-flex text-xs leading-5 font-semibold rounded-full"
                     :class="getSourceClass(item.original_result?.classification_source)">
                 {{ item.original_result?.classification_source }}
               </span>
             </td>
            <td class="px-3 py-2 text-xs text-gray-500 max-w-xs break-words bg-blue-50">
              {{ item.original_result?.classification_notes_or_reason || '-' }}
            </td>


            <!-- New Classification -->
            <td class="px-3 py-2 whitespace-nowrap text-xs font-mono bg-green-50" :class="getCellClass(item.new_result, 1)">{{ item.new_result?.level1_id || '-' }}</td>
            <td class="px-3 py-2 text-xs bg-green-50" :class="getCellClass(item.new_result, 1)">{{ item.new_result?.level1_name || '-' }}</td>
            <td class="px-3 py-2 whitespace-nowrap text-xs font-mono bg-green-50" :class="getCellClass(item.new_result, 2)">{{ item.new_result?.level2_id || '-' }}</td>
            <td class="px-3 py-2 text-xs bg-green-50" :class="getCellClass(item.new_result, 2)">{{ item.new_result?.level2_name || '-' }}</td>
            <td class="px-3 py-2 whitespace-nowrap text-xs font-mono bg-green-50" :class="getCellClass(item.new_result, 3)">{{ item.new_result?.level3_id || '-' }}</td>
            <td class="px-3 py-2 text-xs bg-green-50" :class="getCellClass(item.new_result, 3)">{{ item.new_result?.level3_name || '-' }}</td>
            <td class="px-3 py-2 whitespace-nowrap text-xs font-mono bg-green-50" :class="getCellClass(item.new_result, 4)">{{ item.new_result?.level4_id || '-' }}</td>
            <td class="px-3 py-2 text-xs bg-green-50" :class="getCellClass(item.new_result, 4)">{{ item.new_result?.level4_name || '-' }}</td>
            <td class="px-3 py-2 whitespace-nowrap text-xs font-mono bg-green-50" :class="getCellClass(item.new_result, 5)">{{ item.new_result?.level5_id || '-' }}</td>
            <td class="px-3 py-2 text-xs bg-green-50" :class="getCellClass(item.new_result, 5)">{{ item.new_result?.level5_name || '-' }}</td>
            <td class="px-3 py-2 whitespace-nowrap text-sm text-center bg-green-50">
              <span v-if="item.new_result?.final_confidence !== null && item.new_result?.final_confidence !== undefined"
                    :class="getConfidenceClass(item.new_result.final_confidence)">
                {{ (item.new_result.final_confidence * 100).toFixed(1) }}%
              </span>
              <span v-else class="text-gray-400 text-xs">N/A</span>
            </td>
            <td class="px-3 py-2 whitespace-nowrap text-xs text-center bg-green-50">
               <span class="px-2 inline-flex text-xs leading-5 font-semibold rounded-full"
                    :class="getStatusClass(item.new_result?.final_status)">
                {{ item.new_result?.final_status }}
              </span>
            </td>
             <td class="px-3 py-2 whitespace-nowrap text-xs text-center bg-green-50">
               <span class="px-2 inline-flex text-xs leading-5 font-semibold rounded-full"
                     :class="getSourceClass(item.new_result?.classification_source)">
                 {{ item.new_result?.classification_source }}
               </span>
             </td>
            <td class="px-3 py-2 text-xs text-gray-500 max-w-xs break-words bg-green-50">
              {{ item.new_result?.classification_notes_or_reason || '-' }}
            </td>
          </tr>
        </tbody>
      </table>
    </div>

     <!-- Row Count -->
    <div class="mt-3 text-xs text-gray-500">
      Showing {{ filteredAndSortedResults.length }} of {{ results?.length || 0 }} reviewed results.
    </div>

  </div>
</template>

<script setup lang="ts">
import { ref, computed, type PropType } from 'vue';
import { useJobStore, type ReviewResultItem, type JobResultItem } from '@/stores/job';
import { FlagIcon as FlagIconOutline, MagnifyingGlassIcon, PaperAirplaneIcon, ArrowPathIcon } from '@heroicons/vue/24/outline';
import { FlagIcon as FlagIconSolid, ChevronUpIcon, ChevronDownIcon, ChevronUpDownIcon } from '@heroicons/vue/20/solid';

// --- Define Header Interface ---
interface ReviewTableHeader {
  key: string; // Use string for complex/nested keys
  label: string;
  sortable: boolean;
  sticky?: boolean; // For sticky columns
  minWidth?: string;
  isOriginal?: boolean; // Flag for styling/grouping
  isNew?: boolean;      // Flag for styling/grouping
}
// --- END Define Header Interface ---

// --- Props ---
const props = defineProps({
  results: {
    type: Array as PropType<ReviewResultItem[] | null>,
    required: true,
  },
  loading: {
    type: Boolean,
    default: false,
  },
  error: {
    type: String as PropType<string | null>,
    default: null,
  },
  targetLevel: { // Pass the job's target level
    type: Number,
    required: true,
  }
});

const emit = defineEmits(['submit-flags']); // Emit event when submit button is clicked

// --- Store ---
const jobStore = useJobStore();

// --- Internal State ---
const searchTerm = ref('');
const sortKey = ref<string | null>('vendor_name'); // Default sort by vendor name
const sortDirection = ref<'asc' | 'desc' | null>('asc'); // Default sort direction

// --- Table Headers Definition ---
const headers = ref<ReviewTableHeader[]>([
  { key: 'vendor_name', label: 'Vendor Name', sortable: true, sticky: true, minWidth: '150px' }, // Make Vendor sticky
  { key: 'hint', label: 'User Hint', sortable: true, minWidth: '180px' },
  // Original Results
  { key: 'original_result.level1_id', label: 'Orig L1 ID', sortable: true, minWidth: '80px', isOriginal: true },
  { key: 'original_result.level1_name', label: 'Orig L1 Name', sortable: true, minWidth: '120px', isOriginal: true },
  { key: 'original_result.level2_id', label: 'Orig L2 ID', sortable: true, minWidth: '80px', isOriginal: true },
  { key: 'original_result.level2_name', label: 'Orig L2 Name', sortable: true, minWidth: '120px', isOriginal: true },
  { key: 'original_result.level3_id', label: 'Orig L3 ID', sortable: true, minWidth: '80px', isOriginal: true },
  { key: 'original_result.level3_name', label: 'Orig L3 Name', sortable: true, minWidth: '120px', isOriginal: true },
  { key: 'original_result.level4_id', label: 'Orig L4 ID', sortable: true, minWidth: '80px', isOriginal: true },
  { key: 'original_result.level4_name', label: 'Orig L4 Name', sortable: true, minWidth: '120px', isOriginal: true },
  { key: 'original_result.level5_id', label: 'Orig L5 ID', sortable: true, minWidth: '80px', isOriginal: true },
  { key: 'original_result.level5_name', label: 'Orig L5 Name', sortable: true, minWidth: '120px', isOriginal: true },
  { key: 'original_result.final_status', label: 'Orig Status', sortable: true, minWidth: '100px', isOriginal: true },
  { key: 'original_result.classification_source', label: 'Orig Source', sortable: true, minWidth: '80px', isOriginal: true },
  { key: 'original_result.classification_notes_or_reason', label: 'Orig Notes/Reason', sortable: false, minWidth: '200px', isOriginal: true },
  // New Results
  { key: 'new_result.level1_id', label: 'New L1 ID', sortable: true, minWidth: '80px', isNew: true },
  { key: 'new_result.level1_name', label: 'New L1 Name', sortable: true, minWidth: '120px', isNew: true },
  { key: 'new_result.level2_id', label: 'New L2 ID', sortable: true, minWidth: '80px', isNew: true },
  { key: 'new_result.level2_name', label: 'New L2 Name', sortable: true, minWidth: '120px', isNew: true },
  { key: 'new_result.level3_id', label: 'New L3 ID', sortable: true, minWidth: '80px', isNew: true },
  { key: 'new_result.level3_name', label: 'New L3 Name', sortable: true, minWidth: '120px', isNew: true },
  { key: 'new_result.level4_id', label: 'New L4 ID', sortable: true, minWidth: '80px', isNew: true },
  { key: 'new_result.level4_name', label: 'New L4 Name', sortable: true, minWidth: '120px', isNew: true },
  { key: 'new_result.level5_id', label: 'New L5 ID', sortable: true, minWidth: '80px', isNew: true },
  { key: 'new_result.level5_name', label: 'New L5 Name', sortable: true, minWidth: '120px', isNew: true },
  { key: 'new_result.final_confidence', label: 'New Confidence', sortable: true, minWidth: '100px', isNew: true },
  { key: 'new_result.final_status', label: 'New Status', sortable: true, minWidth: '100px', isNew: true },
  { key: 'new_result.classification_source', label: 'New Source', sortable: true, minWidth: '80px', isNew: true },
  { key: 'new_result.classification_notes_or_reason', label: 'New Notes / Reason', sortable: false, minWidth: '200px', isNew: true },
]);

// --- Computed Properties ---

// Helper to get nested values for sorting/filtering
const getNestedValue = (obj: any, path: string): any => {
  // Handle cases where obj might be null or undefined early
  if (!obj) return null;
  return path.split('.').reduce((value, key) => (value && value[key] !== undefined ? value[key] : null), obj);
};


const filteredAndSortedResults = computed(() => {
  if (!props.results) return [];

  let filtered = props.results;

  // Filtering
  if (searchTerm.value) {
    const lowerSearchTerm = searchTerm.value.toLowerCase();
    filtered = filtered.filter(item =>
      item.vendor_name?.toLowerCase().includes(lowerSearchTerm) ||
      item.hint?.toLowerCase().includes(lowerSearchTerm) ||
      // Search within original results (L1-L5)
      getNestedValue(item, 'original_result.level1_id')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.level1_name')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.level2_id')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.level2_name')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.level3_id')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.level3_name')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.level4_id')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.level4_name')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.level5_id')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.level5_name')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.final_status')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.classification_source')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'original_result.classification_notes_or_reason')?.toLowerCase().includes(lowerSearchTerm) ||
      // Search within new results (L1-L5)
      getNestedValue(item, 'new_result.level1_id')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.level1_name')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.level2_id')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.level2_name')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.level3_id')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.level3_name')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.level4_id')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.level4_name')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.level5_id')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.level5_name')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.final_status')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.classification_source')?.toLowerCase().includes(lowerSearchTerm) ||
      getNestedValue(item, 'new_result.classification_notes_or_reason')?.toLowerCase().includes(lowerSearchTerm)
    );
  }

  // Sorting
  if (sortKey.value && sortDirection.value) {
    const key = sortKey.value;
    const direction = sortDirection.value === 'asc' ? 1 : -1;

    filtered = filtered.slice().sort((a, b) => {
      const valA = getNestedValue(a, key);
      const valB = getNestedValue(b, key);

      const aIsNull = valA === null || valA === undefined || valA === '';
      const bIsNull = valB === null || valB === undefined || valB === '';

      if (aIsNull && bIsNull) return 0;
      if (aIsNull) return 1 * direction; // Nulls/empty last when ascending
      if (bIsNull) return -1 * direction; // Nulls/empty last when ascending

      if (typeof valA === 'string' && typeof valB === 'string') {
        return valA.localeCompare(valB) * direction;
      }
      if (typeof valA === 'number' && typeof valB === 'number') {
        return (valA - valB) * direction;
      }

      // Fallback: compare as strings
      const strA = String(valA).toLowerCase();
      const strB = String(valB).toLowerCase();
      if (strA < strB) return -1 * direction;
      if (strA > strB) return 1 * direction;
      return 0;
    });
  }

  return filtered;
});

// --- Methods ---

function sortBy(key: string) { // Key is now string due to nesting
  if (sortKey.value === key) {
    if (sortDirection.value === 'asc') {
        sortDirection.value = 'desc';
    } else if (sortDirection.value === 'desc') {
        // Cycle back to no sort instead of asc
        sortDirection.value = null;
        sortKey.value = null;
    } else { // Was null
        sortDirection.value = 'asc'; // Start with asc
        sortKey.value = key;
    }
  } else {
    sortKey.value = key;
    sortDirection.value = 'asc'; // Default to asc when changing column
  }
}

function getConfidenceClass(confidence: number | null | undefined): string {
  if (confidence === null || confidence === undefined) return 'text-gray-400';
  if (confidence >= 0.8) return 'text-green-700 font-medium';
  if (confidence >= 0.5) return 'text-yellow-700';
  return 'text-red-700';
}

function getStatusClass(status: string | null | undefined): string {
    switch(status?.toLowerCase()){
        case 'classified': return 'bg-green-100 text-green-800';
        case 'not possible': return 'bg-yellow-100 text-yellow-800';
        case 'error': return 'bg-red-100 text-red-800';
        default: return 'bg-gray-100 text-gray-800';
    }
}

function getSourceClass(source: string | null | undefined): string {
    switch(source?.toLowerCase()){
        case 'initial': return 'bg-green-100 text-green-800';
        case 'search': return 'bg-blue-100 text-blue-800';
        case 'review': return 'bg-purple-100 text-purple-800'; // Added style for review source
        default: return 'bg-gray-100 text-gray-800';
    }
}

// Highlight cells beyond the target classification depth in the *new* result
// Or if the ID itself is null/empty
function getCellClass(item: JobResultItem | null | undefined, level: number): string {
    const baseClass = 'text-gray-700';
    const beyondDepthClass = 'text-gray-400 italic'; // Style for levels beyond target
    const nullClass = 'text-gray-400'; // Style for null/empty values

    if (!item) return nullClass; // Handle case where new_result might be null

    const levelIdKey = `level${level}_id` as keyof JobResultItem;
    const hasId = item[levelIdKey] !== null && item[levelIdKey] !== undefined && String(item[levelIdKey]).trim() !== '';

    if (!hasId) {
        return nullClass; // Use null style if ID is missing/empty
    }

    // Check if the *achieved* level for the *new* result is less than the current cell's level
    const achievedLevel = item.achieved_level ?? 0;
    if (level > achievedLevel) {
         // If the classification stopped before this level, but the ID somehow exists (unlikely but possible), style it as less important
         // Or, more likely, the ID *is* null, handled above. This check is secondary.
         // Let's prioritize the null check. If it has an ID, show it normally unless it's beyond the *target* level.
    }

    // Style differently if the cell's level is beyond the *job's* target level
    if (level > props.targetLevel) {
        return beyondDepthClass;
    }

    return baseClass; // Default style if it has an ID and is within target level
}

// --- Flagging Handling (Simplified: No Hint Input Here) ---
function toggleFlag(vendorName: string) {
    if (jobStore.isFlagged(vendorName)) {
        jobStore.unflagVendor(vendorName); // Unflagging removes hint automatically in store
    } else {
        // Just flag the vendor, no hint needed here.
        // Hints will be collected when submitting from the original job view.
        jobStore.flagVendor(vendorName);
    }
}

// REMOVED updateHint method as it's no longer needed here

async function submitFlags() {
    // Emit the event. The parent (JobStatus) will call the store's submit action.
    // The store's submit action should be aware that hints might not be present
    // if submitted from this table, or ideally, submission from here is disabled
    // or triggers a different flow (e.g., navigating back to original job).
    // For now, we keep the button and emission, assuming the store handles it.
    // A better UX might be to disable the submit button here and only allow it
    // on the JobResultsTable view.
    emit('submit-flags');
}

// --- Helper Component for Sort Icons ---
const SortIcon = {
  props: {
    direction: {
      type: String as PropType<'asc' | 'desc' | null>,
      default: null,
    },
  },
  components: { ChevronUpIcon, ChevronDownIcon, ChevronUpDownIcon },
  template: `
    <span class="inline-block ml-1 w-4 h-4 align-middle">
      <ChevronUpIcon v-if="direction === 'asc'" class="w-4 h-4 text-gray-700" />
      <ChevronDownIcon v-else-if="direction === 'desc'" class="w-4 h-4 text-gray-700" />
      <ChevronUpDownIcon v-else class="w-4 h-4 text-gray-400 opacity-50" />
    </span>
  `,
};

</script>

<style scoped>
/* Ensure sticky header cells have appropriate background */
thead th.sticky {
  position: sticky;
  /* Apply background color matching the thead */
  background-color: #f3f4f6; /* bg-gray-100 */
}

/* Ensure sticky body cells have appropriate background */
tbody td.sticky {
    position: sticky;
    /* Apply background color matching the row's background (consider hover/flagged states) */
    background-color: inherit; /* Inherit from parent tr */
}
/* Ensure flagged rows inherit sticky background correctly */
tbody tr.bg-indigo-50 td.sticky {
    background-color: #e0e7ff; /* bg-indigo-50 */
}


/* Add slight borders for visual separation */
th.isOriginal, td.isOriginal {
    border-left: 1px solid #e5e7eb; /* gray-200 */
}
th.isNew, td.isNew {
    border-left: 1px solid #e5e7eb; /* gray-200 */
}
th:first-child, td:first-child { /* Flag column */
    border-left: none;
}
th:nth-child(2), td:nth-child(2) { /* Vendor name column */
     border-left: none;
}
/* Adjust border for hint column if it's the first after vendor name */
th:nth-child(3), td:nth-child(3) {
    border-left: 1px solid #e5e7eb; /* Hint column always has left border now */
}

</style>
</file>

<file path='frontend/vue_frontend/src/components/StatCard.vue'>
<template>
  <div class="bg-white shadow rounded-lg p-4 flex items-center space-x-4">
    <div :class="['rounded-full p-3 flex items-center justify-center', iconBackgroundClass]">
      <component :is="iconComponent" class="h-6 w-6" :class="iconColorClass" />
    </div>
    <div>
      <p class="text-sm font-medium text-gray-500 truncate">{{ title }}</p>
      <p class="mt-1 text-2xl font-semibold" :class="valueClass">{{ formattedValue }}</p>
    </div>
  </div>
</template>

<script setup lang="ts">
import { computed } from 'vue';
import {
  UsersIcon,
  BriefcaseIcon,
  CogIcon,
  ExclamationTriangleIcon,
  CheckCircleIcon,
  CurrencyDollarIcon, // Example for cost
  QuestionMarkCircleIcon // Default
} from '@heroicons/vue/24/outline'; // Using outline icons

const props = defineProps<{
  title: string;
  value: number | string | null | undefined;
  icon: 'users' | 'briefcase' | 'cog' | 'exclamation-triangle' | 'check-circle' | 'currency-dollar' | string; // Allow known icons or string fallback
  error?: boolean; // Optional flag for error state styling
}>();

const formattedValue = computed(() => {
  if (props.value === null || props.value === undefined) {
    return 'N/A';
  }
  // Add formatting if needed (e.g., large numbers)
  return props.value.toLocaleString();
});

const iconComponent = computed(() => {
  switch (props.icon) {
    case 'users': return UsersIcon;
    case 'briefcase': return BriefcaseIcon;
    case 'cog': return CogIcon;
    case 'exclamation-triangle': return ExclamationTriangleIcon;
    case 'check-circle': return CheckCircleIcon;
    case 'currency-dollar': return CurrencyDollarIcon;
    default: return QuestionMarkCircleIcon;
  }
});

const baseIconBg = 'bg-indigo-100';
const errorIconBg = 'bg-red-100';
const baseIconColor = 'text-indigo-600';
const errorIconColor = 'text-red-600';

const iconBackgroundClass = computed(() => (props.error ? errorIconBg : baseIconBg));
const iconColorClass = computed(() => (props.error ? errorIconColor : baseIconColor));
const valueClass = computed(() => (props.error ? 'text-red-600' : 'text-gray-900'));

</script>
</file>

<file path='frontend/vue_frontend/src/components/UploadForm.vue'>

<!-- <file path='frontend/vue_frontend/src/components/UploadForm.vue'> -->
<template>
    <div class="bg-white rounded-lg shadow-lg overflow-hidden border border-gray-200">
      <div class="bg-primary text-white p-4 sm:p-5">
        <h4 class="text-xl font-semibold mb-0">Upload Vendor File</h4>
      </div>
      <div class="p-6 sm:p-8">
        <!-- Job Success Alert -->
        <div v-if="jobSuccessMessage" class="mb-5 p-3 bg-green-100 border border-green-300 text-green-800 rounded-md text-sm flex items-center">
            <CheckCircleIcon class="h-5 w-5 mr-2 text-green-600 flex-shrink-0"/>
            <span>{{ jobSuccessMessage }}</span>
        </div>
         <!-- Job Error Alert -->
        <div v-if="jobErrorMessage" class="mb-5 p-3 bg-red-100 border border-red-300 text-red-800 rounded-md text-sm flex items-center">
             <ExclamationTriangleIcon class="h-5 w-5 mr-2 text-red-600 flex-shrink-0"/>
            <span>{{ jobErrorMessage }}</span>
        </div>

        <form @submit.prevent="handleUpload" enctype="multipart/form-data">
          <div class="mb-5">
            <label for="companyName" class="block text-sm font-medium text-gray-700 mb-1.5">
                Company Name <span class="text-red-500">*</span>
            </label>
            <input
              type="text"
              class="block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-60 disabled:bg-gray-100 disabled:cursor-not-allowed"
              id="companyName"
              v-model="companyName"
              required
              :disabled="isUploading"
              placeholder="e.g., Your Company Inc."
            />
          </div>

          <!-- Target Level Selection -->
          <div class="mb-5">
            <label for="targetLevel" class="block text-sm font-medium text-gray-700 mb-1.5">
                Target Classification Level <span class="text-red-500">*</span>
            </label>
            <select
              id="targetLevel"
              v-model.number="selectedLevel"
              required
              :disabled="isUploading"
              class="block w-full px-3 py-2 border border-gray-300 bg-white rounded-md shadow-sm focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:opacity-60 disabled:bg-gray-100 disabled:cursor-not-allowed"
            >
              <option value="1">Level 1 (Sector)</option>
              <option value="2">Level 2 (Subsector)</option>
              <option value="3">Level 3 (Industry Group)</option>
              <option value="4">Level 4 (NAICS Industry)</option>
              <option value="5">Level 5 (National Industry)</option>
            </select>
            <p class="mt-1 text-xs text-gray-500">Select the maximum NAICS level you want the classification to reach.</p>
          </div>

          <!-- File Input -->
          <div class="mb-5">
            <label for="vendorFile" class="block text-sm font-medium text-gray-700 mb-1.5">
                Vendor Excel File <span class="text-red-500">*</span>
            </label>
            <input
              type="file"
              class="block w-full text-sm text-gray-500 border border-gray-300 rounded-md cursor-pointer bg-gray-50 focus:outline-none focus:ring-primary focus:border-primary file:mr-4 file:py-2 file:px-4 file:rounded-l-md file:border-0 file:text-sm file:font-semibold file:bg-gray-100 file:text-gray-700 hover:file:bg-gray-200 disabled:opacity-60 disabled:cursor-not-allowed"
              id="vendorFile"
              ref="fileInputRef"
              @change="handleFileChange"
              accept=".xlsx,.xls"
              required
              :disabled="isUploading"
            />
            <p class="mt-2 text-xs text-gray-500">
                Requires '.xlsx' or '.xls'. Must contain 'vendor_name' column.
                <br/>Optional context columns enhance accuracy (address, website, example, etc.).
            </p>
          </div>

          <!-- Validation Status Area -->
          <div v-if="validationStatus !== 'idle'" class="mb-5 p-3 rounded-md text-sm border" :class="{
            'bg-blue-50 border-blue-200 text-blue-700': validationStatus === 'loading',
            'bg-green-50 border-green-300 text-green-800': validationStatus === 'success',
            'bg-red-50 border-red-300 text-red-800': validationStatus === 'error'
          }">
            <div class="flex items-center">
              <svg v-if="validationStatus === 'loading'" class="animate-spin h-4 w-4 mr-2 text-blue-500" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                 <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                 <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
              </svg>
              <CheckCircleIcon v-if="validationStatus === 'success'" class="h-5 w-5 mr-2 text-green-600 flex-shrink-0"/>
              <ExclamationTriangleIcon v-if="validationStatus === 'error'" class="h-5 w-5 mr-2 text-red-600 flex-shrink-0"/>
              <span class="font-medium">
                {{ validationStatus === 'loading' ? 'Validating file...' : (validationStatus === 'success' ? 'Validation Passed' : 'Validation Failed') }}
              </span>
            </div>
            <p v-if="validationMessage" class="mt-1 ml-7 text-xs">{{ validationMessage }}</p>
            <div v-if="validationStatus === 'success' && detectedColumns.length > 0" class="mt-2 ml-7">
                <p class="text-xs font-medium mb-1">Detected Columns:</p>
                <ul class="list-disc list-inside text-xs space-y-0.5 max-h-20 overflow-y-auto bg-white p-2 rounded border border-gray-200">
                    <li v-for="col in detectedColumns" :key="col" :class="{'font-semibold text-green-700': col.toLowerCase().includes('vendor_name')}">
                        {{ col }}
                    </li>
                </ul>
            </div>
          </div>
          <!-- End Validation Status Area -->

          <button type="submit" class="w-full flex justify-center items-center px-4 py-2.5 border border-transparent rounded-md shadow-sm text-base font-medium text-white bg-primary hover:bg-primary-hover focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-primary disabled:opacity-50 disabled:cursor-not-allowed"
            :disabled="isUploading || validationStatus !== 'success' || !selectedFile || !companyName"
            title="Requires Company Name, valid file selection, and successful file validation."
          >
             <svg v-if="isUploading" class="animate-spin -ml-1 mr-3 h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
             </svg>
             <ArrowUpTrayIcon v-else class="h-5 w-5 mr-2 -ml-1" />
            {{ isUploading ? ' Uploading & Processing...' : 'Upload and Process' }}
          </button>
        </form>
      </div>
    </div>
  </template>

  <script setup lang="ts">
  import { ref } from 'vue';
  import apiService from '@/services/api';
  import { useJobStore } from '@/stores/job';
  import { ArrowUpTrayIcon, CheckCircleIcon, ExclamationTriangleIcon } from '@heroicons/vue/20/solid'; // Using solid icons

  const jobStore = useJobStore();
  const companyName = ref('');
  const selectedFile = ref<File | null>(null);
  const fileInputRef = ref<HTMLInputElement | null>(null);
  const isUploading = ref(false); // Renamed from isLoading for clarity
  const jobSuccessMessage = ref<string | null>(null); // For job submission success
  const jobErrorMessage = ref<string | null>(null); // For job submission errors
  const selectedLevel = ref<number>(5); // Default to Level 5

  // --- ADDED: Validation State ---
  type ValidationStatus = 'idle' | 'loading' | 'success' | 'error';
  const validationStatus = ref<ValidationStatus>('idle');
  const validationMessage = ref<string | null>(null);
  const detectedColumns = ref<string[]>([]);
  // --- END ADDED ---

  const emit = defineEmits(['upload-successful']);

  const resetValidation = () => {
      validationStatus.value = 'idle';
      validationMessage.value = null;
      detectedColumns.value = [];
  };

  const handleFileChange = async (event: Event) => {
    const target = event.target as HTMLInputElement;
    resetValidation(); // Reset previous validation state
    jobSuccessMessage.value = null; // Clear previous job messages
    jobErrorMessage.value = null;

    if (target.files && target.files.length > 0) {
      const file = target.files[0];
      selectedFile.value = file;

      // --- Trigger Validation ---
      validationStatus.value = 'loading';
      validationMessage.value = null;
      detectedColumns.value = [];

      const formData = new FormData();
      formData.append('file', file);

      try {
        const response = await apiService.validateUpload(formData);
        validationMessage.value = response.message;
        detectedColumns.value = response.detected_columns || [];
        if (response.is_valid) {
          validationStatus.value = 'success';
        } else {
          validationStatus.value = 'error';
          // Optionally clear the file input if validation fails severely
          // selectedFile.value = null;
          // if (fileInputRef.value) fileInputRef.value.value = '';
        }
      } catch (error: any) {
        validationStatus.value = 'error';
        // Use the detailed error message from api.ts interceptor
        validationMessage.value = error.message || 'An unexpected error occurred during file validation.';
        detectedColumns.value = [];
        // Clear file selection on validation API error
        selectedFile.value = null;
        if (fileInputRef.value) fileInputRef.value.value = '';
      }
      // --- End Trigger Validation ---

    } else {
      selectedFile.value = null;
      resetValidation();
    }
  };

  const handleUpload = async () => {
    // Double check conditions, though button should be disabled
    if (!selectedFile.value || !companyName.value || validationStatus.value !== 'success') {
      jobErrorMessage.value = 'Please provide company name, select a valid file, and ensure file validation passes.';
      jobSuccessMessage.value = null;
      return;
    }
    if (selectedLevel.value < 1 || selectedLevel.value > 5) {
      jobErrorMessage.value = 'Please select a valid target level (1-5).';
      jobSuccessMessage.value = null;
      return;
    }

    isUploading.value = true;
    jobSuccessMessage.value = null;
    jobErrorMessage.value = null;
    jobStore.clearJob(); // Clear any previous job being monitored

    const formData = new FormData();
    formData.append('company_name', companyName.value);
    formData.append('file', selectedFile.value);
    formData.append('target_level', selectedLevel.value.toString());

    try {
      const response = await apiService.uploadFile(formData);
      jobSuccessMessage.value = `Upload successful! Job ${response.id} started (Target Level: ${response.target_level}). Monitoring status below...`;
      emit('upload-successful', response.id);
      jobStore.setCurrentJobId(response.id); // Set the current job in the store

      // Reset form fields after successful submission
      companyName.value = '';
      selectedFile.value = null;
      selectedLevel.value = 5; // Reset level to default
      resetValidation(); // Reset validation state as well
      if (fileInputRef.value) {
          fileInputRef.value.value = '';
      }
    } catch (error: any) {
      // Use the detailed error message from api.ts interceptor
      jobErrorMessage.value = error.message || 'An unexpected error occurred during upload.';
      jobSuccessMessage.value = null;
    } finally {
      isUploading.value = false;
    }
  };
  </script>

  <style scoped>
  /* Style the file input button more effectively */
  input[type="file"]::file-selector-button {
      /* Tailwind handles most, but you can add custom tweaks */
      cursor: pointer;
  }

  /* Style for the detected columns list */
  .max-h-20 {
      max-height: 5rem; /* 80px */
  }
  </style>

</file>

<file path='frontend/vue_frontend/src/components/UserFormModal.vue'>
<template>
  <TransitionRoot appear :show="show" as="template">
    <Dialog as="div" @close="closeModal" class="relative z-50">
      <!-- Backdrop -->
      <TransitionChild
        as="template"
        enter="duration-300 ease-out"
        enter-from="opacity-0"
        enter-to="opacity-100"
        leave="duration-200 ease-in"
        leave-from="opacity-100"
        leave-to="opacity-0"
      >
        <div class="fixed inset-0 bg-black/30 backdrop-blur-sm" aria-hidden="true" />
      </TransitionChild>

      <!-- Full-screen container to center the panel -->
      <div class="fixed inset-0 overflow-y-auto">
        <div class="flex min-h-full items-center justify-center p-4 text-center">
          <!-- Modal Panel -->
          <TransitionChild
            as="template"
            enter="duration-300 ease-out"
            enter-from="opacity-0 scale-95"
            enter-to="opacity-100 scale-100"
            leave="duration-200 ease-in"
            leave-from="opacity-100 scale-100"
            leave-to="opacity-0 scale-95"
          >
            <DialogPanel class="w-full max-w-lg transform overflow-hidden rounded-lg bg-white p-6 text-left align-middle shadow-xl transition-all">
              <DialogTitle as="h3" class="text-xl font-semibold leading-6 text-gray-800 border-b border-gray-200 pb-4 mb-5">
                {{ isEditing ? 'Edit User' : 'Create New User' }}
              </DialogTitle>

              <!-- Form -->
              <form @submit.prevent="submitForm" class="space-y-5">
                 <!-- Error Message within Modal -->
                 <div v-if="formError" class="p-3 bg-red-100 border border-red-300 text-red-700 rounded-md text-sm flex items-center space-x-2">
                    <ExclamationTriangleIcon class="h-5 w-5 text-red-600 flex-shrink-0"/>
                    <span>{{ formError }}</span>
                 </div>

                 <!-- Username (Readonly on Edit) -->
                 <div>
                   <label for="username" class="block text-sm font-medium text-gray-700 mb-1">Username <span class="text-red-500">*</span></label>
                   <input
                     type="text"
                     v-model="formData.username"
                     id="username"
                     required
                     class="mt-1 block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm focus:outline-none focus:ring-primary focus:border-primary sm:text-sm disabled:bg-gray-100 disabled:text-gray-500 disabled:cursor-not-allowed"
                     :disabled="isEditing"
                     placeholder="e.g., jsmith"
                   >
                    <p v-if="isEditing" class="text-xs text-gray-500 mt-1">Username cannot be changed after creation.</p>
                 </div>

                 <!-- Email -->
                 <div>
                   <label for="email" class="block text-sm font-medium text-gray-700 mb-1">Email <span class="text-red-500">*</span></label>
                   <input
                     type="email"
                     v-model="formData.email"
                     id="email"
                     required
                     class="mt-1 block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm focus:outline-none focus:ring-primary focus:border-primary sm:text-sm"
                     placeholder="e.g., j.smith@example.com"
                   >
                 </div>

                 <!-- Full Name -->
                 <div>
                   <label for="full_name" class="block text-sm font-medium text-gray-700 mb-1">Full Name</label>
                   <input
                     type="text"
                     v-model="formData.full_name"
                     id="full_name"
                     class="mt-1 block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm focus:outline-none focus:ring-primary focus:border-primary sm:text-sm"
                     placeholder="e.g., John Smith"
                    >
                 </div>

                 <!-- Password -->
                  <div>
                   <label for="password" class="block text-sm font-medium text-gray-700 mb-1">
                       Password {{ isEditing ? '(Leave blank to keep unchanged)' : '' }}
                       <span v-if="!isEditing" class="text-red-500">*</span>
                    </label>
                   <input
                     type="password"
                     v-model="formData.password"
                     id="password"
                     :required="!isEditing"
                     minlength="8"
                     class="mt-1 block w-full px-3 py-2 border border-gray-300 rounded-md shadow-sm focus:outline-none focus:ring-primary focus:border-primary sm:text-sm"
                     placeholder="Min. 8 characters"
                    >
                    <p v-if="isEditing && formData.password && formData.password.length < 8" class="text-xs text-red-500 mt-1">Password must be at least 8 characters if changing.</p>
                 </div>

                 <!-- Status Toggles -->
                 <div class="flex items-center space-x-8 pt-2">
                    <div class="flex items-center">
                       <Switch
                         :modelValue="Boolean(formData.is_active)" @update:modelValue="formData.is_active = $event"
                         :class="formData.is_active ? 'bg-primary' : 'bg-gray-200'"
                         class="relative inline-flex h-6 w-11 flex-shrink-0 cursor-pointer rounded-full border-2 border-transparent transition-colors duration-200 ease-in-out focus:outline-none focus:ring-2 focus:ring-primary focus:ring-offset-2"
                       >
                         <span class="sr-only">Active Status</span>
                         <span
                           aria-hidden="true"
                           :class="formData.is_active ? 'translate-x-5' : 'translate-x-0'"
                           class="pointer-events-none inline-block h-5 w-5 transform rounded-full bg-white shadow ring-0 transition duration-200 ease-in-out"
                         />
                       </Switch>
                       <label for="is_active_label" class="ml-3 block text-sm font-medium text-gray-700">Active</label>
                    </div>
                     <div class="flex items-center">
                       <Switch
                         :modelValue="Boolean(formData.is_superuser)" @update:modelValue="formData.is_superuser = $event"
                         :class="formData.is_superuser ? 'bg-indigo-600' : 'bg-gray-200'"
                         class="relative inline-flex h-6 w-11 flex-shrink-0 cursor-pointer rounded-full border-2 border-transparent transition-colors duration-200 ease-in-out focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2"
                       >
                         <span class="sr-only">Admin Status</span>
                         <span
                           aria-hidden="true"
                           :class="formData.is_superuser ? 'translate-x-5' : 'translate-x-0'"
                           class="pointer-events-none inline-block h-5 w-5 transform rounded-full bg-white shadow ring-0 transition duration-200 ease-in-out"
                         />
                       </Switch>
                       <label for="is_superuser_label" class="ml-3 block text-sm font-medium text-gray-700">Admin</label>
                    </div>
                 </div>

                <!-- Action Buttons -->
                <div class="mt-6 flex justify-end space-x-3 border-t border-gray-200 pt-5">
                  <button
                    type="button"
                    class="inline-flex justify-center rounded-md border border-gray-300 bg-white px-4 py-2 text-sm font-medium text-gray-700 shadow-sm hover:bg-gray-50 focus:outline-none focus:ring-2 focus:ring-primary focus:ring-offset-2"
                    @click="closeModal"
                    :disabled="isSubmitting"
                  >
                    Cancel
                  </button>
                  <button
                    type="submit"
                    class="inline-flex justify-center items-center rounded-md border border-transparent bg-primary px-4 py-2 text-sm font-medium text-white shadow-sm hover:bg-primary-hover focus:outline-none focus:ring-2 focus:ring-primary focus:ring-offset-2 disabled:opacity-60"
                    :disabled="isSubmitting"
                  >
                     <svg v-if="isSubmitting" class="animate-spin -ml-1 mr-2 h-4 w-4 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                         <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                         <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                     </svg>
                    {{ isSubmitting ? 'Saving...' : (isEditing ? 'Update User' : 'Create User') }}
                  </button>
                </div>
              </form>
            </DialogPanel>
          </TransitionChild>
        </div>
      </div>
    </Dialog>
  </TransitionRoot>
</template>

<script setup lang="ts">
import { ref, watch, computed } from 'vue';
import {
  Dialog,
  DialogPanel,
  DialogTitle,
  TransitionRoot,
  TransitionChild,
  Switch // Import Switch component
} from '@headlessui/vue';
import { ExclamationTriangleIcon } from '@heroicons/vue/24/outline'; // Icon for errors
import type { UserResponse, UserCreateData, UserUpdateData } from '@/services/api';

interface Props {
  show: boolean;
  userToEdit: UserResponse | null;
}

const props = defineProps<Props>();
const emit = defineEmits(['close', 'save']);

// --- Form Data ---
interface FormDataState {
    username: string;
    email: string;
    full_name: string | null;
    password?: string;
    is_active: boolean;
    is_superuser: boolean;
}

const defaultFormData: FormDataState = {
    username: '',
    email: '',
    full_name: null,
    password: '',
    is_active: true,
    is_superuser: false,
};

// Helper to initialize or reset form data
const initializeFormData = (user: UserResponse | null): FormDataState => {
    if (user) {
        return {
            username: user.username,
            email: user.email,
            full_name: user.full_name || null,
            password: '', // Always clear password field on open
            is_active: user.is_active ?? true,
            is_superuser: user.is_superuser ?? false,
        };
    } else {
        return { ...defaultFormData };
    }
};

const formData = ref<FormDataState>(initializeFormData(props.userToEdit));
const formError = ref<string | null>(null);
const isSubmitting = ref(false);

const isEditing = computed(() => !!props.userToEdit);

// --- Watcher to populate form when userToEdit prop changes ---
// --- REMOVED immediate: true ---
watch(() => props.userToEdit, (newUser) => {
    console.log("UserFormModal: Watcher triggered for userToEdit:", newUser ? newUser.username : 'null');
    formData.value = initializeFormData(newUser); // Use the helper function to reset/populate
    formError.value = null; // Clear error when user changes
    isSubmitting.value = false; // Reset submitting state
});

// Watcher to reset state when modal is closed (show becomes false)
watch(() => props.show, (newVal, oldVal) => {
    // Only reset when closing (transitioning from true to false)
    if (oldVal === true && newVal === false) {
        console.log("UserFormModal: Watcher triggered for show=false. Resetting form.");
        // Reset form data to default when modal closes
        formData.value = { ...defaultFormData };
        formError.value = null;
        isSubmitting.value = false;
    }
    // Optionally populate when opening if needed, though the userToEdit watcher handles it
    // if (oldVal === false && newVal === true) {
    //    formData.value = initializeFormData(props.userToEdit);
    // }
});


const closeModal = () => {
  if (isSubmitting.value) return; // Prevent closing while submitting
  emit('close');
};

const submitForm = async () => {
    formError.value = null; // Clear previous errors
    isSubmitting.value = true;

    // Basic Frontend Validation
    if (!formData.value.username.trim()) {
        formError.value = "Username is required.";
        isSubmitting.value = false;
        return;
    }
    if (!formData.value.email.trim() || !/\S+@\S+\.\S+/.test(formData.value.email)) {
        formError.value = "A valid email address is required.";
        isSubmitting.value = false;
        return;
    }

    // Prepare data based on create or edit
    let dataToSend: UserCreateData | UserUpdateData;
    if (isEditing.value) {
        const updateData: UserUpdateData = {
            email: formData.value.email,
            full_name: formData.value.full_name?.trim() || null,
            is_active: formData.value.is_active,
            is_superuser: formData.value.is_superuser,
        };
        if (formData.value.password && formData.value.password.length >= 8) {
            updateData.password = formData.value.password;
        } else if (formData.value.password && formData.value.password.length > 0) {
             formError.value = "Password must be at least 8 characters long if changing.";
             isSubmitting.value = false;
             return;
        }
        dataToSend = updateData;
    } else {
        if (!formData.value.password || formData.value.password.length < 8) {
             formError.value = "Password is required and must be at least 8 characters long.";
             isSubmitting.value = false;
             return;
        }
        const createData: UserCreateData = {
            username: formData.value.username.trim(),
            email: formData.value.email.trim(),
            full_name: formData.value.full_name?.trim() || null,
            password: formData.value.password,
            is_active: formData.value.is_active,
            is_superuser: formData.value.is_superuser,
        };
         dataToSend = createData;
    }

    try {
        // Emit the save event - parent handles API call & closing/resetting isSubmitting
        await emit('save', dataToSend);
    } catch (err: any) {
        // If the parent re-throws the error after handling it
        console.error("Error during form submission (caught in modal):", err);
        formError.value = err.message || "Failed to save user.";
        isSubmitting.value = false; // Ensure button is re-enabled on error
    }
    // Do NOT set isSubmitting to false here if emit was successful, parent controls it.
};

</script>

<style scoped>
/* Add custom styles if needed, though Tailwind should cover most */
</style>
</file>

<file path='frontend/vue_frontend/src/components/UserManagement.vue'>
<template>
    <div class="bg-white rounded-lg shadow-lg overflow-hidden border border-gray-200">
    <div class="bg-gray-100 text-gray-800 p-4 sm:p-5 border-b border-gray-200 flex justify-between items-center">
        <h4 class="text-xl font-semibold mb-0">User Management</h4>
        <button
        @click="openCreateModal"
        class="inline-flex items-center px-4 py-2 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-primary hover:bg-primary-hover focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-primary"
        >
        <PlusIcon class="h-5 w-5 mr-2 -ml-1" />
        Create User
        </button>
    </div>

    <div class="p-6 sm:p-8">
        <!-- Loading State -->
        <div v-if="isLoading" class="text-center text-gray-500 py-8">
        <svg class="animate-spin inline-block h-6 w-6 text-primary mr-2" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
            <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
            <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
        </svg>
        <span>Loading users...</span>
        </div>

        <!-- Error State -->
        <div v-else-if="error" class="p-4 bg-red-100 border border-red-300 text-red-800 rounded-md text-sm flex items-center">
        <ExclamationTriangleIcon class="h-5 w-5 mr-2 text-red-600 flex-shrink-0"/>
        <span>Error loading users: {{ error }}</span>
        </div>

        <!-- Empty State -->
        <div v-else-if="!users || users.length === 0" class="text-center text-gray-500 py-8">
        <p>No users found.</p>
        <p class="text-sm">Click 'Create User' to add the first user.</p>
        </div>

        <!-- User Table -->
        <div v-else class="overflow-x-auto">
        <table class="min-w-full divide-y divide-gray-200">
            <thead class="bg-gray-50">
            <tr>
                <th scope="col" class="px-4 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Username</th>
                <th scope="col" class="px-4 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Email</th>
                <th scope="col" class="px-4 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Full Name</th>
                <th scope="col" class="px-4 py-3 text-center text-xs font-medium text-gray-500 uppercase tracking-wider">Active</th>
                <th scope="col" class="px-4 py-3 text-center text-xs font-medium text-gray-500 uppercase tracking-wider">Admin</th>
                <th scope="col" class="px-4 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Created</th>
                <th scope="col" class="px-4 py-3 text-right text-xs font-medium text-gray-500 uppercase tracking-wider">Actions</th>
            </tr>
            </thead>
            <tbody class="bg-white divide-y divide-gray-200">
            <tr v-for="user in users" :key="user.id" class="hover:bg-gray-50">
                <td class="px-4 py-3 whitespace-nowrap text-sm font-medium text-gray-900">{{ user.username }}</td>
                <td class="px-4 py-3 whitespace-nowrap text-sm text-gray-600">{{ user.email }}</td>
                <td class="px-4 py-3 whitespace-nowrap text-sm text-gray-600">{{ user.full_name || '-' }}</td>
                <td class="px-4 py-3 whitespace-nowrap text-center">
                <span :class="user.is_active ? 'text-green-600' : 'text-red-600'">
                    <CheckCircleIcon v-if="user.is_active" class="h-5 w-5 inline-block" />
                    <XCircleIcon v-else class="h-5 w-5 inline-block" />
                </span>
                </td>
                <td class="px-4 py-3 whitespace-nowrap text-center">
                    <span :class="user.is_superuser ? 'text-indigo-600' : 'text-gray-400'">
                    <ShieldCheckIcon v-if="user.is_superuser" class="h-5 w-5 inline-block" />
                    <ShieldExclamationIcon v-else class="h-5 w-5 inline-block" />
                    </span>
                </td>
                <td class="px-4 py-3 whitespace-nowrap text-sm text-gray-500">
                    {{ formatDateTime(user.created_at) }}
                </td>
                <td class="px-4 py-3 whitespace-nowrap text-right text-sm font-medium space-x-2">
                <button @click="openEditModal(user)" class="text-indigo-600 hover:text-indigo-800" title="Edit User">
                    <PencilSquareIcon class="h-5 w-5 inline-block" />
                </button>
                <button
                    @click="confirmDelete(user)"
                    :disabled="user.username === authStore.username"
                    class="text-red-600 hover:text-red-800 disabled:opacity-50 disabled:cursor-not-allowed"
                    title="Delete User"
                >
                    <TrashIcon class="h-5 w-5 inline-block" />
                </button>
                </td>
            </tr>
            </tbody>
        </table>
        </div>
        <!-- TODO: Add Pagination Controls -->
    </div>

    <!-- Create/Edit User Modal -->
    <UserFormModal
        :show="showModal"
        :user-to-edit="userToEdit"
        @close="closeModal"
        @save="handleSaveUser"
    />

    </div>
</template>

<script setup lang="ts">
import { ref, onMounted } from 'vue';
import apiService, { type UserResponse, type UserCreateData, type UserUpdateData } from '@/services/api';
import { useAuthStore } from '@/stores/auth';
import UserFormModal from './UserFormModal.vue'; // Assume this component exists
import {
    PlusIcon, PencilSquareIcon, TrashIcon, CheckCircleIcon, XCircleIcon,
    ExclamationTriangleIcon, ShieldCheckIcon, ShieldExclamationIcon
} from '@heroicons/vue/24/outline'; // Use outline icons

const authStore = useAuthStore();
const users = ref<UserResponse[]>([]);
const isLoading = ref(false);
const error = ref<string | null>(null);
const showModal = ref(false);
const userToEdit = ref<UserResponse | null>(null);

const fetchUsers = async () => {
    isLoading.value = true;
    error.value = null;
    try {
    users.value = await apiService.getUsers();
    } catch (err: any) {
    error.value = err.message || 'Failed to load users.';
    } finally {
    isLoading.value = false;
    }
};

const openCreateModal = () => {
    userToEdit.value = null;
    showModal.value = true;
};

const openEditModal = (user: UserResponse) => {
    userToEdit.value = { ...user }; // Clone user data
    showModal.value = true;
};

const closeModal = () => {
    showModal.value = false;
    userToEdit.value = null;
};

const handleSaveUser = async (userData: UserCreateData | UserUpdateData) => {
    isLoading.value = true; // Consider a different loading state for modal actions
    error.value = null; // Clear main table error
    try {
        if (userToEdit.value) {
            // Update user
            await apiService.updateUser(userToEdit.value.id, userData as UserUpdateData);
        } else {
            // Create user
            await apiService.createUser(userData as UserCreateData);
        }
        closeModal();
        await fetchUsers(); // Refresh the user list
    } catch (err: any) {
        // Handle error (maybe display in modal or globally)
        console.error("Failed to save user:", err);
        // For now, log it, ideally show in modal
        alert(`Error saving user: ${err.message}`);
        // error.value = `Error saving user: ${err.message}`;
    } finally {
            isLoading.value = false;
    }
};

const confirmDelete = async (user: UserResponse) => {
    if (user.username === authStore.username) {
    alert("You cannot delete your own account.");
    return;
    }
    if (confirm(`Are you sure you want to delete user "${user.username}" (${user.email})? This action cannot be undone.`)) {
    isLoading.value = true; // Use main loading indicator for now
    error.value = null;
    try {
        await apiService.deleteUser(user.id);
        await fetchUsers(); // Refresh list
    } catch (err: any) {
        error.value = `Failed to delete user: ${err.message}`;
    } finally {
        isLoading.value = false;
    }
    }
};

    const formatDateTime = (isoString: string | null | undefined): string => {
    if (!isoString) return 'N/A';
    try {
        return new Date(isoString).toLocaleDateString(undefined, {
            year: 'numeric', month: 'short', day: 'numeric'
        });
    } catch { return 'Invalid Date'; }
};


onMounted(() => {
    fetchUsers();
});
</script>
</file>

<file path='frontend/vue_frontend/src/components/icons/IconCommunity.vue'>
<template>
  <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor">
    <path
      d="M15 4a1 1 0 1 0 0 2V4zm0 11v-1a1 1 0 0 0-1 1h1zm0 4l-.707.707A1 1 0 0 0 16 19h-1zm-4-4l.707-.707A1 1 0 0 0 11 14v1zm-4.707-1.293a1 1 0 0 0-1.414 1.414l1.414-1.414zm-.707.707l-.707-.707.707.707zM9 11v-1a1 1 0 0 0-.707.293L9 11zm-4 0h1a1 1 0 0 0-1-1v1zm0 4H4a1 1 0 0 0 1.707.707L5 15zm10-9h2V4h-2v2zm2 0a1 1 0 0 1 1 1h2a3 3 0 0 0-3-3v2zm1 1v6h2V7h-2zm0 6a1 1 0 0 1-1 1v2a3 3 0 0 0 3-3h-2zm-1 1h-2v2h2v-2zm-3 1v4h2v-4h-2zm1.707 3.293l-4-4-1.414 1.414 4 4 1.414-1.414zM11 14H7v2h4v-2zm-4 0c-.276 0-.525-.111-.707-.293l-1.414 1.414C5.42 15.663 6.172 16 7 16v-2zm-.707 1.121l3.414-3.414-1.414-1.414-3.414 3.414 1.414 1.414zM9 12h4v-2H9v2zm4 0a3 3 0 0 0 3-3h-2a1 1 0 0 1-1 1v2zm3-3V3h-2v6h2zm0-6a3 3 0 0 0-3-3v2a1 1 0 0 1 1 1h2zm-3-3H3v2h10V0zM3 0a3 3 0 0 0-3 3h2a1 1 0 0 1 1-1V0zM0 3v6h2V3H0zm0 6a3 3 0 0 0 3 3v-2a1 1 0 0 1-1-1H0zm3 3h2v-2H3v2zm1-1v4h2v-4H4zm1.707 4.707l.586-.586-1.414-1.414-.586.586 1.414 1.414z"
    />
  </svg>
</template>

</file>

<file path='frontend/vue_frontend/src/components/icons/IconDocumentation.vue'>
<template>
  <svg xmlns="http://www.w3.org/2000/svg" width="20" height="17" fill="currentColor">
    <path
      d="M11 2.253a1 1 0 1 0-2 0h2zm-2 13a1 1 0 1 0 2 0H9zm.447-12.167a1 1 0 1 0 1.107-1.666L9.447 3.086zM1 2.253L.447 1.42A1 1 0 0 0 0 2.253h1zm0 13H0a1 1 0 0 0 1.553.833L1 15.253zm8.447.833a1 1 0 1 0 1.107-1.666l-1.107 1.666zm0-14.666a1 1 0 1 0 1.107 1.666L9.447 1.42zM19 2.253h1a1 1 0 0 0-.447-.833L19 2.253zm0 13l-.553.833A1 1 0 0 0 20 15.253h-1zm-9.553-.833a1 1 0 1 0 1.107 1.666L9.447 14.42zM9 2.253v13h2v-13H9zm1.553-.833C9.203.523 7.42 0 5.5 0v2c1.572 0 2.961.431 3.947 1.086l1.107-1.666zM5.5 0C3.58 0 1.797.523.447 1.42l1.107 1.666C2.539 2.431 3.928 2 5.5 2V0zM0 2.253v13h2v-13H0zm1.553 13.833C2.539 15.431 3.928 15 5.5 15v-2c-1.92 0-3.703.523-5.053 1.42l1.107 1.666zM5.5 15c1.572 0 2.961.431 3.947 1.086l1.107-1.666C9.203 13.523 7.42 13 5.5 13v2zm5.053-11.914C11.539 2.431 12.928 2 14.5 2V0c-1.92 0-3.703.523-5.053 1.42l1.107 1.666zM14.5 2c1.573 0 2.961.431 3.947 1.086l1.107-1.666C18.203.523 16.421 0 14.5 0v2zm3.5.253v13h2v-13h-2zm1.553 12.167C18.203 13.523 16.421 13 14.5 13v2c1.573 0 2.961.431 3.947 1.086l1.107-1.666zM14.5 13c-1.92 0-3.703.523-5.053 1.42l1.107 1.666C11.539 15.431 12.928 15 14.5 15v-2z"
    />
  </svg>
</template>

</file>

<file path='frontend/vue_frontend/src/components/icons/IconEcosystem.vue'>
<template>
  <svg xmlns="http://www.w3.org/2000/svg" width="18" height="20" fill="currentColor">
    <path
      d="M11.447 8.894a1 1 0 1 0-.894-1.789l.894 1.789zm-2.894-.789a1 1 0 1 0 .894 1.789l-.894-1.789zm0 1.789a1 1 0 1 0 .894-1.789l-.894 1.789zM7.447 7.106a1 1 0 1 0-.894 1.789l.894-1.789zM10 9a1 1 0 1 0-2 0h2zm-2 2.5a1 1 0 1 0 2 0H8zm9.447-5.606a1 1 0 1 0-.894-1.789l.894 1.789zm-2.894-.789a1 1 0 1 0 .894 1.789l-.894-1.789zm2 .789a1 1 0 1 0 .894-1.789l-.894 1.789zm-1.106-2.789a1 1 0 1 0-.894 1.789l.894-1.789zM18 5a1 1 0 1 0-2 0h2zm-2 2.5a1 1 0 1 0 2 0h-2zm-5.447-4.606a1 1 0 1 0 .894-1.789l-.894 1.789zM9 1l.447-.894a1 1 0 0 0-.894 0L9 1zm-2.447.106a1 1 0 1 0 .894 1.789l-.894-1.789zm-6 3a1 1 0 1 0 .894 1.789L.553 4.106zm2.894.789a1 1 0 1 0-.894-1.789l.894 1.789zm-2-.789a1 1 0 1 0-.894 1.789l.894-1.789zm1.106 2.789a1 1 0 1 0 .894-1.789l-.894 1.789zM2 5a1 1 0 1 0-2 0h2zM0 7.5a1 1 0 1 0 2 0H0zm8.553 12.394a1 1 0 1 0 .894-1.789l-.894 1.789zm-1.106-2.789a1 1 0 1 0-.894 1.789l.894-1.789zm1.106 1a1 1 0 1 0 .894 1.789l-.894-1.789zm2.894.789a1 1 0 1 0-.894-1.789l.894 1.789zM8 19a1 1 0 1 0 2 0H8zm2-2.5a1 1 0 1 0-2 0h2zm-7.447.394a1 1 0 1 0 .894-1.789l-.894 1.789zM1 15H0a1 1 0 0 0 .553.894L1 15zm1-2.5a1 1 0 1 0-2 0h2zm12.553 2.606a1 1 0 1 0 .894 1.789l-.894-1.789zM17 15l.447.894A1 1 0 0 0 18 15h-1zm1-2.5a1 1 0 1 0-2 0h2zm-7.447-5.394l-2 1 .894 1.789 2-1-.894-1.789zm-1.106 1l-2-1-.894 1.789 2 1 .894-1.789zM8 9v2.5h2V9H8zm8.553-4.894l-2 1 .894 1.789 2-1-.894-1.789zm.894 0l-2-1-.894 1.789 2 1 .894-1.789zM16 5v2.5h2V5h-2zm-4.553-3.894l-2-1-.894 1.789 2 1 .894-1.789zm-2.894-1l-2 1 .894 1.789 2-1L8.553.106zM1.447 5.894l2-1-.894-1.789-2 1 .894 1.789zm-.894 0l2 1 .894-1.789-2-1-.894 1.789zM0 5v2.5h2V5H0zm9.447 13.106l-2-1-.894 1.789 2 1 .894-1.789zm0 1.789l2-1-.894-1.789-2 1 .894 1.789zM10 19v-2.5H8V19h2zm-6.553-3.894l-2-1-.894 1.789 2 1 .894-1.789zM2 15v-2.5H0V15h2zm13.447 1.894l2-1-.894-1.789-2 1 .894 1.789zM18 15v-2.5h-2V15h2z"
    />
  </svg>
</template>

</file>

<file path='frontend/vue_frontend/src/components/icons/IconSupport.vue'>
<template>
  <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor">
    <path
      d="M10 3.22l-.61-.6a5.5 5.5 0 0 0-7.666.105 5.5 5.5 0 0 0-.114 7.665L10 18.78l8.39-8.4a5.5 5.5 0 0 0-.114-7.665 5.5 5.5 0 0 0-7.666-.105l-.61.61z"
    />
  </svg>
</template>

</file>

<file path='frontend/vue_frontend/src/components/icons/IconTooling.vue'>
<!-- This icon is from <https://github.com/Templarian/MaterialDesign>, distributed under Apache 2.0 (https://www.apache.org/licenses/LICENSE-2.0) license-->
<template>
  <svg
    xmlns="http://www.w3.org/2000/svg"
    xmlns:xlink="http://www.w3.org/1999/xlink"
    aria-hidden="true"
    role="img"
    class="iconify iconify--mdi"
    width="24"
    height="24"
    preserveAspectRatio="xMidYMid meet"
    viewBox="0 0 24 24"
  >
    <path
      d="M20 18v-4h-3v1h-2v-1H9v1H7v-1H4v4h16M6.33 8l-1.74 4H7v-1h2v1h6v-1h2v1h2.41l-1.74-4H6.33M9 5v1h6V5H9m12.84 7.61c.1.22.16.48.16.8V18c0 .53-.21 1-.6 1.41c-.4.4-.85.59-1.4.59H4c-.55 0-1-.19-1.4-.59C2.21 19 2 18.53 2 18v-4.59c0-.32.06-.58.16-.8L4.5 7.22C4.84 6.41 5.45 6 6.33 6H7V5c0-.55.18-1 .57-1.41C7.96 3.2 8.44 3 9 3h6c.56 0 1.04.2 1.43.59c.39.41.57.86.57 1.41v1h.67c.88 0 1.49.41 1.83 1.22l2.34 5.39z"
      fill="currentColor"
    ></path>
  </svg>
</template>

</file>

<file path='frontend/vue_frontend/src/main.ts'>
// frontend/vue_frontend/src/main.ts
import { createApp } from 'vue';
import { createPinia } from 'pinia';
import App from './App.vue';
import './assets/styles.css';

// --- REMOVED Unused Import ---
// import { useViewStore } from './stores/view';
// --- END REMOVED ---

console.log("[main.ts] Initializing Vue application...");

const app = createApp(App);
const pinia = createPinia(); // Create Pinia instance

console.log("[main.ts] Installing Pinia state management...");
app.use(pinia); // Use Pinia

// Stores are typically initialized within components or App.vue setup

console.log("[main.ts] Mounting the application to the '#app' element...");
app.mount('#app');

console.log("[main.ts] Vue application mounted successfully.");
</file>

<file path='frontend/vue_frontend/src/services/api.ts'>
import axios, {
    type AxiosInstance,
    type InternalAxiosRequestConfig,
    type AxiosError // Import AxiosError type
} from 'axios';
import { useAuthStore } from '@/stores/auth'; // Adjust path as needed
// --- UPDATED: Import JobResultItem and ReviewResultItem ---
// --- REMOVED JobStatsData from this import ---
import type { JobDetails, JobResultItem, ReviewResultItem } from '@/stores/job'; // Adjust path as needed
// --- END REMOVED ---
// --- END UPDATED ---

// --- Define API Response Interfaces ---

// Matches backend schemas/user.py -> UserResponse
export interface UserResponse {
    email: string;
    full_name: string | null;
    is_active: boolean | null;
    is_superuser: boolean | null;
    username: string;
    id: string; // UUID as string
    created_at: string; // ISO Date string
    updated_at: string; // ISO Date string
}

// Matches backend schemas/user.py -> UserCreate (for request body)
export interface UserCreateData {
    email: string;
    full_name?: string | null;
    is_active?: boolean | null;
    is_superuser?: boolean | null;
    username: string;
    password?: string; // Password required on create
}

// Matches backend schemas/user.py -> UserUpdate (for request body)
export interface UserUpdateData {
    email?: string | null;
    full_name?: string | null;
    password?: string | null; // Optional password update
    is_active?: boolean | null;
    is_superuser?: boolean | null;
}


// Matches backend response for /token (modified to include user object)
interface AuthResponse {
    access_token: string;
    token_type: string;
    user: UserResponse; // Include the user details
}

// --- ADDED: File Validation Response Interface ---
// Matches backend api/main.py -> FileValidationResponse
export interface FileValidationResponse {
    is_valid: boolean;
    message: string;
    detected_columns: string[];
    missing_mandatory_columns: string[];
}
// --- END ADDED ---

// Matches backend response for /api/v1/jobs/{job_id}/notify
interface NotifyResponse {
    success: boolean;
    message: string;
}

// Matches backend response for /api/v1/jobs/ (list endpoint)
// Should align with app/schemas/job.py -> JobResponse
export interface JobResponse {
    id: string;
    company_name: string;
    status: 'pending' | 'processing' | 'completed' | 'failed';
    progress: number;
    current_stage: string;
    created_at: string; // ISO Date string
    updated_at?: string | null;
    completed_at?: string | null;
    output_file_name?: string | null;
    input_file_name: string;
    created_by: string;
    error_message?: string | null;
    target_level: number; // Ensure target_level is included here
    // --- ADDED: Job Type and Parent Link ---
    job_type: 'CLASSIFICATION' | 'REVIEW';
    parent_job_id: string | null;
    // --- END ADDED ---
    stats?: Record<string, any>; // Include stats field optionally
}

// --- ADDED: Job Results Response Interface ---
// Matches backend schemas/job.py -> JobResultsResponse
export interface JobResultsResponse {
    job_id: string;
    job_type: 'CLASSIFICATION' | 'REVIEW';
    results: JobResultItem[] | ReviewResultItem[]; // Union type
}
// --- END ADDED ---

// --- ADDED: Job Stats Data Interface ---
// Matches backend models/classification.py -> ProcessingStats and console log
// --- UPDATED: Export the interface ---
export interface JobStatsData {
// --- END UPDATED ---
    job_id: string;
    company_name: string;
    start_time: string | null; // Assuming ISO string
    end_time: string | null; // Assuming ISO string
    processing_duration_seconds: number | null; // Renamed from processing_time
    total_vendors: number | null; // Added
    unique_vendors: number | null; // Added (was present in console)
    target_level: number | null; // Added target level to stats
    successfully_classified_l4?: number | null; // Keep for reference (optional)
    successfully_classified_l5?: number | null; // Keep L5 count (optional)
    classification_not_possible_initial?: number | null; // Added (optional)
    invalid_category_errors?: number | null; // Added (was present in console) (optional)
    search_attempts?: number | null; // Added (optional)
    search_successful_classifications_l1?: number | null; // Added (optional)
    search_successful_classifications_l5?: number | null; // Renamed from search_assisted_l5 (optional)
    api_usage?: { // Nested structure (optional)
        openrouter_calls: number | null;
        openrouter_prompt_tokens: number | null;
        openrouter_completion_tokens: number | null;
        openrouter_total_tokens: number | null;
        tavily_search_calls?: number | null; // Optional if not always present
        cost_estimate_usd: number | null;
    } | null; // Allow api_usage itself to be null if not populated
    // --- ADDED: Stats specific to REVIEW jobs ---
    reclassify_input?: Array<{ vendor_name: string; hint: string }>; // Input hints (optional)
    total_items_processed?: number; // Optional
    successful_reclassifications?: number; // Optional
    failed_reclassifications?: number; // Optional
    parent_job_id?: string; // Include parent ID in stats for review jobs (optional)
    merged_at?: string | null; // Added merge timestamp (optional)
    // --- END ADDED ---
}
// --- END ADDED ---


// Structure for download result helper
interface DownloadResult {
    blob: Blob;
    filename: string;
}

// Parameters for the job history list endpoint
interface GetJobsParams {
    status?: string;
    start_date?: string; // ISO string format
    end_date?: string; // ISO string format
    job_type?: 'CLASSIFICATION' | 'REVIEW'; // Filter by type
    skip?: number;
    limit?: number;
}

// --- ADDED: Password Reset Interfaces ---
// Matches backend schemas/password_reset.py -> MessageResponse
interface MessageResponse {
    message: string;
}
// --- END ADDED ---

// --- ADDED: Reclassification Interfaces ---
// Matches backend schemas/review.py -> ReclassifyRequestItem
interface ReclassifyRequestItemData {
    vendor_name: string;
    hint: string;
}
// Matches backend schemas/review.py -> ReclassifyResponse
interface ReclassifyResponseData {
    review_job_id: string;
    message: string;
}
// --- END ADDED ---

// --- ADDED: Merge Response Interface ---
// Matches backend api/jobs.py -> merge_review_results response
interface MergeResponseData {
    message: string;
    updated_parent_job_id: string;
}
// --- END ADDED ---

// --- ADDED: Admin Dashboard Interfaces ---
// Matches backend schemas/admin.py -> SystemStatsResponse
export interface SystemStatsResponse {
    total_users: number;
    total_jobs: number;
    pending_jobs: number;
    processing_jobs: number;
    completed_jobs: number;
    failed_jobs_last_24h: number;
    estimated_recent_cost?: number | null;
    health_status: Record<string, any>; // Dictionary for health check data
}

// Matches backend schemas/admin.py -> RecentJobItem
export interface RecentJobItem {
    id: string;
    created_by: string;
    company_name: string;
    status: 'pending' | 'processing' | 'completed' | 'failed';
    created_at: string; // ISO Date string
    job_type: 'CLASSIFICATION' | 'REVIEW';
}

// Matches backend schemas/admin.py -> RecentJobsResponse
export interface RecentJobsResponse {
    jobs: RecentJobItem[];
}
// --- END ADDED: Admin Dashboard Interfaces ---


// --- Axios Instance Setup ---

const axiosInstance: AxiosInstance = axios.create({
    baseURL: '/api/v1', // Assumes Vite dev server proxies /api/v1 to your backend
    timeout: 60000, // 60 seconds timeout
    headers: {
        'Content-Type': 'application/json',
        'Accept': 'application/json',
    },
});

// --- Request Interceptor (Add Auth Token) ---
axiosInstance.interceptors.request.use(
    (config: InternalAxiosRequestConfig) => {
        const authStore = useAuthStore();
        const token = authStore.getToken();
        // Define URLs that should NOT receive the auth token
        // --- UPDATED: Added /users/register ---
        const noAuthUrls = ['/auth/password-recovery', '/auth/reset-password', '/users/register'];
        // --- END UPDATED ---

        // Check if the request URL matches any of the no-auth URLs
        const requiresAuth = token && config.url && !noAuthUrls.some(url => config.url?.startsWith(url));

        if (requiresAuth) {
            // LOGGING: Log token presence and target URL
            // console.log(`[api.ts Request Interceptor] Adding token for URL: ${config.url}`);
            config.headers.Authorization = `Bearer ${token}`;
        } else {
            // console.log(`[api.ts Request Interceptor] No token added for URL: ${config.url} (Token: ${token ? 'present' : 'missing'}, No-Auth Match: ${!requiresAuth && !!token})`);
        }
        return config;
    },
    (error: AxiosError) => {
        console.error('[api.ts Request Interceptor] Error:', error);
        return Promise.reject(error);
    }
);

// --- Response Interceptor (Handle Errors) ---
axiosInstance.interceptors.response.use(
    (response) => {
        // LOGGING: Log successful response status and URL
        // console.log(`[api.ts Response Interceptor] Success for URL: ${response.config.url} | Status: ${response.status}`);
        return response;
    },
    (error: AxiosError) => {
        console.error('[api.ts Response Interceptor] Error:', error.config?.url, error.response?.status, error.message);
        const authStore = useAuthStore();

        if (error.response) {
            const { status, data } = error.response;

            // Handle 401 Unauthorized (except for login attempts and password reset)
            const isLoginAttempt = error.config?.url === '/token'; // Base URL for login
            // --- UPDATED: Check register url ---
            const isPublicAuthOperation = error.config?.url?.startsWith('/auth/') || error.config?.url?.startsWith('/users/register');
            // --- END UPDATED ---

            // --- UPDATED: Check isPublicAuthOperation ---
            if (status === 401 && !isLoginAttempt && !isPublicAuthOperation) {
            // --- END UPDATED ---
                console.warn('[api.ts Response Interceptor] Received 401 Unauthorized on protected route. Logging out.');
                authStore.logout(); // Trigger logout action
                // No reload here, let the component handle redirection or UI change
                return Promise.reject(new Error('Session expired. Please log in again.'));
            }

            // Extract detailed error message from response data
            let detailMessage = 'An error occurred.';
            const responseData = data as any;

            // Handle FastAPI validation errors (detail is an array)
            if (responseData?.detail && Array.isArray(responseData.detail)) {
                 detailMessage = `Validation Error: ${responseData.detail.map((err: any) => `${err.loc?.join('.') ?? 'field'}: ${err.msg}`).join('; ')}`;
            }
            // Handle other FastAPI errors (detail is a string) or custom errors
            else if (responseData?.detail && typeof responseData.detail === 'string') {
                detailMessage = responseData.detail;
            }
            // Handle cases where the error might be directly in the data object (less common)
            else if (typeof data === 'string' && data.length > 0 && data.length < 300) {
                detailMessage = data;
            }
            // Fallback to Axios error message
            else if (error.message) {
                detailMessage = error.message;
            }

            // Prepend status code for clarity, unless it's a 422 validation error where the message is usually sufficient
            const errorMessage = status === 422 ? detailMessage : `Error ${status}: ${detailMessage}`;
            console.error(`[api.ts Response Interceptor] Rejecting with error: ${errorMessage}`); // LOGGING
            return Promise.reject(new Error(errorMessage));

        } else if (error.request) {
            console.error('[api.ts Response Interceptor] Network error or no response received:', error.request);
            return Promise.reject(new Error('Network error or server did not respond. Please check connection.'));
        } else {
            console.error('[api.ts Response Interceptor] Axios setup error:', error.message);
            return Promise.reject(new Error(`Request setup error: ${error.message}`));
        }
    }
);


// --- API Service Object ---

const apiService = {
    /**
        * Logs in a user. Uses base axios for specific headers.
        */
    async login(usernameInput: string, passwordInput: string): Promise<AuthResponse> {
        const params = new URLSearchParams();
        params.append('username', usernameInput);
        params.append('password', passwordInput);
        console.log(`[api.ts login] Attempting login for user: ${usernameInput}`); // LOGGING
        // Use base axios to avoid default JSON headers and ensure correct Content-Type
        // Also avoids the interceptor adding an Authorization header if a previous token exists
        const response = await axios.post<AuthResponse>('/token', params, {
            baseURL: '/', // Use root base URL since '/token' is not under /api/v1
            headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
        });
        console.log(`[api.ts login] Login successful for user: ${usernameInput}`); // LOGGING
        return response.data;
    },

    /**
        * Validates the header of an uploaded file.
        */
    async validateUpload(formData: FormData): Promise<FileValidationResponse> {
        console.log('[api.ts validateUpload] Attempting file header validation...'); // LOGGING
        // Uses axiosInstance, includes auth token if available and URL requires it
        const response = await axiosInstance.post<FileValidationResponse>('/validate-upload', formData, {
             headers: { 'Content-Type': undefined } // Let browser set Content-Type for FormData
        });
        console.log(`[api.ts validateUpload] Validation response received: isValid=${response.data.is_valid}`); // LOGGING
        return response.data;
    },


    /**
        * Uploads the vendor file (after validation).
        * Returns the full JobResponse object.
        */
    async uploadFile(formData: FormData): Promise<JobResponse> { // Return JobResponse
        console.log('[api.ts uploadFile] Attempting file upload...'); // LOGGING
        // This uses axiosInstance, so /api/v1 prefix is added automatically
        const response = await axiosInstance.post<JobResponse>('/upload', formData, { // Expect JobResponse
                headers: { 'Content-Type': undefined } // Let browser set Content-Type for FormData
        });
        console.log(`[api.ts uploadFile] Upload successful, job ID: ${response.data.id}, Target Level: ${response.data.target_level}`); // LOGGING
        return response.data;
    },

    /**
        * Fetches the status and details of a specific job.
        */
    async getJobStatus(jobId: string): Promise<JobDetails> {
        console.log(`[api.ts getJobStatus] Fetching status for job ID: ${jobId}`); // LOGGING
        const response = await axiosInstance.get<JobDetails>(`/jobs/${jobId}`);
        console.log(`[api.ts getJobStatus] Received status for job ${jobId}:`, response.data.status, `Target Level: ${response.data.target_level}`, `Job Type: ${response.data.job_type}`); // LOGGING
        return response.data;
    },

    /**
        * Fetches statistics for a specific job.
        */
    async getJobStats(jobId: string): Promise<JobStatsData> { // Use the updated interface here
        console.log(`[api.ts getJobStats] Fetching stats for job ID: ${jobId}`); // LOGGING
        // Use the exported JobStatsData interface
        const response = await axiosInstance.get<JobStatsData>(`/jobs/${jobId}/stats`);
        // LOGGING: Log the received stats structure
        console.log(`[api.ts getJobStats] Received stats for job ${jobId}:`, JSON.parse(JSON.stringify(response.data)));
        return response.data;
    },

    /**
     * Fetches the detailed classification results for a specific job.
     * Returns the JobResultsResponse structure containing job type and results list.
     */
    async getJobResults(jobId: string): Promise<JobResultsResponse> {
        console.log(`[api.ts getJobResults] Fetching detailed results for job ID: ${jobId}`); // LOGGING
        const response = await axiosInstance.get<JobResultsResponse>(`/jobs/${jobId}/results`);
        console.log(`[api.ts getJobResults] Received ${response.data.results.length} detailed result items for job ${jobId} (Type: ${response.data.job_type}).`); // LOGGING
        return response.data;
    },

    /**
        * Requests email notification for a job completion.
        */
    async requestNotification(jobId: string, email: string): Promise<NotifyResponse> {
        console.log(`[api.ts requestNotification] Requesting notification for job ${jobId} to email ${email}`); // LOGGING
        const response = await axiosInstance.post<NotifyResponse>(`/jobs/${jobId}/notify`, { email });
        console.log(`[api.ts requestNotification] Notification request response:`, response.data.success); // LOGGING
        return response.data;
    },

    /**
        * Downloads the results file for a completed job.
        */
    async downloadResults(jobId: string): Promise<DownloadResult> {
        console.log(`[api.ts downloadResults] Requesting download for job ID: ${jobId}`); // LOGGING
        const response = await axiosInstance.get(`/jobs/${jobId}/download`, {
            responseType: 'blob',
        });
        const disposition = response.headers['content-disposition'];
        let filename = `results_${jobId}.xlsx`;
        if (disposition?.includes('attachment')) {
            const filenameMatch = disposition.match(/filename\*?=(?:(?:"((?:[^"\\]|\\.)*)")|(?:([^;\n]*)))/i);
            if (filenameMatch?.[1]) { filename = filenameMatch[1].replace(/\\"/g, '"'); }
            else if (filenameMatch?.[2]) {
                    const utf8Match = filenameMatch[2].match(/^UTF-8''(.*)/i);
                    if (utf8Match?.[1]) { try { filename = decodeURIComponent(utf8Match[1]); } catch (e) { filename = utf8Match[1]; } }
                    else { filename = filenameMatch[2]; }
            }
        }
        console.log(`[api.ts downloadResults] Determined download filename: ${filename}`); // LOGGING
        return { blob: response.data as Blob, filename };
    },

    /**
        * Fetches a list of jobs for the current user, with optional filtering/pagination.
        */
    async getJobs(params: GetJobsParams = {}): Promise<JobResponse[]> {
        const cleanedParams = Object.fromEntries(
            Object.entries(params).filter(([, value]) => value !== undefined && value !== null && value !== '')
        );
        console.log('[api.ts getJobs] Fetching job list with params:', cleanedParams); // LOGGING
        const response = await axiosInstance.get<JobResponse[]>('/jobs/', { params: cleanedParams });
        console.log(`[api.ts getJobs] Received ${response.data.length} jobs.`); // LOGGING
        return response.data;
    },

    // --- User Management API Methods ---

    /**
        * Fetches the current logged-in user's details.
        */
    async getCurrentUser(): Promise<UserResponse> {
        console.log('[api.ts getCurrentUser] Fetching current user details...'); // LOGGING
        const response = await axiosInstance.get<UserResponse>('/users/me');
        console.log(`[api.ts getCurrentUser] Received user: ${response.data.username}`); // LOGGING
        return response.data;
    },

    /**
        * Fetches a list of all users (admin only).
        */
    async getUsers(skip: number = 0, limit: number = 100): Promise<UserResponse[]> {
        console.log(`[api.ts getUsers] Fetching user list (skip: ${skip}, limit: ${limit})...`); // LOGGING
        const response = await axiosInstance.get<UserResponse[]>('/users/', { params: { skip, limit } });
         console.log(`[api.ts getUsers] Received ${response.data.length} users.`); // LOGGING
        return response.data;
    },

        /**
        * Fetches a specific user by ID (admin or self).
        */
        async getUserById(userId: string): Promise<UserResponse> {
        console.log(`[api.ts getUserById] Fetching user ID: ${userId}`); // LOGGING
        const response = await axiosInstance.get<UserResponse>(`/users/${userId}`);
        console.log(`[api.ts getUserById] Received user: ${response.data.username}`); // LOGGING
        return response.data;
    },

    /**
        * Creates a new user (admin only).
        */
    async createUser(userData: UserCreateData): Promise<UserResponse> {
        console.log(`[api.ts createUser] Attempting to create user (admin): ${userData.username}`); // LOGGING
        const response = await axiosInstance.post<UserResponse>('/users/', userData);
        console.log(`[api.ts createUser] User created successfully (admin): ${response.data.username}`); // LOGGING
        return response.data;
    },

    /**
        * Updates a user (admin or self).
        */
    async updateUser(userId: string, userData: UserUpdateData): Promise<UserResponse> {
        console.log(`[api.ts updateUser] Attempting to update user ID: ${userId}`); // LOGGING
        const response = await axiosInstance.put<UserResponse>(`/users/${userId}`, userData);
        console.log(`[api.ts updateUser] User updated successfully: ${response.data.username}`); // LOGGING
        return response.data;
    },

    /**
        * Deletes a user (admin only).
        */
    async deleteUser(userId: string): Promise<{ message: string }> {
        console.log(`[api.ts deleteUser] Attempting to delete user ID: ${userId}`); // LOGGING
        const response = await axiosInstance.delete<{ message: string }>(`/users/${userId}`);
        console.log(`[api.ts deleteUser] User delete response: ${response.data.message}`); // LOGGING
        return response.data;
    },
    // --- END User Management API Methods ---

    // --- ADDED: Public Registration API Method ---
    /**
     * Registers a new user publicly.
     */
    async registerUser(userData: UserCreateData): Promise<UserResponse> {
        console.log(`[api.ts registerUser] Attempting public registration for user: ${userData.username}`);
        // Uses axiosInstance, interceptor skips auth token for this URL
        const response = await axiosInstance.post<UserResponse>('/users/register', userData);
        console.log(`[api.ts registerUser] Public registration successful: ${response.data.username}`);
        return response.data;
    },
    // --- END Public Registration API Method ---


    // --- ADDED: Password Reset API Methods ---
    /**
     * Requests a password reset email to be sent.
     */
    async requestPasswordRecovery(email: string): Promise<MessageResponse> {
        console.log(`[api.ts requestPasswordRecovery] Requesting password reset for email: ${email}`);
        // This uses axiosInstance, but the interceptor should skip adding auth token for this URL
        const response = await axiosInstance.post<MessageResponse>('/auth/password-recovery', { email });
        console.log(`[api.ts requestPasswordRecovery] Request response: ${response.data.message}`);
        return response.data;
    },

    /**
     * Resets the password using the provided token and new password.
     */
    async resetPassword(token: string, newPassword: string): Promise<MessageResponse> {
        console.log(`[api.ts resetPassword] Attempting password reset with token: ${token.substring(0, 10)}...`);
        // This uses axiosInstance, but the interceptor should skip adding auth token for this URL
        const response = await axiosInstance.post<MessageResponse>('/auth/reset-password', {
            token: token,
            new_password: newPassword
        });
        console.log(`[api.ts resetPassword] Reset response: ${response.data.message}`);
        return response.data;
    },
    // --- END Password Reset API Methods ---

    // --- ADDED: Reclassification API Method ---
    /**
     * Submits flagged items for reclassification.
     */
    async reclassifyJob(originalJobId: string, items: ReclassifyRequestItemData[]): Promise<ReclassifyResponseData> {
        console.log(`[api.ts reclassifyJob] Submitting ${items.length} items for reclassification for job ${originalJobId}`);
        const payload = { items: items };
        const response = await axiosInstance.post<ReclassifyResponseData>(`/jobs/${originalJobId}/reclassify`, payload);
        console.log(`[api.ts reclassifyJob] Reclassification job started: ${response.data.review_job_id}`);
        return response.data;
    },
    // --- END ADDED ---

    // --- ADDED: Merge API Method ---
    /**
     * Merges results from a review job into its parent.
     */
    async mergeReviewResults(reviewJobId: string): Promise<MergeResponseData> {
        console.log(`[api.ts mergeReviewResults] Requesting merge for review job ${reviewJobId}`);
        const response = await axiosInstance.post<MergeResponseData>(`/jobs/${reviewJobId}/merge`);
        console.log(`[api.ts mergeReviewResults] Merge request successful: ${response.data.message}`);
        return response.data;
    },
    // --- END ADDED ---

    // --- ADDED: Admin Dashboard API Methods ---
    /**
     * Fetches system statistics (admin only).
     */
    async getSystemStats(): Promise<SystemStatsResponse> {
        console.log('[api.ts getSystemStats] Fetching admin system stats...');
        const response = await axiosInstance.get<SystemStatsResponse>('/admin/stats');
        console.log('[api.ts getSystemStats] System stats received.');
        return response.data;
    },

    /**
     * Fetches recent jobs across all users (admin only).
     */
    async getRecentJobs(limit: number = 15): Promise<RecentJobsResponse> {
        console.log(`[api.ts getRecentJobs] Fetching recent jobs (limit: ${limit})...`);
        const response = await axiosInstance.get<RecentJobsResponse>('/admin/recent-jobs', { params: { limit } });
        console.log(`[api.ts getRecentJobs] Received ${response.data.jobs.length} recent jobs.`);
        return response.data;
    },
    // --- END ADDED: Admin Dashboard API Methods ---

};

export default apiService;
</file>

<file path='frontend/vue_frontend/src/stores/admin.ts'>
// frontend/vue_frontend/src/stores/admin.ts
import { defineStore } from 'pinia';
import { ref } from 'vue';
import apiService from '@/services/api'; // Adjust path as needed
import type { SystemStatsResponse, RecentJobItem } from '@/services/api'; // Import specific types

export const useAdminStore = defineStore('admin', () => {
    // --- State ---
    const systemStats = ref<SystemStatsResponse | null>(null);
    const recentJobs = ref<RecentJobItem[] | null>(null);
    const loadingStats = ref(false);
    const loadingJobs = ref(false);
    const errorStats = ref<string | null>(null);
    const errorJobs = ref<string | null>(null);

    // --- Actions ---
    async function fetchSystemStats(): Promise<void> {
        loadingStats.value = true;
        errorStats.value = null;
        console.log('AdminStore: Fetching system stats...');
        try {
            const stats = await apiService.getSystemStats();
            systemStats.value = stats;
            console.log('AdminStore: System stats fetched successfully.');
        } catch (err: any) {
            console.error('AdminStore: Failed to fetch system stats:', err);
            errorStats.value = err.message || 'An unknown error occurred while fetching system stats.';
            systemStats.value = null; // Clear potentially stale data on error
        } finally {
            loadingStats.value = false;
        }
    }

    async function fetchRecentJobs(limit: number = 15): Promise<void> {
        loadingJobs.value = true;
        errorJobs.value = null;
        console.log(`AdminStore: Fetching recent jobs (limit=${limit})...`);
        try {
            // Pass limit to apiService if the function supports it
            const response = await apiService.getRecentJobs(limit);
            recentJobs.value = response.jobs;
            console.log(`AdminStore: Fetched ${recentJobs.value?.length ?? 0} recent jobs.`);
        } catch (err: any) {
            console.error('AdminStore: Failed to fetch recent jobs:', err);
            errorJobs.value = err.message || 'An unknown error occurred while fetching recent jobs.';
            recentJobs.value = null; // Clear potentially stale data on error
        } finally {
            loadingJobs.value = false;
        }
    }

    // --- Getters (Implicit via refs, or add computed if needed) ---
    // Example computed getter (though direct refs are often fine in setup scripts)
    // const activeJobCount = computed(() => {
    //   if (!systemStats.value) return 0;
    //   return systemStats.value.pending_jobs + systemStats.value.processing_jobs;
    // });

    return {
        // State
        systemStats,
        recentJobs,
        loadingStats,
        loadingJobs,
        errorStats,
        errorJobs,

        // Actions
        fetchSystemStats,
        fetchRecentJobs,

        // Getters (if defined)
        // activeJobCount,
    };
});
</file>

<file path='frontend/vue_frontend/src/stores/auth.ts'>
// frontend/vue_frontend/src/stores/auth.ts
import { defineStore } from 'pinia';
import { ref, computed } from 'vue';
import apiService from '@/services/api'; // Adjust path as needed
import type { UserResponse } from '@/services/api'; // Import the UserResponse type

// Use the imported UserResponse interface directly
// interface User {
//     username: string;
//     email: string;
//     id: string; // Use string for UUID compatibility
//     is_active: boolean;
//     is_superuser: boolean;
//     full_name: string | null;
//     created_at: string;
//     updated_at: string;
// }

export const useAuthStore = defineStore('auth', () => {
    // --- State ---
    const token = ref<string | null>(localStorage.getItem('authToken'));
    // Use UserResponse type for user state
    const user = ref<UserResponse | null>(null);
    const loading = ref(false);
    const error = ref<string | null>(null);

    // --- Getters ---
    const isAuthenticated = computed(() => !!token.value && !!user.value); // Check user too
    const username = computed(() => user.value?.username || null);
    const isSuperuser = computed(() => user.value?.is_superuser || false); // Getter for superuser status

    // --- Actions ---
    async function login(usernameInput: string, passwordInput: string): Promise<void> {
        loading.value = true;
        error.value = null;
        try {
            console.log('AuthStore: Attempting login...');
            // API now returns user details in 'user' field
            const response = await apiService.login(usernameInput, passwordInput);
            token.value = response.access_token;
            user.value = response.user; // Store the full user object

            // Persist to localStorage
            if (token.value) {
                localStorage.setItem('authToken', token.value);
            } else {
                localStorage.removeItem('authToken');
            }
            if (user.value) {
                localStorage.setItem('authUser', JSON.stringify(user.value));
            } else {
                localStorage.removeItem('authUser');
            }

            console.log('AuthStore: Login successful.');
        } catch (err: any) {
            console.error('AuthStore: Login failed:', err);
            token.value = null;
            user.value = null;
            localStorage.removeItem('authToken');
            localStorage.removeItem('authUser');
            error.value = err.message || 'Login failed. Please check credentials.';
            throw err;
        } finally {
            loading.value = false;
        }
    }

    function logout(): void {
        console.log('AuthStore: Logging out...');
        token.value = null;
        user.value = null;
        error.value = null;
        localStorage.removeItem('authToken');
        localStorage.removeItem('authUser');
        // Optionally redirect or clear other stores if needed
        console.log('AuthStore: Logout complete.');
            // Reload to ensure clean state, especially if routing depends on auth
            window.location.reload();
    }

    function checkAuthStatus(): void {
        console.log('AuthStore: Checking auth status from localStorage...');
        const storedToken = localStorage.getItem('authToken');
        const storedUserJson = localStorage.getItem('authUser');

        if (storedToken && storedUserJson) {
            try {
                const parsedUser: UserResponse = JSON.parse(storedUserJson);
                // Basic validation
                if (parsedUser && parsedUser.id && parsedUser.username) {
                    token.value = storedToken;
                    user.value = parsedUser;
                    console.log('AuthStore: Session restored from localStorage.');
                } else {
                    console.warn('AuthStore: Invalid user data in localStorage. Logging out.');
                    logout(); // Call logout to clear everything
                }
            } catch (e) {
                console.error('AuthStore: Error parsing stored user data. Logging out.');
                logout(); // Call logout to clear everything
            }
        } else {
            console.log('AuthStore: No token or user found in localStorage.');
            // Ensure state matches localStorage absence
            if (token.value || user.value) {
                token.value = null;
                user.value = null;
                error.value = null; // Clear any lingering errors
            }
        }
    }

    // Action to get the current token (useful for API service interceptor)
    function getToken(): string | null {
        return token.value;
    }

    // --- ADDED: Action to fetch user details (e.g., after login or on refresh) ---
    async function fetchCurrentUserDetails(): Promise<void> {
            if (!isAuthenticated.value) {
                console.log("AuthStore: Not authenticated, cannot fetch user details.");
                return;
            }
            loading.value = true;
            error.value = null;
            try {
                console.log("AuthStore: Fetching current user details...");
                const currentUserDetails = await apiService.getCurrentUser(); // Assuming apiService has this
                user.value = currentUserDetails;
                localStorage.setItem('authUser', JSON.stringify(user.value)); // Update local storage
                console.log("AuthStore: Current user details updated.", currentUserDetails);
            } catch (err: any) {
                console.error("AuthStore: Failed to fetch current user details:", err);
                error.value = err.message || "Failed to load user details.";
                // Optional: Logout if fetching user details fails?
                // logout();
            } finally {
                loading.value = false;
            }
        }


    return {
        token,
        user,
        loading,
        error,
        isAuthenticated,
        username,
        isSuperuser, // Expose the new getter
        login,
        logout,
        checkAuthStatus,
        getToken,
        fetchCurrentUserDetails, // Expose the new action
    };
});

</file>

<file path='frontend/vue_frontend/src/stores/counter.ts'>
import { ref, computed } from 'vue'
import { defineStore } from 'pinia'

export const useCounterStore = defineStore('counter', () => {
  const count = ref(0)
  const doubleCount = computed(() => count.value * 2)
  function increment() {
    count.value++
  }

  return { count, doubleCount, increment }
})

</file>

<file path='frontend/vue_frontend/src/stores/job.ts'>
// <file path='frontend/vue_frontend/src/stores/job.ts'>
import { defineStore } from 'pinia';
import { ref, reactive, computed } from 'vue';
// --- UPDATED: Import JobStatsData from apiService ---
import apiService, { type JobResponse, type JobStatsData } from '@/services/api';
// --- END UPDATED ---

// Define the structure of the job details object based on your API response
// Should align with app/schemas/job.py -> JobResponse
export interface JobDetails {
    id: string;
    status: 'pending' | 'processing' | 'completed' | 'failed';
    progress: number;
    current_stage: string;
    created_at: string | null;
    updated_at: string | null;
    completed_at?: string | null;
    estimated_completion?: string | null;
    error_message: string | null;
    target_level: number;
    company_name?: string;
    input_file_name?: string;
    output_file_name?: string | null;
    created_by?: string;
    job_type: 'CLASSIFICATION' | 'REVIEW';
    parent_job_id: string | null;
    stats?: Record<string, any>; // Include stats field optionally
}

// Interface for a single detailed result item (for CLASSIFICATION jobs)
// Should align with app/schemas/job.py -> JobResultItem
export interface JobResultItem {
    vendor_name: string;
    level1_id: string | null;
    level1_name: string | null;
    level2_id: string | null;
    level2_name: string | null;
    level3_id: string | null;
    level3_name: string | null;
    level4_id: string | null;
    level4_name: string | null;
    level5_id: string | null;
    level5_name: string | null;
    final_confidence: number | null;
    final_status: string; // 'Classified', 'Not Possible', 'Error'
    classification_source: string | null; // 'Initial', 'Search', 'Review'
    classification_notes_or_reason: string | null;
    achieved_level: number | null; // 0-5
}

// Interface for a single detailed result item (for REVIEW jobs)
// Should align with app/schemas/review.py -> ReviewResultItem
export interface ReviewResultItem {
    vendor_name: string;
    hint: string;
    original_result: JobResultItem; // Use JobResultItem type for structure
    new_result: JobResultItem; // Use JobResultItem type for structure
}


export const useJobStore = defineStore('job', () => {
    // --- State ---
    const currentJobId = ref<string | null>(null);
    const jobDetails = ref<JobDetails | null>(null);
    const jobStats = ref<JobStatsData | null>(null); // Add state for job stats
    const isLoading = ref(false); // For tracking polling/loading state for CURRENT job details
    const statsLoading = ref(false); // For tracking stats loading state
    const error = ref<string | null>(null); // For storing errors related to fetching CURRENT job status/details
    const statsError = ref<string | null>(null); // For storing errors related to fetching CURRENT job stats

    const jobHistory = ref<JobResponse[]>([]);
    const historyLoading = ref(false);
    const historyError = ref<string | null>(null);

    // --- UPDATED: Results State ---
    // Holds the primary results for the currentJobId (JobResultItem[] or ReviewResultItem[])
    const jobResults = ref<JobResultItem[] | ReviewResultItem[] | null>(null);
    // Holds results from the latest review job *if* currentJobId is a CLASSIFICATION job
    const relatedReviewResults = ref<ReviewResultItem[] | null>(null); // NEW
    const resultsLoading = ref(false);
    const resultsError = ref<string | null>(null);
    // --- END UPDATED ---

    const flaggedForReview = reactive<Map<string, { hint: string | null }>>(new Map());
    const reclassifyLoading = ref(false);
    const reclassifyError = ref<string | null>(null);
    const lastReviewJobId = ref<string | null>(null);

    // --- ADDED: Merge State ---
    const mergeLoading = ref(false);
    const mergeError = ref<string | null>(null);
    const isMerged = computed(() => !!jobStats.value?.merged_at); // Derive merge status from stats
    // --- END ADDED ---

    // --- Computed ---
    const hasFlaggedItems = computed(() => flaggedForReview.size > 0);

    // --- Actions ---
    function setCurrentJobId(jobId: string | null): void {
        console.log(`JobStore: Setting currentJobId from '${currentJobId.value}' to '${jobId}'`);
        if (currentJobId.value !== jobId) {
            currentJobId.value = jobId;
            // Clear details and results when ID changes
            jobDetails.value = null;
            jobStats.value = null; // Clear stats
            jobResults.value = null;
            relatedReviewResults.value = null; // Clear related results too
            console.log(`JobStore: Cleared jobDetails, stats, and results due to ID change.`);
            error.value = null;
            statsError.value = null; // Clear stats error
            isLoading.value = false;
            statsLoading.value = false; // Reset stats loading
            resultsLoading.value = false; // Reset results loading
            resultsError.value = null; // Reset results error
            // Clear flagging state
            flaggedForReview.clear();
            reclassifyLoading.value = false;
            reclassifyError.value = null;
            lastReviewJobId.value = null;
            // Clear merge state
            mergeLoading.value = false;
            mergeError.value = null;
            console.log(`JobStore: Cleared flagging and merge state due to ID change.`);

            // Update URL
            try {
                 const url = new URL(window.location.href);
                 if (jobId) {
                     url.searchParams.set('job_id', jobId);
                     console.log(`JobStore: Updated URL searchParam 'job_id' to ${jobId}`);
                 } else {
                     url.searchParams.delete('job_id');
                     console.log(`JobStore: Removed 'job_id' from URL searchParams.`);
                 }
                 window.history.replaceState({}, '', url.toString());
            } catch (e) {
                 console.error("JobStore: Failed to update URL:", e);
            }
        }
         // If the same job ID is set again, force a refresh
         else if (jobId !== null) {
             console.log(`JobStore: Re-setting same job ID ${jobId}, clearing details, stats, and results to force refresh.`);
             jobDetails.value = null;
             jobStats.value = null; // Clear stats
             jobResults.value = null;
             relatedReviewResults.value = null; // Clear related results too
             error.value = null;
             statsError.value = null; // Clear stats error
             isLoading.value = false;
             statsLoading.value = false; // Reset stats loading
             resultsLoading.value = false;
             resultsError.value = null;
             // Clear flagging state
             flaggedForReview.clear();
             reclassifyLoading.value = false;
             reclassifyError.value = null;
             lastReviewJobId.value = null;
             // Clear merge state
             mergeLoading.value = false;
             mergeError.value = null;
         }
    }

    function updateJobDetails(details: JobDetails): void {
        if (details && details.id === currentJobId.value) {
            console.log(`JobStore: Updating jobDetails for ${currentJobId.value} with status ${details.status}, progress ${details.progress}, target_level ${details.target_level}, job_type ${details.job_type}`);
            // Check if job type changed (e.g., initial load vs poll update)
            const typeChanged = jobDetails.value?.job_type !== details.job_type;
            jobDetails.value = { ...details };
            error.value = null;
            // If type changed, results might need refetching/reinterpreting
            if (typeChanged) {
                console.log("JobStore: Job type changed, clearing existing results.");
                jobResults.value = null;
                relatedReviewResults.value = null;
                resultsLoading.value = false;
                resultsError.value = null;
                // Trigger results fetch again? Or let the calling component handle it.
                // Let's assume the component watching jobDetails will trigger fetchCurrentJobResults.
            }
        } else if (details) {
            console.warn(`JobStore: Received details for job ${details.id}, but currently tracking ${currentJobId.value}. Ignoring update.`);
        } else {
            console.warn(`JobStore: updateJobDetails called with invalid details object.`);
        }
    }

    function setLoading(loading: boolean): void {
        isLoading.value = loading;
    }

    function setError(errorMessage: string | null): void {
        error.value = errorMessage;
    }

    function clearJob(): void {
        console.log('JobStore: Clearing job state.');
        setCurrentJobId(null);
    }

    async function fetchJobHistory(params = {}): Promise<void> {
        console.log('JobStore: Fetching job history with params:', params);
        historyLoading.value = true;
        historyError.value = null;
        try {
            const jobs = await apiService.getJobs(params);
            jobHistory.value = jobs;
            console.log(`JobStore: Fetched ${jobs.length} jobs.`);
        } catch (err: any) {
            console.error('JobStore: Failed to fetch job history:', err);
            historyError.value = err.message || 'Failed to load job history.';
            jobHistory.value = [];
        } finally {
            historyLoading.value = false;
        }
    }

    // --- ADDED: Action to fetch job stats ---
    async function fetchJobStats(jobId: string): Promise<void> {
        if (!jobId || jobId !== currentJobId.value) {
            console.warn(`JobStore: fetchJobStats called for non-current job ${jobId}. Current: ${currentJobId.value}`);
            return;
        }
        if (statsLoading.value) {
            console.log(`JobStore: fetchJobStats called for ${jobId} while already loading. Skipping.`);
            return;
        }
        console.log(`JobStore: Fetching stats for job ${jobId}...`);
        statsLoading.value = true;
        statsError.value = null;
        try {
            const stats = await apiService.getJobStats(jobId);
            if (jobId === currentJobId.value) { // Check again after await
                jobStats.value = stats;
                console.log(`JobStore: Successfully fetched stats for job ${jobId}. Merged status: ${isMerged.value}`);
            } else {
                 console.log(`JobStore: Job ID changed while fetching stats for ${jobId}. Discarding.`);
            }
        } catch (err: any) {
            console.error(`JobStore: Failed to fetch stats for job ${jobId}:`, err);
            if (jobId === currentJobId.value) {
                statsError.value = err.message || 'Failed to load job statistics.';
                jobStats.value = null;
            }
        } finally {
            if (jobId === currentJobId.value) {
                statsLoading.value = false;
            }
        }
    }
    // --- END ADDED ---

    // --- NEW HELPER: Find latest completed review job for a parent ---
    function findLatestReviewJobFor(parentId: string): JobResponse | null {
        const completedReviewJobs = jobHistory.value
            .filter(job =>
                job.parent_job_id === parentId &&
                job.job_type === 'REVIEW' &&
                job.status === 'completed' &&
                job.completed_at // Ensure completed_at is not null
            )
            .sort((a, b) => {
                // Sort descending by completed_at date
                const dateA = a.completed_at ? new Date(a.completed_at) : new Date(0);
                const dateB = b.completed_at ? new Date(b.completed_at) : new Date(0);
                return dateB.getTime() - dateA.getTime();
            });

        if (completedReviewJobs.length > 0) {
            console.log(`JobStore: Found latest review job ${completedReviewJobs[0].id} for parent ${parentId}`);
            return completedReviewJobs[0];
        }
        return null;
    }
    // --- END NEW HELPER ---

    // --- UPDATED: Action to fetch results based on current job type ---
    async function fetchCurrentJobResults(): Promise<void> {
        if (!currentJobId.value || !jobDetails.value) {
            console.warn("JobStore: fetchCurrentJobResults called without currentJobId or jobDetails.");
            resultsLoading.value = false; // Ensure loading is false if we exit early
            return;
        }
        // Avoid redundant fetches
        if (resultsLoading.value) {
            console.log("JobStore: fetchCurrentJobResults called while already loading. Skipping.");
            return;
        }

        const jobId = currentJobId.value;
        const jobType = jobDetails.value.job_type;

        console.log(`JobStore: Starting fetchCurrentJobResults for ${jobId} (Type: ${jobType})`);

        // Clear previous results
        jobResults.value = null;
        relatedReviewResults.value = null;
        resultsLoading.value = true;
        resultsError.value = null;

        try {
            // Fetch primary results for the current job ID
            console.log(`JobStore: Fetching primary results for ${jobId}...`);
            // The actual response type from apiService.getJobResults is inferred here
            const primaryResponse = await apiService.getJobResults(jobId);

            // Check if job ID changed *during* the API call
            if (jobId !== currentJobId.value) {
                 console.log(`JobStore: Job ID changed while fetching primary results for ${jobId}. Discarding.`);
                 resultsLoading.value = false; // Ensure loading is reset
                 return; // Exit early
            }

            // Store primary results (casting based on expected type)
            if (jobType === 'CLASSIFICATION') {
                jobResults.value = primaryResponse.results as JobResultItem[];
            } else if (jobType === 'REVIEW') {
                jobResults.value = primaryResponse.results as ReviewResultItem[];
            } else {
                console.error(`JobStore: Unknown job type '${jobType}' encountered.`);
                jobResults.value = primaryResponse.results; // Store as is, might cause issues downstream
            }
            console.log(`JobStore: Successfully fetched ${primaryResponse.results.length} primary results for ${jobId}.`);

            // If it's a CLASSIFICATION job, try to find and fetch the latest *completed* review results
            if (jobType === 'CLASSIFICATION') {
                // Ensure job history is available. Fetch if needed?
                // For simplicity, assume history is reasonably up-to-date when this is called.
                // If not, add: if (jobHistory.value.length === 0) await fetchJobHistory();
                const latestReviewJob = findLatestReviewJobFor(jobId);
                if (latestReviewJob) {
                    console.log(`JobStore: Found related completed review job: ${latestReviewJob.id}. Fetching its results...`);
                    try {
                        // The actual response type from apiService.getJobResults is inferred here
                        const reviewResponse = await apiService.getJobResults(latestReviewJob.id);
                         // Check if job ID changed *during* this second API call
                        if (jobId !== currentJobId.value) {
                             console.log(`JobStore: Job ID changed while fetching related review results for ${jobId}. Discarding.`);
                             // Don't reset loading here, let the finally block handle it
                             return; // Exit early
                        }
                        // Ensure the response is ReviewResultItem[]
                        if (latestReviewJob.job_type === 'REVIEW') { // Sanity check
                             relatedReviewResults.value = reviewResponse.results as ReviewResultItem[];
                             console.log(`JobStore: Successfully fetched ${reviewResponse.results.length} related review results for ${jobId} from review job ${latestReviewJob.id}`);
                        } else {
                             console.warn(`JobStore: Found related job ${latestReviewJob.id}, but it's not a REVIEW job type.`);
                        }
                    } catch (reviewErr: any) {
                        console.error(`JobStore: Failed to fetch results for related review job ${latestReviewJob.id}:`, reviewErr);
                        // Don't set the main resultsError, just log it.
                        // Clear related results if fetch failed
                        relatedReviewResults.value = null;
                    }
                } else {
                     console.log(`JobStore: No related completed review job found for classification job ${jobId}.`);
                     relatedReviewResults.value = null; // Ensure it's null if none found
                }
            }
        } catch (err: any) {
            console.error(`JobStore: Failed to fetch primary results for ${jobId}:`, err);
            // Only set error if it's for the currently selected job
            if (jobId === currentJobId.value) {
                resultsError.value = err.message || 'Failed to load results.';
                jobResults.value = null; // Clear results on primary fetch error
                relatedReviewResults.value = null; // Clear related results too
            }
        } finally {
             // Only stop loading if it's for the currently selected job
            if (jobId === currentJobId.value) {
                resultsLoading.value = false;
                console.log(`JobStore: Finished fetchCurrentJobResults for ${jobId}. Loading: ${resultsLoading.value}`);
            } else {
                 console.log(`JobStore: Finished fetchCurrentJobResults for ${jobId}, but current job is now ${currentJobId.value}. Loading state not updated for current job.`);
            }
        }
    }
    // --- END UPDATED ---

    // --- Reclassification Actions (Minor Adjustments) ---
    function isFlagged(vendorName: string): boolean {
        return flaggedForReview.has(vendorName);
    }

    function getHint(vendorName: string): string | null {
        return flaggedForReview.get(vendorName)?.hint ?? null;
    }

    function flagVendor(vendorName: string, initialHint: string | null = null): void { // Added optional initial hint
        if (!flaggedForReview.has(vendorName)) {
            // Only set hint if provided (relevant for JobResultsTable)
            flaggedForReview.set(vendorName, { hint: initialHint });
            console.log(`JobStore: Flagged vendor '${vendorName}' for review.`);
        }
    }

    function unflagVendor(vendorName: string): void {
        if (flaggedForReview.has(vendorName)) {
            flaggedForReview.delete(vendorName);
            console.log(`JobStore: Unflagged vendor '${vendorName}'.`);
        }
    }

    function setHint(vendorName: string, hint: string | null): void {
        if (flaggedForReview.has(vendorName)) {
            flaggedForReview.set(vendorName, { hint });
            console.log(`JobStore: Set hint for '${vendorName}': ${hint ? `'${hint}'` : 'cleared'}`);
        } else {
            console.warn(`JobStore: Tried to set hint for unflagged vendor '${vendorName}'.`);
        }
    }

    async function submitFlagsForReview(): Promise<string | null> {
        // --- Ensure submission always uses the original classification job ID ---
        let submissionJobId = currentJobId.value;
        // If the current job is a REVIEW job, find its parent (original CLASSIFICATION job)
        if (jobDetails.value?.job_type === 'REVIEW' && jobDetails.value?.parent_job_id) {
            submissionJobId = jobDetails.value.parent_job_id;
            console.log(`JobStore: Current job is REVIEW type, submitting flags against parent job ${submissionJobId}`);
        } else if (jobDetails.value?.job_type === 'CLASSIFICATION') {
             console.log(`JobStore: Current job is CLASSIFICATION type, submitting flags against job ${submissionJobId}`);
        } else {
             console.error("JobStore: Cannot determine original job ID for submitting flags.");
             reclassifyError.value = "Cannot determine the original job to reclassify from.";
             return null;
        }

        if (!submissionJobId || flaggedForReview.size === 0) {
            console.warn("JobStore: submitFlagsForReview called with no submission job ID or no flagged items.");
            reclassifyError.value = "No items flagged for review.";
            return null;
        }
        // --- End Ensure submission job ID ---

        // --- Validation: Ensure all flagged items have hints (if submitting from JobResultsTable) ---
        // This check is more relevant if the submission is triggered from JobResultsTable where hints are edited.
        // If triggered from ReviewResultsTable (where hints are not edited), this check might be skipped or adapted.
        // Let's assume hints ARE required for *any* submission for now.
        const itemsWithoutHints = Array.from(flaggedForReview.keys())
            .filter(vendorName => !flaggedForReview.get(vendorName)?.hint?.trim());

        if (itemsWithoutHints.length > 0) {
            console.warn(`JobStore: Submission blocked. Flagged items missing hints: ${itemsWithoutHints.join(', ')}`);
            reclassifyError.value = `Please provide hints for all flagged items: ${itemsWithoutHints.slice(0, 3).join(', ')}${itemsWithoutHints.length > 3 ? '...' : ''}`;
            return null;
        }
        // --- End Validation ---

        const itemsToReclassify = Array.from(flaggedForReview.entries())
            .map(([vendorName, data]) => ({
                vendor_name: vendorName,
                hint: data.hint!, // Hint is guaranteed non-empty due to validation above
            }));


        console.log(`JobStore: Submitting ${itemsToReclassify.length} flags for reclassification against job ${submissionJobId}...`);
        reclassifyLoading.value = true;
        reclassifyError.value = null;
        lastReviewJobId.value = null;

        try {
            // Use the determined submissionJobId
            const response = await apiService.reclassifyJob(submissionJobId, itemsToReclassify);
            console.log(`JobStore: Reclassification job started successfully. Review Job ID: ${response.review_job_id}`);
            lastReviewJobId.value = response.review_job_id;
            flaggedForReview.clear(); // Clear flags after successful submission
            // Optionally: Fetch job history again AFTER a short delay to show the new PENDING review job
            setTimeout(() => fetchJobHistory(), 1000); // Refresh history after 1s
            return response.review_job_id;
        } catch (err: any) {
            console.error('JobStore: Failed to submit flags for reclassification:', err);
            reclassifyError.value = err.message || 'Failed to start reclassification job.';
            return null;
        } finally {
            reclassifyLoading.value = false;
        }
    }
    // --- END Reclassification Actions ---

    // --- ADDED: Merge Action ---
    async function mergeReviewResults(reviewJobId: string): Promise<boolean> {
        if (!reviewJobId) {
            console.error("JobStore: mergeReviewResults called without reviewJobId.");
            mergeError.value = "Review Job ID is missing.";
            return false;
        }
        console.log(`JobStore: Attempting to merge results for review job ${reviewJobId}`);
        mergeLoading.value = true;
        mergeError.value = null;

        try {
            const response = await apiService.mergeReviewResults(reviewJobId);
            console.log(`JobStore: Merge successful for review job ${reviewJobId}. Response: ${response.message}`);
            // Update merge status (by refetching stats)
            await fetchJobStats(reviewJobId);
            // Refresh job history to show updated parent job potentially
            await fetchJobHistory();
            mergeLoading.value = false;
            return true;
        } catch (err: any) {
            console.error(`JobStore: Failed to merge results for review job ${reviewJobId}:`, err);
            mergeError.value = err.message || 'Failed to merge results.';
            mergeLoading.value = false;
            return false;
        }
    }
    // --- END ADDED ---


    return {
        // State
        currentJobId,
        jobDetails,
        jobStats, // Expose stats
        isLoading,
        statsLoading, // Expose stats loading
        error,
        statsError, // Expose stats error
        jobHistory,
        historyLoading,
        historyError,
        jobResults, // Holds JobResultItem[] or ReviewResultItem[]
        relatedReviewResults, // Holds ReviewResultItem[] or null
        resultsLoading,
        resultsError,
        flaggedForReview,
        reclassifyLoading,
        reclassifyError,
        lastReviewJobId,
        mergeLoading, // Expose merge loading
        mergeError, // Expose merge error
        isMerged, // Expose computed merge status

        // Computed
        hasFlaggedItems,

        // Actions
        setCurrentJobId,
        updateJobDetails,
        setLoading,
        setError,
        clearJob,
        fetchJobHistory,
        fetchJobStats, // Expose stats fetch action
        fetchCurrentJobResults, // Use this action to fetch results
        isFlagged,
        getHint,
        flagVendor,
        unflagVendor,
        setHint,
        submitFlagsForReview,
        mergeReviewResults, // Expose merge action
    };
});
</file>

<file path='frontend/vue_frontend/src/stores/view.ts'>
// frontend/vue_frontend/src/stores/view.ts
import { defineStore } from 'pinia';
import { ref } from 'vue';

export const useViewStore = defineStore('view', () => {
    // --- State ---
    // 'landing', 'app', 'admin'
    const currentView = ref<'landing' | 'app' | 'admin'>('landing');

    // --- Actions ---
    function setView(view: 'landing' | 'app' | 'admin'): void {
        console.log(`ViewStore: Setting view to '${view}'`);
        currentView.value = view;
    }

    return {
        currentView,
        setView,
    };
});
</file>

<file path='frontend/vue_frontend/tailwind.config.js'>
// frontend/vue_frontend/tailwind.config.js
/** @type {import('tailwindcss').Config} */
import colors from 'tailwindcss/colors' // <-- Import default colors

export default {
  content: [
    "./index.html",
    "./src/**/*.{vue,js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        // Change primary to Indigo
        'primary': colors.indigo[600],         // #4f46e5
        'primary-hover': colors.indigo[700],    // #4338ca
        // Keep others or customize further
        'secondary': colors.gray[600],          // #4b5563
        'light': colors.gray[100],            // #f3f4f6
        'dark': colors.gray[800],             // #1f2937
        // You can add more custom colors here
      },
      fontFamily: {
         sans: ['Inter', 'sans-serif'],
      },
    },
  },
  plugins: [],
}
</file>

<file path='frontend/vue_frontend/vite.config.ts'>
// frontend/vue_frontend/vite.config.ts
// No changes needed based on errors, assuming tsconfig.node.json is set up correctly
import { fileURLToPath, URL } from 'node:url'

import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'
import vueDevTools from 'vite-plugin-vue-devtools'

// https://vite.dev/config/
export default defineConfig({
  plugins: [
    vue(),
    vueDevTools(),
  ],
  resolve: {
    alias: {
      '@': fileURLToPath(new URL('./src', import.meta.url))
    }
  },
  server: {
    port: 5173, // Default Vite port
    proxy: {
      // Proxy API requests starting with /api or /token to the backend server
      // Change target based on where your FastAPI backend runs locally
      '/api': {
        target: 'http://localhost:8001', // Your FastAPI backend port from run_local.sh
        changeOrigin: true,
        // secure: false, // Uncomment if backend uses self-signed certs
        // rewrite: (path) => path.replace(/^\/api/, '/api') // Keep prefix if backend expects it
      },
       '/token': { // Proxy the /token endpoint separately if it's not under /api
        target: 'http://localhost:8001',
        changeOrigin: true,
        // secure: false,
      }
    }
  }
})
</file>

<file path='frontend/vue_frontend/yarn.lock'>
# THIS IS AN AUTOGENERATED FILE. DO NOT EDIT THIS FILE DIRECTLY.
# yarn lockfile v1


"@alloc/quick-lru@^5.2.0":
  version "5.2.0"
  resolved "https://registry.npmjs.org/@alloc/quick-lru/-/quick-lru-5.2.0.tgz"
  integrity sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==

"@ampproject/remapping@^2.2.0":
  version "2.3.0"
  resolved "https://registry.npmjs.org/@ampproject/remapping/-/remapping-2.3.0.tgz"
  integrity sha512-30iZtAPgz+LTIYoeivqYo853f02jBYSd5uGnGpkFV0M3xOt9aN73erkgYAmZU43x4VfqcnLxW9Kpg3R5LC4YYw==
  dependencies:
    "@jridgewell/gen-mapping" "^0.3.5"
    "@jridgewell/trace-mapping" "^0.3.24"

"@antfu/utils@^0.7.10":
  version "0.7.10"
  resolved "https://registry.npmjs.org/@antfu/utils/-/utils-0.7.10.tgz"
  integrity sha512-+562v9k4aI80m1+VuMHehNJWLOFjBnXn3tdOitzD0il5b7smkSBal4+a3oKiQTbrwMmN/TBUMDvbdoWDehgOww==

"@babel/code-frame@^7.26.2":
  version "7.26.2"
  resolved "https://registry.npmjs.org/@babel/code-frame/-/code-frame-7.26.2.tgz"
  integrity sha512-RJlIHRueQgwWitWgF8OdFYGZX328Ax5BCemNGlqHfplnRT9ESi8JkFlvaVYbS+UubVY6dpv87Fs2u5M29iNFVQ==
  dependencies:
    "@babel/helper-validator-identifier" "^7.25.9"
    js-tokens "^4.0.0"
    picocolors "^1.0.0"

"@babel/compat-data@^7.26.8":
  version "7.26.8"
  resolved "https://registry.npmjs.org/@babel/compat-data/-/compat-data-7.26.8.tgz"
  integrity sha512-oH5UPLMWR3L2wEFLnFJ1TZXqHufiTKAiLfqw5zkhS4dKXLJ10yVztfil/twG8EDTA4F/tvVNw9nOl4ZMslB8rQ==

"@babel/core@^7.0.0", "@babel/core@^7.0.0-0", "@babel/core@^7.23.0":
  version "7.26.10"
  resolved "https://registry.npmjs.org/@babel/core/-/core-7.26.10.tgz"
  integrity sha512-vMqyb7XCDMPvJFFOaT9kxtiRh42GwlZEg1/uIgtZshS5a/8OaduUfCi7kynKgc3Tw/6Uo2D+db9qBttghhmxwQ==
  dependencies:
    "@ampproject/remapping" "^2.2.0"
    "@babel/code-frame" "^7.26.2"
    "@babel/generator" "^7.26.10"
    "@babel/helper-compilation-targets" "^7.26.5"
    "@babel/helper-module-transforms" "^7.26.0"
    "@babel/helpers" "^7.26.10"
    "@babel/parser" "^7.26.10"
    "@babel/template" "^7.26.9"
    "@babel/traverse" "^7.26.10"
    "@babel/types" "^7.26.10"
    convert-source-map "^2.0.0"
    debug "^4.1.0"
    gensync "^1.0.0-beta.2"
    json5 "^2.2.3"
    semver "^6.3.1"

"@babel/generator@^7.26.10", "@babel/generator@^7.27.0":
  version "7.27.0"
  resolved "https://registry.npmjs.org/@babel/generator/-/generator-7.27.0.tgz"
  integrity sha512-VybsKvpiN1gU1sdMZIp7FcqphVVKEwcuj02x73uvcHE0PTihx1nlBcowYWhDwjpoAXRv43+gDzyggGnn1XZhVw==
  dependencies:
    "@babel/parser" "^7.27.0"
    "@babel/types" "^7.27.0"
    "@jridgewell/gen-mapping" "^0.3.5"
    "@jridgewell/trace-mapping" "^0.3.25"
    jsesc "^3.0.2"

"@babel/helper-annotate-as-pure@^7.25.9":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/helper-annotate-as-pure/-/helper-annotate-as-pure-7.25.9.tgz"
  integrity sha512-gv7320KBUFJz1RnylIg5WWYPRXKZ884AGkYpgpWW02TH66Dl+HaC1t1CKd0z3R4b6hdYEcmrNZHUmfCP+1u3/g==
  dependencies:
    "@babel/types" "^7.25.9"

"@babel/helper-compilation-targets@^7.26.5":
  version "7.27.0"
  resolved "https://registry.npmjs.org/@babel/helper-compilation-targets/-/helper-compilation-targets-7.27.0.tgz"
  integrity sha512-LVk7fbXml0H2xH34dFzKQ7TDZ2G4/rVTOrq9V+icbbadjbVxxeFeDsNHv2SrZeWoA+6ZiTyWYWtScEIW07EAcA==
  dependencies:
    "@babel/compat-data" "^7.26.8"
    "@babel/helper-validator-option" "^7.25.9"
    browserslist "^4.24.0"
    lru-cache "^5.1.1"
    semver "^6.3.1"

"@babel/helper-create-class-features-plugin@^7.25.9", "@babel/helper-create-class-features-plugin@^7.27.0":
  version "7.27.0"
  resolved "https://registry.npmjs.org/@babel/helper-create-class-features-plugin/-/helper-create-class-features-plugin-7.27.0.tgz"
  integrity sha512-vSGCvMecvFCd/BdpGlhpXYNhhC4ccxyvQWpbGL4CWbvfEoLFWUZuSuf7s9Aw70flgQF+6vptvgK2IfOnKlRmBg==
  dependencies:
    "@babel/helper-annotate-as-pure" "^7.25.9"
    "@babel/helper-member-expression-to-functions" "^7.25.9"
    "@babel/helper-optimise-call-expression" "^7.25.9"
    "@babel/helper-replace-supers" "^7.26.5"
    "@babel/helper-skip-transparent-expression-wrappers" "^7.25.9"
    "@babel/traverse" "^7.27.0"
    semver "^6.3.1"

"@babel/helper-member-expression-to-functions@^7.25.9":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/helper-member-expression-to-functions/-/helper-member-expression-to-functions-7.25.9.tgz"
  integrity sha512-wbfdZ9w5vk0C0oyHqAJbc62+vet5prjj01jjJ8sKn3j9h3MQQlflEdXYvuqRWjHnM12coDEqiC1IRCi0U/EKwQ==
  dependencies:
    "@babel/traverse" "^7.25.9"
    "@babel/types" "^7.25.9"

"@babel/helper-module-imports@^7.25.9":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/helper-module-imports/-/helper-module-imports-7.25.9.tgz"
  integrity sha512-tnUA4RsrmflIM6W6RFTLFSXITtl0wKjgpnLgXyowocVPrbYrLUXSBXDgTs8BlbmIzIdlBySRQjINYs2BAkiLtw==
  dependencies:
    "@babel/traverse" "^7.25.9"
    "@babel/types" "^7.25.9"

"@babel/helper-module-transforms@^7.26.0":
  version "7.26.0"
  resolved "https://registry.npmjs.org/@babel/helper-module-transforms/-/helper-module-transforms-7.26.0.tgz"
  integrity sha512-xO+xu6B5K2czEnQye6BHA7DolFFmS3LB7stHZFaOLb1pAwO1HWLS8fXA+eh0A2yIvltPVmx3eNNDBJA2SLHXFw==
  dependencies:
    "@babel/helper-module-imports" "^7.25.9"
    "@babel/helper-validator-identifier" "^7.25.9"
    "@babel/traverse" "^7.25.9"

"@babel/helper-optimise-call-expression@^7.25.9":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/helper-optimise-call-expression/-/helper-optimise-call-expression-7.25.9.tgz"
  integrity sha512-FIpuNaz5ow8VyrYcnXQTDRGvV6tTjkNtCK/RYNDXGSLlUD6cBuQTSw43CShGxjvfBTfcUA/r6UhUCbtYqkhcuQ==
  dependencies:
    "@babel/types" "^7.25.9"

"@babel/helper-plugin-utils@^7.10.4", "@babel/helper-plugin-utils@^7.25.9", "@babel/helper-plugin-utils@^7.26.5":
  version "7.26.5"
  resolved "https://registry.npmjs.org/@babel/helper-plugin-utils/-/helper-plugin-utils-7.26.5.tgz"
  integrity sha512-RS+jZcRdZdRFzMyr+wcsaqOmld1/EqTghfaBGQQd/WnRdzdlvSZ//kF7U8VQTxf1ynZ4cjUcYgjVGx13ewNPMg==

"@babel/helper-replace-supers@^7.26.5":
  version "7.26.5"
  resolved "https://registry.npmjs.org/@babel/helper-replace-supers/-/helper-replace-supers-7.26.5.tgz"
  integrity sha512-bJ6iIVdYX1YooY2X7w1q6VITt+LnUILtNk7zT78ykuwStx8BauCzxvFqFaHjOpW1bVnSUM1PN1f0p5P21wHxvg==
  dependencies:
    "@babel/helper-member-expression-to-functions" "^7.25.9"
    "@babel/helper-optimise-call-expression" "^7.25.9"
    "@babel/traverse" "^7.26.5"

"@babel/helper-skip-transparent-expression-wrappers@^7.25.9":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/helper-skip-transparent-expression-wrappers/-/helper-skip-transparent-expression-wrappers-7.25.9.tgz"
  integrity sha512-K4Du3BFa3gvyhzgPcntrkDgZzQaq6uozzcpGbOO1OEJaI+EJdqWIMTLgFgQf6lrfiDFo5FU+BxKepI9RmZqahA==
  dependencies:
    "@babel/traverse" "^7.25.9"
    "@babel/types" "^7.25.9"

"@babel/helper-string-parser@^7.25.9":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/helper-string-parser/-/helper-string-parser-7.25.9.tgz"
  integrity sha512-4A/SCr/2KLd5jrtOMFzaKjVtAei3+2r/NChoBNoZ3EyP/+GlhoaEGoWOZUmFmoITP7zOJyHIMm+DYRd8o3PvHA==

"@babel/helper-validator-identifier@^7.25.9":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/helper-validator-identifier/-/helper-validator-identifier-7.25.9.tgz"
  integrity sha512-Ed61U6XJc3CVRfkERJWDz4dJwKe7iLmmJsbOGu9wSloNSFttHV0I8g6UAgb7qnK5ly5bGLPd4oXZlxCdANBOWQ==

"@babel/helper-validator-option@^7.25.9":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/helper-validator-option/-/helper-validator-option-7.25.9.tgz"
  integrity sha512-e/zv1co8pp55dNdEcCynfj9X7nyUKUXoUEwfXqaZt0omVOmDe9oOTdKStH4GmAw6zxMFs50ZayuMfHDKlO7Tfw==

"@babel/helpers@^7.26.10":
  version "7.27.0"
  resolved "https://registry.npmjs.org/@babel/helpers/-/helpers-7.27.0.tgz"
  integrity sha512-U5eyP/CTFPuNE3qk+WZMxFkp/4zUzdceQlfzf7DdGdhp+Fezd7HD+i8Y24ZuTMKX3wQBld449jijbGq6OdGNQg==
  dependencies:
    "@babel/template" "^7.27.0"
    "@babel/types" "^7.27.0"

"@babel/parser@^7.25.3", "@babel/parser@^7.26.10", "@babel/parser@^7.26.9", "@babel/parser@^7.27.0":
  version "7.27.0"
  resolved "https://registry.npmjs.org/@babel/parser/-/parser-7.27.0.tgz"
  integrity sha512-iaepho73/2Pz7w2eMS0Q5f83+0RKI7i4xmiYeBmDzfRVbQtTOG7Ts0S4HzJVsTMGI9keU8rNfuZr8DKfSt7Yyg==
  dependencies:
    "@babel/types" "^7.27.0"

"@babel/plugin-proposal-decorators@^7.23.0":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/plugin-proposal-decorators/-/plugin-proposal-decorators-7.25.9.tgz"
  integrity sha512-smkNLL/O1ezy9Nhy4CNosc4Va+1wo5w4gzSZeLe6y6dM4mmHfYOCPolXQPHQxonZCF+ZyebxN9vqOolkYrSn5g==
  dependencies:
    "@babel/helper-create-class-features-plugin" "^7.25.9"
    "@babel/helper-plugin-utils" "^7.25.9"
    "@babel/plugin-syntax-decorators" "^7.25.9"

"@babel/plugin-syntax-decorators@^7.25.9":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/plugin-syntax-decorators/-/plugin-syntax-decorators-7.25.9.tgz"
  integrity sha512-ryzI0McXUPJnRCvMo4lumIKZUzhYUO/ScI+Mz4YVaTLt04DHNSjEUjKVvbzQjZFLuod/cYEc07mJWhzl6v4DPg==
  dependencies:
    "@babel/helper-plugin-utils" "^7.25.9"

"@babel/plugin-syntax-import-attributes@^7.22.5":
  version "7.26.0"
  resolved "https://registry.npmjs.org/@babel/plugin-syntax-import-attributes/-/plugin-syntax-import-attributes-7.26.0.tgz"
  integrity sha512-e2dttdsJ1ZTpi3B9UYGLw41hifAubg19AtCu/2I/F1QNVclOBr1dYpTdmdyZ84Xiz43BS/tCUkMAZNLv12Pi+A==
  dependencies:
    "@babel/helper-plugin-utils" "^7.25.9"

"@babel/plugin-syntax-import-meta@^7.10.4":
  version "7.10.4"
  resolved "https://registry.npmjs.org/@babel/plugin-syntax-import-meta/-/plugin-syntax-import-meta-7.10.4.tgz"
  integrity sha512-Yqfm+XDx0+Prh3VSeEQCPU81yC+JWZ2pDPFSS4ZdpfZhp4MkFMaDC1UqseovEKwSUpnIL7+vK+Clp7bfh0iD7g==
  dependencies:
    "@babel/helper-plugin-utils" "^7.10.4"

"@babel/plugin-syntax-jsx@^7.25.9":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/plugin-syntax-jsx/-/plugin-syntax-jsx-7.25.9.tgz"
  integrity sha512-ld6oezHQMZsZfp6pWtbjaNDF2tiiCYYDqQszHt5VV437lewP9aSi2Of99CK0D0XB21k7FLgnLcmQKyKzynfeAA==
  dependencies:
    "@babel/helper-plugin-utils" "^7.25.9"

"@babel/plugin-syntax-typescript@^7.25.9":
  version "7.25.9"
  resolved "https://registry.npmjs.org/@babel/plugin-syntax-typescript/-/plugin-syntax-typescript-7.25.9.tgz"
  integrity sha512-hjMgRy5hb8uJJjUcdWunWVcoi9bGpJp8p5Ol1229PoN6aytsLwNMgmdftO23wnCLMfVmTwZDWMPNq/D1SY60JQ==
  dependencies:
    "@babel/helper-plugin-utils" "^7.25.9"

"@babel/plugin-transform-typescript@^7.22.15":
  version "7.27.0"
  resolved "https://registry.npmjs.org/@babel/plugin-transform-typescript/-/plugin-transform-typescript-7.27.0.tgz"
  integrity sha512-fRGGjO2UEGPjvEcyAZXRXAS8AfdaQoq7HnxAbJoAoW10B9xOKesmmndJv+Sym2a+9FHWZ9KbyyLCe9s0Sn5jtg==
  dependencies:
    "@babel/helper-annotate-as-pure" "^7.25.9"
    "@babel/helper-create-class-features-plugin" "^7.27.0"
    "@babel/helper-plugin-utils" "^7.26.5"
    "@babel/helper-skip-transparent-expression-wrappers" "^7.25.9"
    "@babel/plugin-syntax-typescript" "^7.25.9"

"@babel/template@^7.26.9", "@babel/template@^7.27.0":
  version "7.27.0"
  resolved "https://registry.npmjs.org/@babel/template/-/template-7.27.0.tgz"
  integrity sha512-2ncevenBqXI6qRMukPlXwHKHchC7RyMuu4xv5JBXRfOGVcTy1mXCD12qrp7Jsoxll1EV3+9sE4GugBVRjT2jFA==
  dependencies:
    "@babel/code-frame" "^7.26.2"
    "@babel/parser" "^7.27.0"
    "@babel/types" "^7.27.0"

"@babel/traverse@^7.25.9", "@babel/traverse@^7.26.10", "@babel/traverse@^7.26.5", "@babel/traverse@^7.26.9", "@babel/traverse@^7.27.0":
  version "7.27.0"
  resolved "https://registry.npmjs.org/@babel/traverse/-/traverse-7.27.0.tgz"
  integrity sha512-19lYZFzYVQkkHkl4Cy4WrAVcqBkgvV2YM2TU3xG6DIwO7O3ecbDPfW3yM3bjAGcqcQHi+CCtjMR3dIEHxsd6bA==
  dependencies:
    "@babel/code-frame" "^7.26.2"
    "@babel/generator" "^7.27.0"
    "@babel/parser" "^7.27.0"
    "@babel/template" "^7.27.0"
    "@babel/types" "^7.27.0"
    debug "^4.3.1"
    globals "^11.1.0"

"@babel/types@^7.25.9", "@babel/types@^7.26.10", "@babel/types@^7.26.9", "@babel/types@^7.27.0":
  version "7.27.0"
  resolved "https://registry.npmjs.org/@babel/types/-/types-7.27.0.tgz"
  integrity sha512-H45s8fVLYjbhFH62dIJ3WtmJ6RSPt/3DRO0ZcT2SUiYiQyz3BLVb9ADEnLl91m74aQPS3AzzeajZHYOalWe3bg==
  dependencies:
    "@babel/helper-string-parser" "^7.25.9"
    "@babel/helper-validator-identifier" "^7.25.9"

"@esbuild/darwin-arm64@0.25.1":
  version "0.25.1"
  resolved "https://registry.npmjs.org/@esbuild/darwin-arm64/-/darwin-arm64-0.25.1.tgz"
  integrity sha512-5hEZKPf+nQjYoSr/elb62U19/l1mZDdqidGfmFutVUjjUZrOazAtwK+Kr+3y0C/oeJfLlxo9fXb1w7L+P7E4FQ==

"@headlessui/vue@^1.7.23":
  version "1.7.23"
  resolved "https://registry.npmjs.org/@headlessui/vue/-/vue-1.7.23.tgz"
  integrity sha512-JzdCNqurrtuu0YW6QaDtR2PIYCKPUWq28csDyMvN4zmGccmE7lz40Is6hc3LA4HFeCI7sekZ/PQMTNmn9I/4Wg==
  dependencies:
    "@tanstack/vue-virtual" "^3.0.0-beta.60"

"@heroicons/vue@^2.2.0":
  version "2.2.0"
  resolved "https://registry.npmjs.org/@heroicons/vue/-/vue-2.2.0.tgz"
  integrity sha512-G3dbSxoeEKqbi/DFalhRxJU4mTXJn7GwZ7ae8NuEQzd1bqdd0jAbdaBZlHPcvPD2xI1iGzNVB4k20Un2AguYPw==

"@isaacs/cliui@^8.0.2":
  version "8.0.2"
  resolved "https://registry.npmjs.org/@isaacs/cliui/-/cliui-8.0.2.tgz"
  integrity sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==
  dependencies:
    string-width "^5.1.2"
    string-width-cjs "npm:string-width@^4.2.0"
    strip-ansi "^7.0.1"
    strip-ansi-cjs "npm:strip-ansi@^6.0.1"
    wrap-ansi "^8.1.0"
    wrap-ansi-cjs "npm:wrap-ansi@^7.0.0"

"@jridgewell/gen-mapping@^0.3.2", "@jridgewell/gen-mapping@^0.3.5":
  version "0.3.8"
  resolved "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.8.tgz"
  integrity sha512-imAbBGkb+ebQyxKgzv5Hu2nmROxoDOXHh80evxdoXNOrvAnVx7zimzc1Oo5h9RlfV4vPXaE2iM5pOFbvOCClWA==
  dependencies:
    "@jridgewell/set-array" "^1.2.1"
    "@jridgewell/sourcemap-codec" "^1.4.10"
    "@jridgewell/trace-mapping" "^0.3.24"

"@jridgewell/resolve-uri@^3.1.0":
  version "3.1.2"
  resolved "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz"
  integrity sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==

"@jridgewell/set-array@^1.2.1":
  version "1.2.1"
  resolved "https://registry.npmjs.org/@jridgewell/set-array/-/set-array-1.2.1.tgz"
  integrity sha512-R8gLRTZeyp03ymzP/6Lil/28tGeGEzhx1q2k703KGWRAI1VdvPIXdG70VJc2pAMw3NA6JKL5hhFu1sJX0Mnn/A==

"@jridgewell/sourcemap-codec@^1.4.10", "@jridgewell/sourcemap-codec@^1.4.14", "@jridgewell/sourcemap-codec@^1.5.0":
  version "1.5.0"
  resolved "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.0.tgz"
  integrity sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ==

"@jridgewell/trace-mapping@^0.3.24", "@jridgewell/trace-mapping@^0.3.25":
  version "0.3.25"
  resolved "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.25.tgz"
  integrity sha512-vNk6aEwybGtawWmy/PzwnGDOjCkLWSD2wqvjGGAgOAwCGWySYXfYoxt00IJkTF+8Lb57DwOb3Aa0o9CApepiYQ==
  dependencies:
    "@jridgewell/resolve-uri" "^3.1.0"
    "@jridgewell/sourcemap-codec" "^1.4.14"

"@nodelib/fs.scandir@2.1.5":
  version "2.1.5"
  resolved "https://registry.npmjs.org/@nodelib/fs.scandir/-/fs.scandir-2.1.5.tgz"
  integrity sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==
  dependencies:
    "@nodelib/fs.stat" "2.0.5"
    run-parallel "^1.1.9"

"@nodelib/fs.stat@^2.0.2", "@nodelib/fs.stat@2.0.5":
  version "2.0.5"
  resolved "https://registry.npmjs.org/@nodelib/fs.stat/-/fs.stat-2.0.5.tgz"
  integrity sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==

"@nodelib/fs.walk@^1.2.3":
  version "1.2.8"
  resolved "https://registry.npmjs.org/@nodelib/fs.walk/-/fs.walk-1.2.8.tgz"
  integrity sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==
  dependencies:
    "@nodelib/fs.scandir" "2.1.5"
    fastq "^1.6.0"

"@pkgjs/parseargs@^0.11.0":
  version "0.11.0"
  resolved "https://registry.npmjs.org/@pkgjs/parseargs/-/parseargs-0.11.0.tgz"
  integrity sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==

"@polka/url@^1.0.0-next.24":
  version "1.0.0-next.28"
  resolved "https://registry.npmjs.org/@polka/url/-/url-1.0.0-next.28.tgz"
  integrity sha512-8LduaNlMZGwdZ6qWrKlfa+2M4gahzFkprZiAt2TF8uS0qQgBizKXpXURqvTJ4WtmupWxaLqjRb2UCTe72mu+Aw==

"@rollup/pluginutils@^5.1.3":
  version "5.1.4"
  resolved "https://registry.npmjs.org/@rollup/pluginutils/-/pluginutils-5.1.4.tgz"
  integrity sha512-USm05zrsFxYLPdWWq+K3STlWiT/3ELn3RcV5hJMghpeAIhxfsUIg6mt12CBJBInWMV4VneoV7SfGv8xIwo2qNQ==
  dependencies:
    "@types/estree" "^1.0.0"
    estree-walker "^2.0.2"
    picomatch "^4.0.2"

"@rollup/rollup-darwin-arm64@4.38.0":
  version "4.38.0"
  resolved "https://registry.npmjs.org/@rollup/rollup-darwin-arm64/-/rollup-darwin-arm64-4.38.0.tgz"
  integrity sha512-buA17AYXlW9Rn091sWMq1xGUvWQFOH4N1rqUxGJtEQzhChxWjldGCCup7r/wUnaI6Au8sKXpoh0xg58a7cgcpg==

"@sec-ant/readable-stream@^0.4.1":
  version "0.4.1"
  resolved "https://registry.npmjs.org/@sec-ant/readable-stream/-/readable-stream-0.4.1.tgz"
  integrity sha512-831qok9r2t8AlxLko40y2ebgSDhenenCatLVeW/uBtnHPyhHOvG0C7TvfgecV+wHzIm5KUICgzmVpWS+IMEAeg==

"@sindresorhus/merge-streams@^4.0.0":
  version "4.0.0"
  resolved "https://registry.npmjs.org/@sindresorhus/merge-streams/-/merge-streams-4.0.0.tgz"
  integrity sha512-tlqY9xq5ukxTUZBmoOp+m61cqwQD5pHJtFY3Mn8CA8ps6yghLH/Hw8UPdqg4OLmFW3IFlcXnQNmo/dh8HzXYIQ==

"@tanstack/virtual-core@3.13.6":
  version "3.13.6"
  resolved "https://registry.npmjs.org/@tanstack/virtual-core/-/virtual-core-3.13.6.tgz"
  integrity sha512-cnQUeWnhNP8tJ4WsGcYiX24Gjkc9ALstLbHcBj1t3E7EimN6n6kHH+DPV4PpDnuw00NApQp+ViojMj1GRdwYQg==

"@tanstack/vue-virtual@^3.0.0-beta.60":
  version "3.13.6"
  resolved "https://registry.npmjs.org/@tanstack/vue-virtual/-/vue-virtual-3.13.6.tgz"
  integrity sha512-GYdZ3SJBQPzgxhuCE2fvpiH46qzHiVx5XzBSdtESgiqh4poj8UgckjGWYEhxaBbcVt1oLzh1m3Ql4TyH32TOzQ==
  dependencies:
    "@tanstack/virtual-core" "3.13.6"

"@tsconfig/node22@^22.0.0":
  version "22.0.1"
  resolved "https://registry.npmjs.org/@tsconfig/node22/-/node22-22.0.1.tgz"
  integrity sha512-VkgOa3n6jvs1p+r3DiwBqeEwGAwEvnVCg/hIjiANl5IEcqP3G0u5m8cBJspe1t9qjZRlZ7WFgqq5bJrGdgAKMg==

"@types/estree@^1.0.0", "@types/estree@1.0.7":
  version "1.0.7"
  resolved "https://registry.npmjs.org/@types/estree/-/estree-1.0.7.tgz"
  integrity sha512-w28IoSUCJpidD/TGviZwwMJckNESJZXFu7NBZ5YJ4mEUnNraUn9Pm8HSZm/jDF1pDWYKspWE7oVphigUPRakIQ==

"@types/node@^18.0.0 || ^20.0.0 || >=22.0.0", "@types/node@^22.13.9":
  version "22.13.14"
  resolved "https://registry.npmjs.org/@types/node/-/node-22.13.14.tgz"
  integrity sha512-Zs/Ollc1SJ8nKUAgc7ivOEdIBM8JAKgrqqUYi2J997JuKO7/tpQC+WCetQ1sypiKCQWHdvdg9wBNpUPEWZae7w==
  dependencies:
    undici-types "~6.20.0"

"@vitejs/plugin-vue@^5.2.1":
  version "5.2.3"
  resolved "https://registry.npmjs.org/@vitejs/plugin-vue/-/plugin-vue-5.2.3.tgz"
  integrity sha512-IYSLEQj4LgZZuoVpdSUCw3dIynTWQgPlaRP6iAvMle4My0HdYwr5g5wQAfwOeHQBmYwEkqF70nRpSilr6PoUDg==

"@volar/language-core@~2.4.11", "@volar/language-core@2.4.12":
  version "2.4.12"
  resolved "https://registry.npmjs.org/@volar/language-core/-/language-core-2.4.12.tgz"
  integrity sha512-RLrFdXEaQBWfSnYGVxvR2WrO6Bub0unkdHYIdC31HzIEqATIuuhRRzYu76iGPZ6OtA4Au1SnW0ZwIqPP217YhA==
  dependencies:
    "@volar/source-map" "2.4.12"

"@volar/source-map@2.4.12":
  version "2.4.12"
  resolved "https://registry.npmjs.org/@volar/source-map/-/source-map-2.4.12.tgz"
  integrity sha512-bUFIKvn2U0AWojOaqf63ER0N/iHIBYZPpNGogfLPQ68F5Eet6FnLlyho7BS0y2HJ1jFhSif7AcuTx1TqsCzRzw==

"@volar/typescript@~2.4.11":
  version "2.4.12"
  resolved "https://registry.npmjs.org/@volar/typescript/-/typescript-2.4.12.tgz"
  integrity sha512-HJB73OTJDgPc80K30wxi3if4fSsZZAOScbj2fcicMuOPoOkcf9NNAINb33o+DzhBdF9xTKC1gnPmIRDous5S0g==
  dependencies:
    "@volar/language-core" "2.4.12"
    path-browserify "^1.0.1"
    vscode-uri "^3.0.8"

"@vue/babel-helper-vue-transform-on@1.4.0":
  version "1.4.0"
  resolved "https://registry.npmjs.org/@vue/babel-helper-vue-transform-on/-/babel-helper-vue-transform-on-1.4.0.tgz"
  integrity sha512-mCokbouEQ/ocRce/FpKCRItGo+013tHg7tixg3DUNS+6bmIchPt66012kBMm476vyEIJPafrvOf4E5OYj3shSw==

"@vue/babel-plugin-jsx@^1.1.5":
  version "1.4.0"
  resolved "https://registry.npmjs.org/@vue/babel-plugin-jsx/-/babel-plugin-jsx-1.4.0.tgz"
  integrity sha512-9zAHmwgMWlaN6qRKdrg1uKsBKHvnUU+Py+MOCTuYZBoZsopa90Di10QRjB+YPnVss0BZbG/H5XFwJY1fTxJWhA==
  dependencies:
    "@babel/helper-module-imports" "^7.25.9"
    "@babel/helper-plugin-utils" "^7.26.5"
    "@babel/plugin-syntax-jsx" "^7.25.9"
    "@babel/template" "^7.26.9"
    "@babel/traverse" "^7.26.9"
    "@babel/types" "^7.26.9"
    "@vue/babel-helper-vue-transform-on" "1.4.0"
    "@vue/babel-plugin-resolve-type" "1.4.0"
    "@vue/shared" "^3.5.13"

"@vue/babel-plugin-resolve-type@1.4.0":
  version "1.4.0"
  resolved "https://registry.npmjs.org/@vue/babel-plugin-resolve-type/-/babel-plugin-resolve-type-1.4.0.tgz"
  integrity sha512-4xqDRRbQQEWHQyjlYSgZsWj44KfiF6D+ktCuXyZ8EnVDYV3pztmXJDf1HveAjUAXxAnR8daCQT51RneWWxtTyQ==
  dependencies:
    "@babel/code-frame" "^7.26.2"
    "@babel/helper-module-imports" "^7.25.9"
    "@babel/helper-plugin-utils" "^7.26.5"
    "@babel/parser" "^7.26.9"
    "@vue/compiler-sfc" "^3.5.13"

"@vue/compiler-core@3.5.13":
  version "3.5.13"
  resolved "https://registry.npmjs.org/@vue/compiler-core/-/compiler-core-3.5.13.tgz"
  integrity sha512-oOdAkwqUfW1WqpwSYJce06wvt6HljgY3fGeM9NcVA1HaYOij3mZG9Rkysn0OHuyUAGMbEbARIpsG+LPVlBJ5/Q==
  dependencies:
    "@babel/parser" "^7.25.3"
    "@vue/shared" "3.5.13"
    entities "^4.5.0"
    estree-walker "^2.0.2"
    source-map-js "^1.2.0"

"@vue/compiler-dom@^3.3.4", "@vue/compiler-dom@^3.5.0", "@vue/compiler-dom@3.5.13":
  version "3.5.13"
  resolved "https://registry.npmjs.org/@vue/compiler-dom/-/compiler-dom-3.5.13.tgz"
  integrity sha512-ZOJ46sMOKUjO3e94wPdCzQ6P1Lx/vhp2RSvfaab88Ajexs0AHeV0uasYhi99WPaogmBlRHNRuly8xV75cNTMDA==
  dependencies:
    "@vue/compiler-core" "3.5.13"
    "@vue/shared" "3.5.13"

"@vue/compiler-sfc@^3.5.13", "@vue/compiler-sfc@3.5.13":
  version "3.5.13"
  resolved "https://registry.npmjs.org/@vue/compiler-sfc/-/compiler-sfc-3.5.13.tgz"
  integrity sha512-6VdaljMpD82w6c2749Zhf5T9u5uLBWKnVue6XWxprDobftnletJ8+oel7sexFfM3qIxNmVE7LSFGTpv6obNyaQ==
  dependencies:
    "@babel/parser" "^7.25.3"
    "@vue/compiler-core" "3.5.13"
    "@vue/compiler-dom" "3.5.13"
    "@vue/compiler-ssr" "3.5.13"
    "@vue/shared" "3.5.13"
    estree-walker "^2.0.2"
    magic-string "^0.30.11"
    postcss "^8.4.48"
    source-map-js "^1.2.0"

"@vue/compiler-ssr@3.5.13":
  version "3.5.13"
  resolved "https://registry.npmjs.org/@vue/compiler-ssr/-/compiler-ssr-3.5.13.tgz"
  integrity sha512-wMH6vrYHxQl/IybKJagqbquvxpWCuVYpoUJfCqFZwa/JY1GdATAQ+TgVtgrwwMZ0D07QhA99rs/EAAWfvG6KpA==
  dependencies:
    "@vue/compiler-dom" "3.5.13"
    "@vue/shared" "3.5.13"

"@vue/compiler-vue2@^2.7.16":
  version "2.7.16"
  resolved "https://registry.npmjs.org/@vue/compiler-vue2/-/compiler-vue2-2.7.16.tgz"
  integrity sha512-qYC3Psj9S/mfu9uVi5WvNZIzq+xnXMhOwbTFKKDD7b1lhpnn71jXSFdTQ+WsIEk0ONCd7VV2IMm7ONl6tbQ86A==
  dependencies:
    de-indent "^1.0.2"
    he "^1.2.0"

"@vue/devtools-api@^7.7.2":
  version "7.7.2"
  resolved "https://registry.npmjs.org/@vue/devtools-api/-/devtools-api-7.7.2.tgz"
  integrity sha512-1syn558KhyN+chO5SjlZIwJ8bV/bQ1nOVTG66t2RbG66ZGekyiYNmRO7X9BJCXQqPsFHlnksqvPhce2qpzxFnA==
  dependencies:
    "@vue/devtools-kit" "^7.7.2"

"@vue/devtools-core@^7.7.2":
  version "7.7.2"
  resolved "https://registry.npmjs.org/@vue/devtools-core/-/devtools-core-7.7.2.tgz"
  integrity sha512-lexREWj1lKi91Tblr38ntSsy6CvI8ba7u+jmwh2yruib/ltLUcsIzEjCnrkh1yYGGIKXbAuYV2tOG10fGDB9OQ==
  dependencies:
    "@vue/devtools-kit" "^7.7.2"
    "@vue/devtools-shared" "^7.7.2"
    mitt "^3.0.1"
    nanoid "^5.0.9"
    pathe "^2.0.2"
    vite-hot-client "^0.2.4"

"@vue/devtools-kit@^7.7.2":
  version "7.7.2"
  resolved "https://registry.npmjs.org/@vue/devtools-kit/-/devtools-kit-7.7.2.tgz"
  integrity sha512-CY0I1JH3Z8PECbn6k3TqM1Bk9ASWxeMtTCvZr7vb+CHi+X/QwQm5F1/fPagraamKMAHVfuuCbdcnNg1A4CYVWQ==
  dependencies:
    "@vue/devtools-shared" "^7.7.2"
    birpc "^0.2.19"
    hookable "^5.5.3"
    mitt "^3.0.1"
    perfect-debounce "^1.0.0"
    speakingurl "^14.0.1"
    superjson "^2.2.1"

"@vue/devtools-shared@^7.7.2":
  version "7.7.2"
  resolved "https://registry.npmjs.org/@vue/devtools-shared/-/devtools-shared-7.7.2.tgz"
  integrity sha512-uBFxnp8gwW2vD6FrJB8JZLUzVb6PNRG0B0jBnHsOH8uKyva2qINY8PTF5Te4QlTbMDqU5K6qtJDr6cNsKWhbOA==
  dependencies:
    rfdc "^1.4.1"

"@vue/language-core@2.2.8":
  version "2.2.8"
  resolved "https://registry.npmjs.org/@vue/language-core/-/language-core-2.2.8.tgz"
  integrity sha512-rrzB0wPGBvcwaSNRriVWdNAbHQWSf0NlGqgKHK5mEkXpefjUlVRP62u03KvwZpvKVjRnBIQ/Lwre+Mx9N6juUQ==
  dependencies:
    "@volar/language-core" "~2.4.11"
    "@vue/compiler-dom" "^3.5.0"
    "@vue/compiler-vue2" "^2.7.16"
    "@vue/shared" "^3.5.0"
    alien-signals "^1.0.3"
    minimatch "^9.0.3"
    muggle-string "^0.4.1"
    path-browserify "^1.0.1"

"@vue/reactivity@3.5.13":
  version "3.5.13"
  resolved "https://registry.npmjs.org/@vue/reactivity/-/reactivity-3.5.13.tgz"
  integrity sha512-NaCwtw8o48B9I6L1zl2p41OHo/2Z4wqYGGIK1Khu5T7yxrn+ATOixn/Udn2m+6kZKB/J7cuT9DbWWhRxqixACg==
  dependencies:
    "@vue/shared" "3.5.13"

"@vue/runtime-core@3.5.13":
  version "3.5.13"
  resolved "https://registry.npmjs.org/@vue/runtime-core/-/runtime-core-3.5.13.tgz"
  integrity sha512-Fj4YRQ3Az0WTZw1sFe+QDb0aXCerigEpw418pw1HBUKFtnQHWzwojaukAs2X/c9DQz4MQ4bsXTGlcpGxU/RCIw==
  dependencies:
    "@vue/reactivity" "3.5.13"
    "@vue/shared" "3.5.13"

"@vue/runtime-dom@3.5.13":
  version "3.5.13"
  resolved "https://registry.npmjs.org/@vue/runtime-dom/-/runtime-dom-3.5.13.tgz"
  integrity sha512-dLaj94s93NYLqjLiyFzVs9X6dWhTdAlEAciC3Moq7gzAc13VJUdCnjjRurNM6uTLFATRHexHCTu/Xp3eW6yoog==
  dependencies:
    "@vue/reactivity" "3.5.13"
    "@vue/runtime-core" "3.5.13"
    "@vue/shared" "3.5.13"
    csstype "^3.1.3"

"@vue/server-renderer@3.5.13":
  version "3.5.13"
  resolved "https://registry.npmjs.org/@vue/server-renderer/-/server-renderer-3.5.13.tgz"
  integrity sha512-wAi4IRJV/2SAW3htkTlB+dHeRmpTiVIK1OGLWV1yeStVSebSQQOwGwIq0D3ZIoBj2C2qpgz5+vX9iEBkTdk5YA==
  dependencies:
    "@vue/compiler-ssr" "3.5.13"
    "@vue/shared" "3.5.13"

"@vue/shared@^3.5.0", "@vue/shared@^3.5.13", "@vue/shared@3.5.13":
  version "3.5.13"
  resolved "https://registry.npmjs.org/@vue/shared/-/shared-3.5.13.tgz"
  integrity sha512-/hnE/qP5ZoGpol0a5mDi45bOd7t3tjYJBjsgCsivow7D48cJeV5l05RD82lPqi7gRiphZM37rnhW1l6ZoCNNnQ==

"@vue/tsconfig@^0.7.0":
  version "0.7.0"
  resolved "https://registry.npmjs.org/@vue/tsconfig/-/tsconfig-0.7.0.tgz"
  integrity sha512-ku2uNz5MaZ9IerPPUyOHzyjhXoX2kVJaVf7hL315DC17vS6IiZRmmCPfggNbU16QTvM80+uYYy3eYJB59WCtvg==

alien-signals@^1.0.3:
  version "1.0.10"
  resolved "https://registry.npmjs.org/alien-signals/-/alien-signals-1.0.10.tgz"
  integrity sha512-pBrgovDvA/c55/aA+ar5pxNCvjQB5IlODtpOQXmUyrpclWIsHmUMsfIuCWsSU/l1iLU2O3ZhICdPaYTsuvGu8Q==

ansi-regex@^3.0.0:
  version "3.0.1"
  resolved "https://registry.npmjs.org/ansi-regex/-/ansi-regex-3.0.1.tgz"
  integrity sha512-+O9Jct8wf++lXxxFc4hc8LsjaSq0HFzzL7cVsw8pRDIPdjKD2mT4ytDZlLuSBZ4cLKZFXIrMGO7DbQCtMJJMKw==

ansi-regex@^5.0.1:
  version "5.0.1"
  resolved "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz"
  integrity sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==

ansi-regex@^6.0.1:
  version "6.1.0"
  resolved "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.1.0.tgz"
  integrity sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==

ansi-styles@^4.0.0:
  version "4.3.0"
  resolved "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz"
  integrity sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==
  dependencies:
    color-convert "^2.0.1"

ansi-styles@^6.1.0:
  version "6.2.1"
  resolved "https://registry.npmjs.org/ansi-styles/-/ansi-styles-6.2.1.tgz"
  integrity sha512-bN798gFfQX+viw3R7yrGWRqnrN2oRkEkUjjl4JNn4E8GxxbjtG3FbrEIIY3l8/hrwUwIeCZvi4QuOTP4MErVug==

ansi-styles@^6.2.1:
  version "6.2.1"
  resolved "https://registry.npmjs.org/ansi-styles/-/ansi-styles-6.2.1.tgz"
  integrity sha512-bN798gFfQX+viw3R7yrGWRqnrN2oRkEkUjjl4JNn4E8GxxbjtG3FbrEIIY3l8/hrwUwIeCZvi4QuOTP4MErVug==

any-promise@^1.0.0:
  version "1.3.0"
  resolved "https://registry.npmjs.org/any-promise/-/any-promise-1.3.0.tgz"
  integrity sha512-7UvmKalWRt1wgjL1RrGxoSJW/0QZFIegpeGvZG9kjp8vrRu55XTHbwnqq2GpXm9uLbcuhxm3IqX9OB4MZR1b2A==

anymatch@~3.1.2:
  version "3.1.3"
  resolved "https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz"
  integrity sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==
  dependencies:
    normalize-path "^3.0.0"
    picomatch "^2.0.4"

arg@^5.0.2:
  version "5.0.2"
  resolved "https://registry.npmjs.org/arg/-/arg-5.0.2.tgz"
  integrity sha512-PYjyFOLKQ9y57JvQ6QLo8dAgNqswh8M1RMJYdQduT6xbWSgK36P/Z/v+p888pM69jMMfS8Xd8F6I1kQ/I9HUGg==

asynckit@^0.4.0:
  version "0.4.0"
  resolved "https://registry.npmjs.org/asynckit/-/asynckit-0.4.0.tgz"
  integrity sha512-Oei9OH4tRh0YqU3GxhX79dM/mwVgvbZJaSNaRk+bshkj0S5cfHcgYakreBjrHwatXKbz+IoIdYLxrKim2MjW0Q==

autoprefixer@^10.4.21:
  version "10.4.21"
  resolved "https://registry.npmjs.org/autoprefixer/-/autoprefixer-10.4.21.tgz"
  integrity sha512-O+A6LWV5LDHSJD3LjHYoNi4VLsj/Whi7k6zG12xTYaU4cQ8oxQGckXNX8cRHK5yOZ/ppVHe0ZBXGzSV9jXdVbQ==
  dependencies:
    browserslist "^4.24.4"
    caniuse-lite "^1.0.30001702"
    fraction.js "^4.3.7"
    normalize-range "^0.1.2"
    picocolors "^1.1.1"
    postcss-value-parser "^4.2.0"

axios@^1.8.4:
  version "1.8.4"
  resolved "https://registry.npmjs.org/axios/-/axios-1.8.4.tgz"
  integrity sha512-eBSYY4Y68NNlHbHBMdeDmKNtDgXWhQsJcGqzO3iLUM0GraQFSS9cVgPX5I9b3lbdFKyYoAEGAZF1DwhTaljNAw==
  dependencies:
    follow-redirects "^1.15.6"
    form-data "^4.0.0"
    proxy-from-env "^1.1.0"

balanced-match@^1.0.0:
  version "1.0.2"
  resolved "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz"
  integrity sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==

binary-extensions@^2.0.0:
  version "2.3.0"
  resolved "https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz"
  integrity sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==

birpc@^0.2.19:
  version "0.2.19"
  resolved "https://registry.npmjs.org/birpc/-/birpc-0.2.19.tgz"
  integrity sha512-5WeXXAvTmitV1RqJFppT5QtUiz2p1mRSYU000Jkft5ZUCLJIk4uQriYNO50HknxKwM6jd8utNc66K1qGIwwWBQ==

brace-expansion@^2.0.1:
  version "2.0.1"
  resolved "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.1.tgz"
  integrity sha512-XnAIvQ8eM+kC6aULx6wuQiwVsnzsi9d3WxzV3FpWTGA19F621kwdbsAcFKXgKUHZWsy+mY6iL1sHTxWEFCytDA==
  dependencies:
    balanced-match "^1.0.0"

braces@^3.0.3, braces@~3.0.2:
  version "3.0.3"
  resolved "https://registry.npmjs.org/braces/-/braces-3.0.3.tgz"
  integrity sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==
  dependencies:
    fill-range "^7.1.1"

browserslist@^4.24.0, browserslist@^4.24.4, "browserslist@>= 4.21.0":
  version "4.24.4"
  resolved "https://registry.npmjs.org/browserslist/-/browserslist-4.24.4.tgz"
  integrity sha512-KDi1Ny1gSePi1vm0q4oxSF8b4DR44GF4BbmS2YdhPLOEqd8pDviZOGH/GsmRwoWJ2+5Lr085X7naowMwKHDG1A==
  dependencies:
    caniuse-lite "^1.0.30001688"
    electron-to-chromium "^1.5.73"
    node-releases "^2.0.19"
    update-browserslist-db "^1.1.1"

bundle-name@^4.1.0:
  version "4.1.0"
  resolved "https://registry.npmjs.org/bundle-name/-/bundle-name-4.1.0.tgz"
  integrity sha512-tjwM5exMg6BGRI+kNmTntNsvdZS1X8BFYS6tnJ2hdH0kVxM6/eVZ2xy+FqStSWvYmtfFMDLIxurorHwDKfDz5Q==
  dependencies:
    run-applescript "^7.0.0"

call-bind-apply-helpers@^1.0.1, call-bind-apply-helpers@^1.0.2:
  version "1.0.2"
  resolved "https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz"
  integrity sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==
  dependencies:
    es-errors "^1.3.0"
    function-bind "^1.1.2"

camelcase-css@^2.0.1:
  version "2.0.1"
  resolved "https://registry.npmjs.org/camelcase-css/-/camelcase-css-2.0.1.tgz"
  integrity sha512-QOSvevhslijgYwRx6Rv7zKdMF8lbRmx+uQGx2+vDc+KI/eBnsy9kit5aj23AgGu3pa4t9AgwbnXWqS+iOY+2aA==

camelcase@^5.0.0:
  version "5.3.1"
  resolved "https://registry.npmjs.org/camelcase/-/camelcase-5.3.1.tgz"
  integrity sha512-L28STB170nwWS63UjtlEOE3dldQApaJXZkOI1uMFfzf3rRuPegHaHesyee+YxQ+W6SvRDQV6UrdOdRiR153wJg==

caniuse-lite@^1.0.30001688, caniuse-lite@^1.0.30001702:
  version "1.0.30001707"
  resolved "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30001707.tgz"
  integrity sha512-3qtRjw/HQSMlDWf+X79N206fepf4SOOU6SQLMaq/0KkZLmSjPxAkBOQQ+FxbHKfHmYLZFfdWsO3KA90ceHPSnw==

chokidar@^3.6.0:
  version "3.6.0"
  resolved "https://registry.npmjs.org/chokidar/-/chokidar-3.6.0.tgz"
  integrity sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==
  dependencies:
    anymatch "~3.1.2"
    braces "~3.0.2"
    glob-parent "~5.1.2"
    is-binary-path "~2.1.0"
    is-glob "~4.0.1"
    normalize-path "~3.0.0"
    readdirp "~3.6.0"
  optionalDependencies:
    fsevents "~2.3.2"

cliui@^6.0.0:
  version "6.0.0"
  resolved "https://registry.npmjs.org/cliui/-/cliui-6.0.0.tgz"
  integrity sha512-t6wbgtoCXvAzst7QgXxJYqPt0usEfbgQdftEPbLL/cvv6HPE5VgvqCuAIDR0NgU52ds6rFwqrgakNLrHEjCbrQ==
  dependencies:
    string-width "^4.2.0"
    strip-ansi "^6.0.0"
    wrap-ansi "^6.2.0"

color-convert@^2.0.1:
  version "2.0.1"
  resolved "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz"
  integrity sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==
  dependencies:
    color-name "~1.1.4"

color-name@~1.1.4:
  version "1.1.4"
  resolved "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz"
  integrity sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==

combined-stream@^1.0.8:
  version "1.0.8"
  resolved "https://registry.npmjs.org/combined-stream/-/combined-stream-1.0.8.tgz"
  integrity sha512-FQN4MRfuJeHf7cBbBMJFXhKSDq+2kAArBlmRBvcvFE5BB1HZKXtSFASDhdlz9zOYwxh8lDdnvmMOe/+5cdoEdg==
  dependencies:
    delayed-stream "~1.0.0"

commander@^4.0.0:
  version "4.1.1"
  resolved "https://registry.npmjs.org/commander/-/commander-4.1.1.tgz"
  integrity sha512-NOKm8xhkzAjzFx8B2v5OAHT+u5pRQc2UCa2Vq9jYL/31o2wi9mxBA7LIFs3sV5VSC49z6pEhfbMULvShKj26WA==

convert-source-map@^2.0.0:
  version "2.0.0"
  resolved "https://registry.npmjs.org/convert-source-map/-/convert-source-map-2.0.0.tgz"
  integrity sha512-Kvp459HrV2FEJ1CAsi1Ku+MY3kasH19TFykTz2xWmMeq6bk2NU3XXvfJ+Q61m0xktWwt+1HSYf3JZsTms3aRJg==

copy-anything@^3.0.2:
  version "3.0.5"
  resolved "https://registry.npmjs.org/copy-anything/-/copy-anything-3.0.5.tgz"
  integrity sha512-yCEafptTtb4bk7GLEQoM8KVJpxAfdBJYaXyzQEgQQQgYrZiDp8SJmGKlYza6CYjEDNstAdNdKA3UuoULlEbS6w==
  dependencies:
    is-what "^4.1.8"

cowsay@^1.6.0:
  version "1.6.0"
  resolved "https://registry.npmjs.org/cowsay/-/cowsay-1.6.0.tgz"
  integrity sha512-8C4H1jdrgNusTQr3Yu4SCm+ZKsAlDFbpa0KS0Z3im8ueag+9pGOf3CrioruvmeaW/A5oqg9L0ar6qeftAh03jw==
  dependencies:
    get-stdin "8.0.0"
    string-width "~2.1.1"
    strip-final-newline "2.0.0"
    yargs "15.4.1"

cross-spawn@^7.0.3, cross-spawn@^7.0.6:
  version "7.0.6"
  resolved "https://registry.npmjs.org/cross-spawn/-/cross-spawn-7.0.6.tgz"
  integrity sha512-uV2QOWP2nWzsy2aMp8aRibhi9dlzF5Hgh5SHaB9OiTGEyDTiJJyx0uy51QXdyWbtAHNua4XJzUKca3OzKUd3vA==
  dependencies:
    path-key "^3.1.0"
    shebang-command "^2.0.0"
    which "^2.0.1"

cssesc@^3.0.0:
  version "3.0.0"
  resolved "https://registry.npmjs.org/cssesc/-/cssesc-3.0.0.tgz"
  integrity sha512-/Tb/JcjK111nNScGob5MNtsntNM1aCNUDipB/TkwZFhyDrrE47SOx/18wF2bbjgc3ZzCSKW1T5nt5EbFoAz/Vg==

csstype@^3.1.3:
  version "3.1.3"
  resolved "https://registry.npmjs.org/csstype/-/csstype-3.1.3.tgz"
  integrity sha512-M1uQkMl8rQK/szD0LNhtqxIPLpimGm8sOBwU7lLnCpSbTyY3yeU1Vc7l4KT5zT4s/yOxHH5O7tIuuLOCnLADRw==

de-indent@^1.0.2:
  version "1.0.2"
  resolved "https://registry.npmjs.org/de-indent/-/de-indent-1.0.2.tgz"
  integrity sha512-e/1zu3xH5MQryN2zdVaF0OrdNLUbvWxzMbi+iNA6Bky7l1RoP8a2fIbRocyHclXt/arDrrR6lL3TqFD9pMQTsg==

debug@^4.1.0, debug@^4.3.1, debug@^4.3.7:
  version "4.4.0"
  resolved "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz"
  integrity sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==
  dependencies:
    ms "^2.1.3"

decamelize@^1.2.0:
  version "1.2.0"
  resolved "https://registry.npmjs.org/decamelize/-/decamelize-1.2.0.tgz"
  integrity sha512-z2S+W9X73hAUUki+N+9Za2lBlun89zigOyGrsax+KUQ6wKW4ZoWpEYBkGhQjwAjjDCkWxhY0VKEhk8wzY7F5cA==

default-browser-id@^5.0.0:
  version "5.0.0"
  resolved "https://registry.npmjs.org/default-browser-id/-/default-browser-id-5.0.0.tgz"
  integrity sha512-A6p/pu/6fyBcA1TRz/GqWYPViplrftcW2gZC9q79ngNCKAeR/X3gcEdXQHl4KNXV+3wgIJ1CPkJQ3IHM6lcsyA==

default-browser@^5.2.1:
  version "5.2.1"
  resolved "https://registry.npmjs.org/default-browser/-/default-browser-5.2.1.tgz"
  integrity sha512-WY/3TUME0x3KPYdRRxEJJvXRHV4PyPoUsxtZa78lwItwRQRHhd2U9xOscaT/YTf8uCXIAjeJOFBVEh/7FtD8Xg==
  dependencies:
    bundle-name "^4.1.0"
    default-browser-id "^5.0.0"

define-lazy-prop@^3.0.0:
  version "3.0.0"
  resolved "https://registry.npmjs.org/define-lazy-prop/-/define-lazy-prop-3.0.0.tgz"
  integrity sha512-N+MeXYoqr3pOgn8xfyRPREN7gHakLYjhsHhWGT3fWAiL4IkAt0iDw14QiiEm2bE30c5XX5q0FtAA3CK5f9/BUg==

delayed-stream@~1.0.0:
  version "1.0.0"
  resolved "https://registry.npmjs.org/delayed-stream/-/delayed-stream-1.0.0.tgz"
  integrity sha512-ZySD7Nf91aLB0RxL4KGrKHBXl7Eds1DAmEdcoVawXnLD7SDhpNgtuII2aAkg7a7QS41jxPSZ17p4VdGnMHk3MQ==

didyoumean@^1.2.2:
  version "1.2.2"
  resolved "https://registry.npmjs.org/didyoumean/-/didyoumean-1.2.2.tgz"
  integrity sha512-gxtyfqMg7GKyhQmb056K7M3xszy/myH8w+B4RT+QXBQsvAOdc3XymqDDPHx1BgPgsdAA5SIifona89YtRATDzw==

dlv@^1.1.3:
  version "1.1.3"
  resolved "https://registry.npmjs.org/dlv/-/dlv-1.1.3.tgz"
  integrity sha512-+HlytyjlPKnIG8XuRG8WvmBP8xs8P71y+SKKS6ZXWoEgLuePxtDoUEiH7WkdePWrQ5JBpE6aoVqfZfJUQkjXwA==

dunder-proto@^1.0.1:
  version "1.0.1"
  resolved "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz"
  integrity sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==
  dependencies:
    call-bind-apply-helpers "^1.0.1"
    es-errors "^1.3.0"
    gopd "^1.2.0"

eastasianwidth@^0.2.0:
  version "0.2.0"
  resolved "https://registry.npmjs.org/eastasianwidth/-/eastasianwidth-0.2.0.tgz"
  integrity sha512-I88TYZWc9XiYHRQ4/3c5rjjfgkjhLyW2luGIheGERbNQ6OY7yTybanSpDXZa8y7VUP9YmDcYa+eyq4ca7iLqWA==

electron-to-chromium@^1.5.73:
  version "1.5.128"
  resolved "https://registry.npmjs.org/electron-to-chromium/-/electron-to-chromium-1.5.128.tgz"
  integrity sha512-bo1A4HH/NS522Ws0QNFIzyPcyUUNV/yyy70Ho1xqfGYzPUme2F/xr4tlEOuM6/A538U1vDA7a4XfCd1CKRegKQ==

emoji-regex@^8.0.0:
  version "8.0.0"
  resolved "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz"
  integrity sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==

emoji-regex@^9.2.2:
  version "9.2.2"
  resolved "https://registry.npmjs.org/emoji-regex/-/emoji-regex-9.2.2.tgz"
  integrity sha512-L18DaJsXSUk2+42pv8mLs5jJT2hqFkFE4j21wOmgbUqsZ2hL72NsUU785g9RXgo3s0ZNgVl42TiHp3ZtOv/Vyg==

entities@^4.5.0:
  version "4.5.0"
  resolved "https://registry.npmjs.org/entities/-/entities-4.5.0.tgz"
  integrity sha512-V0hjH4dGPh9Ao5p0MoRY6BVqtwCjhz6vI5LT8AJ55H+4g9/4vbHx1I54fS0XuclLhDHArPQCiMjDxjaL8fPxhw==

error-stack-parser-es@^0.1.5:
  version "0.1.5"
  resolved "https://registry.npmjs.org/error-stack-parser-es/-/error-stack-parser-es-0.1.5.tgz"
  integrity sha512-xHku1X40RO+fO8yJ8Wh2f2rZWVjqyhb1zgq1yZ8aZRQkv6OOKhKWRUaht3eSCUbAOBaKIgM+ykwFLE+QUxgGeg==

es-define-property@^1.0.1:
  version "1.0.1"
  resolved "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz"
  integrity sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==

es-errors@^1.3.0:
  version "1.3.0"
  resolved "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz"
  integrity sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==

es-object-atoms@^1.0.0, es-object-atoms@^1.1.1:
  version "1.1.1"
  resolved "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz"
  integrity sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==
  dependencies:
    es-errors "^1.3.0"

es-set-tostringtag@^2.1.0:
  version "2.1.0"
  resolved "https://registry.npmjs.org/es-set-tostringtag/-/es-set-tostringtag-2.1.0.tgz"
  integrity sha512-j6vWzfrGVfyXxge+O0x5sh6cvxAog0a/4Rdd2K36zCMV5eJ+/+tOAngRO8cODMNWbVRdVlmGZQL2YS3yR8bIUA==
  dependencies:
    es-errors "^1.3.0"
    get-intrinsic "^1.2.6"
    has-tostringtag "^1.0.2"
    hasown "^2.0.2"

esbuild@^0.25.0:
  version "0.25.1"
  resolved "https://registry.npmjs.org/esbuild/-/esbuild-0.25.1.tgz"
  integrity sha512-BGO5LtrGC7vxnqucAe/rmvKdJllfGaYWdyABvyMoXQlfYMb2bbRuReWR5tEGE//4LcNJj9XrkovTqNYRFZHAMQ==
  optionalDependencies:
    "@esbuild/aix-ppc64" "0.25.1"
    "@esbuild/android-arm" "0.25.1"
    "@esbuild/android-arm64" "0.25.1"
    "@esbuild/android-x64" "0.25.1"
    "@esbuild/darwin-arm64" "0.25.1"
    "@esbuild/darwin-x64" "0.25.1"
    "@esbuild/freebsd-arm64" "0.25.1"
    "@esbuild/freebsd-x64" "0.25.1"
    "@esbuild/linux-arm" "0.25.1"
    "@esbuild/linux-arm64" "0.25.1"
    "@esbuild/linux-ia32" "0.25.1"
    "@esbuild/linux-loong64" "0.25.1"
    "@esbuild/linux-mips64el" "0.25.1"
    "@esbuild/linux-ppc64" "0.25.1"
    "@esbuild/linux-riscv64" "0.25.1"
    "@esbuild/linux-s390x" "0.25.1"
    "@esbuild/linux-x64" "0.25.1"
    "@esbuild/netbsd-arm64" "0.25.1"
    "@esbuild/netbsd-x64" "0.25.1"
    "@esbuild/openbsd-arm64" "0.25.1"
    "@esbuild/openbsd-x64" "0.25.1"
    "@esbuild/sunos-x64" "0.25.1"
    "@esbuild/win32-arm64" "0.25.1"
    "@esbuild/win32-ia32" "0.25.1"
    "@esbuild/win32-x64" "0.25.1"

escalade@^3.2.0:
  version "3.2.0"
  resolved "https://registry.npmjs.org/escalade/-/escalade-3.2.0.tgz"
  integrity sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==

estree-walker@^2.0.2:
  version "2.0.2"
  resolved "https://registry.npmjs.org/estree-walker/-/estree-walker-2.0.2.tgz"
  integrity sha512-Rfkk/Mp/DL7JVje3u18FxFujQlTNR2q6QfMSMB7AvCBx91NGj/ba3kCfza0f6dVDbw7YlRf/nDrn7pQrCCyQ/w==

execa@^9.5.1:
  version "9.5.2"
  resolved "https://registry.npmjs.org/execa/-/execa-9.5.2.tgz"
  integrity sha512-EHlpxMCpHWSAh1dgS6bVeoLAXGnJNdR93aabr4QCGbzOM73o5XmRfM/e5FUqsw3aagP8S8XEWUWFAxnRBnAF0Q==
  dependencies:
    "@sindresorhus/merge-streams" "^4.0.0"
    cross-spawn "^7.0.3"
    figures "^6.1.0"
    get-stream "^9.0.0"
    human-signals "^8.0.0"
    is-plain-obj "^4.1.0"
    is-stream "^4.0.1"
    npm-run-path "^6.0.0"
    pretty-ms "^9.0.0"
    signal-exit "^4.1.0"
    strip-final-newline "^4.0.0"
    yoctocolors "^2.0.0"

fast-glob@^3.3.2:
  version "3.3.3"
  resolved "https://registry.npmjs.org/fast-glob/-/fast-glob-3.3.3.tgz"
  integrity sha512-7MptL8U0cqcFdzIzwOTHoilX9x5BrNqye7Z/LuC7kCMRio1EMSyqRK3BEAUD7sXRq4iT4AzTVuZdhgQ2TCvYLg==
  dependencies:
    "@nodelib/fs.stat" "^2.0.2"
    "@nodelib/fs.walk" "^1.2.3"
    glob-parent "^5.1.2"
    merge2 "^1.3.0"
    micromatch "^4.0.8"

fastq@^1.6.0:
  version "1.19.1"
  resolved "https://registry.npmjs.org/fastq/-/fastq-1.19.1.tgz"
  integrity sha512-GwLTyxkCXjXbxqIhTsMI2Nui8huMPtnxg7krajPJAjnEG/iiOS7i+zCtWGZR9G0NBKbXKh6X9m9UIsYX/N6vvQ==
  dependencies:
    reusify "^1.0.4"

figures@^6.1.0:
  version "6.1.0"
  resolved "https://registry.npmjs.org/figures/-/figures-6.1.0.tgz"
  integrity sha512-d+l3qxjSesT4V7v2fh+QnmFnUWv9lSpjarhShNTgBOfA0ttejbQUAlHLitbjkoRiDulW0OPoQPYIGhIC8ohejg==
  dependencies:
    is-unicode-supported "^2.0.0"

fill-range@^7.1.1:
  version "7.1.1"
  resolved "https://registry.npmjs.org/fill-range/-/fill-range-7.1.1.tgz"
  integrity sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==
  dependencies:
    to-regex-range "^5.0.1"

find-up@^4.1.0:
  version "4.1.0"
  resolved "https://registry.npmjs.org/find-up/-/find-up-4.1.0.tgz"
  integrity sha512-PpOwAdQ/YlXQ2vj8a3h8IipDuYRi3wceVQQGYWxNINccq40Anw7BlsEXCMbt1Zt+OLA6Fq9suIpIWD0OsnISlw==
  dependencies:
    locate-path "^5.0.0"
    path-exists "^4.0.0"

follow-redirects@^1.15.6:
  version "1.15.9"
  resolved "https://registry.npmjs.org/follow-redirects/-/follow-redirects-1.15.9.tgz"
  integrity sha512-gew4GsXizNgdoRyqmyfMHyAmXsZDk6mHkSxZFCzW9gwlbtOW44CDtYavM+y+72qD/Vq2l550kMF52DT8fOLJqQ==

foreground-child@^3.1.0:
  version "3.3.1"
  resolved "https://registry.npmjs.org/foreground-child/-/foreground-child-3.3.1.tgz"
  integrity sha512-gIXjKqtFuWEgzFRJA9WCQeSJLZDjgJUOMCMzxtvFq/37KojM1BFGufqsCy0r4qSQmYLsZYMeyRqzIWOMup03sw==
  dependencies:
    cross-spawn "^7.0.6"
    signal-exit "^4.0.1"

form-data@^4.0.0:
  version "4.0.2"
  resolved "https://registry.npmjs.org/form-data/-/form-data-4.0.2.tgz"
  integrity sha512-hGfm/slu0ZabnNt4oaRZ6uREyfCj6P4fT/n6A1rGV+Z0VdGXjfOhVUpkn6qVQONHGIFwmveGXyDs75+nr6FM8w==
  dependencies:
    asynckit "^0.4.0"
    combined-stream "^1.0.8"
    es-set-tostringtag "^2.1.0"
    mime-types "^2.1.12"

fraction.js@^4.3.7:
  version "4.3.7"
  resolved "https://registry.npmjs.org/fraction.js/-/fraction.js-4.3.7.tgz"
  integrity sha512-ZsDfxO51wGAXREY55a7la9LScWpwv9RxIrYABrlvOFBlH/ShPnrtsXeuUIfXKKOVicNxQ+o8JTbJvjS4M89yew==

fs-extra@^11.2.0:
  version "11.3.0"
  resolved "https://registry.npmjs.org/fs-extra/-/fs-extra-11.3.0.tgz"
  integrity sha512-Z4XaCL6dUDHfP/jT25jJKMmtxvuwbkrD1vNSMFlo9lNLY2c5FHYSQgHPRZUjAB26TpDEoW9HCOgplrdbaPV/ew==
  dependencies:
    graceful-fs "^4.2.0"
    jsonfile "^6.0.1"
    universalify "^2.0.0"

fsevents@~2.3.2, fsevents@~2.3.3:
  version "2.3.3"
  resolved "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz"
  integrity sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==

function-bind@^1.1.2:
  version "1.1.2"
  resolved "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz"
  integrity sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==

gensync@^1.0.0-beta.2:
  version "1.0.0-beta.2"
  resolved "https://registry.npmjs.org/gensync/-/gensync-1.0.0-beta.2.tgz"
  integrity sha512-3hN7NaskYvMDLQY55gnW3NQ+mesEAepTqlg+VEbj7zzqEMBVNhzcGYYeqFo/TlYz6eQiFcp1HcsCZO+nGgS8zg==

get-caller-file@^2.0.1:
  version "2.0.5"
  resolved "https://registry.npmjs.org/get-caller-file/-/get-caller-file-2.0.5.tgz"
  integrity sha512-DyFP3BM/3YHTQOCUL/w0OZHR0lpKeGrxotcHWcqNEdnltqFwXVfhEBQ94eIo34AfQpo0rGki4cyIiftY06h2Fg==

get-intrinsic@^1.2.6:
  version "1.3.0"
  resolved "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz"
  integrity sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==
  dependencies:
    call-bind-apply-helpers "^1.0.2"
    es-define-property "^1.0.1"
    es-errors "^1.3.0"
    es-object-atoms "^1.1.1"
    function-bind "^1.1.2"
    get-proto "^1.0.1"
    gopd "^1.2.0"
    has-symbols "^1.1.0"
    hasown "^2.0.2"
    math-intrinsics "^1.1.0"

get-proto@^1.0.1:
  version "1.0.1"
  resolved "https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz"
  integrity sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==
  dependencies:
    dunder-proto "^1.0.1"
    es-object-atoms "^1.0.0"

get-stdin@8.0.0:
  version "8.0.0"
  resolved "https://registry.npmjs.org/get-stdin/-/get-stdin-8.0.0.tgz"
  integrity sha512-sY22aA6xchAzprjyqmSEQv4UbAAzRN0L2dQB0NlN5acTTK9Don6nhoc3eAbUnpZiCANAMfd/+40kVdKfFygohg==

get-stream@^9.0.0:
  version "9.0.1"
  resolved "https://registry.npmjs.org/get-stream/-/get-stream-9.0.1.tgz"
  integrity sha512-kVCxPF3vQM/N0B1PmoqVUqgHP+EeVjmZSQn+1oCRPxd2P21P2F19lIgbR3HBosbB1PUhOAoctJnfEn2GbN2eZA==
  dependencies:
    "@sec-ant/readable-stream" "^0.4.1"
    is-stream "^4.0.1"

glob-parent@^5.1.2, glob-parent@~5.1.2:
  version "5.1.2"
  resolved "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz"
  integrity sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==
  dependencies:
    is-glob "^4.0.1"

glob-parent@^6.0.2:
  version "6.0.2"
  resolved "https://registry.npmjs.org/glob-parent/-/glob-parent-6.0.2.tgz"
  integrity sha512-XxwI8EOhVQgWp6iDL+3b0r86f4d6AX6zSU55HfB4ydCEuXLXc5FcYeOu+nnGftS4TEju/11rt4KJPTMgbfmv4A==
  dependencies:
    is-glob "^4.0.3"

glob@^10.3.10:
  version "10.4.5"
  resolved "https://registry.npmjs.org/glob/-/glob-10.4.5.tgz"
  integrity sha512-7Bv8RF0k6xjo7d4A/PxYLbUCfb6c+Vpd2/mB2yRDlew7Jb5hEXiCD9ibfO7wpk8i4sevK6DFny9h7EYbM3/sHg==
  dependencies:
    foreground-child "^3.1.0"
    jackspeak "^3.1.2"
    minimatch "^9.0.4"
    minipass "^7.1.2"
    package-json-from-dist "^1.0.0"
    path-scurry "^1.11.1"

globals@^11.1.0:
  version "11.12.0"
  resolved "https://registry.npmjs.org/globals/-/globals-11.12.0.tgz"
  integrity sha512-WOBp/EEGUiIsJSp7wcv/y6MO+lV9UoncWqxuFfm8eBwzWNgyfBd6Gz+IeKQ9jCmyhoH99g15M3T+QaVHFjizVA==

gopd@^1.2.0:
  version "1.2.0"
  resolved "https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz"
  integrity sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==

graceful-fs@^4.1.6, graceful-fs@^4.2.0:
  version "4.2.11"
  resolved "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz"
  integrity sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==

has-symbols@^1.0.3, has-symbols@^1.1.0:
  version "1.1.0"
  resolved "https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz"
  integrity sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==

has-tostringtag@^1.0.2:
  version "1.0.2"
  resolved "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.2.tgz"
  integrity sha512-NqADB8VjPFLM2V0VvHUewwwsw0ZWBaIdgo+ieHtK3hasLz4qeCRjYcqfB6AQrBggRKppKF8L52/VqdVsO47Dlw==
  dependencies:
    has-symbols "^1.0.3"

hasown@^2.0.2:
  version "2.0.2"
  resolved "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz"
  integrity sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==
  dependencies:
    function-bind "^1.1.2"

he@^1.2.0:
  version "1.2.0"
  resolved "https://registry.npmjs.org/he/-/he-1.2.0.tgz"
  integrity sha512-F/1DnUGPopORZi0ni+CvrCgHQ5FyEAHRLSApuYWMmrbSwoN2Mn/7k+Gl38gJnR7yyDZk6WLXwiGod1JOWNDKGw==

hookable@^5.5.3:
  version "5.5.3"
  resolved "https://registry.npmjs.org/hookable/-/hookable-5.5.3.tgz"
  integrity sha512-Yc+BQe8SvoXH1643Qez1zqLRmbA5rCL+sSmk6TVos0LWVfNIB7PGncdlId77WzLGSIB5KaWgTaNTs2lNVEI6VQ==

human-signals@^8.0.0:
  version "8.0.1"
  resolved "https://registry.npmjs.org/human-signals/-/human-signals-8.0.1.tgz"
  integrity sha512-eKCa6bwnJhvxj14kZk5NCPc6Hb6BdsU9DZcOnmQKSnO1VKrfV0zCvtttPZUsBvjmNDn8rpcJfpwSYnHBjc95MQ==

is-binary-path@~2.1.0:
  version "2.1.0"
  resolved "https://registry.npmjs.org/is-binary-path/-/is-binary-path-2.1.0.tgz"
  integrity sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==
  dependencies:
    binary-extensions "^2.0.0"

is-core-module@^2.16.0:
  version "2.16.1"
  resolved "https://registry.npmjs.org/is-core-module/-/is-core-module-2.16.1.tgz"
  integrity sha512-UfoeMA6fIJ8wTYFEUjelnaGI67v6+N7qXJEvQuIGa99l4xsCruSYOVSQ0uPANn4dAzm8lkYPaKLrrijLq7x23w==
  dependencies:
    hasown "^2.0.2"

is-docker@^3.0.0:
  version "3.0.0"
  resolved "https://registry.npmjs.org/is-docker/-/is-docker-3.0.0.tgz"
  integrity sha512-eljcgEDlEns/7AXFosB5K/2nCM4P7FQPkGc/DWLy5rmFEWvZayGrik1d9/QIY5nJ4f9YsVvBkA6kJpHn9rISdQ==

is-extglob@^2.1.1:
  version "2.1.1"
  resolved "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz"
  integrity sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==

is-fullwidth-code-point@^2.0.0:
  version "2.0.0"
  resolved "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-2.0.0.tgz"
  integrity sha512-VHskAKYM8RfSFXwee5t5cbN5PZeq1Wrh6qd5bkyiXIf6UQcN6w/A0eXM9r6t8d+GYOh+o6ZhiEnb88LN/Y8m2w==

is-fullwidth-code-point@^3.0.0:
  version "3.0.0"
  resolved "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz"
  integrity sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==

is-glob@^4.0.1, is-glob@^4.0.3, is-glob@~4.0.1:
  version "4.0.3"
  resolved "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz"
  integrity sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==
  dependencies:
    is-extglob "^2.1.1"

is-inside-container@^1.0.0:
  version "1.0.0"
  resolved "https://registry.npmjs.org/is-inside-container/-/is-inside-container-1.0.0.tgz"
  integrity sha512-KIYLCCJghfHZxqjYBE7rEy0OBuTd5xCHS7tHVgvCLkx7StIoaxwNW3hCALgEUjFfeRk+MG/Qxmp/vtETEF3tRA==
  dependencies:
    is-docker "^3.0.0"

is-number@^7.0.0:
  version "7.0.0"
  resolved "https://registry.npmjs.org/is-number/-/is-number-7.0.0.tgz"
  integrity sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==

is-plain-obj@^4.1.0:
  version "4.1.0"
  resolved "https://registry.npmjs.org/is-plain-obj/-/is-plain-obj-4.1.0.tgz"
  integrity sha512-+Pgi+vMuUNkJyExiMBt5IlFoMyKnr5zhJ4Uspz58WOhBF5QoIZkFyNHIbBAtHwzVAgk5RtndVNsDRN61/mmDqg==

is-stream@^4.0.1:
  version "4.0.1"
  resolved "https://registry.npmjs.org/is-stream/-/is-stream-4.0.1.tgz"
  integrity sha512-Dnz92NInDqYckGEUJv689RbRiTSEHCQ7wOVeALbkOz999YpqT46yMRIGtSNl2iCL1waAZSx40+h59NV/EwzV/A==

is-unicode-supported@^2.0.0:
  version "2.1.0"
  resolved "https://registry.npmjs.org/is-unicode-supported/-/is-unicode-supported-2.1.0.tgz"
  integrity sha512-mE00Gnza5EEB3Ds0HfMyllZzbBrmLOX3vfWoj9A9PEnTfratQ/BcaJOuMhnkhjXvb2+FkY3VuHqtAGpTPmglFQ==

is-what@^4.1.8:
  version "4.1.16"
  resolved "https://registry.npmjs.org/is-what/-/is-what-4.1.16.tgz"
  integrity sha512-ZhMwEosbFJkA0YhFnNDgTM4ZxDRsS6HqTo7qsZM08fehyRYIYa0yHu5R6mgo1n/8MgaPBXiPimPD77baVFYg+A==

is-wsl@^3.1.0:
  version "3.1.0"
  resolved "https://registry.npmjs.org/is-wsl/-/is-wsl-3.1.0.tgz"
  integrity sha512-UcVfVfaK4Sc4m7X3dUSoHoozQGBEFeDC+zVo06t98xe8CzHSZZBekNXH+tu0NalHolcJ/QAGqS46Hef7QXBIMw==
  dependencies:
    is-inside-container "^1.0.0"

isexe@^2.0.0:
  version "2.0.0"
  resolved "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz"
  integrity sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==

isexe@^3.1.1:
  version "3.1.1"
  resolved "https://registry.npmjs.org/isexe/-/isexe-3.1.1.tgz"
  integrity sha512-LpB/54B+/2J5hqQ7imZHfdU31OlgQqx7ZicVlkm9kzg9/w8GKLEcFfJl/t7DCEDueOyBAD6zCCwTO6Fzs0NoEQ==

jackspeak@^3.1.2:
  version "3.4.3"
  resolved "https://registry.npmjs.org/jackspeak/-/jackspeak-3.4.3.tgz"
  integrity sha512-OGlZQpz2yfahA/Rd1Y8Cd9SIEsqvXkLVoSw/cgwhnhFMDbsQFeZYoJJ7bIZBS9BcamUW96asq/npPWugM+RQBw==
  dependencies:
    "@isaacs/cliui" "^8.0.2"
  optionalDependencies:
    "@pkgjs/parseargs" "^0.11.0"

jiti@^1.21.6, jiti@>=1.21.0:
  version "1.21.7"
  resolved "https://registry.npmjs.org/jiti/-/jiti-1.21.7.tgz"
  integrity sha512-/imKNG4EbWNrVjoNC/1H5/9GFy+tqjGBHCaSsN+P2RnPqjsLmv6UD3Ej+Kj8nBWaRAwyk7kK5ZUc+OEatnTR3A==

js-tokens@^4.0.0:
  version "4.0.0"
  resolved "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz"
  integrity sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==

jsesc@^3.0.2:
  version "3.1.0"
  resolved "https://registry.npmjs.org/jsesc/-/jsesc-3.1.0.tgz"
  integrity sha512-/sM3dO2FOzXjKQhJuo0Q173wf2KOo8t4I8vHy6lF9poUp7bKT0/NHE8fPX23PwfhnykfqnC2xRxOnVw5XuGIaA==

json-parse-even-better-errors@^4.0.0:
  version "4.0.0"
  resolved "https://registry.npmjs.org/json-parse-even-better-errors/-/json-parse-even-better-errors-4.0.0.tgz"
  integrity sha512-lR4MXjGNgkJc7tkQ97kb2nuEMnNCyU//XYVH0MKTGcXEiSudQ5MKGKen3C5QubYy0vmq+JGitUg92uuywGEwIA==

json5@^2.2.3:
  version "2.2.3"
  resolved "https://registry.npmjs.org/json5/-/json5-2.2.3.tgz"
  integrity sha512-XmOWe7eyHYH14cLdVPoyg+GOH3rYX++KpzrylJwSW98t3Nk+U8XOl8FWKOgwtzdb8lXGf6zYwDUzeHMWfxasyg==

jsonfile@^6.0.1:
  version "6.1.0"
  resolved "https://registry.npmjs.org/jsonfile/-/jsonfile-6.1.0.tgz"
  integrity sha512-5dgndWOriYSm5cnYaJNhalLNDKOqFwyDB/rr1E9ZsGciGvKPs8R2xYGCacuf3z6K1YKDz182fd+fY3cn3pMqXQ==
  dependencies:
    universalify "^2.0.0"
  optionalDependencies:
    graceful-fs "^4.1.6"

kolorist@^1.8.0:
  version "1.8.0"
  resolved "https://registry.npmjs.org/kolorist/-/kolorist-1.8.0.tgz"
  integrity sha512-Y+60/zizpJ3HRH8DCss+q95yr6145JXZo46OTpFvDZWLfRCE4qChOyk1b26nMaNpfHHgxagk9dXT5OP0Tfe+dQ==

lilconfig@^3.0.0, lilconfig@^3.1.3:
  version "3.1.3"
  resolved "https://registry.npmjs.org/lilconfig/-/lilconfig-3.1.3.tgz"
  integrity sha512-/vlFKAoH5Cgt3Ie+JLhRbwOsCQePABiU3tJ1egGvyQ+33R/vcwM2Zl2QR/LzjsBeItPt3oSVXapn+m4nQDvpzw==

lines-and-columns@^1.1.6:
  version "1.2.4"
  resolved "https://registry.npmjs.org/lines-and-columns/-/lines-and-columns-1.2.4.tgz"
  integrity sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==

locate-path@^5.0.0:
  version "5.0.0"
  resolved "https://registry.npmjs.org/locate-path/-/locate-path-5.0.0.tgz"
  integrity sha512-t7hw9pI+WvuwNJXwk5zVHpyhIqzg2qTlklJOf0mVxGSbe3Fp2VieZcduNYjaLDoy6p9uGpQEGWG87WpMKlNq8g==
  dependencies:
    p-locate "^4.1.0"

lru-cache@^10.2.0:
  version "10.4.3"
  resolved "https://registry.npmjs.org/lru-cache/-/lru-cache-10.4.3.tgz"
  integrity sha512-JNAzZcXrCt42VGLuYz0zfAzDfAvJWW6AfYlDBQyDV5DClI2m5sAmK+OIO7s59XfsRsWHp02jAJrRadPRGTt6SQ==

lru-cache@^5.1.1:
  version "5.1.1"
  resolved "https://registry.npmjs.org/lru-cache/-/lru-cache-5.1.1.tgz"
  integrity sha512-KpNARQA3Iwv+jTA0utUVVbrh+Jlrr1Fv0e56GGzAFOXN7dk/FviaDW8LHmK52DlcH4WP2n6gI8vN1aesBFgo9w==
  dependencies:
    yallist "^3.0.2"

magic-string@^0.30.11, magic-string@^0.30.4:
  version "0.30.17"
  resolved "https://registry.npmjs.org/magic-string/-/magic-string-0.30.17.tgz"
  integrity sha512-sNPKHvyjVf7gyjwS4xGTaW/mCnF8wnjtifKBEhxfZ7E/S8tQ0rssrwGNn6q8JH/ohItJfSQp9mBtQYuTlH5QnA==
  dependencies:
    "@jridgewell/sourcemap-codec" "^1.5.0"

math-intrinsics@^1.1.0:
  version "1.1.0"
  resolved "https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz"
  integrity sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==

memorystream@^0.3.1:
  version "0.3.1"
  resolved "https://registry.npmjs.org/memorystream/-/memorystream-0.3.1.tgz"
  integrity sha512-S3UwM3yj5mtUSEfP41UZmt/0SCoVYUcU1rkXv+BQ5Ig8ndL4sPoJNBUJERafdPb5jjHJGuMgytgKvKIf58XNBw==

merge2@^1.3.0:
  version "1.4.1"
  resolved "https://registry.npmjs.org/merge2/-/merge2-1.4.1.tgz"
  integrity sha512-8q7VEgMJW4J8tcfVPy8g09NcQwZdbwFEqhe/WZkoIzjn/3TGDwtOCYtXGxA3O8tPzpczCCDgv+P2P5y00ZJOOg==

micromatch@^4.0.8:
  version "4.0.8"
  resolved "https://registry.npmjs.org/micromatch/-/micromatch-4.0.8.tgz"
  integrity sha512-PXwfBhYu0hBCPw8Dn0E+WDYb7af3dSLVWKi3HGv84IdF4TyFoC0ysxFd0Goxw7nSv4T/PzEJQxsYsEiFCKo2BA==
  dependencies:
    braces "^3.0.3"
    picomatch "^2.3.1"

mime-db@1.52.0:
  version "1.52.0"
  resolved "https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz"
  integrity sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==

mime-types@^2.1.12:
  version "2.1.35"
  resolved "https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz"
  integrity sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==
  dependencies:
    mime-db "1.52.0"

minimatch@^9.0.0, minimatch@^9.0.3, minimatch@^9.0.4:
  version "9.0.5"
  resolved "https://registry.npmjs.org/minimatch/-/minimatch-9.0.5.tgz"
  integrity sha512-G6T0ZX48xgozx7587koeX9Ys2NYy6Gmv//P89sEte9V9whIapMNF4idKxnW2QtCcLiTWlb/wfCabAtAFWhhBow==
  dependencies:
    brace-expansion "^2.0.1"

"minipass@^5.0.0 || ^6.0.2 || ^7.0.0", minipass@^7.1.2:
  version "7.1.2"
  resolved "https://registry.npmjs.org/minipass/-/minipass-7.1.2.tgz"
  integrity sha512-qOOzS1cBTWYF4BH8fVePDBOO9iptMnGUEZwNc/cMWnTV2nVLZ7VoNWEPHkYczZA0pdoA7dl6e7FL659nX9S2aw==

mitt@^3.0.1:
  version "3.0.1"
  resolved "https://registry.npmjs.org/mitt/-/mitt-3.0.1.tgz"
  integrity sha512-vKivATfr97l2/QBCYAkXYDbrIWPM2IIKEl7YPhjCvKlG3kE2gm+uBo6nEXK3M5/Ffh/FLpKExzOQ3JJoJGFKBw==

mrmime@^2.0.0:
  version "2.0.1"
  resolved "https://registry.npmjs.org/mrmime/-/mrmime-2.0.1.tgz"
  integrity sha512-Y3wQdFg2Va6etvQ5I82yUhGdsKrcYox6p7FfL1LbK2J4V01F9TGlepTIhnK24t7koZibmg82KGglhA1XK5IsLQ==

ms@^2.1.3:
  version "2.1.3"
  resolved "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz"
  integrity sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==

muggle-string@^0.4.1:
  version "0.4.1"
  resolved "https://registry.npmjs.org/muggle-string/-/muggle-string-0.4.1.tgz"
  integrity sha512-VNTrAak/KhO2i8dqqnqnAHOa3cYBwXEZe9h+D5h/1ZqFSTEFHdM65lR7RoIqq3tBBYavsOXV84NoHXZ0AkPyqQ==

mz@^2.7.0:
  version "2.7.0"
  resolved "https://registry.npmjs.org/mz/-/mz-2.7.0.tgz"
  integrity sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==
  dependencies:
    any-promise "^1.0.0"
    object-assign "^4.0.1"
    thenify-all "^1.0.0"

nanoid@^3.3.8:
  version "3.3.11"
  resolved "https://registry.npmjs.org/nanoid/-/nanoid-3.3.11.tgz"
  integrity sha512-N8SpfPUnUp1bK+PMYW8qSWdl9U+wwNWI4QKxOYDy9JAro3WMX7p2OeVRF9v+347pnakNevPmiHhNmZ2HbFA76w==

nanoid@^5.0.9:
  version "5.1.5"
  resolved "https://registry.npmjs.org/nanoid/-/nanoid-5.1.5.tgz"
  integrity sha512-Ir/+ZpE9fDsNH0hQ3C68uyThDXzYcim2EqcZ8zn8Chtt1iylPT9xXJB0kPCnqzgcEGikO9RxSrh63MsmVCU7Fw==

node-releases@^2.0.19:
  version "2.0.19"
  resolved "https://registry.npmjs.org/node-releases/-/node-releases-2.0.19.tgz"
  integrity sha512-xxOWJsBKtzAq7DY0J+DTzuz58K8e7sJbdgwkbMWQe8UYB6ekmsQ45q0M/tJDsGaZmbC+l7n57UV8Hl5tHxO9uw==

normalize-path@^3.0.0, normalize-path@~3.0.0:
  version "3.0.0"
  resolved "https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz"
  integrity sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==

normalize-range@^0.1.2:
  version "0.1.2"
  resolved "https://registry.npmjs.org/normalize-range/-/normalize-range-0.1.2.tgz"
  integrity sha512-bdok/XvKII3nUpklnV6P2hxtMNrCboOjAcyBuQnWEhO665FwrSNRxU+AqpsyvO6LgGYPspN+lu5CLtw4jPRKNA==

npm-normalize-package-bin@^4.0.0:
  version "4.0.0"
  resolved "https://registry.npmjs.org/npm-normalize-package-bin/-/npm-normalize-package-bin-4.0.0.tgz"
  integrity sha512-TZKxPvItzai9kN9H/TkmCtx/ZN/hvr3vUycjlfmH0ootY9yFBzNOpiXAdIn1Iteqsvk4lQn6B5PTrt+n6h8k/w==

npm-run-all2@^7.0.2:
  version "7.0.2"
  resolved "https://registry.npmjs.org/npm-run-all2/-/npm-run-all2-7.0.2.tgz"
  integrity sha512-7tXR+r9hzRNOPNTvXegM+QzCuMjzUIIq66VDunL6j60O4RrExx32XUhlrS7UK4VcdGw5/Wxzb3kfNcFix9JKDA==
  dependencies:
    ansi-styles "^6.2.1"
    cross-spawn "^7.0.6"
    memorystream "^0.3.1"
    minimatch "^9.0.0"
    pidtree "^0.6.0"
    read-package-json-fast "^4.0.0"
    shell-quote "^1.7.3"
    which "^5.0.0"

npm-run-path@^6.0.0:
  version "6.0.0"
  resolved "https://registry.npmjs.org/npm-run-path/-/npm-run-path-6.0.0.tgz"
  integrity sha512-9qny7Z9DsQU8Ou39ERsPU4OZQlSTP47ShQzuKZ6PRXpYLtIFgl/DEBYEXKlvcEa+9tHVcK8CF81Y2V72qaZhWA==
  dependencies:
    path-key "^4.0.0"
    unicorn-magic "^0.3.0"

object-assign@^4.0.1:
  version "4.1.1"
  resolved "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz"
  integrity sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==

object-hash@^3.0.0:
  version "3.0.0"
  resolved "https://registry.npmjs.org/object-hash/-/object-hash-3.0.0.tgz"
  integrity sha512-RSn9F68PjH9HqtltsSnqYC1XXoWe9Bju5+213R98cNGttag9q9yAOTzdbsqvIa7aNm5WffBZFpWYr2aWrklWAw==

open@^10.1.0:
  version "10.1.0"
  resolved "https://registry.npmjs.org/open/-/open-10.1.0.tgz"
  integrity sha512-mnkeQ1qP5Ue2wd+aivTD3NHd/lZ96Lu0jgf0pwktLPtx6cTZiH7tyeGRRHs0zX0rbrahXPnXlUnbeXyaBBuIaw==
  dependencies:
    default-browser "^5.2.1"
    define-lazy-prop "^3.0.0"
    is-inside-container "^1.0.0"
    is-wsl "^3.1.0"

p-limit@^2.2.0:
  version "2.3.0"
  resolved "https://registry.npmjs.org/p-limit/-/p-limit-2.3.0.tgz"
  integrity sha512-//88mFWSJx8lxCzwdAABTJL2MyWB12+eIY7MDL2SqLmAkeKU9qxRvWuSyTjm3FUmpBEMuFfckAIqEaVGUDxb6w==
  dependencies:
    p-try "^2.0.0"

p-locate@^4.1.0:
  version "4.1.0"
  resolved "https://registry.npmjs.org/p-locate/-/p-locate-4.1.0.tgz"
  integrity sha512-R79ZZ/0wAxKGu3oYMlz8jy/kbhsNrS7SKZ7PxEHBgJ5+F2mtFW2fK2cOtBh1cHYkQsbzFV7I+EoRKe6Yt0oK7A==
  dependencies:
    p-limit "^2.2.0"

p-try@^2.0.0:
  version "2.2.0"
  resolved "https://registry.npmjs.org/p-try/-/p-try-2.2.0.tgz"
  integrity sha512-R4nPAVTAU0B9D35/Gk3uJf/7XYbQcyohSKdvAxIRSNghFl4e71hVoGnBNQz9cWaXxO2I10KTC+3jMdvvoKw6dQ==

package-json-from-dist@^1.0.0:
  version "1.0.1"
  resolved "https://registry.npmjs.org/package-json-from-dist/-/package-json-from-dist-1.0.1.tgz"
  integrity sha512-UEZIS3/by4OC8vL3P2dTXRETpebLI2NiI5vIrjaD/5UtrkFX/tNbwjTSRAGC/+7CAo2pIcBaRgWmcBBHcsaCIw==

parse-ms@^4.0.0:
  version "4.0.0"
  resolved "https://registry.npmjs.org/parse-ms/-/parse-ms-4.0.0.tgz"
  integrity sha512-TXfryirbmq34y8QBwgqCVLi+8oA3oWx2eAnSn62ITyEhEYaWRlVZ2DvMM9eZbMs/RfxPu/PK/aBLyGj4IrqMHw==

path-browserify@^1.0.1:
  version "1.0.1"
  resolved "https://registry.npmjs.org/path-browserify/-/path-browserify-1.0.1.tgz"
  integrity sha512-b7uo2UCUOYZcnF/3ID0lulOJi/bafxa1xPe7ZPsammBSpjSWQkjNxlt635YGS2MiR9GjvuXCtz2emr3jbsz98g==

path-exists@^4.0.0:
  version "4.0.0"
  resolved "https://registry.npmjs.org/path-exists/-/path-exists-4.0.0.tgz"
  integrity sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==

path-key@^3.1.0:
  version "3.1.1"
  resolved "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz"
  integrity sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==

path-key@^4.0.0:
  version "4.0.0"
  resolved "https://registry.npmjs.org/path-key/-/path-key-4.0.0.tgz"
  integrity sha512-haREypq7xkM7ErfgIyA0z+Bj4AGKlMSdlQE2jvJo6huWD1EdkKYV+G/T4nq0YEF2vgTT8kqMFKo1uHn950r4SQ==

path-parse@^1.0.7:
  version "1.0.7"
  resolved "https://registry.npmjs.org/path-parse/-/path-parse-1.0.7.tgz"
  integrity sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==

path-scurry@^1.11.1:
  version "1.11.1"
  resolved "https://registry.npmjs.org/path-scurry/-/path-scurry-1.11.1.tgz"
  integrity sha512-Xa4Nw17FS9ApQFJ9umLiJS4orGjm7ZzwUrwamcGQuHSzDyth9boKDaycYdDcZDuqYATXw4HFXgaqWTctW/v1HA==
  dependencies:
    lru-cache "^10.2.0"
    minipass "^5.0.0 || ^6.0.2 || ^7.0.0"

pathe@^2.0.2:
  version "2.0.3"
  resolved "https://registry.npmjs.org/pathe/-/pathe-2.0.3.tgz"
  integrity sha512-WUjGcAqP1gQacoQe+OBJsFA7Ld4DyXuUIjZ5cc75cLHvJ7dtNsTugphxIADwspS+AraAUePCKrSVtPLFj/F88w==

perfect-debounce@^1.0.0:
  version "1.0.0"
  resolved "https://registry.npmjs.org/perfect-debounce/-/perfect-debounce-1.0.0.tgz"
  integrity sha512-xCy9V055GLEqoFaHoC1SoLIaLmWctgCUaBaWxDZ7/Zx4CTyX7cJQLJOok/orfjZAh9kEYpjJa4d0KcJmCbctZA==

picocolors@^1.0.0, picocolors@^1.1.1:
  version "1.1.1"
  resolved "https://registry.npmjs.org/picocolors/-/picocolors-1.1.1.tgz"
  integrity sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==

picomatch@^2.0.4, picomatch@^2.2.1, picomatch@^2.3.1:
  version "2.3.1"
  resolved "https://registry.npmjs.org/picomatch/-/picomatch-2.3.1.tgz"
  integrity sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==

picomatch@^4.0.2:
  version "4.0.2"
  resolved "https://registry.npmjs.org/picomatch/-/picomatch-4.0.2.tgz"
  integrity sha512-M7BAV6Rlcy5u+m6oPhAPFgJTzAioX/6B0DxyvDlo9l8+T3nLKbrczg2WLUyzd45L8RqfUMyGPzekbMvX2Ldkwg==

pidtree@^0.6.0:
  version "0.6.0"
  resolved "https://registry.npmjs.org/pidtree/-/pidtree-0.6.0.tgz"
  integrity sha512-eG2dWTVw5bzqGRztnHExczNxt5VGsE6OwTeCG3fdUf9KBsZzO3R5OIIIzWR+iZA0NtZ+RDVdaoE2dK1cn6jH4g==

pify@^2.3.0:
  version "2.3.0"
  resolved "https://registry.npmjs.org/pify/-/pify-2.3.0.tgz"
  integrity sha512-udgsAY+fTnvv7kI7aaxbqwWNb0AHiB0qBO89PZKPkoTmGOgdbrHDKD+0B2X4uTfJ/FT1R09r9gTsjUjNJotuog==

pinia@^3.0.1:
  version "3.0.1"
  resolved "https://registry.npmjs.org/pinia/-/pinia-3.0.1.tgz"
  integrity sha512-WXglsDzztOTH6IfcJ99ltYZin2mY8XZCXujkYWVIJlBjqsP6ST7zw+Aarh63E1cDVYeyUcPCxPHzJpEOmzB6Wg==
  dependencies:
    "@vue/devtools-api" "^7.7.2"

pirates@^4.0.1:
  version "4.0.7"
  resolved "https://registry.npmjs.org/pirates/-/pirates-4.0.7.tgz"
  integrity sha512-TfySrs/5nm8fQJDcBDuUng3VOUKsd7S+zqvbOTiGXHfxX4wK31ard+hoNuvkicM/2YFzlpDgABOevKSsB4G/FA==

postcss-import@^15.1.0:
  version "15.1.0"
  resolved "https://registry.npmjs.org/postcss-import/-/postcss-import-15.1.0.tgz"
  integrity sha512-hpr+J05B2FVYUAXHeK1YyI267J/dDDhMU6B6civm8hSY1jYJnBXxzKDKDswzJmtLHryrjhnDjqqp/49t8FALew==
  dependencies:
    postcss-value-parser "^4.0.0"
    read-cache "^1.0.0"
    resolve "^1.1.7"

postcss-js@^4.0.1:
  version "4.0.1"
  resolved "https://registry.npmjs.org/postcss-js/-/postcss-js-4.0.1.tgz"
  integrity sha512-dDLF8pEO191hJMtlHFPRa8xsizHaM82MLfNkUHdUtVEV3tgTp5oj+8qbEqYM57SLfc74KSbw//4SeJma2LRVIw==
  dependencies:
    camelcase-css "^2.0.1"

postcss-load-config@^4.0.2:
  version "4.0.2"
  resolved "https://registry.npmjs.org/postcss-load-config/-/postcss-load-config-4.0.2.tgz"
  integrity sha512-bSVhyJGL00wMVoPUzAVAnbEoWyqRxkjv64tUl427SKnPrENtq6hJwUojroMz2VB+Q1edmi4IfrAPpami5VVgMQ==
  dependencies:
    lilconfig "^3.0.0"
    yaml "^2.3.4"

postcss-nested@^6.2.0:
  version "6.2.0"
  resolved "https://registry.npmjs.org/postcss-nested/-/postcss-nested-6.2.0.tgz"
  integrity sha512-HQbt28KulC5AJzG+cZtj9kvKB93CFCdLvog1WFLf1D+xmMvPGlBstkpTEZfK5+AN9hfJocyBFCNiqyS48bpgzQ==
  dependencies:
    postcss-selector-parser "^6.1.1"

postcss-selector-parser@^6.1.1, postcss-selector-parser@^6.1.2:
  version "6.1.2"
  resolved "https://registry.npmjs.org/postcss-selector-parser/-/postcss-selector-parser-6.1.2.tgz"
  integrity sha512-Q8qQfPiZ+THO/3ZrOrO0cJJKfpYCagtMUkXbnEfmgUjwXg6z/WBeOyS9APBBPCTSiDV+s4SwQGu8yFsiMRIudg==
  dependencies:
    cssesc "^3.0.0"
    util-deprecate "^1.0.2"

postcss-value-parser@^4.0.0, postcss-value-parser@^4.2.0:
  version "4.2.0"
  resolved "https://registry.npmjs.org/postcss-value-parser/-/postcss-value-parser-4.2.0.tgz"
  integrity sha512-1NNCs6uurfkVbeXG4S8JFT9t19m45ICnif8zWLd5oPSZ50QnwMfK+H3jv408d4jw/7Bttv5axS5IiHoLaVNHeQ==

postcss@^8.0.0, postcss@^8.1.0, postcss@^8.2.14, postcss@^8.4.21, postcss@^8.4.47, postcss@^8.4.48, postcss@^8.5.3, postcss@>=8.0.9:
  version "8.5.3"
  resolved "https://registry.npmjs.org/postcss/-/postcss-8.5.3.tgz"
  integrity sha512-dle9A3yYxlBSrt8Fu+IpjGT8SY8hN0mlaA6GY8t0P5PjIOZemULz/E2Bnm/2dcUOena75OTNkHI76uZBNUUq3A==
  dependencies:
    nanoid "^3.3.8"
    picocolors "^1.1.1"
    source-map-js "^1.2.1"

pretty-ms@^9.0.0:
  version "9.2.0"
  resolved "https://registry.npmjs.org/pretty-ms/-/pretty-ms-9.2.0.tgz"
  integrity sha512-4yf0QO/sllf/1zbZWYnvWw3NxCQwLXKzIj0G849LSufP15BXKM0rbD2Z3wVnkMfjdn/CB0Dpp444gYAACdsplg==
  dependencies:
    parse-ms "^4.0.0"

proxy-from-env@^1.1.0:
  version "1.1.0"
  resolved "https://registry.npmjs.org/proxy-from-env/-/proxy-from-env-1.1.0.tgz"
  integrity sha512-D+zkORCbA9f1tdWRK0RaCR3GPv50cMxcrz4X8k5LTSUD1Dkw47mKJEZQNunItRTkWwgtaUSo1RVFRIG9ZXiFYg==

queue-microtask@^1.2.2:
  version "1.2.3"
  resolved "https://registry.npmjs.org/queue-microtask/-/queue-microtask-1.2.3.tgz"
  integrity sha512-NuaNSa6flKT5JaSYQzJok04JzTL1CA6aGhv5rfLW3PgqA+M2ChpZQnAC8h8i4ZFkBS8X5RqkDBHA7r4hej3K9A==

read-cache@^1.0.0:
  version "1.0.0"
  resolved "https://registry.npmjs.org/read-cache/-/read-cache-1.0.0.tgz"
  integrity sha512-Owdv/Ft7IjOgm/i0xvNDZ1LrRANRfew4b2prF3OWMQLxLfu3bS8FVhCsrSCMK4lR56Y9ya+AThoTpDCTxCmpRA==
  dependencies:
    pify "^2.3.0"

read-package-json-fast@^4.0.0:
  version "4.0.0"
  resolved "https://registry.npmjs.org/read-package-json-fast/-/read-package-json-fast-4.0.0.tgz"
  integrity sha512-qpt8EwugBWDw2cgE2W+/3oxC+KTez2uSVR8JU9Q36TXPAGCaozfQUs59v4j4GFpWTaw0i6hAZSvOmu1J0uOEUg==
  dependencies:
    json-parse-even-better-errors "^4.0.0"
    npm-normalize-package-bin "^4.0.0"

readdirp@~3.6.0:
  version "3.6.0"
  resolved "https://registry.npmjs.org/readdirp/-/readdirp-3.6.0.tgz"
  integrity sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==
  dependencies:
    picomatch "^2.2.1"

require-directory@^2.1.1:
  version "2.1.1"
  resolved "https://registry.npmjs.org/require-directory/-/require-directory-2.1.1.tgz"
  integrity sha512-fGxEI7+wsG9xrvdjsrlmL22OMTTiHRwAMroiEeMgq8gzoLC/PQr7RsRDSTLUg/bZAZtF+TVIkHc6/4RIKrui+Q==

require-main-filename@^2.0.0:
  version "2.0.0"
  resolved "https://registry.npmjs.org/require-main-filename/-/require-main-filename-2.0.0.tgz"
  integrity sha512-NKN5kMDylKuldxYLSUfrbo5Tuzh4hd+2E8NPPX02mZtn1VuREQToYe/ZdlJy+J3uCpfaiGF05e7B8W0iXbQHmg==

resolve@^1.1.7, resolve@^1.22.8:
  version "1.22.10"
  resolved "https://registry.npmjs.org/resolve/-/resolve-1.22.10.tgz"
  integrity sha512-NPRy+/ncIMeDlTAsuqwKIiferiawhefFJtkNSW0qZJEqMEb+qBt/77B/jGeeek+F0uOeN05CDa6HXbbIgtVX4w==
  dependencies:
    is-core-module "^2.16.0"
    path-parse "^1.0.7"
    supports-preserve-symlinks-flag "^1.0.0"

reusify@^1.0.4:
  version "1.1.0"
  resolved "https://registry.npmjs.org/reusify/-/reusify-1.1.0.tgz"
  integrity sha512-g6QUff04oZpHs0eG5p83rFLhHeV00ug/Yf9nZM6fLeUrPguBTkTQOdpAWWspMh55TZfVQDPaN3NQJfbVRAxdIw==

rfdc@^1.4.1:
  version "1.4.1"
  resolved "https://registry.npmjs.org/rfdc/-/rfdc-1.4.1.tgz"
  integrity sha512-q1b3N5QkRUWUl7iyylaaj3kOpIT0N2i9MqIEQXP73GVsN9cw3fdx8X63cEmWhJGi2PPCF23Ijp7ktmd39rawIA==

rollup@^1.20.0||^2.0.0||^3.0.0||^4.0.0, rollup@^4.30.1:
  version "4.38.0"
  resolved "https://registry.npmjs.org/rollup/-/rollup-4.38.0.tgz"
  integrity sha512-5SsIRtJy9bf1ErAOiFMFzl64Ex9X5V7bnJ+WlFMb+zmP459OSWCEG7b0ERZ+PEU7xPt4OG3RHbrp1LJlXxYTrw==
  dependencies:
    "@types/estree" "1.0.7"
  optionalDependencies:
    "@rollup/rollup-android-arm-eabi" "4.38.0"
    "@rollup/rollup-android-arm64" "4.38.0"
    "@rollup/rollup-darwin-arm64" "4.38.0"
    "@rollup/rollup-darwin-x64" "4.38.0"
    "@rollup/rollup-freebsd-arm64" "4.38.0"
    "@rollup/rollup-freebsd-x64" "4.38.0"
    "@rollup/rollup-linux-arm-gnueabihf" "4.38.0"
    "@rollup/rollup-linux-arm-musleabihf" "4.38.0"
    "@rollup/rollup-linux-arm64-gnu" "4.38.0"
    "@rollup/rollup-linux-arm64-musl" "4.38.0"
    "@rollup/rollup-linux-loongarch64-gnu" "4.38.0"
    "@rollup/rollup-linux-powerpc64le-gnu" "4.38.0"
    "@rollup/rollup-linux-riscv64-gnu" "4.38.0"
    "@rollup/rollup-linux-riscv64-musl" "4.38.0"
    "@rollup/rollup-linux-s390x-gnu" "4.38.0"
    "@rollup/rollup-linux-x64-gnu" "4.38.0"
    "@rollup/rollup-linux-x64-musl" "4.38.0"
    "@rollup/rollup-win32-arm64-msvc" "4.38.0"
    "@rollup/rollup-win32-ia32-msvc" "4.38.0"
    "@rollup/rollup-win32-x64-msvc" "4.38.0"
    fsevents "~2.3.2"

run-applescript@^7.0.0:
  version "7.0.0"
  resolved "https://registry.npmjs.org/run-applescript/-/run-applescript-7.0.0.tgz"
  integrity sha512-9by4Ij99JUr/MCFBUkDKLWK3G9HVXmabKz9U5MlIAIuvuzkiOicRYs8XJLxX+xahD+mLiiCYDqF9dKAgtzKP1A==

run-parallel@^1.1.9:
  version "1.2.0"
  resolved "https://registry.npmjs.org/run-parallel/-/run-parallel-1.2.0.tgz"
  integrity sha512-5l4VyZR86LZ/lDxZTR6jqL8AFE2S0IFLMP26AbjsLVADxHdhB/c0GUsH+y39UfCi3dzz8OlQuPmnaJOMoDHQBA==
  dependencies:
    queue-microtask "^1.2.2"

semver@^6.3.1:
  version "6.3.1"
  resolved "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz"
  integrity sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==

set-blocking@^2.0.0:
  version "2.0.0"
  resolved "https://registry.npmjs.org/set-blocking/-/set-blocking-2.0.0.tgz"
  integrity sha512-KiKBS8AnWGEyLzofFfmvKwpdPzqiy16LvQfK3yv/fVH7Bj13/wl3JSR1J+rfgRE9q7xUJK4qvgS8raSOeLUehw==

shebang-command@^2.0.0:
  version "2.0.0"
  resolved "https://registry.npmjs.org/shebang-command/-/shebang-command-2.0.0.tgz"
  integrity sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==
  dependencies:
    shebang-regex "^3.0.0"

shebang-regex@^3.0.0:
  version "3.0.0"
  resolved "https://registry.npmjs.org/shebang-regex/-/shebang-regex-3.0.0.tgz"
  integrity sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==

shell-quote@^1.7.3:
  version "1.8.2"
  resolved "https://registry.npmjs.org/shell-quote/-/shell-quote-1.8.2.tgz"
  integrity sha512-AzqKpGKjrj7EM6rKVQEPpB288oCfnrEIuyoT9cyF4nmGa7V8Zk6f7RRqYisX8X9m+Q7bd632aZW4ky7EhbQztA==

signal-exit@^4.0.1, signal-exit@^4.1.0:
  version "4.1.0"
  resolved "https://registry.npmjs.org/signal-exit/-/signal-exit-4.1.0.tgz"
  integrity sha512-bzyZ1e88w9O1iNJbKnOlvYTrWPDl46O1bG0D3XInv+9tkPrxrN8jUUTiFlDkkmKWgn1M6CfIA13SuGqOa9Korw==

sirv@^3.0.0:
  version "3.0.1"
  resolved "https://registry.npmjs.org/sirv/-/sirv-3.0.1.tgz"
  integrity sha512-FoqMu0NCGBLCcAkS1qA+XJIQTR6/JHfQXl+uGteNCQ76T91DMUjPa9xfmeqMY3z80nLSg9yQmNjK0Px6RWsH/A==
  dependencies:
    "@polka/url" "^1.0.0-next.24"
    mrmime "^2.0.0"
    totalist "^3.0.0"

source-map-js@^1.2.0, source-map-js@^1.2.1:
  version "1.2.1"
  resolved "https://registry.npmjs.org/source-map-js/-/source-map-js-1.2.1.tgz"
  integrity sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==

speakingurl@^14.0.1:
  version "14.0.1"
  resolved "https://registry.npmjs.org/speakingurl/-/speakingurl-14.0.1.tgz"
  integrity sha512-1POYv7uv2gXoyGFpBCmpDVSNV74IfsWlDW216UPjbWufNf+bSU6GdbDsxdcxtfwb4xlI3yxzOTKClUosxARYrQ==

"string-width-cjs@npm:string-width@^4.2.0":
  version "4.2.3"
  resolved "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz"
  integrity sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==
  dependencies:
    emoji-regex "^8.0.0"
    is-fullwidth-code-point "^3.0.0"
    strip-ansi "^6.0.1"

string-width@^4.1.0, string-width@^4.2.0:
  version "4.2.3"
  resolved "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz"
  integrity sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==
  dependencies:
    emoji-regex "^8.0.0"
    is-fullwidth-code-point "^3.0.0"
    strip-ansi "^6.0.1"

string-width@^5.0.1, string-width@^5.1.2:
  version "5.1.2"
  resolved "https://registry.npmjs.org/string-width/-/string-width-5.1.2.tgz"
  integrity sha512-HnLOCR3vjcY8beoNLtcjZ5/nxn2afmME6lhrDrebokqMap+XbeW8n9TXpPDOqdGK5qcI3oT0GKTW6wC7EMiVqA==
  dependencies:
    eastasianwidth "^0.2.0"
    emoji-regex "^9.2.2"
    strip-ansi "^7.0.1"

string-width@~2.1.1:
  version "2.1.1"
  resolved "https://registry.npmjs.org/string-width/-/string-width-2.1.1.tgz"
  integrity sha512-nOqH59deCq9SRHlxq1Aw85Jnt4w6KvLKqWVik6oA9ZklXLNIOlqg4F2yrT1MVaTjAqvVwdfeZ7w7aCvJD7ugkw==
  dependencies:
    is-fullwidth-code-point "^2.0.0"
    strip-ansi "^4.0.0"

"strip-ansi-cjs@npm:strip-ansi@^6.0.1":
  version "6.0.1"
  resolved "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz"
  integrity sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==
  dependencies:
    ansi-regex "^5.0.1"

strip-ansi@^4.0.0:
  version "4.0.0"
  resolved "https://registry.npmjs.org/strip-ansi/-/strip-ansi-4.0.0.tgz"
  integrity sha512-4XaJ2zQdCzROZDivEVIDPkcQn8LMFSa8kj8Gxb/Lnwzv9A8VctNZ+lfivC/sV3ivW8ElJTERXZoPBRrZKkNKow==
  dependencies:
    ansi-regex "^3.0.0"

strip-ansi@^6.0.0, strip-ansi@^6.0.1:
  version "6.0.1"
  resolved "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz"
  integrity sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==
  dependencies:
    ansi-regex "^5.0.1"

strip-ansi@^7.0.1:
  version "7.1.0"
  resolved "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz"
  integrity sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==
  dependencies:
    ansi-regex "^6.0.1"

strip-final-newline@^4.0.0:
  version "4.0.0"
  resolved "https://registry.npmjs.org/strip-final-newline/-/strip-final-newline-4.0.0.tgz"
  integrity sha512-aulFJcD6YK8V1G7iRB5tigAP4TsHBZZrOV8pjV++zdUwmeV8uzbY7yn6h9MswN62adStNZFuCIx4haBnRuMDaw==

strip-final-newline@2.0.0:
  version "2.0.0"
  resolved "https://registry.npmjs.org/strip-final-newline/-/strip-final-newline-2.0.0.tgz"
  integrity sha512-BrpvfNAE3dcvq7ll3xVumzjKjZQ5tI1sEUIKr3Uoks0XUl45St3FlatVqef9prk4jRDzhW6WZg+3bk93y6pLjA==

sucrase@^3.35.0:
  version "3.35.0"
  resolved "https://registry.npmjs.org/sucrase/-/sucrase-3.35.0.tgz"
  integrity sha512-8EbVDiu9iN/nESwxeSxDKe0dunta1GOlHufmSSXxMD2z2/tMZpDMpvXQGsc+ajGo8y2uYUmixaSRUc/QPoQ0GA==
  dependencies:
    "@jridgewell/gen-mapping" "^0.3.2"
    commander "^4.0.0"
    glob "^10.3.10"
    lines-and-columns "^1.1.6"
    mz "^2.7.0"
    pirates "^4.0.1"
    ts-interface-checker "^0.1.9"

superjson@^2.2.1:
  version "2.2.2"
  resolved "https://registry.npmjs.org/superjson/-/superjson-2.2.2.tgz"
  integrity sha512-5JRxVqC8I8NuOUjzBbvVJAKNM8qoVuH0O77h4WInc/qC2q5IreqKxYwgkga3PfA22OayK2ikceb/B26dztPl+Q==
  dependencies:
    copy-anything "^3.0.2"

supports-preserve-symlinks-flag@^1.0.0:
  version "1.0.0"
  resolved "https://registry.npmjs.org/supports-preserve-symlinks-flag/-/supports-preserve-symlinks-flag-1.0.0.tgz"
  integrity sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==

tailwindcss@^3.4.0:
  version "3.4.17"
  resolved "https://registry.npmjs.org/tailwindcss/-/tailwindcss-3.4.17.tgz"
  integrity sha512-w33E2aCvSDP0tW9RZuNXadXlkHXqFzSkQew/aIa2i/Sj8fThxwovwlXHSPXTbAHwEIhBFXAedUhP2tueAKP8Og==
  dependencies:
    "@alloc/quick-lru" "^5.2.0"
    arg "^5.0.2"
    chokidar "^3.6.0"
    didyoumean "^1.2.2"
    dlv "^1.1.3"
    fast-glob "^3.3.2"
    glob-parent "^6.0.2"
    is-glob "^4.0.3"
    jiti "^1.21.6"
    lilconfig "^3.1.3"
    micromatch "^4.0.8"
    normalize-path "^3.0.0"
    object-hash "^3.0.0"
    picocolors "^1.1.1"
    postcss "^8.4.47"
    postcss-import "^15.1.0"
    postcss-js "^4.0.1"
    postcss-load-config "^4.0.2"
    postcss-nested "^6.2.0"
    postcss-selector-parser "^6.1.2"
    resolve "^1.22.8"
    sucrase "^3.35.0"

thenify-all@^1.0.0:
  version "1.6.0"
  resolved "https://registry.npmjs.org/thenify-all/-/thenify-all-1.6.0.tgz"
  integrity sha512-RNxQH/qI8/t3thXJDwcstUO4zeqo64+Uy/+sNVRBx4Xn2OX+OZ9oP+iJnNFqplFra2ZUVeKCSa2oVWi3T4uVmA==
  dependencies:
    thenify ">= 3.1.0 < 4"

"thenify@>= 3.1.0 < 4":
  version "3.3.1"
  resolved "https://registry.npmjs.org/thenify/-/thenify-3.3.1.tgz"
  integrity sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==
  dependencies:
    any-promise "^1.0.0"

to-regex-range@^5.0.1:
  version "5.0.1"
  resolved "https://registry.npmjs.org/to-regex-range/-/to-regex-range-5.0.1.tgz"
  integrity sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==
  dependencies:
    is-number "^7.0.0"

totalist@^3.0.0:
  version "3.0.1"
  resolved "https://registry.npmjs.org/totalist/-/totalist-3.0.1.tgz"
  integrity sha512-sf4i37nQ2LBx4m3wB74y+ubopq6W/dIzXg0FDGjsYnZHVa1Da8FH853wlL2gtUhg+xJXjfk3kUZS3BRoQeoQBQ==

ts-interface-checker@^0.1.9:
  version "0.1.13"
  resolved "https://registry.npmjs.org/ts-interface-checker/-/ts-interface-checker-0.1.13.tgz"
  integrity sha512-Y/arvbn+rrz3JCKl9C4kVNfTfSm2/mEp5FSz5EsZSANGPSlQrpRI5M4PKF+mJnE52jOO90PnPSc3Ur3bTQw0gA==

typescript@*, typescript@>=4.4.4, typescript@>=5.0.0, typescript@~5.8.0, typescript@5.x:
  version "5.8.2"
  resolved "https://registry.npmjs.org/typescript/-/typescript-5.8.2.tgz"
  integrity sha512-aJn6wq13/afZp/jT9QZmwEjDqqvSGp1VT5GVg+f/t6/oVyrgXM6BY1h9BRh/O5p3PlUPAe+WuiEZOmb/49RqoQ==

undici-types@~6.20.0:
  version "6.20.0"
  resolved "https://registry.npmjs.org/undici-types/-/undici-types-6.20.0.tgz"
  integrity sha512-Ny6QZ2Nju20vw1SRHe3d9jVu6gJ+4e3+MMpqu7pqE5HT6WsTSlce++GQmK5UXS8mzV8DSYHrQH+Xrf2jVcuKNg==

unicorn-magic@^0.3.0:
  version "0.3.0"
  resolved "https://registry.npmjs.org/unicorn-magic/-/unicorn-magic-0.3.0.tgz"
  integrity sha512-+QBBXBCvifc56fsbuxZQ6Sic3wqqc3WWaqxs58gvJrcOuN83HGTCwz3oS5phzU9LthRNE9VrJCFCLUgHeeFnfA==

universalify@^2.0.0:
  version "2.0.1"
  resolved "https://registry.npmjs.org/universalify/-/universalify-2.0.1.tgz"
  integrity sha512-gptHNQghINnc/vTGIk0SOFGFNXw7JVrlRUtConJRlvaw6DuX0wO5Jeko9sWrMBhh+PsYAZ7oXAiOnf/UKogyiw==

update-browserslist-db@^1.1.1:
  version "1.1.3"
  resolved "https://registry.npmjs.org/update-browserslist-db/-/update-browserslist-db-1.1.3.tgz"
  integrity sha512-UxhIZQ+QInVdunkDAaiazvvT/+fXL5Osr0JZlJulepYu6Jd7qJtDZjlur0emRlT71EN3ScPoE7gvsuIKKNavKw==
  dependencies:
    escalade "^3.2.0"
    picocolors "^1.1.1"

util-deprecate@^1.0.2:
  version "1.0.2"
  resolved "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz"
  integrity sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==

vite-hot-client@^0.2.4:
  version "0.2.4"
  resolved "https://registry.npmjs.org/vite-hot-client/-/vite-hot-client-0.2.4.tgz"
  integrity sha512-a1nzURqO7DDmnXqabFOliz908FRmIppkBKsJthS8rbe8hBEXwEwe4C3Pp33Z1JoFCYfVL4kTOMLKk0ZZxREIeA==

vite-plugin-inspect@0.8.9:
  version "0.8.9"
  resolved "https://registry.npmjs.org/vite-plugin-inspect/-/vite-plugin-inspect-0.8.9.tgz"
  integrity sha512-22/8qn+LYonzibb1VeFZmISdVao5kC22jmEKm24vfFE8siEn47EpVcCLYMv6iKOYMJfjSvSJfueOwcFCkUnV3A==
  dependencies:
    "@antfu/utils" "^0.7.10"
    "@rollup/pluginutils" "^5.1.3"
    debug "^4.3.7"
    error-stack-parser-es "^0.1.5"
    fs-extra "^11.2.0"
    open "^10.1.0"
    perfect-debounce "^1.0.0"
    picocolors "^1.1.1"
    sirv "^3.0.0"

vite-plugin-vue-devtools@^7.7.2:
  version "7.7.2"
  resolved "https://registry.npmjs.org/vite-plugin-vue-devtools/-/vite-plugin-vue-devtools-7.7.2.tgz"
  integrity sha512-5V0UijQWiSBj32blkyPEqIbzc6HO9c1bwnBhx+ay2dzU0FakH+qMdNUT8nF9BvDE+i6I1U8CqCuJiO20vKEdQw==
  dependencies:
    "@vue/devtools-core" "^7.7.2"
    "@vue/devtools-kit" "^7.7.2"
    "@vue/devtools-shared" "^7.7.2"
    execa "^9.5.1"
    sirv "^3.0.0"
    vite-plugin-inspect "0.8.9"
    vite-plugin-vue-inspector "^5.3.1"

vite-plugin-vue-inspector@^5.3.1:
  version "5.3.1"
  resolved "https://registry.npmjs.org/vite-plugin-vue-inspector/-/vite-plugin-vue-inspector-5.3.1.tgz"
  integrity sha512-cBk172kZKTdvGpJuzCCLg8lJ909wopwsu3Ve9FsL1XsnLBiRT9U3MePcqrgGHgCX2ZgkqZmAGR8taxw+TV6s7A==
  dependencies:
    "@babel/core" "^7.23.0"
    "@babel/plugin-proposal-decorators" "^7.23.0"
    "@babel/plugin-syntax-import-attributes" "^7.22.5"
    "@babel/plugin-syntax-import-meta" "^7.10.4"
    "@babel/plugin-transform-typescript" "^7.22.15"
    "@vue/babel-plugin-jsx" "^1.1.5"
    "@vue/compiler-dom" "^3.3.4"
    kolorist "^1.8.0"
    magic-string "^0.30.4"

"vite@^2.6.0 || ^3.0.0 || ^4.0.0 || ^5.0.0-0 || ^6.0.0-0", "vite@^3.0.0-0 || ^4.0.0-0 || ^5.0.0-0 || ^6.0.0-0", "vite@^3.1.0 || ^4.0.0 || ^5.0.0-0 || ^6.0.1", "vite@^3.1.0 || ^4.0.0-0 || ^5.0.0-0 || ^6.0.0-0", "vite@^5.0.0 || ^6.0.0", vite@^6.2.1:
  version "6.2.4"
  resolved "https://registry.npmjs.org/vite/-/vite-6.2.4.tgz"
  integrity sha512-veHMSew8CcRzhL5o8ONjy8gkfmFJAd5Ac16oxBUjlwgX3Gq2Wqr+qNC3TjPIpy7TPV/KporLga5GT9HqdrCizw==
  dependencies:
    esbuild "^0.25.0"
    postcss "^8.5.3"
    rollup "^4.30.1"
  optionalDependencies:
    fsevents "~2.3.3"

vscode-uri@^3.0.8:
  version "3.1.0"
  resolved "https://registry.npmjs.org/vscode-uri/-/vscode-uri-3.1.0.tgz"
  integrity sha512-/BpdSx+yCQGnCvecbyXdxHDkuk55/G3xwnC0GqY4gmQ3j+A+g8kzzgB4Nk/SINjqn6+waqw3EgbVF2QKExkRxQ==

vue-tsc@^2.2.8:
  version "2.2.8"
  resolved "https://registry.npmjs.org/vue-tsc/-/vue-tsc-2.2.8.tgz"
  integrity sha512-jBYKBNFADTN+L+MdesNX/TB3XuDSyaWynKMDgR+yCSln0GQ9Tfb7JS2lr46s2LiFUT1WsmfWsSvIElyxzOPqcQ==
  dependencies:
    "@volar/typescript" "~2.4.11"
    "@vue/language-core" "2.2.8"

"vue@^2.7.0 || ^3.0.0", "vue@^2.7.0 || ^3.5.11", vue@^3.0.0, vue@^3.2.0, vue@^3.2.25, vue@^3.4.0, vue@^3.5.13, "vue@>= 3", vue@3.5.13:
  version "3.5.13"
  resolved "https://registry.npmjs.org/vue/-/vue-3.5.13.tgz"
  integrity sha512-wmeiSMxkZCSc+PM2w2VRsOYAZC8GdipNFRTsLSfodVqI9mbejKeXEGr8SckuLnrQPGe3oJN5c3K0vpoU9q/wCQ==
  dependencies:
    "@vue/compiler-dom" "3.5.13"
    "@vue/compiler-sfc" "3.5.13"
    "@vue/runtime-dom" "3.5.13"
    "@vue/server-renderer" "3.5.13"
    "@vue/shared" "3.5.13"

which-module@^2.0.0:
  version "2.0.1"
  resolved "https://registry.npmjs.org/which-module/-/which-module-2.0.1.tgz"
  integrity sha512-iBdZ57RDvnOR9AGBhML2vFZf7h8vmBjhoaZqODJBFWHVtKkDmKuHai3cx5PgVMrX5YDNp27AofYbAwctSS+vhQ==

which@^2.0.1:
  version "2.0.2"
  resolved "https://registry.npmjs.org/which/-/which-2.0.2.tgz"
  integrity sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==
  dependencies:
    isexe "^2.0.0"

which@^5.0.0:
  version "5.0.0"
  resolved "https://registry.npmjs.org/which/-/which-5.0.0.tgz"
  integrity sha512-JEdGzHwwkrbWoGOlIHqQ5gtprKGOenpDHpxE9zVR1bWbOtYRyPPHMe9FaP6x61CmNaTThSkb0DAJte5jD+DmzQ==
  dependencies:
    isexe "^3.1.1"

"wrap-ansi-cjs@npm:wrap-ansi@^7.0.0":
  version "7.0.0"
  resolved "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz"
  integrity sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==
  dependencies:
    ansi-styles "^4.0.0"
    string-width "^4.1.0"
    strip-ansi "^6.0.0"

wrap-ansi@^6.2.0:
  version "6.2.0"
  resolved "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-6.2.0.tgz"
  integrity sha512-r6lPcBGxZXlIcymEu7InxDMhdW0KDxpLgoFLcguasxCaJ/SOIZwINatK9KY/tf+ZrlywOKU0UDj3ATXUBfxJXA==
  dependencies:
    ansi-styles "^4.0.0"
    string-width "^4.1.0"
    strip-ansi "^6.0.0"

wrap-ansi@^8.1.0:
  version "8.1.0"
  resolved "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-8.1.0.tgz"
  integrity sha512-si7QWI6zUMq56bESFvagtmzMdGOtoxfR+Sez11Mobfc7tm+VkUckk9bW2UeffTGVUbOksxmSw0AA2gs8g71NCQ==
  dependencies:
    ansi-styles "^6.1.0"
    string-width "^5.0.1"
    strip-ansi "^7.0.1"

y18n@^4.0.0:
  version "4.0.3"
  resolved "https://registry.npmjs.org/y18n/-/y18n-4.0.3.tgz"
  integrity sha512-JKhqTOwSrqNA1NY5lSztJ1GrBiUodLMmIZuLiDaMRJ+itFd+ABVE8XBjOvIWL+rSqNDC74LCSFmlb/U4UZ4hJQ==

yallist@^3.0.2:
  version "3.1.1"
  resolved "https://registry.npmjs.org/yallist/-/yallist-3.1.1.tgz"
  integrity sha512-a4UGQaWPH59mOXUYnAG2ewncQS4i4F43Tv3JoAM+s2VDAmS9NsK8GpDMLrCHPksFT7h3K6TOoUNn2pb7RoXx4g==

yaml@^2.3.4, yaml@^2.4.2:
  version "2.7.1"
  resolved "https://registry.npmjs.org/yaml/-/yaml-2.7.1.tgz"
  integrity sha512-10ULxpnOCQXxJvBgxsn9ptjq6uviG/htZKk9veJGhlqn3w/DxQ631zFF+nlQXLwmImeS5amR2dl2U8sg6U9jsQ==

yargs-parser@^18.1.2:
  version "18.1.3"
  resolved "https://registry.npmjs.org/yargs-parser/-/yargs-parser-18.1.3.tgz"
  integrity sha512-o50j0JeToy/4K6OZcaQmW6lyXXKhq7csREXcDwk2omFPJEwUNOVtJKvmDr9EI1fAJZUyZcRF7kxGBWmRXudrCQ==
  dependencies:
    camelcase "^5.0.0"
    decamelize "^1.2.0"

yargs@15.4.1:
  version "15.4.1"
  resolved "https://registry.npmjs.org/yargs/-/yargs-15.4.1.tgz"
  integrity sha512-aePbxDmcYW++PaqBsJ+HYUFwCdv4LVvdnhBy78E57PIor8/OVvhMrADFFEDh8DHDFRv/O9i3lPhsENjO7QX0+A==
  dependencies:
    cliui "^6.0.0"
    decamelize "^1.2.0"
    find-up "^4.1.0"
    get-caller-file "^2.0.1"
    require-directory "^2.1.1"
    require-main-filename "^2.0.0"
    set-blocking "^2.0.0"
    string-width "^4.2.0"
    which-module "^2.0.0"
    y18n "^4.0.0"
    yargs-parser "^18.1.2"

yoctocolors@^2.0.0:
  version "2.1.1"
  resolved "https://registry.npmjs.org/yoctocolors/-/yoctocolors-2.1.1.tgz"
  integrity sha512-GQHQqAopRhwU8Kt1DDM8NjibDXHC8eoh1erhGAJPEyveY9qqVeXvVikNKrDz69sHowPMorbPUrH/mx8c50eiBQ==

</file>

<file path='requirements.txt'>
# Web Framework
fastapi==0.103.1
uvicorn==0.23.2
pydantic==2.8.1  # <-- UPGRADED from 2.3.0 to match pydantic-settings requirement
python-multipart==0.0.6
email-validator==2.0.0

# Database
sqlalchemy==2.0.20
alembic==1.12.0
psycopg2-binary==2.9.7

# Task Queue
celery==5.3.4
redis==4.6.0

# File Processing
numpy==1.24.4  # Pinning NumPy version that's compatible with pandas 2.1.0
pandas==2.1.0
openpyxl==3.1.2
xlsxwriter==3.1.2

# API Clients
openai==0.28.0
httpx==0.24.1

# Security
python-jose==3.3.0
passlib==1.7.4
bcrypt==4.0.1

# Testing
pytest==7.4.2
pytest-asyncio==0.21.1

# Utilities
python-dotenv==1.0.0
tenacity==8.2.3
loguru==0.7.0
pydantic-settings==2.8.1 # Keep this newer version
</file>

<file path='run_local_V2.sh'>
#!/usr/bin/env bash

# ./run_local_V2.sh [PORT]
# Run this script to setup and initialize the local development environment
# for the NAICS vendor classification system.
# WARNING: THIS VERSION *REMOVES* THE DATABASE VOLUME ON EACH RUN,
#          CLEARING ALL PREVIOUS DATA.
# Optional parameter:
#   PORT - The host port to use (default: 8001)

set -e

echo "Starting vendor classification setup (DATABASE WILL BE RESET)..." # Updated message

# Check if a port was provided as an argument, otherwise use default
WEB_PORT=${1:-8001}
echo "Using host port $WEB_PORT for the web service"

# ----- DOCKER CLEANUP SECTION (MODIFIED TO REMOVE DB VOLUME) -----
echo "Cleaning up Docker resources (Containers, Networks, and DB Volume)..."
# Use docker compose command based on version (v1 or v2+)
if docker compose version >/dev/null 2>&1; then
    COMPOSE_CMD="docker compose"
    NETWORK_NAME="vendor_classification_app-network" # Default network name for v2+
    VOLUME_NAME="vendor_classification_postgres_data" # Default volume name for v2+
elif docker-compose version >/dev/null 2>&1; then
    COMPOSE_CMD="docker-compose"
    PROJECT_NAME=$(basename "$PWD" | sed 's/[^a-zA-Z0-9]//g') # Simple project name from dir
    NETWORK_NAME="${PROJECT_NAME}_app-network" # Common pattern for v1
    VOLUME_NAME="${PROJECT_NAME}_postgres_data" # Common pattern for v1
else
    echo "ERROR: Neither 'docker compose' (v2+) nor 'docker-compose' (v1) found. Please install Docker Compose."
    exit 1
fi
echo "Using compose command: '$COMPOSE_CMD'"
echo "Database volume name expected: '$VOLUME_NAME' (will be REMOVED)"

# Bring down containers and networks, AND remove volumes (-v flag ADDED)
$COMPOSE_CMD down --remove-orphans || echo "Warning: docker compose down failed, continuing cleanup..."

# Force remove network if it persists (compose down should handle this, but just in case)
if docker network inspect $NETWORK_NAME >/dev/null 2>&1; then
    echo "Network '$NETWORK_NAME' still exists, attempting force removal..."
    docker network rm -f $NETWORK_NAME || echo "Warning: Failed to force remove network '$NETWORK_NAME'"
else
    echo "Network '$NETWORK_NAME' does not exist or was removed."
fi

# (No longer removing the database volume)
echo "Database volume '$VOLUME_NAME' was NOT removed. Previous data is preserved except for jobs cleanup."
echo "Docker container/network cleanup attempt finished."
# ----- END DOCKER CLEANUP -----

# Create necessary directories
echo "Creating data directories (input, output, taxonomy, logs, cache)..."
mkdir -p data/input data/output data/taxonomy data/logs data/cache # Ensures all structure exists

# --- ADDED: Clear logs directory ---
echo "Clearing previous contents of data/logs/ ..."
# Remove the directory and its contents, then recreate it to ensure it's empty
# Using rm -rf followed by mkdir -p is robust
rm -rf data/logs && mkdir -p data/logs || { echo "ERROR: Failed to clear and recreate data/logs directory. Check permissions."; exit 1; }
# --- END: Clear logs directory ---

# --- ADDED: Ensure cache file exists (Optional but helpful) ---
CACHE_FILE="data/cache/openrouter_dev_cache.json"
if [ ! -f "$CACHE_FILE" ]; then
    echo "Cache file '$CACHE_FILE' not found. Creating empty file..."
    touch "$CACHE_FILE" || { echo "ERROR: Failed to create cache file '$CACHE_FILE'. Check permissions."; exit 1; }
else
    echo "Cache file '$CACHE_FILE' already exists."
fi
# --- END: Ensure cache file exists ---

# Set permissions for log and cache directories (needs to happen AFTER recreation/creation)
echo "Setting permissions for data directories (logs and cache)..."
chmod -R 777 data/logs || echo "Warning: Could not set permissions on data/logs. Logging might fail if user IDs mismatch."
chmod -R 777 data/cache || echo "Warning: Could not set permissions on data/cache. Caching might fail if user IDs mismatch." # <-- ADDED THIS LINE

# Export the port as an environment variable
export WEB_PORT

# --- ADDED LOGGING ---
echo "Checking for frontend build files locally before Docker build:"
ls -l frontend/vue_frontend/package.json || { echo "ERROR: frontend/vue_frontend/package.json not found locally! Cannot build frontend."; exit 1; }
ls -l frontend/vue_frontend/vite.config.js || ls -l frontend/vue_frontend/vite.config.ts || { echo "WARNING: vite.config file not found locally! Frontend build might fail."; }
# --- END ADDED LOGGING ---

echo "Building Docker images (this will include the Vue frontend build)..."
# Use the detected compose command
$COMPOSE_CMD build --no-cache web # Rebuild web to ensure latest code
$COMPOSE_CMD build worker db redis

# Check if build was successful
if [ $? -ne 0 ]; then
    echo "Docker build failed. Please check the error messages above."
    exit 1
fi
echo "Docker build completed successfully."

echo "Starting containers in the background..."
# Use the detected compose command
$COMPOSE_CMD up -d

# Check if containers started successfully
if [ $? -ne 0 ]; then
    echo "There was an error starting the containers. Please check the Docker logs."
    exit 1
fi

WAIT_SECONDS=15 # Keep wait time as DB init might take a moment
echo "Waiting $WAIT_SECONDS seconds for containers to start and DB to initialize..."
sleep $WAIT_SECONDS

echo "===> Checking container statuses:"
$COMPOSE_CMD ps

# Check if web container is running
WEB_CONTAINER_ID=$($COMPOSE_CMD ps -q web)
if [ -z "$WEB_CONTAINER_ID" ]; then
    echo "Web container failed to start! Check logs with: $COMPOSE_CMD logs web"
    exit 1
else
    echo "Web container ($WEB_CONTAINER_ID) appears to be running."
fi

echo "===> Checking web container logs (last 30 lines):"
$COMPOSE_CMD logs web --tail 30

echo "===> Testing web service connectivity (Health Check):"
retry_count=0
max_retries=5
until curl -f -s -o /dev/null "http://localhost:$WEB_PORT/health"; do
    retry_count=$((retry_count+1))
    if [ $retry_count -ge $max_retries ]; then
        echo "Warning: Could not connect to web service health endpoint (http://localhost:$WEB_PORT/health) after $max_retries attempts! Check logs."
        break
    fi
    echo "Health check failed, retrying in 5 seconds... ($retry_count/$max_retries)"
    sleep 5
done
if [ $retry_count -lt $max_retries ]; then
    echo "Health check successful!"
fi

# Clean up jobs table, keeping only completed jobs
DB_CONTAINER_ID=$($COMPOSE_CMD ps -q db)
if [ -n "$DB_CONTAINER_ID" ]; then
    echo "Cleaning up jobs table: keeping only jobs with status 'completed'..."
    docker exec -i $DB_CONTAINER_ID psql -U postgres -d vendor_classification -c "DELETE FROM jobs WHERE status != 'completed';"
else
    echo "Could not find DB container to clean up jobs table."
fi

echo ""
echo "===> Setup completed (Jobs table cleaned, Logs Cleared)." # Updated message
echo "Access the web interface (built Vue app) at: http://localhost:$WEB_PORT"
echo "Login with username: admin, password: password"
echo "PostgreSQL is available on host port 5433"
echo "Database data in volume '$VOLUME_NAME' was PRESERVED except for jobs table cleanup." # Updated message
echo "Log directory 'data/logs' was cleared before this run."
echo "Cache file '$CACHE_FILE' ensured to exist." # Added message
echo ""
echo "*** Frontend Development Note ***"
echo "The frontend served by this container is the *built* version."
echo "For frontend development, run the Vue dev server separately:"
echo "  cd frontend/vue_frontend"
echo "  npm install  # If needed"
echo "  npm run dev"
echo "Then access the dev server (usually http://localhost:5173 or similar)."
echo "The dev server should proxy API requests to http://localhost:$WEB_PORT (configure in frontend/vue_frontend/vite.config.js/ts if needed)."
echo "*******************************"
echo ""
echo "Press Enter to show continuous logs, or Ctrl+C to exit."
read -r
$COMPOSE_CMD logs -f

</file>

</Project Source Code>

--- Identified Files (Provide comma-separated list below) ---


